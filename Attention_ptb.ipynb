{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118da7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 24 16:35:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    46W / 250W |  27018MiB / 40536MiB |     39%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    35W / 250W |      7MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2907      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    619011      C   ...envs/torch-gpu/bin/python     2239MiB |\n",
      "|    0   N/A  N/A    623824      C   ...envs/torch-gpu/bin/python     2283MiB |\n",
      "|    0   N/A  N/A    628406      C   ...envs/torch-gpu/bin/python     2259MiB |\n",
      "|    0   N/A  N/A    635288      C   ...envs/torch-gpu/bin/python     2205MiB |\n",
      "|    0   N/A  N/A    651585      C   ...envs/torch-gpu/bin/python     2381MiB |\n",
      "|    0   N/A  N/A    666587      C   ...envs/torch-gpu/bin/python     2215MiB |\n",
      "|    0   N/A  N/A    800549      C   ...envs/torch-gpu/bin/python     2277MiB |\n",
      "|    0   N/A  N/A    805393      C   ...envs/torch-gpu/bin/python     4851MiB |\n",
      "|    0   N/A  N/A    905584      C   ...envs/torch-gpu/bin/python     2227MiB |\n",
      "|    0   N/A  N/A   1321970      C   ...envs/torch-gpu/bin/python     2211MiB |\n",
      "|    0   N/A  N/A   1323456      C   ...envs/torch-gpu/bin/python     1861MiB |\n",
      "|    1   N/A  N/A      2907      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Requirement already satisfied: pandas in /home/test/conda/envs/torch-gpu/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/test/conda/envs/torch-gpu/lib/python3.7/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/test/conda/envs/torch-gpu/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/test/conda/envs/torch-gpu/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/test/conda/envs/torch-gpu/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e47648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application of attention model with PTB dataset lead II\n",
    "#modified by FSB\n",
    "# * ***** 20211209 *FSB* USING convolution in front of LSTM to extract features and feed it to lstm gives an initial accuracy of 99.50%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "#import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "#from tensorflow import keras\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "from torchinfo import summary\n",
    "\n",
    "from datetime import datetime\n",
    "#from tensorflow.keras import regularizers\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import itertools\n",
    "#from tensorflow_addons.optimizers import CyclicalLearningRate\n",
    "#from tensorflow.keras.layers import LSTM,Bidirectional,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e645af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "TEST\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6IklEQVR4nO2deZwkVZXvvyeX2rt637uru2kasEHWZlU2dRAQBZeH4DYuDKAy4zx1BtQReTKbOj513BBHBDdwAQUcZHHFeYDQ3azdDfQCdFev1WutXVVZed4f92ZVVFZmVlZ1ZUVU5vl+PvmpzIgbEScjsuIX555zzxVVxTAMw6hcYmEbYBiGYYSLCYFhGEaFY0JgGIZR4ZgQGIZhVDgmBIZhGBWOCYFhGEaFY0IwQRGRdhE5LGw7ikVEPi0i/xW2HVFFRP4oIleEbUfUEZGXReQNY7zPNSJyzljuM89xInuNTQiKxP8Au/wNeKeIfF9EGvyPqN2/+kTkYODzp0Xk/X55ZtkmEflwgeOcIyLpQPtmEfmZiJwcbKeqDaq6qfTffOT479AcXKaq/6qqI/4n8P88wXPaLiL3BtY3ishXRWSzX7fBf54RaHOZiPxFRDpEZJd//xERkWGO2SYirSKySkSuE5HqEditInL4SL+vMf6o6tGq+sew7QgTE4KR8WZVbQBOBE4G/sn/iBr88j8D12Q+q+q/+u0eDbR5B/BFETmhwHG2+baTgNOA54E/i8jrS/bNok3wnDao6psBRKQK+B1wNHA+0AicAewBTvFtPgF8DfgSMAeYDVwNvAaoGuaYk4C5wCeAy4D78omHYUxkTAhGgapuBX4DHDOKbVcD64BXFdFWVbVZVa8H/gv4QmZd8IlTRN4kIk/6p9ctInJDcD8i8j4ReUVE9ojIZ4PutYjc4D2OH/gn4DUisiKw7av8E/J+v+4tgXUXishav91WEfmkiNT7czMv8AQ/zx/nR4FtXysij/j9bhGR94/0XALvA5qAt6rqWlVNq+ouVb1RVe8TkcnA54GPqOovVLXNn9MnVfXdqtpdxDXo8E+LbwFOB97k7T9FRB719m8XkW94YUJEHvabP+2//ztFZKqI/FpEWkRkn3+/IOtwS0XkcRE5ICJ3i8i0wPn6uYjs8OseFpGjA+uGXIfAuotE5Clv5yMicmy+7yoiR4nIQyKyV0ReEJFL/fKlftmJ/vM8EdktvjtFRD4gIuv88TeJyFWBfZ4jzqv9R++NbReRS7zNL/r9fjrQ/gYR+YWI/NTvb7WIHJfH3pj31Db63/bPgucsq+0Mf873+2P+WURifl3w/6FWRG7z12idt7s5sJ+X/e/8GX8tfioiNX5dMdc4kpgQjAIRWQhcCDw5im1PBo4AVo5w07uAE/2NNpsO3E1xCu5G9WERucQfbznwLeDduKfbycD8rO3fAtzht78H+IbfNgncCzwIzAL+FvixiBzpt/secJV/cj4G+L2qdgAX4L0a/9qWdQ6acGLxdWAmcDzw1AjPB8AbgPtVtT3P+tOBauDuUex7EKq6GXfNzvSL+oD/Dczwx3k98BHf9izf5jj//X+K+1/7PrAIJ15d+PMc4H3AB4F5QAr4z8C63wDLcNdhNfDjwLoh1wHA37hvAa4CpgPfAe6RHF1c/nf1EPATf4zLgW+JyNGquhG4Fnft6/z3uDXQnbILuAjnkX0A+EpGNDxzgBrc7+564LvAe4CT/Pm8XgbHuy4Gfg5M8/b8yv8Ws/k74BLgbH/O9gHfzNEOnFfXjPu9zQY+DeSqr/M5YDFwGPBX3s5sLsV5oEuAY4H3++XFXONooqr2KuIFvAy0A/uBV3A319qsNn8Ersha9n7cP/V+v73iboCS5zjnAM05lh/lt53vPytweJ59fBX4in9/PXB7YF0d0AO8wX++AfhtYP1yoMu/PxPYAcQC628HbvDvN+NuMo3DfQd/nB/5958Cflnkef8j0OnPX+Z1o1/3EPDvBbZ9D7Aja9kjfh9dwFkFjnlFjuV3AN/Ns83fB79Toevj1x8P7Ms65r8HPi/31ymeY9spfv+Th7kO386cq8CyF4Czc+zzncCfs5Z9B/hc4PM9wLPAM0B1ge/2K+Bjgd9CV+Z74Lo7FTg10H4VcEngd/JYYF0M2A6cGfg/zPx21wGvD7SdC/QCiRw2fR73QDDkmmTtcxPwxsC6Kwj8ln3b9wQ+fxG4aQTXeMjvKgov8whGxiWqOkVVF6nqR1S1q8jtHvPbNeCejo4G/nWYbbKZj/sH2p+9QkROFZE/eJf0AK4PPBMsnQdsybRV1U5cH3qQHYH3nUCNiCQy26pqOrD+FQY8irfjPKNXRORPInJ6kd9lIbCxyLYAf+fPX+b1Wb98D+6fPx97gBn+uwCgqmeo6hS/bqS///nAXgAROcK7/jtEpBV3PWfk21BE6kTkO+K66FqBh4EpIhIPNNsSeP8KkPT2x0Xk330XSCvuZkTgePmuwyLgE747ZL+I7Med+3k5TFwEnJrV9t2432uG7+I8jq9roFtNRC4Qkcd8l8t+b0vwXOxR1T7/PvM/szOwvgtoyHUe/G+vuYDNvwzYuw7nqc3O0fZLwAbgQd99dV2ONpD1/5L1PkP2/0sDFH2NI4kJwTijqjuBO4E3j3DTtwKr1XW9ZPMT3NPaQlWdDNwEZIKa24H+fkoRqcV1ExTDNmBhpi/V0wRsBVDVJ1T1YlxXwq+An/k2w5W03QIsLdKGQvwWeGOe7jKAR4FuXFfDIeG7A0/CJQSAe9p+Hlimqo24roZCgeRPAEfinoQbgUz3UXCbhYH3Tbin293Au/x3eAOua29xcNsC12EL8C9ZIlqnqrfnsG8L8Kestg2q+mH//Rtwnub3gBsyffG+m+lO4D+A2V5k7xvmXAxH/3nwv70FuN9iLpsvyLK5Rl0MbxDq4kOfUNXDcP97H5fcyReD/l8YfE2Go5hrHElMCMYZEZmOu6mvKaKtiMh8EfkczkX9dJ6mk4C9qnpQRE7B3Tgy/AJ4s4icIS6Y+X8o/of5F1z84R9FJCkuOPhm4A4RqRKRd4vIZFXtBVpxT2PgnvamiwvW5uLHwBtE5FIRSYjIdBE5vkibgvwQdzO4U1ygM+b39WkRuVBV9/vv+y0ReYe4dN+YP1Y+8RiEf8o7G9et8DjuJgfunLcC7SJyFJCdErwT189MoH0XsN/fRD+X43DvEZHlvh/+88Av/JP0JJyg7cF17fV7k8Nch+8CV3uPUUSkXlxiwaQcx/41cISIvNdf66SInCwimaSGrwGr1KUA/zfuYQNc5lU10AKkROQC4Lxc53IEnCQib/Oe3N/77/5YjnY3Af8iIov8uZgpIjlFX1zQ/HAREQbOUV+Opj8DPiUu8DsfuGYEdhdzjSOJCcH4cLr4DBqc+9qCC7zmY55v2w48AbwaOEdVH8zT/iPA50WkDRcTyDwRoqpr/LHuwD3ttOGCe8VkzPTgAskX4J5MvwW8T1Wf903eC7zs3eCr8YE1v/52YJN32+dl7XczrvvgE7iulqeAnJkhnm/I4HEEq/x+unFPyc/j4gWtuJv1DJyIoapfBD4O/KP/3jtxfd/X4uIFhY7Z5tt/FffUe36gm+yTOMFtw91wf5q1/Q3Abf77X+r3UYs7j48B9+c45g+BW3FdDzW4YCjAD3BdRVuBtQy9Kea7DiuBv8EFLPfhukben+vLqmob7gZ+Ge7pewcuS63a31zP9/sGdz5PFJF3++3+Dveb2+fPyT25jjEC7sbFLPb57/Y2L3LZfM0f60F/rR4DTs2zz2U4D7Id5yl+S3OPHfg8rivqJd/+FxTxv+L5KsNf40giPohhVAjexd+P69J4KWRzDGMQ4lKfD1fVXNk64464wZ+XqerZYdtSSswjqABE5M2+i6Me15f7LAMBR8MwPCIyV0Re47sQj8R5rb8M265SY0JQGVyMc/e34Vzky9RcQcPIRRWu67ANNx7jblyXaFljXUOGYRgVjnkEhmEYFU5i+CbRYsaMGbp48eKwzTAMw5hQrFq1areqzsy1bsIJweLFi1m5cqRlegzDMCobEXkl3zrrGjIMw6hwTAgMwzAqHBMCwzCMCseEwDAMo8IxITAMw6hwSiYEInKLuKnpnsuzXkTkP8VNNv6MDJ7RyDAMwxgnSukR3IqrWJiPC3DlDpYBV+LquxuGYRjjTMmEQFUfxs/mlIeLgR+o4zHcTD6FZpuakDzbfIBVrxQ6DYZhGOESZoxgPoOngWtm6KTqAIjIlSKyUkRWtrS0jItxY8WNv17LdXc+G7YZhmEYeQlTCHLNkpWzAp6q3qyqK1R1xcyZOUdIR5aX93Tw0u4OevvSwzc2DMMIgTCFoJnB84Hmm5d0wtLV08eutm5SaeWVPZ1hm2MYhpGTMIXgHuB9PnvoNOCAqm4P0Z4xZ8u+gZv/hl1tIVpiGIaRn5IVnROR24FzgBki0oybyDkJoKo34SYBvxA3j2on8IFS2RIWm/cEhaA9REsMwzDyUzIhUNXLh1mvwEdLdfwo8MpeJwSTahKsNyEwDCOi2MjiErJlbycN1QlObJrK+p0mBIZhRBMTghLyyp4OmqbVsWxWAxtb2ulL27SghmFEDxOCErJ5b6cTgtkNdKfSbN3XFbZJhmEYQzAhKBHptLJlXxeLptdx+KwGADa0WOaQYRjRw4SgROxsO0hPKk3T9DoWTa8HYMte8wgMw4geJgQlIjOArGlaHdUJd5ptdLFhGFGkYoQg1Zdmy95OUnluxqrKA2t20N6dGpPjbd47IATxmKumYcFiwzCiSMUIwb3PbOPML/6BlwODvHa2HuTbf9xIX1p5ast+rvrhKu59emyqXDTv6yImMHdybb8QpEwIDMOIICUbUBY1mqbVAS63PxO8/fnKLfzHgy9yxOwGHtu0B4C9HT1jcryt+7qY01hDVSLW7wmYR2AYRhSpGCFY6IUg02UDsGZbKwA//stmXtjhMnpaD/aOyfGa93WyYKo7pncITAgMw4gkFdM1NLOhmppkbIgQiMDvn9/F1v0uo6e1a2xiBM37ulgwtRYAESERExMCwzAiScUIgYjQNK2uXwhaD/ayeW8nl53sKmEnYsKMhuox8QhSfWl2tB5kvhcCgHhMLEZgGEYkqZiuIXBxgi1eCNb6bqHzjp5D28EUiZjw0p5OWrsOXQi2HzhIX1r7PQLAewSWPmoYRvSoKCFYOK2ORzbuQVX74wNHz2vk3CNPBOC93/sLrQcPvWuo2ZeSyMQIAGLmERiGEVEqpmsInEfQ2dPHno4e1mw7wMxJ1cyaVNO/vrE2SdsYeASZeMNQj8CEwDCM6FFxQgAuc2jttlaOntc4aH1jTXJMYgTN+zoRP4YgQzwWMyEwDCOSVJQQLJruhODZ5gOs39U+VAhqE7R2pXBz5oye5sAYggzmERiGEVUqSggyffZf/e2L9KWVNx83b9D6xpokPX1pulOHFtRt3tfJ/Cm1g5ZZ1pBhGFGlooSgJhlndmM1+zp7edOr53LUnGyPIAlwyJlDwTEEGRJx8wgMw4gmFSUE4OIEIvCxNywbsq6xxiVRHUqcIJ1Wth8YPIYAIC7mERiGEU0qKn0U4N2nLuLco2ZxxOxJQ9ZlPIIDhzC6uO1gir60Mq2+etDyuI0jMAwjolScEFxywvy86xprfNfQIXgE+7tc0brJXlQyxGNCqs88AsMwokfFdQ0VYnKt7xo6hBjBAb9tthAk4kL6ELORDMMwSoEJQYABj2D0XUP5hCAei1mMwDCMSGJCEGAssobyegQ2jsAwjIhiQhCgOhGjKh47pBhBfo/AYgSGYUQTE4IAItI/uni05BUCMY/AMIxoYkKQxaHWGzrQ1UtVPEZNcvCpTcSFlKWPGoYRQUwIsphUmzykGEFrVy+NtUlEZNDyuMUIDMOIKCYEWTTWJA45ayiThhokERP6LH3UMIwIYkKQxeRDnJPACUFyyHILFhuGEVVKKgQicr6IvCAiG0TkuhzrJ4vIvSLytIisEZEPlNKeYmisPfQYwZS6qiHLEzYfgWEYEaVkQiAiceCbwAXAcuByEVme1eyjwFpVPQ44B/iyiAy9i44jjTXJQ5qToJBHYEJgGEYUKaVHcAqwQVU3qWoPcAdwcVYbBSaJi6w2AHuBQ580+BCYXOvmJOjo6RvV9gc6C3QNmRAYhhFBSikE84Etgc/NflmQbwCvArYBzwIfU9UhOZYicqWIrBSRlS0tLaWyF4AlM9zkNS+1dIx423RaaetO9Y9QDmIegWEYUaWUQiA5lmXfCd8IPAXMA44HviEijVltUNWbVXWFqq6YOXPmWNs5iMNnNQCwoaVtxNu2HUyhOnQwGbisIRtH4Lj/uR185aEXwzbDMAxPKYWgGVgY+LwA9+Qf5APAXerYALwEHFVCm4Zl0fR6EjFh/c72EW+bb1QxZDyCQzavLPjRY6/w7T9tNA/JMCJCKYXgCWCZiCzxAeDLgHuy2mwGXg8gIrOBI4FNJbRpWJLxGItn1LNh19gKQcImpgFAVVm3vZWeVJpX9oy8+80wjLGnZEKgqingGuABYB3wM1VdIyJXi8jVvtmNwBki8izwO+BaVd1dKpuKZdmshjEXAitD7Whp62ZPh5u858VReF2GYYw9JZ2hTFXvA+7LWnZT4P024LxS2jAaDp/VwANrdtCd6qM6ES96u4IegU1eD8Da7a3979fvbOP8Y+aEaI1hGGAji3Ny+KwG0gov7+4c0Xb5pqkEiNnk9cCAEEyrr+LFUXhdhmGMPUV5BCJyBrA42F5Vf1Aim0Inkzm0flcbR84ZOsl9PoaPEZgQrNvexvwptRw5ZxLrd448M8swjLFnWCEQkR8CS3FpnplRVgqUrRAsndmACCOOE+QrQQ0D4whUdUhl0nJjX0cP1ckYdVVDf17rtrfyqrmNLJ1Vz/+s302qL00ibo6pYYRJMR7BCmC5jrbmwgSkJhln4dQ61o9QCPKVoAbnEQCkFeLlrQNc+p1HOXxWA99+z0kApPrSfPmhF5lcm2RTSzsXHjOHRdPr6elL8/Kezn4PzDCMcChGCJ4D5gDbS2xLpFg8o54te0cWI8hXghog7u/+qXSaeKz4APREY8veTtbvauel3R3sae9mal0V//iLZ7jrya39bV41t5EFU90I7vU720wIDCNkihGCGcBaEXkc6M4sVNW3lMyqCNA0rZZnmvePaJt9Hb1MzVF5FAY8gnKPEzy6cQ8AqbRyz9Pb2NF6kLue3MrH/+oITjtsOg+u2cHZR85E/MDz0aTpGoYxthQjBDeU2ogo0jStjv2dvXmrieZiX2dP/5NuNvGY6wcv98yhRzbuZkZDFbMba/jmHzayu72bd53axN++7nBEhFOWTOtvW5WI0d4Tao1BwzAoIn1UVf8EPA9M8q91fllZ0zTN3dBH0j10oKuXqXW5RSMTF+gr08lpVF0g/P9t3MPpS2fw9hMXsLu9m6PmTOL6i5bnjJvERUiXuTAaxkSgmKyhS4EvAX/EFZL7uoj8g6r+osS2hcpCLwSb93ZyzPzJRW2zr7OHqfW5u4bi8fL1CHa1HeT8r/6ZFYum0tLWzWuWTueCV89l/a52rjzrMGqSuWMiVn/JMKJBMV1DnwFOVtVdACIyE/gtUDFCUAwHe/s42JvO241UzjGCv2zay96OHh5cuxOAM5bOYHJtkn9726sLbhcTSFdOMpphRJZihCCWEQHPHipgRHJjTZKpdcmihWBfpxtVnC9YHM8IQRne+FZv3kdNMsZN7zmJDbvaaZqeO06Sjc3RYBjRoBghuF9EHgBu95/fSVb9oHKlaVpd0TGCfR1uVHG+GEG/R1CGMYLVm/dz7IIpnHPkLM45clbR28VEzCMwjAhQTLD4H4CbgWOB44CbVfXaUhsWBRZOqyvaI9jvPYJcE9fDgEdQbpPTHOztY+22A5zYNHXE28ZiJgSGEQWKqjWkqncCd5bYlsjRNK2O+5/bUVQZhH2d3iOoz+cRuO3LrSvkua0H6O1TTmyaMuJt42JdQ4YRBfLe3UTkf/zfNhFpDbzaRKQ133blRNO0OlJpZfuBg8O2zVQezR8jcH/LLWto9eZ9AJy4aOQegWUNGUY0yOsRqOpr/d/iy2+WGU2BzKFMFlE+9nfmrzwKAwPKyu0JeNUr+2iaVseMhuoRbxuLWdaQYUSBYWMEvvrosMvKkUUz6gF4affwUyru6+ihNhnPmzOf6I8RlM+Nb2frQf7wfAtnHzFzVNtb15BhRINi0kCPDn4QkQRwUmnMiRbzJtdQVxUvqh7Ovs78o4ohkD5aRje+7z68iT5V/ubMw0a1fSwmZZlOaxgTjbxdQyLyKeDTQG0gJiBADy6LqOwREZbObGBjy/BCsL+zJ2/GEEzsAWV72rv52cpmrjrrMHr60rzz5sdYOLWW3z+/i7ccN6/ocQPZWIkJw4gGhWIE/wb8m4j8m6p+ahxtihSHz2rgsU178q7f1XaQxpqkLy8xvEcwEdNHb3v0Ff7zd+s5fel04iI8vWU/a7YeQIGPnLN01PuNWdeQYUSCYdNHVfVTIjIVWAbUBJY/XErDosLhsxr45ZNbae9O0VA9+HQ907yfd37nMd5zWhP7O3uZO6U2734S8YnrETzkS0e8uLOt37O56yNnMKkmyRIfRxkNbhzBmJhoGMYhUEzRuSuAjwELcNNVngY8CryupJZFhKUz3aQpm1raOXbBlP7lW/Z28sFbV9LV28fvn9/F/gKVR8E9/cLECxZv2dvJOj/h/PqdbSTiMRIx4VVzG0ke4hSTccsaMoxIUMx/8seAk4FXVPVc4ASgpaRWRYjM7FkbdrWz/UAXnb5+/o2/Xkt3qo/LT1nIxpYO9nb0MKW2UIzAp49OsBITGW9gRkMVL+xsZ/3OdpbMqD9kEQDLGjKMqFDMf/NBVT0IICLVqvo8cGRpzYoOi6bXkYgJT7y8lzd+5WHe//0n2Lq/i9+u28l7T1vEe09b3N92ShFZQxPNI3ho7U6WzWrgrGUzeXFHG+t3tXHE7LEZWmIlJgwjGhQjBM0iMgX4FfCQiNwNbCulUVEiGY+xeEY9tz++hdaDKR5/aS8f/fFqAN51ahNHzZnEdD8HQb5RxTAQIyh041NVfv/8TlIRGW7b0Z3i8Zf38oblszliziR2tB5k896xm2zePALDiAbFFJ17q6ruV9UbgM8C3wMuKbFdkWLpTBcQfdepTRwxu4GntuzndUfNZsHUOmIx4YzDZwD56wxBcR7Buu1tfPDWldzxxJYxtH70PNN8gL60csriaRzpvQBVWDZ7bIQgZmWoDSMSFDOy+Gsicga4aStV9R5V7Sm9adHhpEVTmV5fxSfPO5LrLzqaREz44GsX968/0wvB9Pr8ZRYGxhHkf9rv8PGHu1Y3j4HVxbN+Zxv3Pr0NzfJWntzi6ggdv3DKoJv/WHUNxa0MtWFEgmKqj64G/klEjgB+CfxUVVeW1qxo8TdnHsb7Tl9MTTLOa5fN4OnPnUd9IJX0khPmU52MceyC/FNa9nsEBYLFPSknEqs37+el3R2HlJqZQVW57ZGXmTellvOOnjNkfevB3v64xzPN+xER7nlqG7dfeRpPbd7Pkhn1TK2vYkpdkvqqOAdTaRZPP3S7wNUa6kuZEBhG2BQzjuA24DYRmQa8HfiCiDSp6rKSWxcRRGRQDaH6rPEEVYkYFx8/v+A+iikx0ROIDdy1uplPnDfymPyTm/dx1+qtvLizjVOXTKOlvZvbH99CXVWc33/iHFa+spdHN+7hny85BhHhxnvXsv1AF288ejbf/fNLgJtC8vbHN/Pklv281ns7IsIRcybR2tVLVWJsJqhzE9OMya4MwzgEipqPwHM4cBSwGFhbEmvKmGJiBL3eI5g1qZq7n9o2KiH47N3PsWFXO0tnNvD1P2xAFS4/ZSF3rt7KVT9axZqtB0illUtXLCSVTvPzVc189NylfPK8I/nFqmYOm1nPzQ9v4id/2Ux7d4oTAvMMXH/R8n6vZSyIW9aQYUSCYgaUfQF4G7AR+Blwo6ruL2bnInI+8DUgDvyXqv57jjbnAF8FksBuVT27ONMnFplxBIVufBmP4OQl0/jvZ7bTneqjOpG7mmkuulN9vLCjjSvOPIxrzz+KLXs72bS7g7OPmMmsSTV87XfrOWJ2Ay/t7uDep7exp6OHSdUJPnru4YgI/2vFQgAuXdHLA2vc+IETFg7MM3DCKGYhK4RlDRlGNCjGI3gJOF1Vd49kxyISB74J/BXQDDwhIveo6tpAmynAt4DzVXWziBQ/4e0Eo5gYQa8XgoVTXRG3Xa3dw86DEGT9znZ6+5Rj5rlYxcJpdf3bf/icpdRVxbn4+Pn806+e5e6nt3Ggq5fLTl5IXdXgn8HZR8xk5qRqWrt6OWpu6aajsKwhw4gGhaqPHuUHjz0ONIlIU3C9qq4eZt+nABtUdZPf3x3AxQzuVnoXcJeqbvb73DXyrzAxKKb6aK8PnC6c5moW7Wo7OCIheG7rAQCOmd84ZF1NMs5VZ7sCcRcdO4/frnOn+rKTm4a0TcRjXHv+UWze2zkmI4jzYVlDhhENCnkEHweuBL6cY50yfK2h+UAwIb4ZODWrzRFAUkT+CEwCvqaqP8jekYhc6W2hqWnojWsiUEyMoNt7BJmZ0XYc6B7RMZ7bdoBJNYn+7fPxhuWzqU7EeNXcRpbPGyoaAO84acGIjj0a4uYRGEYkKFSG+kr/9oJMiYkMIlKTY5NsJNducxz/JOD1QC3wqIg8pqovZtlyM34OhBUrVkzIO0cx4wgyweJM19CO1uHnSg7y3NZWjpk3GZFcp36AhuoEN733JOZNzl8tdTyw6qOGEQ2K8fsfKXJZNs3AwsDnBQwtTdEM3K+qHT4G8TBwXBH7nnAUlTXkPYKZk6qpSsTYNQIhSPWlWbe9NWe3UC7OPXIWR84JdzrquEzMstyGUW4UihHMwXXv1IrICQw84TcCxXRcPwEsE5ElwFbgMlxMIMjdwDf89JdVuK6jr4zoG0wQRITYMDe+TGpmVSLG7MbqEXkEG1s66E6lOWZ+/kFtUcMmpjGMaFAoRvBG4P24J/kvMyAErbgpLAuiqikRuQZ4AJc+eouqrhGRq/36m1R1nYjcDzwDpHEpps+N9stEnUQsVjhY3JdGxHUjzWmsYceB4oSgL63c+ogbDHb0vAkkBDEZUtbCMIzxp1CMIDOi+O2qeudodq6q9wH3ZS27Kevzl4AvjWb/E43hgqPdfWmS8RgiwqzGGtZua83bNoOq8uEfreLBtTv50GuXjFll0PEgLjZ5vWFEgWJiBCf5fH8ARGSqiPxz6UwqXxIxGWZksVLl0zUzHsFwT8x7O3p4cO1OrjzrMD570fIxtbfUuHEEYVthGEYxQnBBcCSxqu4DLiyZRWVMPF7YI+jtS/fX8ZnTWENXbx9t3amC+2xpdymmxwWm0Zwo2FSVhhENihGCuIj011cWkVogf71lIy/OI8j/CNyTSpP0E9jManSneOcwcYKWtu5B7ScSVmLCMKJBMULwI+B3IvIhEfkg8BBwW2nNKk+Gy5Lp9TECcB4BDD+WYFerE4KZDRNPCGIxIW1CYBihU0wZ6i+KyLO4QV+CKzr3QMktK0MSMSk8H0Gga2i2F4KdrYVHF2e6hmZOmnhCYMFiw4gGRZWhVtXfAL8psS1lTzxe+MbXk0oPBIsnZ4Rg+K6huqr4kDkSJgJWdM4wokExU1WeJiJPiEi7iPSISJ+IDJ/XaAyhmHEEGY+gJhmnsSYx7OjilrbuCekNgOsqM4fAMMKnmBjBN4DLgfW4ekBXAF8vpVHlSnyY9NGeQIwAYFJNcvisobbuCRkfAJc1ZF1DhhE+RdUYVtUNQFxV+1T1+8C5pTWrPEnEhL5C8xGktD9rCKCuKk5XT1/Bfba0T1yPwLKGDCMaFNOx3CkiVcBTIvJFYDswNrOXVxjFeASNVcn+z3XVCTqGE4K2bs5YOn3MbBxPYr4QXzqt/e8Nwxh/ivEI3uvbXQN04CqKvr2URpUrrsRE4XEEVUGPIBmnqyd/11B3qo8DXb0Tt2vIl8u27iHDCJdi0kdf8W8PAv+ntOaUN8N5BL1ZMYL66jjb9vfmbb+7vQeYmKmjMOAR9KWVZPFTMxuGMcaUbh5CYwiJWOGpGYNZQwC1VQm6evN3DWVGFU9UIcjM0WBlJgwjXEwIxpH4cAPKUlkeQVWcjgJZQxNeCGT4eZwNwyg9JgTjyHDjCHr6dJAQ1A6TNTTRhSAzo2aBsIlhGONAoRnK7mXoHMP9qOpbSmJRGVNMjKA6EfQIEnT0pFDVnPMQZ4Rgev3EFALrGjKMaFAoWPwf/u/bgDm44nPgBpe9XEKbypbEMCUVgtVHAeqq46QVulNpanJEU3e1HWRafdWguMJEIiMEljVkGOFSaIayPwGIyI2qelZg1b0i8nDJLStDYkV4BMGbep2/+Xf29OUUgt3t3cxoqBp7Q8eJmAyMIzAMIzyKeZScKSKHZT74yehnls6k8iVRYBxBOq2k0oNjBHW+kFxnnrEE+zt7mVI7cYXAPALDiAbFjCz+38AfRWST/7wYuKpkFpUxheYs7vFzNg4SgqoBjyAXB7p6WTitboytHD8sa8gwokExA8ruF5FlwFF+0fOqWrhIvpGTQjGCXi8E2cFiIG8K6YGuXo6pTeZcNxEYKDERsiGGUeEUU4a6DvgH4BpVfRpoEpGLSm5ZGRKPxfLGCHpSQz2CWu8R5EshPdDVy+QJLASZr2pdQ4YRLsXECL4P9ACn+8/NwD+XzKIyprBH4JYPHlDmPYIcQtDbl6azp29CC0HMuoYMIxIUIwRLVfWLQC+Aqnbhpqw0Rkg8nj9rKNM1NLjERCZGMLRr6ECXq0FUDkKg5hEYRqgUIwQ9IlKLH1wmIksBixGMgkL197v7u4YGNLa+On+wuByEwLKGDCMaFJM1dANwP7BQRH4MvAZ4fwltKltcraHckdF+jyCYNZTMpI+WpxBY15BhRINisoYeFJFVwGm4LqGPqerukltWhrjqo7nXZYLFObuGcmQN9QtB3cQVgrhlDRlGJCgma+h3wKmq+t+q+mtV3S0iN4+DbWWHixEU9giCweKqRIxkXOjMUYr6QOfE9wgsa8gwokExMYIlwLUi8rnAshUlsqesKZQ11JMjWAxQV5Uo7BFMYCGwriHDiAbFCMF+4PXAbBG5V0Qml9ak8mWk4wjAjS4u1xiBVR81jGhQjBCIqqZU9SPAncD/ALNKa1Z5kogJqrmLrGXGEVSNQAjqquJDhGMiYSUmDCMaFHMXuSnzRlVvxWUMPVjMzkXkfBF5QUQ2iMh1BdqdLCJ9IvKOYvY7Uck8AefyCnKNIwDfNZRnHMFE9gaA/jkWzCMwjHDJKwQi0ujf/lxEpmVewEvAJ4fbsYjEgW8CFwDLgctFZHmedl8AHhiF/ROKeCz/E3BPjnEE4DyCXCOLy0EILGvIMKJBofTRnwAXAatwg8mCdygFDsu1UYBTgA2quglARO4ALgbWZrX7W1yX08nFmz0xSRQYQJWr+ig4Idjd3jOkfXkIgftrWUOGES6FJqa5yP9dMsp9zwe2BD43A6cGG4jIfOCtwOsoIAQiciVwJUBTU9MozQmf/q6hHIPKclUfBTcnQcfeziHtD3T2smj6xC1BDTYxjWFEhUJzFp9YaENVXT3MvnPVI8r+j/8qcK2q9uWakzdwrJuBmwFWrFgxYe8aCf8InAkMB8mbNZSM09ld3l1DFiw2jHAp1DX05QLrFPcUX4hmYGHg8wJgW1abFcAdXgRmABeKSEpVfzXMvickyf5gcX6PIDtYXF9dvsHi/nEE1jVkGKFSqGvo3EPc9xPAMj+15VbgMuBdWcfo73YSkVuBX5erCMDA035qBB5BbY700Z5Umq7eiV2CGoLBYhMCwwiTYorOISLH4DJ/ajLLVPUHhbZR1ZSIXIPLBooDt6jqGhG52q+/qdD25UjCZwT15IgR9PTPRzC4i6y+Kk4qrfSkBia2L4c6Q2DVRw0jKgwrBL60xDk4IbgPlw76P0BBIQBQ1fv8NsFlOQVAVd8/rLUTnEIeQW9fmqp4jOxYSW3VwAT2VQk3UX05jCoG8DpgMQLDCJliBpS9A1diYoeqfgA4DqguqVVlSrI/WJzDI0ilh3gD4DwCGFyKunyEIDMxTciGGEaFU4wQdKlqGkj5QWa7GH4MgZGDTNdQLiHo7UuTTAy9HLlmKTvQ5cYVTHQhsKwhw4gGxcQIVorIFOC7uMFl7cDjpTSqXMnUEcpXYiK7zhAMzFsc9Aj2+xLUU+qqSmHmuGFZQ4YRDYqZmOYj/u1NInI/0Kiqz5TWrPIkM7K4NzXUI+hOpXMWkKuvdpeo/eCAR7C3w3kE0+onthBY1pBhRINis4aOBRZn2ovI4ap6VwntKkv6B5TlqT6aPYYAoLHWXaLWgBDs6eghGRcaa4q6fJHFsoYMIxoUkzV0C3AssAbIPMoqYEIwQjJdP7k8gp5UX86uocYaFwdoPdjbv2xvew9T66qGZBhNNKzEhGFEg2IeKU9T1SFVQ42RkwkW5x5ZrCQTQ2/sjT4g3No1IAR7OnomfLcQWLDYMKJCMVlDj+YqH22MnGR/1lDxweJJ1QlEBgvB3o5upjeUgRD0B4tDNsQwKpxiPILbcGKwA+jGFZNTVT22pJaVIYXGEeQLFsdiQkN1YlCMYG9HD6+eOqVkdo4X4r+uWozAMEKlGCG4BXgv8CwDMQJjFCSGGVncUJ37ckyuTQ7pGppeDl1DNlWlYUSCYoRgs6reU3JLKoBkgVpD+bqGwAWMM8HinlSatoOp8ooRmEdgGKFSjBA8LyI/Ae7FdQ0BYOmjIycZy3gE+UpM5BGC2gStXa5raF9neYwhAMsaMoyoUIwQ1OIE4LzAMksfHQUDWUO5y1DnGkcAziPY7Gcp29NePkIwkDUUsiGGUeEUFAI/sfxuVf2HcbKnrMk88efqGurs6aO+Op5zu8baZH+huXIZVQyB6qPWNWQYoVIwfVRV+4CCU1YaxVOoDHVnTx91Vbl1ubFmIFi8p8P1zpVDsFhEiIl1DRlG2BTTNfSUiNwD/BzoyCy0GMHIiccEkaExAlWloyfVX3I6m8baBB09faT60mXlEYA7J+YRGEa4FCME04A9DJ6j2GIEoyQZj/XPRpbhYG8aVajLkz6aKTPRdjDF3o4eRCZ+5dEMImIegWGETDHVRz8wHoZUCsmYDPEIOvxcA/k8gsy8A60He9nT4eoMZQKtE524CGnzCAwjVIYtMSEiC0TklyKyS0R2isidIrJgPIwrR5KJ2JCRxZ3dbq6BvDGC/npDKfa2l0edoQzxmFjWkGGETDG1hr4P3APMA+bjxhN8v5RGlTOJWGxIGep+jyBf1lBNphR1L3vLpOBchphgHoFhhEwxQjBTVb+vqin/uhWYWWK7ypZkfGjXUGYayuE9gl72dHSXRcZQBucRmBAYRpgUIwS7ReQ9IhL3r/fggsfGKEjGY0Oqj3b4rqFC4wjATVpfbh6BZQ0ZRvgUIwQfBC4FdgDbgXf4ZcYoSMRlSIygo3sYj8B3DW3Z18m+zl7mTaktrZHjSMyyhgwjdIrJGtoMvGUcbKkIkrGhweIOPzF9fR4hqK9KEBP44wstAJzYNLW0Ro4j1jVkGOGTVwhE5PoC26mq3lgCe8qeZEKGjCzujxHk6RqKxYRJNUnWbGslEROOXzil1GaOGzGxriHDCJtCXUMdOV4AHwKuLbFdZUvOrKHuwh4BDIwlOHr+ZGrzjDeYiMRiYDpgGOGS986jql/OvBeRScDHgA8AdwBfzredUZiqeGzI5PWdPSlEoCaZX5cba92lOnlR+XQLgRtQZl1DhhEuw1UfnQZ8HHg3bsrKE1V133gYVq7kDhb3UV+VQCT/aOFMmYkVi6eV1L7xJmZZQ4YROoViBF8C3gbcDLxaVdvHzaoyJhGP0emDwxk6e1LUDdPdMyAE5ecRWNaQYYRLIY/gE7gJaf4J+EzgaTUzeX1jiW0rS6pyeQQ9fdTnKTiX4Zj5jezr7GFGQ3UpzRt3LGvIMMInb6e0qsZUtVZVJ6lqY+A1qVgREJHzReQFEdkgItflWP9uEXnGvx4RkeMO5ctMBBKx2NCsoe7hPYJrXreMn151eilNC4WYFZ0zjNApZkDZqPCzm30TuABYDlwuIsuzmr0EnK2qxwI34rqhypqcMYKeVMGMoXLGPALDCJ+SCQFwCrBBVTepag8u2+jiYANVfSQQfH4MKPuqplXxGL3p7KyhvrxjCModFywO2wrDqGxKKQTzgS2Bz81+WT4+BPwm1woRuVJEVorIypaWljE0cfxJxIcOKOvorlyPwKaqNIzwKaUQ5MqFzPkfLyLnUmCgmqrerKorVHXFzJkTu/CpKzqXwyMoo0FiI8EmpjGM8CnlY2gzsDDweQGwLbuRiBwL/BdwgaqWfVXT3NVHU8NmDZUrMYsRGEbolNIjeAJYJiJLRKQKuAw3wU0/ItKEm/v4var6YgltiQyJ2OBgsaqaR2AegWGESskeQ1U1JSLXAA8AceAWVV0jIlf79TcB1wPTgW/5cQopVV1RKpuiQDIxOH20py9NKq0V6xHEY0J3yoTAMMKkpHcfVb0PuC9r2U2B91cAV5TShqiRjAm96TSqiogE5iuuTI/AsoYMI3xK2TVk5CARj6FKf794/3zFFZo1FLesIcMIHROCcSYZd6c85W9+mbpDlTqOwAaUGUb4mBCMM8m4y6rt8QHjzDSVleoRiAWLDSN0TAjGmX6PoC/LI6jQGIFlDRlG+JgQjDMJ7xGksj2CCs4asq4hwwgXE4JxJhlzpzzTNVTpHkEsJpgOGEa4mBCMM8lExiPIyhqqVI9AMI/AMELGhGCcScQyWUPeI7BxBCYEhhEyJgTjTH/WkB9N2+ZjBHUVmjVkwWLDCB8TgnFmYByB8wh2t3czrb6KeCz/xPXljAWLDSN8TAjGmYQXgkzhud1t3cwss3mIR4ILFpsQGEaYmBCMM5muoUwp6pb2bmZOqmAhsGCxYYSOCcE4kz2grKWtsoXAxQjCtsIwKhsTgnEmEct4BK4CaUtbNzMaqkK2KjxiMbGic4YRMiYE40wyECNo607RnUpXvEfQZzECwwgVE4JxZkAIlN1t3QCVLQSWNWQYoWNCMM701xpKp2nJCEFDTZgmhYplDRlG+JgQjDNVAY+gpd08griYR2AYYVOZw1lDJBEfCBa3HewFKlsIMkXnMlN3GoYx/phHMM4MpI+m2d3eTTwmTKlNhmxVeGQGVJtTYBjhYUIwzmTKUPf2DaSOxiq0vAS4riHA4gSGESImBONMsGuo0geTAf0iaHECwwgPE4JxJjh5fUt7ZdcZAvqL7ZlHYBjhYUIwzgyUoU6zu62n4j2CTNeQeQSGER4mBOOMiBCPCb0+WFzpQpDpGvJVuQ3DCAETghBIxoWWtm5SaWVGpXcN+Ti5lZkwjPAwIQiBZCzGi7vaAZg/pTZka8IlbsFiwwgdE4IQSCZirNl6AIDjFk4J15iQiVmw2DBCx4QgBBIxIZVW5k6uYXZj5dYZAojZOALDCB0TghDIpJAeX+HeAFjWkGFEAROCEMikkFZ6txBY1pBhRIGSCoGInC8iL4jIBhG5Lsd6EZH/9OufEZETS2lPVEiYR9CPPxWWNWQYIVIyIRCROPBN4AJgOXC5iCzPanYBsMy/rgS+XSp7okQiJsQEXj1/ctimhE7MuoYMI3RKWYb6FGCDqm4CEJE7gIuBtYE2FwM/UFUFHhORKSIyV1W3l9Cu0KlKxDhi9iTqq60KeCZ99EO3PdE/V4NhGLl558kLueLMw8Z8v6W8E80HtgQ+NwOnFtFmPjBICETkSpzHQFNT05gbOt5cddZSqhJ20wM4Zck03nbCfA6m+sI2xTAiT6kGoJZSCHLVVs72/4tpg6reDNwMsGLFignfh/CmY+eGbUJkmDWphv/7zuPDNsMwKppSPpY2AwsDnxcA20bRxjAMwyghpRSCJ4BlIrJERKqAy4B7strcA7zPZw+dBhwo9/iAYRhG1ChZ15CqpkTkGuABIA7coqprRORqv/4m4D7gQmAD0Al8oFT2GIZhGLkpadqKqt6Hu9kHl90UeK/AR0tpg2EYhlEYS10xDMOocEwIDMMwKhwTAsMwjArHhMAwDKPCEZ1gxb5EpAV4ZZSbzwB2j6E5pWIi2Gk2jg1m49hgNg7PIlWdmWvFhBOCQ0FEVqrqirDtGI6JYKfZODaYjWOD2XhoWNeQYRhGhWNCYBiGUeFUmhDcHLYBRTIR7DQbxwazcWwwGw+BiooRGIZhGEOpNI/AMAzDyMKEwDAMo8KpGCEQkfNF5AUR2SAi14VtD4CILBSRP4jIOhFZIyIf88tvEJGtIvKUf10Ysp0vi8iz3paVftk0EXlIRNb7v1NDtO/IwLl6SkRaReTvo3AeReQWEdklIs8FluU9dyLyKf8bfUFE3hiijV8SkedF5BkR+aWITPHLF4tIV+Cc3pR3x6W3Me/1jdB5/GnAvpdF5Cm/PJTzmBdVLfsXrgz2RuAwoAp4GlgeAbvmAif695OAF4HlwA3AJ8O2L2Dny8CMrGVfBK7z768DvhC2nYFrvQNYFIXzCJwFnAg8N9y589f+aaAaWOJ/s/GQbDwPSPj3XwjYuDjYLuTzmPP6Ruk8Zq3/MnB9mOcx36tSPIJTgA2quklVe4A7gItDtglV3a6qq/37NmAdbs7micDFwG3+/W3AJeGZMojXAxtVdbSjz8cUVX0Y2Ju1ON+5uxi4Q1W7VfUl3Dwdp4Rho6o+qKop//Ex3OyBoZHnPOYjMucxg4gIcClwe6ntGA2VIgTzgS2Bz81E7IYrIouBE4C/+EXXeLf8ljC7XTwKPCgiq0TkSr9stvrZ5PzfWaFZN5jLGPzPFqXzmCHfuYvq7/SDwG8Cn5eIyJMi8icROTMsozy5rm8Uz+OZwE5VXR9YFpnzWClCIDmWRSZvVkQagDuBv1fVVuDbwFLgeGA7zqUMk9eo6onABcBHReSskO3JiZ8S9S3Az/2iqJ3H4Yjc71REPgOkgB/7RduBJlU9Afg48BMRaQzJvHzXN3LnEbicwQ8oUTqPFSMEzcDCwOcFwLaQbBmEiCRxIvBjVb0LQFV3qmqfqqaB7zIObm0hVHWb/7sL+KW3Z6eIzAXwf3eFZ2E/FwCrVXUnRO88Bsh37iL1OxWRvwYuAt6tvmPbd7fs8e9X4frfjwjDvgLXN2rnMQG8DfhpZlmUziNUjhA8ASwTkSX+qfEy4J6Qbcr0G34PWKeq/zewfG6g2VuB57K3HS9EpF5EJmXe44KIz+HO31/7Zn8N3B2OhYMY9NQVpfOYRb5zdw9wmYhUi8gSYBnweAj2ISLnA9cCb1HVzsDymSIS9+8P8zZuCsnGfNc3MufR8wbgeVVtziyI0nkEKiNryD/MXIjLytkIfCZse7xNr8W5rM8AT/nXhcAPgWf98nuAuSHaeBguA+NpYE3m3AHTgd8B6/3faSGfyzpgDzA5sCz084gTpu1AL+5J9UOFzh3wGf8bfQG4IEQbN+D62TO/y5t827f738HTwGrgzSHamPf6RuU8+uW3AldntQ3lPOZ7WYkJwzCMCqdSuoYMwzCMPJgQGIZhVDgmBIZhGBWOCYFhGEaFY0JgGIZR4ZgQGEYeRGR6oDrkjkCly3YR+VbY9hnGWGHpo4ZRBCJyA9Cuqv8Rti2GMdaYR2AYI0REzhGRX/v3N4jIbSLyoK83/zYR+aK4+Rvu9yVEEJGTfHGxVSLyQNaoWMMIFRMCwzh0lgJvwpU//hHwB1V9NdAFvMmLwdeBd6jqScAtwL+EZaxhZJMI2wDDKAN+o6q9IvIsbmKc+/3yZ3ETkBwJHAM85MpLEceVIjCMSGBCYBiHTjeAqqZFpFcHAm9p3P+YAGtU9fSwDDSMQljXkGGUnheAmSJyOrjS4yJydMg2GUY/JgSGUWLUTY/6DuALIvI0rprnGaEaZRgBLH3UMAyjwjGPwDAMo8IxITAMw6hwTAgMwzAqHBMCwzCMCseEwDAMo8IxITAMw6hwTAgMwzAqnP8PpSxRCOMavecAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "#mitbih_test = pd.read_csv(\"/tmp/ecg/mitbih_test.csv\", header=None)\n",
    "#mitbih_train = pd.read_csv(\"/tmp/ecg/mitbih_train.csv\", header=None)\n",
    "ptbdb_abnormal = pd.read_csv(\"ptbdb_abnormal.csv\", header=None)\n",
    "ptbdb_normal = pd.read_csv(\"ptbdb_normal.csv\", header=None)\n",
    "ptbdb = pd.concat([ptbdb_abnormal, ptbdb_normal], axis=0, ignore_index=True)\n",
    "ptbdb_abnormal.values[:,-1]\n",
    "ptbdb_labels = {'Normal': 0, 'Abnormal': 1}\n",
    "print('TEST')\n",
    "ptbdb_reverse_labels = {v:k for k,v in ptbdb_labels.items()}\n",
    "ptbdb_labels = ptbdb.iloc[:,-1].replace(ptbdb_reverse_labels)\n",
    "plt.hist(ptbdb_labels)\n",
    "plt.title(\"Distribution of the PTB Diagnostic ECG Database labels\")\n",
    "plt.show()\n",
    "plt.plot(ptbdb.iloc[0,:-2])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized activation')\n",
    "plt.title(\"PTB Diagnostic ECG Database example signal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b82e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "# TODO check irreproducibilty with Cuda\n",
    "# DOES NOT WORK ! os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:2'\n",
    "#os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'\n",
    "#RANDOM_SEED = 42\n",
    "#torch.manual_seed(RANDOM_SEED)\n",
    "#np.random.seed(RANDOM_SEED)\n",
    "#torch.cuda.manual_seed(RANDOM_SEED)\n",
    "#torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "560b58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dwt(X):  \n",
    "    res = []\n",
    "    for x in X:   \n",
    "        #print(x.shape)\n",
    "            coeffs = pywt.wavedec(x, 'db5', level=2) \n",
    "        #x = smooth(x, level=4)\n",
    "        #coeffs = pywt.wavedec(x, 'sym6', level=4) \n",
    "        cA2, cD2, cD1 = coeffs\n",
    "        #cA1, cD1 = coeffs\n",
    "        #print(cD1.shape)\n",
    "        #interleaved = [val for pair in zip(cA4, cD4) for val in pair]\n",
    "        #res.append(torch.from_numpy(interleaved)))\n",
    "        res.append(torch.from_numpy(np.concatenate([cA2, cD1, cD2], axis=2)))\n",
    "        #print(torch.from_numpy(np.concatenate([cA1, cD1])).shape)\n",
    "        #res.append(torch.from_numpy(cA1))        \n",
    "        #print(cA1.shape)\n",
    "        #print(len(cD3))\n",
    "    tensors = torch.stack(res)\n",
    "    print(tensors.shape)\n",
    "    return(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c69420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOO - must not hardcode\n",
    "# takes input tensor and splits it into (17 hardcoded) chunks of smaller window size\n",
    "# each is transformed using discrete wavelet tramsformation - we only keep cA component \n",
    "# TODO we could inlucde more components (also high frequency cDn's) and should use flexible levels\n",
    "# This way, we create a dim embedding using the dimension n = number of cA's. \n",
    "#\n",
    "# With the current hardcoded setup we reduce time steps from 187 to 17 but increase features from 1 to 28, \n",
    "# henceforth we map (14552, 1, 187) to (14552, 28, 17). This creates a dim_embedding of 28 which is high enough \n",
    "# to preserve information and enable grad descent for attention / transformer using also res connections, compare\n",
    "# line x = x + self.transformer_encoder(x) (instead of x = self.transformer_encoder(x)) in transformer \n",
    "# forward method (TODO check whether still necessary)\n",
    "#\n",
    "# The dim_embedding of 28 is a result of taking coeffiecnts cA2, cD2, cD1 of 'db5', level=2, because\n",
    "# len(cA2) = 14 and len(cD2) = len(cD1) = 7\n",
    "#\n",
    "# TODO check whether positional encoding is beneficial\n",
    "#\n",
    "\n",
    "def dim_embedding(x):\n",
    "    #print(x.shape)\n",
    "\n",
    "    chunks = torch.split(x, 11, dim=2)\n",
    "    #print(len(chunks))\n",
    "\n",
    "    # transform using dwt\n",
    "    # skip last chunk because it is shorter\n",
    "\n",
    "    chunks_dwt = torch.flatten(compute_dwt(chunks[0:18]), start_dim=2, end_dim=3)\n",
    "\n",
    "    # reshape tensor to match batch x features x seq_length\n",
    "    print(chunks_dwt.shape)\n",
    "    chunks_dwt = chunks_dwt.permute(1, 2, 0)\n",
    "    print(chunks_dwt.shape)    \n",
    "    return chunks_dwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6756232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14552, 187)\n",
      "(14552,)\n",
      "ANOTHER TEST\n",
      "<built-in method type of Tensor object at 0x7f65908e5e30>\n",
      "Before\n",
      "(14552, 1, 187)\n",
      "torch.Size([14552, 1, 187])\n",
      "data.shape\n",
      "torch.Size([17, 14552, 1, 28])\n",
      "torch.Size([17, 14552, 28])\n",
      "torch.Size([14552, 28, 17])\n",
      "data.shape after\n",
      "torch.Size([14552, 28, 17])\n",
      "ANOTHER TEST\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_FEATURES = 28\n",
    "# For complex phase included, number of features doubles\n",
    "# NUM_FEATURES = 232*2\n",
    "\n",
    "#SEQ_LENGTH = 187#from shape the number of coloumns\n",
    "SEQ_LENGTH = 17\n",
    "\n",
    "# TODO must not hardcode\n",
    "# BATCH_SIZE = 32\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1000\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "NUM_CLASSES = -1\n",
    "X,y= ptbdb.iloc[:,:-1].values, ptbdb.iloc[:,-1].values,\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "def data2tensor(X, y, encoder):\n",
    "    \"\"\"convert rawdata and rawlabel with encoder to pytorch tensor\n",
    "\n",
    "    Keyword arguments:\n",
    "    rawdata -- np array of rawdata\n",
    "    rawlabels -- np array of labels corresponding to rawdata\n",
    "    encoder -- instance of LabelEncoder used for encoding\n",
    "\n",
    "    Returns:\n",
    "    tensor: torch.Tensor of type DoubleTensor with\n",
    "            dimension [batch size (i.e. number of X instances), NUM_FEATURES, SEQ_LENGTH]\n",
    "    \"\"\"\n",
    "    # labels as digit representation instead of letters\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    #print('ANOTHER TEST')\n",
    "    tensors = []\n",
    "    labels = []\n",
    "    for i in range(len(y)):\n",
    "        #if X[i].shape == (NUM_FEATURES, SEQ_LENGTH):  # skip data with incorrect dimensions TODO: avoid hardcoding\n",
    "            # r_tensor = torch.tensor(rawdata[i].real, device=device)\n",
    "            # i_tensor = torch.tensor(rawdata[i].imag, device=device)\n",
    "            # tensors.append(torch.cat((r_tensor, i_tensor), 0))\n",
    "\n",
    "            # append the absolute value (TODO should be configurable)\n",
    "\n",
    "            # ts_fft = sp.fftpack.fft(rawdata[i])\n",
    "            # ts_psd = np.abs(ts_fft) ** 2\n",
    "            # tensors.append(torch.tensor(ts_psd, device=device))\n",
    "        tensors.append(torch.tensor(np.absolute(X[i]), device=device))\n",
    "        labels.append(y[i])\n",
    "    #tensors=np.array(tensors)\n",
    "    #tensors=np.expand_dims(tensors,2)\n",
    "    return torch.stack(tensors), torch.as_tensor(labels, device=device)\n",
    "\n",
    "#rawdata, rawlabels = load_dataset(csi_data)\n",
    "print('ANOTHER TEST')\n",
    "data, labels = data2tensor(X, y, encoder)\n",
    "print(data.type)\n",
    "#data= data.argmax\n",
    "data=data.cpu().numpy()\n",
    "\n",
    "#data=np.array(data)\n",
    "#print(data.shape)\n",
    "#expanding dimensions to make it 3-D\n",
    "print('Before')\n",
    "#data=data.expand_dims(data,1)\n",
    "\n",
    "data=np.expand_dims(data,1)\n",
    "print(data.shape)\n",
    "data = torch.tensor(data)\n",
    "print(data.shape)\n",
    "print(\"data.shape\")\n",
    "data = dim_embedding(data)\n",
    "print(\"data.shape after\")\n",
    "print(data.shape)\n",
    "mean = torch.mean(data)\n",
    "std = torch.std(data)\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "normalize = transforms.Normalize(mean, std)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "nor_data = normalize(data).to(device)\n",
    "\n",
    "\n",
    "dataset = TensorDataset(nor_data, labels)\n",
    "#dataset = TensorDataset(data, labels)\n",
    "#dataset = dataset.to(device=torch.device(\"cuda:0\"))\n",
    "print('ANOTHER TEST')\n",
    "NUM_CLASSES = len(encoder.classes_)\n",
    "print(NUM_CLASSES)\n",
    "# split data into training, validation, and test (todo: make better configurable)\n",
    "full_size = int(len(dataset))\n",
    "train_size = int(0.8 * full_size)\n",
    "val_size = (len(dataset) - train_size)//2\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, full_size - train_size-val_size], generator=torch.Generator().manual_seed(4))\n",
    "\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator())\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator())\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0570656e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf4af16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14552, 28, 17])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3137bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER dataloading\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f667b18a050>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f6592c3f2d0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f66b3219b10>\n",
      "AFTER DIVISION\n",
      "6\n",
      "6\n",
      "torch.Size([14552, 28, 17])\n",
      "torch.DoubleTensor\n",
      "DATA SHAPE 28\n",
      "BEFO>rE\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "TransformerModel                                                  --\n",
      "├─PositionalEncoding: 1-1                                         --\n",
      "├─TransformerEncoder: 1-2                                         --\n",
      "│    └─ModuleList: 2-1                                            --\n",
      "│    │    └─TransformerEncoderLayer: 3-1                          17,638\n",
      "│    │    └─TransformerEncoderLayer: 3-2                          17,638\n",
      "│    │    └─TransformerEncoderLayer: 3-3                          17,638\n",
      "│    │    └─TransformerEncoderLayer: 3-4                          17,638\n",
      "├─Dropout: 1-3                                                    --\n",
      "├─Linear: 1-4                                                     954\n",
      "==========================================================================================\n",
      "Total params: 61,762\n",
      "Trainable params: 61,762\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.659966  [    0/11641]\n",
      "loss: 0.613060  [ 2560/11641]\n",
      "loss: 0.452660  [ 5120/11641]\n",
      "loss: 0.482360  [ 7680/11641]\n",
      "loss: 0.410072  [10240/11641]\n",
      "Accuracy: 80.89%, Avg loss: 0.393922\n",
      "Model saved\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.387568  [    0/11641]\n",
      "loss: 0.376245  [ 2560/11641]\n",
      "loss: 0.307315  [ 5120/11641]\n",
      "loss: 0.319275  [ 7680/11641]\n",
      "loss: 0.375894  [10240/11641]\n",
      "Accuracy: 83.99%, Avg loss: 0.333346\n",
      "Model saved\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.326658  [    0/11641]\n",
      "loss: 0.333297  [ 2560/11641]\n",
      "loss: 0.358625  [ 5120/11641]\n",
      "loss: 0.311996  [ 7680/11641]\n",
      "loss: 0.278726  [10240/11641]\n",
      "Accuracy: 87.56%, Avg loss: 0.291326\n",
      "Model saved\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.332346  [    0/11641]\n",
      "loss: 0.290287  [ 2560/11641]\n",
      "loss: 0.316113  [ 5120/11641]\n",
      "loss: 0.302829  [ 7680/11641]\n",
      "loss: 0.258357  [10240/11641]\n",
      "Accuracy: 88.52%, Avg loss: 0.257895\n",
      "Model saved\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.214897  [    0/11641]\n",
      "loss: 0.193079  [ 2560/11641]\n",
      "loss: 0.229413  [ 5120/11641]\n",
      "loss: 0.223373  [ 7680/11641]\n",
      "loss: 0.240571  [10240/11641]\n",
      "Accuracy: 90.52%, Avg loss: 0.228853\n",
      "Model saved\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.179685  [    0/11641]\n",
      "loss: 0.178706  [ 2560/11641]\n",
      "loss: 0.223763  [ 5120/11641]\n",
      "loss: 0.209424  [ 7680/11641]\n",
      "loss: 0.130536  [10240/11641]\n",
      "Accuracy: 91.00%, Avg loss: 0.219113\n",
      "Model saved\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.173546  [    0/11641]\n",
      "loss: 0.212391  [ 2560/11641]\n",
      "loss: 0.172812  [ 5120/11641]\n",
      "loss: 0.219576  [ 7680/11641]\n",
      "loss: 0.148334  [10240/11641]\n",
      "Accuracy: 92.71%, Avg loss: 0.190013\n",
      "Model saved\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.114531  [    0/11641]\n",
      "loss: 0.128158  [ 2560/11641]\n",
      "loss: 0.196355  [ 5120/11641]\n",
      "loss: 0.142867  [ 7680/11641]\n",
      "loss: 0.124337  [10240/11641]\n",
      "Accuracy: 93.75%, Avg loss: 0.170649\n",
      "Model saved\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.210979  [    0/11641]\n",
      "loss: 0.169180  [ 2560/11641]\n",
      "loss: 0.215879  [ 5120/11641]\n",
      "loss: 0.146553  [ 7680/11641]\n",
      "loss: 0.157618  [10240/11641]\n",
      "Accuracy: 93.06%, Avg loss: 0.178299\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.189235  [    0/11641]\n",
      "loss: 0.120448  [ 2560/11641]\n",
      "loss: 0.191532  [ 5120/11641]\n",
      "loss: 0.160287  [ 7680/11641]\n",
      "loss: 0.135639  [10240/11641]\n",
      "Accuracy: 93.20%, Avg loss: 0.177927\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.131461  [    0/11641]\n",
      "loss: 0.134672  [ 2560/11641]\n",
      "loss: 0.151682  [ 5120/11641]\n",
      "loss: 0.138746  [ 7680/11641]\n",
      "loss: 0.148989  [10240/11641]\n",
      "Accuracy: 94.02%, Avg loss: 0.145166\n",
      "Model saved\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.129077  [    0/11641]\n",
      "loss: 0.154199  [ 2560/11641]\n",
      "loss: 0.133705  [ 5120/11641]\n",
      "loss: 0.134068  [ 7680/11641]\n",
      "loss: 0.134942  [10240/11641]\n",
      "Accuracy: 93.68%, Avg loss: 0.171273\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.146725  [    0/11641]\n",
      "loss: 0.151209  [ 2560/11641]\n",
      "loss: 0.151563  [ 5120/11641]\n",
      "loss: 0.168801  [ 7680/11641]\n",
      "loss: 0.113826  [10240/11641]\n",
      "Accuracy: 94.71%, Avg loss: 0.145504\n",
      "Model saved\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.111449  [    0/11641]\n",
      "loss: 0.104713  [ 2560/11641]\n",
      "loss: 0.093296  [ 5120/11641]\n",
      "loss: 0.156882  [ 7680/11641]\n",
      "loss: 0.137303  [10240/11641]\n",
      "Accuracy: 95.53%, Avg loss: 0.135576\n",
      "Model saved\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.083025  [    0/11641]\n",
      "loss: 0.168319  [ 2560/11641]\n",
      "loss: 0.134750  [ 5120/11641]\n",
      "loss: 0.110896  [ 7680/11641]\n",
      "loss: 0.124213  [10240/11641]\n",
      "Accuracy: 95.74%, Avg loss: 0.131296\n",
      "Model saved\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.081621  [    0/11641]\n",
      "loss: 0.104570  [ 2560/11641]\n",
      "loss: 0.076613  [ 5120/11641]\n",
      "loss: 0.063067  [ 7680/11641]\n",
      "loss: 0.118067  [10240/11641]\n",
      "Accuracy: 95.26%, Avg loss: 0.120483\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.123164  [    0/11641]\n",
      "loss: 0.106312  [ 2560/11641]\n",
      "loss: 0.093609  [ 5120/11641]\n",
      "loss: 0.116766  [ 7680/11641]\n",
      "loss: 0.101966  [10240/11641]\n",
      "Accuracy: 95.60%, Avg loss: 0.115682\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.098839  [    0/11641]\n",
      "loss: 0.094865  [ 2560/11641]\n",
      "loss: 0.066475  [ 5120/11641]\n",
      "loss: 0.073409  [ 7680/11641]\n",
      "loss: 0.096247  [10240/11641]\n",
      "Accuracy: 95.88%, Avg loss: 0.118924\n",
      "Model saved\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.074647  [    0/11641]\n",
      "loss: 0.061026  [ 2560/11641]\n",
      "loss: 0.070767  [ 5120/11641]\n",
      "loss: 0.084883  [ 7680/11641]\n",
      "loss: 0.126776  [10240/11641]\n",
      "Accuracy: 95.40%, Avg loss: 0.124076\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.096408  [    0/11641]\n",
      "loss: 0.058292  [ 2560/11641]\n",
      "loss: 0.094028  [ 5120/11641]\n",
      "loss: 0.073693  [ 7680/11641]\n",
      "loss: 0.087414  [10240/11641]\n",
      "Accuracy: 95.46%, Avg loss: 0.136525\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.084032  [    0/11641]\n",
      "loss: 0.079505  [ 2560/11641]\n",
      "loss: 0.056192  [ 5120/11641]\n",
      "loss: 0.089666  [ 7680/11641]\n",
      "loss: 0.091946  [10240/11641]\n",
      "Accuracy: 96.63%, Avg loss: 0.106669\n",
      "Model saved\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.096640  [    0/11641]\n",
      "loss: 0.058718  [ 2560/11641]\n",
      "loss: 0.065677  [ 5120/11641]\n",
      "loss: 0.083083  [ 7680/11641]\n",
      "loss: 0.075102  [10240/11641]\n",
      "Accuracy: 96.15%, Avg loss: 0.109053\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.119333  [    0/11641]\n",
      "loss: 0.061103  [ 2560/11641]\n",
      "loss: 0.071057  [ 5120/11641]\n",
      "loss: 0.121940  [ 7680/11641]\n",
      "loss: 0.074353  [10240/11641]\n",
      "Accuracy: 96.29%, Avg loss: 0.103547\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.082434  [    0/11641]\n",
      "loss: 0.106903  [ 2560/11641]\n",
      "loss: 0.054397  [ 5120/11641]\n",
      "loss: 0.090330  [ 7680/11641]\n",
      "loss: 0.049573  [10240/11641]\n",
      "Accuracy: 96.84%, Avg loss: 0.092105\n",
      "Model saved\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.056595  [    0/11641]\n",
      "loss: 0.090091  [ 2560/11641]\n",
      "loss: 0.076853  [ 5120/11641]\n",
      "loss: 0.087838  [ 7680/11641]\n",
      "loss: 0.067872  [10240/11641]\n",
      "Accuracy: 96.56%, Avg loss: 0.107485\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.047469  [    0/11641]\n",
      "loss: 0.047899  [ 2560/11641]\n",
      "loss: 0.107892  [ 5120/11641]\n",
      "loss: 0.060928  [ 7680/11641]\n",
      "loss: 0.105944  [10240/11641]\n",
      "Accuracy: 96.15%, Avg loss: 0.095360\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.074794  [    0/11641]\n",
      "loss: 0.084960  [ 2560/11641]\n",
      "loss: 0.076844  [ 5120/11641]\n",
      "loss: 0.064926  [ 7680/11641]\n",
      "loss: 0.055007  [10240/11641]\n",
      "Accuracy: 97.11%, Avg loss: 0.090413\n",
      "Model saved\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.080636  [    0/11641]\n",
      "loss: 0.055854  [ 2560/11641]\n",
      "loss: 0.052961  [ 5120/11641]\n",
      "loss: 0.092558  [ 7680/11641]\n",
      "loss: 0.056057  [10240/11641]\n",
      "Accuracy: 95.81%, Avg loss: 0.123299\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.086191  [    0/11641]\n",
      "loss: 0.063885  [ 2560/11641]\n",
      "loss: 0.043180  [ 5120/11641]\n",
      "loss: 0.082220  [ 7680/11641]\n",
      "loss: 0.062637  [10240/11641]\n",
      "Accuracy: 96.49%, Avg loss: 0.100794\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.045707  [    0/11641]\n",
      "loss: 0.025652  [ 2560/11641]\n",
      "loss: 0.041906  [ 5120/11641]\n",
      "loss: 0.056686  [ 7680/11641]\n",
      "loss: 0.082872  [10240/11641]\n",
      "Accuracy: 96.43%, Avg loss: 0.109696\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.086354  [    0/11641]\n",
      "loss: 0.082062  [ 2560/11641]\n",
      "loss: 0.052459  [ 5120/11641]\n",
      "loss: 0.065807  [ 7680/11641]\n",
      "loss: 0.041711  [10240/11641]\n",
      "Accuracy: 97.32%, Avg loss: 0.099546\n",
      "Model saved\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.048496  [    0/11641]\n",
      "loss: 0.057396  [ 2560/11641]\n",
      "loss: 0.030503  [ 5120/11641]\n",
      "loss: 0.041819  [ 7680/11641]\n",
      "loss: 0.040479  [10240/11641]\n",
      "Accuracy: 97.18%, Avg loss: 0.090983\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.041424  [    0/11641]\n",
      "loss: 0.071217  [ 2560/11641]\n",
      "loss: 0.055073  [ 5120/11641]\n",
      "loss: 0.071449  [ 7680/11641]\n",
      "loss: 0.058771  [10240/11641]\n",
      "Accuracy: 96.01%, Avg loss: 0.113334\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.128513  [    0/11641]\n",
      "loss: 0.077029  [ 2560/11641]\n",
      "loss: 0.053492  [ 5120/11641]\n",
      "loss: 0.054678  [ 7680/11641]\n",
      "loss: 0.058686  [10240/11641]\n",
      "Accuracy: 96.43%, Avg loss: 0.105070\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.053525  [    0/11641]\n",
      "loss: 0.043232  [ 2560/11641]\n",
      "loss: 0.051478  [ 5120/11641]\n",
      "loss: 0.065073  [ 7680/11641]\n",
      "loss: 0.053242  [10240/11641]\n",
      "Accuracy: 97.46%, Avg loss: 0.083428\n",
      "Model saved\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.062342  [    0/11641]\n",
      "loss: 0.028590  [ 2560/11641]\n",
      "loss: 0.038456  [ 5120/11641]\n",
      "loss: 0.069324  [ 7680/11641]\n",
      "loss: 0.038040  [10240/11641]\n",
      "Accuracy: 97.18%, Avg loss: 0.090921\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.037732  [    0/11641]\n",
      "loss: 0.052176  [ 2560/11641]\n",
      "loss: 0.053270  [ 5120/11641]\n",
      "loss: 0.038983  [ 7680/11641]\n",
      "loss: 0.026687  [10240/11641]\n",
      "Accuracy: 96.77%, Avg loss: 0.098222\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.056706  [    0/11641]\n",
      "loss: 0.038734  [ 2560/11641]\n",
      "loss: 0.026244  [ 5120/11641]\n",
      "loss: 0.059761  [ 7680/11641]\n",
      "loss: 0.081661  [10240/11641]\n",
      "Accuracy: 97.04%, Avg loss: 0.088154\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.035765  [    0/11641]\n",
      "loss: 0.044416  [ 2560/11641]\n",
      "loss: 0.036220  [ 5120/11641]\n",
      "loss: 0.106205  [ 7680/11641]\n",
      "loss: 0.056119  [10240/11641]\n",
      "Accuracy: 97.04%, Avg loss: 0.087723\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.044315  [    0/11641]\n",
      "loss: 0.054674  [ 2560/11641]\n",
      "loss: 0.025843  [ 5120/11641]\n",
      "loss: 0.025107  [ 7680/11641]\n",
      "loss: 0.020757  [10240/11641]\n",
      "Accuracy: 97.39%, Avg loss: 0.079019\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.043434  [    0/11641]\n",
      "loss: 0.029578  [ 2560/11641]\n",
      "loss: 0.054492  [ 5120/11641]\n",
      "loss: 0.058741  [ 7680/11641]\n",
      "loss: 0.063304  [10240/11641]\n",
      "Accuracy: 96.77%, Avg loss: 0.092903\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.032093  [    0/11641]\n",
      "loss: 0.041430  [ 2560/11641]\n",
      "loss: 0.020256  [ 5120/11641]\n",
      "loss: 0.058599  [ 7680/11641]\n",
      "loss: 0.042855  [10240/11641]\n",
      "Accuracy: 97.59%, Avg loss: 0.077613\n",
      "Model saved\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.051220  [    0/11641]\n",
      "loss: 0.036039  [ 2560/11641]\n",
      "loss: 0.066070  [ 5120/11641]\n",
      "loss: 0.047045  [ 7680/11641]\n",
      "loss: 0.027692  [10240/11641]\n",
      "Accuracy: 96.56%, Avg loss: 0.082923\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.045246  [    0/11641]\n",
      "loss: 0.042841  [ 2560/11641]\n",
      "loss: 0.056844  [ 5120/11641]\n",
      "loss: 0.028405  [ 7680/11641]\n",
      "loss: 0.064982  [10240/11641]\n",
      "Accuracy: 97.73%, Avg loss: 0.080575\n",
      "Model saved\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.021592  [    0/11641]\n",
      "loss: 0.027262  [ 2560/11641]\n",
      "loss: 0.026212  [ 5120/11641]\n",
      "loss: 0.030826  [ 7680/11641]\n",
      "loss: 0.032982  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.071193\n",
      "Model saved\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.027189  [    0/11641]\n",
      "loss: 0.044272  [ 2560/11641]\n",
      "loss: 0.056080  [ 5120/11641]\n",
      "loss: 0.058842  [ 7680/11641]\n",
      "loss: 0.024928  [10240/11641]\n",
      "Accuracy: 96.91%, Avg loss: 0.097392\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.034986  [    0/11641]\n",
      "loss: 0.059711  [ 2560/11641]\n",
      "loss: 0.075032  [ 5120/11641]\n",
      "loss: 0.031836  [ 7680/11641]\n",
      "loss: 0.019174  [10240/11641]\n",
      "Accuracy: 96.98%, Avg loss: 0.083166\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.047994  [    0/11641]\n",
      "loss: 0.028282  [ 2560/11641]\n",
      "loss: 0.041739  [ 5120/11641]\n",
      "loss: 0.029691  [ 7680/11641]\n",
      "loss: 0.026432  [10240/11641]\n",
      "Accuracy: 97.73%, Avg loss: 0.079607\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.073035  [    0/11641]\n",
      "loss: 0.025208  [ 2560/11641]\n",
      "loss: 0.030817  [ 5120/11641]\n",
      "loss: 0.044768  [ 7680/11641]\n",
      "loss: 0.055059  [10240/11641]\n",
      "Accuracy: 97.46%, Avg loss: 0.084944\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.080260  [    0/11641]\n",
      "loss: 0.025302  [ 2560/11641]\n",
      "loss: 0.059237  [ 5120/11641]\n",
      "loss: 0.055384  [ 7680/11641]\n",
      "loss: 0.060486  [10240/11641]\n",
      "Accuracy: 97.59%, Avg loss: 0.070483\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.033419  [    0/11641]\n",
      "loss: 0.062732  [ 2560/11641]\n",
      "loss: 0.073732  [ 5120/11641]\n",
      "loss: 0.036577  [ 7680/11641]\n",
      "loss: 0.009888  [10240/11641]\n",
      "Accuracy: 97.11%, Avg loss: 0.093229\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.011941  [    0/11641]\n",
      "loss: 0.032320  [ 2560/11641]\n",
      "loss: 0.016300  [ 5120/11641]\n",
      "loss: 0.061804  [ 7680/11641]\n",
      "loss: 0.010389  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.070427\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.027012  [    0/11641]\n",
      "loss: 0.039567  [ 2560/11641]\n",
      "loss: 0.024748  [ 5120/11641]\n",
      "loss: 0.050120  [ 7680/11641]\n",
      "loss: 0.115681  [10240/11641]\n",
      "Accuracy: 97.73%, Avg loss: 0.067753\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.014439  [    0/11641]\n",
      "loss: 0.038114  [ 2560/11641]\n",
      "loss: 0.050319  [ 5120/11641]\n",
      "loss: 0.029607  [ 7680/11641]\n",
      "loss: 0.018039  [10240/11641]\n",
      "Accuracy: 97.80%, Avg loss: 0.079918\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.015045  [    0/11641]\n",
      "loss: 0.024999  [ 2560/11641]\n",
      "loss: 0.037946  [ 5120/11641]\n",
      "loss: 0.039048  [ 7680/11641]\n",
      "loss: 0.027315  [10240/11641]\n",
      "Accuracy: 97.53%, Avg loss: 0.081515\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.039952  [    0/11641]\n",
      "loss: 0.009005  [ 2560/11641]\n",
      "loss: 0.050392  [ 5120/11641]\n",
      "loss: 0.011724  [ 7680/11641]\n",
      "loss: 0.069630  [10240/11641]\n",
      "Accuracy: 97.04%, Avg loss: 0.088103\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.025243  [    0/11641]\n",
      "loss: 0.023620  [ 2560/11641]\n",
      "loss: 0.025954  [ 5120/11641]\n",
      "loss: 0.026979  [ 7680/11641]\n",
      "loss: 0.035220  [10240/11641]\n",
      "Accuracy: 97.53%, Avg loss: 0.073874\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.031827  [    0/11641]\n",
      "loss: 0.043654  [ 2560/11641]\n",
      "loss: 0.058963  [ 5120/11641]\n",
      "loss: 0.051532  [ 7680/11641]\n",
      "loss: 0.012730  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.064536\n",
      "Model saved\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.016019  [    0/11641]\n",
      "loss: 0.019483  [ 2560/11641]\n",
      "loss: 0.020754  [ 5120/11641]\n",
      "loss: 0.023506  [ 7680/11641]\n",
      "loss: 0.014635  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.061754\n",
      "Model saved\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.017979  [    0/11641]\n",
      "loss: 0.046548  [ 2560/11641]\n",
      "loss: 0.031422  [ 5120/11641]\n",
      "loss: 0.014434  [ 7680/11641]\n",
      "loss: 0.016617  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.064591\n",
      "Model saved\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.034855  [    0/11641]\n",
      "loss: 0.034531  [ 2560/11641]\n",
      "loss: 0.040610  [ 5120/11641]\n",
      "loss: 0.034121  [ 7680/11641]\n",
      "loss: 0.018039  [10240/11641]\n",
      "Accuracy: 97.25%, Avg loss: 0.107858\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.039308  [    0/11641]\n",
      "loss: 0.048643  [ 2560/11641]\n",
      "loss: 0.022769  [ 5120/11641]\n",
      "loss: 0.013782  [ 7680/11641]\n",
      "loss: 0.010860  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.084911\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.047802  [    0/11641]\n",
      "loss: 0.014488  [ 2560/11641]\n",
      "loss: 0.028907  [ 5120/11641]\n",
      "loss: 0.017295  [ 7680/11641]\n",
      "loss: 0.020587  [10240/11641]\n",
      "Accuracy: 97.80%, Avg loss: 0.078876\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.011229  [    0/11641]\n",
      "loss: 0.039357  [ 2560/11641]\n",
      "loss: 0.055342  [ 5120/11641]\n",
      "loss: 0.037165  [ 7680/11641]\n",
      "loss: 0.029665  [10240/11641]\n",
      "Accuracy: 97.32%, Avg loss: 0.091565\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.029712  [    0/11641]\n",
      "loss: 0.013526  [ 2560/11641]\n",
      "loss: 0.010328  [ 5120/11641]\n",
      "loss: 0.016843  [ 7680/11641]\n",
      "loss: 0.040492  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.072199\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.027694  [    0/11641]\n",
      "loss: 0.018862  [ 2560/11641]\n",
      "loss: 0.044783  [ 5120/11641]\n",
      "loss: 0.029325  [ 7680/11641]\n",
      "loss: 0.031778  [10240/11641]\n",
      "Accuracy: 97.53%, Avg loss: 0.085148\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.012510  [    0/11641]\n",
      "loss: 0.023783  [ 2560/11641]\n",
      "loss: 0.030498  [ 5120/11641]\n",
      "loss: 0.036346  [ 7680/11641]\n",
      "loss: 0.028285  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.068404\n",
      "Model saved\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.011249  [    0/11641]\n",
      "loss: 0.033070  [ 2560/11641]\n",
      "loss: 0.014532  [ 5120/11641]\n",
      "loss: 0.028538  [ 7680/11641]\n",
      "loss: 0.045793  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.085083\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.026757  [    0/11641]\n",
      "loss: 0.022221  [ 2560/11641]\n",
      "loss: 0.018511  [ 5120/11641]\n",
      "loss: 0.020194  [ 7680/11641]\n",
      "loss: 0.032717  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.077686\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.017011  [    0/11641]\n",
      "loss: 0.031751  [ 2560/11641]\n",
      "loss: 0.016136  [ 5120/11641]\n",
      "loss: 0.015384  [ 7680/11641]\n",
      "loss: 0.041363  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.069818\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.047319  [    0/11641]\n",
      "loss: 0.008455  [ 2560/11641]\n",
      "loss: 0.030943  [ 5120/11641]\n",
      "loss: 0.033837  [ 7680/11641]\n",
      "loss: 0.016597  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.077045\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.015586  [    0/11641]\n",
      "loss: 0.017448  [ 2560/11641]\n",
      "loss: 0.018159  [ 5120/11641]\n",
      "loss: 0.035268  [ 7680/11641]\n",
      "loss: 0.025776  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.056204\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.017527  [    0/11641]\n",
      "loss: 0.029157  [ 2560/11641]\n",
      "loss: 0.015659  [ 5120/11641]\n",
      "loss: 0.029146  [ 7680/11641]\n",
      "loss: 0.012321  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.048743\n",
      "Model saved\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.023061  [    0/11641]\n",
      "loss: 0.004858  [ 2560/11641]\n",
      "loss: 0.041121  [ 5120/11641]\n",
      "loss: 0.005052  [ 7680/11641]\n",
      "loss: 0.035663  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.051962\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.025773  [    0/11641]\n",
      "loss: 0.008363  [ 2560/11641]\n",
      "loss: 0.009879  [ 5120/11641]\n",
      "loss: 0.016795  [ 7680/11641]\n",
      "loss: 0.028890  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.057795\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.028791  [    0/11641]\n",
      "loss: 0.018369  [ 2560/11641]\n",
      "loss: 0.013784  [ 5120/11641]\n",
      "loss: 0.009500  [ 7680/11641]\n",
      "loss: 0.010719  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.064058\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.018903  [    0/11641]\n",
      "loss: 0.009547  [ 2560/11641]\n",
      "loss: 0.008260  [ 5120/11641]\n",
      "loss: 0.012749  [ 7680/11641]\n",
      "loss: 0.054827  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.071672\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.048693  [    0/11641]\n",
      "loss: 0.035438  [ 2560/11641]\n",
      "loss: 0.024696  [ 5120/11641]\n",
      "loss: 0.007624  [ 7680/11641]\n",
      "loss: 0.008045  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.053291\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.028793  [    0/11641]\n",
      "loss: 0.030896  [ 2560/11641]\n",
      "loss: 0.012873  [ 5120/11641]\n",
      "loss: 0.019478  [ 7680/11641]\n",
      "loss: 0.008496  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.057921\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.012642  [    0/11641]\n",
      "loss: 0.012290  [ 2560/11641]\n",
      "loss: 0.018843  [ 5120/11641]\n",
      "loss: 0.015067  [ 7680/11641]\n",
      "loss: 0.008671  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.063943\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.023064  [    0/11641]\n",
      "loss: 0.045220  [ 2560/11641]\n",
      "loss: 0.006809  [ 5120/11641]\n",
      "loss: 0.004362  [ 7680/11641]\n",
      "loss: 0.015445  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.064985\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.029872  [    0/11641]\n",
      "loss: 0.018338  [ 2560/11641]\n",
      "loss: 0.033675  [ 5120/11641]\n",
      "loss: 0.016952  [ 7680/11641]\n",
      "loss: 0.007323  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.056164\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.006983  [    0/11641]\n",
      "loss: 0.003864  [ 2560/11641]\n",
      "loss: 0.019097  [ 5120/11641]\n",
      "loss: 0.009223  [ 7680/11641]\n",
      "loss: 0.014719  [10240/11641]\n",
      "Accuracy: 97.04%, Avg loss: 0.101030\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.055899  [    0/11641]\n",
      "loss: 0.028741  [ 2560/11641]\n",
      "loss: 0.005833  [ 5120/11641]\n",
      "loss: 0.007303  [ 7680/11641]\n",
      "loss: 0.044364  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.077442\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.007011  [    0/11641]\n",
      "loss: 0.015309  [ 2560/11641]\n",
      "loss: 0.042017  [ 5120/11641]\n",
      "loss: 0.009258  [ 7680/11641]\n",
      "loss: 0.016766  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.061324\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.008305  [    0/11641]\n",
      "loss: 0.030008  [ 2560/11641]\n",
      "loss: 0.027245  [ 5120/11641]\n",
      "loss: 0.034356  [ 7680/11641]\n",
      "loss: 0.042403  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.060564\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.017894  [    0/11641]\n",
      "loss: 0.006430  [ 2560/11641]\n",
      "loss: 0.021821  [ 5120/11641]\n",
      "loss: 0.019522  [ 7680/11641]\n",
      "loss: 0.008399  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.076009\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.013177  [    0/11641]\n",
      "loss: 0.033133  [ 2560/11641]\n",
      "loss: 0.003749  [ 5120/11641]\n",
      "loss: 0.011870  [ 7680/11641]\n",
      "loss: 0.014397  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.061988\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.014081  [    0/11641]\n",
      "loss: 0.006942  [ 2560/11641]\n",
      "loss: 0.004100  [ 5120/11641]\n",
      "loss: 0.056911  [ 7680/11641]\n",
      "loss: 0.014597  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.045815\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.016630  [    0/11641]\n",
      "loss: 0.013329  [ 2560/11641]\n",
      "loss: 0.035984  [ 5120/11641]\n",
      "loss: 0.042918  [ 7680/11641]\n",
      "loss: 0.018727  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.060534\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.017558  [    0/11641]\n",
      "loss: 0.013130  [ 2560/11641]\n",
      "loss: 0.015322  [ 5120/11641]\n",
      "loss: 0.014682  [ 7680/11641]\n",
      "loss: 0.008930  [10240/11641]\n",
      "Accuracy: 97.80%, Avg loss: 0.070767\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.034947  [    0/11641]\n",
      "loss: 0.008022  [ 2560/11641]\n",
      "loss: 0.011789  [ 5120/11641]\n",
      "loss: 0.018849  [ 7680/11641]\n",
      "loss: 0.002176  [10240/11641]\n",
      "Accuracy: 97.59%, Avg loss: 0.067874\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.021980  [    0/11641]\n",
      "loss: 0.024169  [ 2560/11641]\n",
      "loss: 0.027745  [ 5120/11641]\n",
      "loss: 0.011309  [ 7680/11641]\n",
      "loss: 0.014690  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.063109\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.010560  [    0/11641]\n",
      "loss: 0.013010  [ 2560/11641]\n",
      "loss: 0.015192  [ 5120/11641]\n",
      "loss: 0.008561  [ 7680/11641]\n",
      "loss: 0.003395  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.063419\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.032868  [    0/11641]\n",
      "loss: 0.011439  [ 2560/11641]\n",
      "loss: 0.018698  [ 5120/11641]\n",
      "loss: 0.015030  [ 7680/11641]\n",
      "loss: 0.020662  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.069970\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.004174  [    0/11641]\n",
      "loss: 0.030638  [ 2560/11641]\n",
      "loss: 0.005904  [ 5120/11641]\n",
      "loss: 0.002855  [ 7680/11641]\n",
      "loss: 0.005299  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.071202\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.018136  [    0/11641]\n",
      "loss: 0.010492  [ 2560/11641]\n",
      "loss: 0.010363  [ 5120/11641]\n",
      "loss: 0.020670  [ 7680/11641]\n",
      "loss: 0.009303  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.066912\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.003361  [    0/11641]\n",
      "loss: 0.016577  [ 2560/11641]\n",
      "loss: 0.050844  [ 5120/11641]\n",
      "loss: 0.011501  [ 7680/11641]\n",
      "loss: 0.025513  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.086221\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.016841  [    0/11641]\n",
      "loss: 0.022939  [ 2560/11641]\n",
      "loss: 0.021962  [ 5120/11641]\n",
      "loss: 0.013522  [ 7680/11641]\n",
      "loss: 0.037507  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.080675\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.006971  [    0/11641]\n",
      "loss: 0.064037  [ 2560/11641]\n",
      "loss: 0.027317  [ 5120/11641]\n",
      "loss: 0.017837  [ 7680/11641]\n",
      "loss: 0.012276  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.072074\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.013917  [    0/11641]\n",
      "loss: 0.004504  [ 2560/11641]\n",
      "loss: 0.015818  [ 5120/11641]\n",
      "loss: 0.019542  [ 7680/11641]\n",
      "loss: 0.044642  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.070092\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.007908  [    0/11641]\n",
      "loss: 0.026435  [ 2560/11641]\n",
      "loss: 0.007696  [ 5120/11641]\n",
      "loss: 0.001043  [ 7680/11641]\n",
      "loss: 0.008290  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.072891\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.035811  [    0/11641]\n",
      "loss: 0.026236  [ 2560/11641]\n",
      "loss: 0.012137  [ 5120/11641]\n",
      "loss: 0.002542  [ 7680/11641]\n",
      "loss: 0.006560  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.059335\n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.008148  [    0/11641]\n",
      "loss: 0.018844  [ 2560/11641]\n",
      "loss: 0.004118  [ 5120/11641]\n",
      "loss: 0.005349  [ 7680/11641]\n",
      "loss: 0.024129  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.067476\n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.009428  [    0/11641]\n",
      "loss: 0.008853  [ 2560/11641]\n",
      "loss: 0.025076  [ 5120/11641]\n",
      "loss: 0.008987  [ 7680/11641]\n",
      "loss: 0.002056  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.070897\n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.008517  [    0/11641]\n",
      "loss: 0.026381  [ 2560/11641]\n",
      "loss: 0.044106  [ 5120/11641]\n",
      "loss: 0.029389  [ 7680/11641]\n",
      "loss: 0.030173  [10240/11641]\n",
      "Accuracy: 97.25%, Avg loss: 0.104244\n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.060231  [    0/11641]\n",
      "loss: 0.036305  [ 2560/11641]\n",
      "loss: 0.061905  [ 5120/11641]\n",
      "loss: 0.014473  [ 7680/11641]\n",
      "loss: 0.011847  [10240/11641]\n",
      "Accuracy: 97.73%, Avg loss: 0.096514\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.029473  [    0/11641]\n",
      "loss: 0.013209  [ 2560/11641]\n",
      "loss: 0.051582  [ 5120/11641]\n",
      "loss: 0.007049  [ 7680/11641]\n",
      "loss: 0.014472  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.071942\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.020001  [    0/11641]\n",
      "loss: 0.006191  [ 2560/11641]\n",
      "loss: 0.002189  [ 5120/11641]\n",
      "loss: 0.009621  [ 7680/11641]\n",
      "loss: 0.015434  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.073970\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.005613  [    0/11641]\n",
      "loss: 0.007990  [ 2560/11641]\n",
      "loss: 0.040041  [ 5120/11641]\n",
      "loss: 0.018025  [ 7680/11641]\n",
      "loss: 0.004151  [10240/11641]\n",
      "Accuracy: 97.11%, Avg loss: 0.084096\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.003783  [    0/11641]\n",
      "loss: 0.035431  [ 2560/11641]\n",
      "loss: 0.009838  [ 5120/11641]\n",
      "loss: 0.018419  [ 7680/11641]\n",
      "loss: 0.015055  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.074030\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.005252  [    0/11641]\n",
      "loss: 0.010854  [ 2560/11641]\n",
      "loss: 0.012958  [ 5120/11641]\n",
      "loss: 0.008399  [ 7680/11641]\n",
      "loss: 0.003136  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.057526\n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.012093  [    0/11641]\n",
      "loss: 0.009789  [ 2560/11641]\n",
      "loss: 0.007399  [ 5120/11641]\n",
      "loss: 0.007690  [ 7680/11641]\n",
      "loss: 0.008015  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.068469\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.023600  [    0/11641]\n",
      "loss: 0.032003  [ 2560/11641]\n",
      "loss: 0.004452  [ 5120/11641]\n",
      "loss: 0.019534  [ 7680/11641]\n",
      "loss: 0.013447  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.067740\n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.007722  [    0/11641]\n",
      "loss: 0.005752  [ 2560/11641]\n",
      "loss: 0.004927  [ 5120/11641]\n",
      "loss: 0.020702  [ 7680/11641]\n",
      "loss: 0.004465  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.068242\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.002951  [    0/11641]\n",
      "loss: 0.018409  [ 2560/11641]\n",
      "loss: 0.014237  [ 5120/11641]\n",
      "loss: 0.015286  [ 7680/11641]\n",
      "loss: 0.004197  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.077393\n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.002167  [    0/11641]\n",
      "loss: 0.006549  [ 2560/11641]\n",
      "loss: 0.006000  [ 5120/11641]\n",
      "loss: 0.013648  [ 7680/11641]\n",
      "loss: 0.013682  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.070567\n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.016291  [    0/11641]\n",
      "loss: 0.010804  [ 2560/11641]\n",
      "loss: 0.002194  [ 5120/11641]\n",
      "loss: 0.014120  [ 7680/11641]\n",
      "loss: 0.008368  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.062703\n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.017920  [    0/11641]\n",
      "loss: 0.003200  [ 2560/11641]\n",
      "loss: 0.073048  [ 5120/11641]\n",
      "loss: 0.003975  [ 7680/11641]\n",
      "loss: 0.007066  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.061645\n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.001585  [    0/11641]\n",
      "loss: 0.004488  [ 2560/11641]\n",
      "loss: 0.007146  [ 5120/11641]\n",
      "loss: 0.010023  [ 7680/11641]\n",
      "loss: 0.007603  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.074399\n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.021446  [    0/11641]\n",
      "loss: 0.017662  [ 2560/11641]\n",
      "loss: 0.021091  [ 5120/11641]\n",
      "loss: 0.015704  [ 7680/11641]\n",
      "loss: 0.003871  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.075352\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.005035  [    0/11641]\n",
      "loss: 0.023067  [ 2560/11641]\n",
      "loss: 0.046436  [ 5120/11641]\n",
      "loss: 0.003029  [ 7680/11641]\n",
      "loss: 0.002487  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.058642\n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.024489  [    0/11641]\n",
      "loss: 0.012967  [ 2560/11641]\n",
      "loss: 0.011334  [ 5120/11641]\n",
      "loss: 0.022247  [ 7680/11641]\n",
      "loss: 0.004030  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.049340\n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.004749  [    0/11641]\n",
      "loss: 0.001854  [ 2560/11641]\n",
      "loss: 0.007095  [ 5120/11641]\n",
      "loss: 0.036127  [ 7680/11641]\n",
      "loss: 0.031697  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.084420\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.025666  [    0/11641]\n",
      "loss: 0.037572  [ 2560/11641]\n",
      "loss: 0.011630  [ 5120/11641]\n",
      "loss: 0.002159  [ 7680/11641]\n",
      "loss: 0.027993  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.056956\n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.007020  [    0/11641]\n",
      "loss: 0.007838  [ 2560/11641]\n",
      "loss: 0.012065  [ 5120/11641]\n",
      "loss: 0.022169  [ 7680/11641]\n",
      "loss: 0.015720  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.056654\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.002839  [    0/11641]\n",
      "loss: 0.034342  [ 2560/11641]\n",
      "loss: 0.039447  [ 5120/11641]\n",
      "loss: 0.003414  [ 7680/11641]\n",
      "loss: 0.003932  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.068964\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.006792  [    0/11641]\n",
      "loss: 0.010463  [ 2560/11641]\n",
      "loss: 0.002379  [ 5120/11641]\n",
      "loss: 0.008407  [ 7680/11641]\n",
      "loss: 0.002150  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.092521\n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.045334  [    0/11641]\n",
      "loss: 0.013308  [ 2560/11641]\n",
      "loss: 0.007791  [ 5120/11641]\n",
      "loss: 0.038607  [ 7680/11641]\n",
      "loss: 0.009269  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.066601\n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.004941  [    0/11641]\n",
      "loss: 0.054638  [ 2560/11641]\n",
      "loss: 0.007457  [ 5120/11641]\n",
      "loss: 0.014270  [ 7680/11641]\n",
      "loss: 0.019829  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.060248\n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.015526  [    0/11641]\n",
      "loss: 0.010567  [ 2560/11641]\n",
      "loss: 0.001506  [ 5120/11641]\n",
      "loss: 0.048788  [ 7680/11641]\n",
      "loss: 0.004266  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.068248\n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.008764  [    0/11641]\n",
      "loss: 0.006989  [ 2560/11641]\n",
      "loss: 0.029508  [ 5120/11641]\n",
      "loss: 0.018572  [ 7680/11641]\n",
      "loss: 0.019876  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.063203\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.003634  [    0/11641]\n",
      "loss: 0.004411  [ 2560/11641]\n",
      "loss: 0.006751  [ 5120/11641]\n",
      "loss: 0.023985  [ 7680/11641]\n",
      "loss: 0.018353  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.061615\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.020374  [    0/11641]\n",
      "loss: 0.002050  [ 2560/11641]\n",
      "loss: 0.006706  [ 5120/11641]\n",
      "loss: 0.004571  [ 7680/11641]\n",
      "loss: 0.009773  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.065011\n",
      "Model saved\n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.018597  [    0/11641]\n",
      "loss: 0.008073  [ 2560/11641]\n",
      "loss: 0.017308  [ 5120/11641]\n",
      "loss: 0.015043  [ 7680/11641]\n",
      "loss: 0.032254  [10240/11641]\n",
      "Accuracy: 97.66%, Avg loss: 0.089150\n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.007717  [    0/11641]\n",
      "loss: 0.017744  [ 2560/11641]\n",
      "loss: 0.009505  [ 5120/11641]\n",
      "loss: 0.019275  [ 7680/11641]\n",
      "loss: 0.027587  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.079007\n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.008053  [    0/11641]\n",
      "loss: 0.015061  [ 2560/11641]\n",
      "loss: 0.012021  [ 5120/11641]\n",
      "loss: 0.003709  [ 7680/11641]\n",
      "loss: 0.014877  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.068435\n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.008122  [    0/11641]\n",
      "loss: 0.002677  [ 2560/11641]\n",
      "loss: 0.003555  [ 5120/11641]\n",
      "loss: 0.043886  [ 7680/11641]\n",
      "loss: 0.030025  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.079068\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.005895  [    0/11641]\n",
      "loss: 0.024597  [ 2560/11641]\n",
      "loss: 0.011968  [ 5120/11641]\n",
      "loss: 0.032474  [ 7680/11641]\n",
      "loss: 0.014264  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.064336\n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.002174  [    0/11641]\n",
      "loss: 0.001203  [ 2560/11641]\n",
      "loss: 0.008228  [ 5120/11641]\n",
      "loss: 0.015022  [ 7680/11641]\n",
      "loss: 0.000674  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.071997\n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.021140  [    0/11641]\n",
      "loss: 0.015586  [ 2560/11641]\n",
      "loss: 0.001780  [ 5120/11641]\n",
      "loss: 0.009544  [ 7680/11641]\n",
      "loss: 0.001258  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.057300\n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.000617  [    0/11641]\n",
      "loss: 0.001118  [ 2560/11641]\n",
      "loss: 0.006297  [ 5120/11641]\n",
      "loss: 0.018846  [ 7680/11641]\n",
      "loss: 0.015291  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.067479\n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.006872  [    0/11641]\n",
      "loss: 0.033284  [ 2560/11641]\n",
      "loss: 0.004586  [ 5120/11641]\n",
      "loss: 0.029516  [ 7680/11641]\n",
      "loss: 0.027408  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.054161\n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.002874  [    0/11641]\n",
      "loss: 0.043805  [ 2560/11641]\n",
      "loss: 0.010834  [ 5120/11641]\n",
      "loss: 0.006455  [ 7680/11641]\n",
      "loss: 0.000476  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.065098\n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.012063  [    0/11641]\n",
      "loss: 0.014259  [ 2560/11641]\n",
      "loss: 0.006481  [ 5120/11641]\n",
      "loss: 0.002156  [ 7680/11641]\n",
      "loss: 0.020050  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.067924\n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.004580  [    0/11641]\n",
      "loss: 0.010437  [ 2560/11641]\n",
      "loss: 0.006686  [ 5120/11641]\n",
      "loss: 0.001082  [ 7680/11641]\n",
      "loss: 0.022053  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.063016\n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.002017  [    0/11641]\n",
      "loss: 0.018587  [ 2560/11641]\n",
      "loss: 0.002291  [ 5120/11641]\n",
      "loss: 0.002392  [ 7680/11641]\n",
      "loss: 0.027921  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.048817\n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.010954  [    0/11641]\n",
      "loss: 0.065939  [ 2560/11641]\n",
      "loss: 0.005393  [ 5120/11641]\n",
      "loss: 0.002596  [ 7680/11641]\n",
      "loss: 0.008614  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.064138\n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.015941  [    0/11641]\n",
      "loss: 0.013767  [ 2560/11641]\n",
      "loss: 0.013679  [ 5120/11641]\n",
      "loss: 0.011600  [ 7680/11641]\n",
      "loss: 0.008438  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.040919\n",
      "Model saved\n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.007865  [    0/11641]\n",
      "loss: 0.009426  [ 2560/11641]\n",
      "loss: 0.017918  [ 5120/11641]\n",
      "loss: 0.010844  [ 7680/11641]\n",
      "loss: 0.005754  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.051360\n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.008426  [    0/11641]\n",
      "loss: 0.000241  [ 2560/11641]\n",
      "loss: 0.000730  [ 5120/11641]\n",
      "loss: 0.007117  [ 7680/11641]\n",
      "loss: 0.033642  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.070208\n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.012491  [    0/11641]\n",
      "loss: 0.011042  [ 2560/11641]\n",
      "loss: 0.001912  [ 5120/11641]\n",
      "loss: 0.026888  [ 7680/11641]\n",
      "loss: 0.012792  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.063991\n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.020427  [    0/11641]\n",
      "loss: 0.004999  [ 2560/11641]\n",
      "loss: 0.018452  [ 5120/11641]\n",
      "loss: 0.013492  [ 7680/11641]\n",
      "loss: 0.007345  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.067350\n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.002743  [    0/11641]\n",
      "loss: 0.017058  [ 2560/11641]\n",
      "loss: 0.022971  [ 5120/11641]\n",
      "loss: 0.001625  [ 7680/11641]\n",
      "loss: 0.004038  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.081889\n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.003814  [    0/11641]\n",
      "loss: 0.009919  [ 2560/11641]\n",
      "loss: 0.004074  [ 5120/11641]\n",
      "loss: 0.005541  [ 7680/11641]\n",
      "loss: 0.009744  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.086360\n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.048949  [    0/11641]\n",
      "loss: 0.002095  [ 2560/11641]\n",
      "loss: 0.002290  [ 5120/11641]\n",
      "loss: 0.005121  [ 7680/11641]\n",
      "loss: 0.013520  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.062797\n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.050994  [    0/11641]\n",
      "loss: 0.004072  [ 2560/11641]\n",
      "loss: 0.006607  [ 5120/11641]\n",
      "loss: 0.002044  [ 7680/11641]\n",
      "loss: 0.037875  [10240/11641]\n",
      "Accuracy: 98.01%, Avg loss: 0.085251\n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.007816  [    0/11641]\n",
      "loss: 0.006992  [ 2560/11641]\n",
      "loss: 0.014159  [ 5120/11641]\n",
      "loss: 0.019241  [ 7680/11641]\n",
      "loss: 0.049152  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.074331\n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.011345  [    0/11641]\n",
      "loss: 0.012452  [ 2560/11641]\n",
      "loss: 0.008106  [ 5120/11641]\n",
      "loss: 0.006755  [ 7680/11641]\n",
      "loss: 0.001365  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.065936\n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.007561  [    0/11641]\n",
      "loss: 0.038358  [ 2560/11641]\n",
      "loss: 0.004200  [ 5120/11641]\n",
      "loss: 0.007408  [ 7680/11641]\n",
      "loss: 0.004629  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.057925\n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.002187  [    0/11641]\n",
      "loss: 0.011163  [ 2560/11641]\n",
      "loss: 0.001191  [ 5120/11641]\n",
      "loss: 0.012734  [ 7680/11641]\n",
      "loss: 0.015137  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.067078\n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.003299  [    0/11641]\n",
      "loss: 0.004255  [ 2560/11641]\n",
      "loss: 0.002745  [ 5120/11641]\n",
      "loss: 0.008961  [ 7680/11641]\n",
      "loss: 0.001616  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.067495\n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.007793  [    0/11641]\n",
      "loss: 0.003149  [ 2560/11641]\n",
      "loss: 0.002267  [ 5120/11641]\n",
      "loss: 0.020598  [ 7680/11641]\n",
      "loss: 0.015271  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.067447\n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.004613  [    0/11641]\n",
      "loss: 0.025448  [ 2560/11641]\n",
      "loss: 0.045249  [ 5120/11641]\n",
      "loss: 0.014181  [ 7680/11641]\n",
      "loss: 0.017826  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.060819\n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.005075  [    0/11641]\n",
      "loss: 0.001021  [ 2560/11641]\n",
      "loss: 0.009764  [ 5120/11641]\n",
      "loss: 0.016191  [ 7680/11641]\n",
      "loss: 0.037388  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.063536\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.016726  [    0/11641]\n",
      "loss: 0.000658  [ 2560/11641]\n",
      "loss: 0.006386  [ 5120/11641]\n",
      "loss: 0.012376  [ 7680/11641]\n",
      "loss: 0.005959  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.062594\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.007714  [    0/11641]\n",
      "loss: 0.010286  [ 2560/11641]\n",
      "loss: 0.002000  [ 5120/11641]\n",
      "loss: 0.003579  [ 7680/11641]\n",
      "loss: 0.002396  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.080640\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.010519  [    0/11641]\n",
      "loss: 0.026534  [ 2560/11641]\n",
      "loss: 0.021833  [ 5120/11641]\n",
      "loss: 0.022947  [ 7680/11641]\n",
      "loss: 0.027648  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.079138\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.015542  [    0/11641]\n",
      "loss: 0.004303  [ 2560/11641]\n",
      "loss: 0.022489  [ 5120/11641]\n",
      "loss: 0.016823  [ 7680/11641]\n",
      "loss: 0.019887  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.081980\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.018447  [    0/11641]\n",
      "loss: 0.006469  [ 2560/11641]\n",
      "loss: 0.008445  [ 5120/11641]\n",
      "loss: 0.013780  [ 7680/11641]\n",
      "loss: 0.006441  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.079686\n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.003933  [    0/11641]\n",
      "loss: 0.010477  [ 2560/11641]\n",
      "loss: 0.020126  [ 5120/11641]\n",
      "loss: 0.007952  [ 7680/11641]\n",
      "loss: 0.037638  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.071932\n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.003972  [    0/11641]\n",
      "loss: 0.012969  [ 2560/11641]\n",
      "loss: 0.011620  [ 5120/11641]\n",
      "loss: 0.005443  [ 7680/11641]\n",
      "loss: 0.004996  [10240/11641]\n",
      "Accuracy: 97.73%, Avg loss: 0.117506\n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.025030  [    0/11641]\n",
      "loss: 0.002127  [ 2560/11641]\n",
      "loss: 0.013473  [ 5120/11641]\n",
      "loss: 0.041796  [ 7680/11641]\n",
      "loss: 0.013267  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.072642\n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.015650  [    0/11641]\n",
      "loss: 0.006316  [ 2560/11641]\n",
      "loss: 0.012344  [ 5120/11641]\n",
      "loss: 0.008494  [ 7680/11641]\n",
      "loss: 0.001788  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.057159\n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.003410  [    0/11641]\n",
      "loss: 0.032772  [ 2560/11641]\n",
      "loss: 0.007543  [ 5120/11641]\n",
      "loss: 0.007352  [ 7680/11641]\n",
      "loss: 0.003023  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.065334\n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.002565  [    0/11641]\n",
      "loss: 0.002361  [ 2560/11641]\n",
      "loss: 0.006962  [ 5120/11641]\n",
      "loss: 0.006488  [ 7680/11641]\n",
      "loss: 0.005925  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.056760\n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.005702  [    0/11641]\n",
      "loss: 0.009572  [ 2560/11641]\n",
      "loss: 0.006067  [ 5120/11641]\n",
      "loss: 0.010547  [ 7680/11641]\n",
      "loss: 0.026362  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.069407\n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.028990  [    0/11641]\n",
      "loss: 0.018229  [ 2560/11641]\n",
      "loss: 0.002549  [ 5120/11641]\n",
      "loss: 0.009196  [ 7680/11641]\n",
      "loss: 0.005424  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.070227\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.003301  [    0/11641]\n",
      "loss: 0.001351  [ 2560/11641]\n",
      "loss: 0.001636  [ 5120/11641]\n",
      "loss: 0.015328  [ 7680/11641]\n",
      "loss: 0.002625  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.094852\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.003141  [    0/11641]\n",
      "loss: 0.026943  [ 2560/11641]\n",
      "loss: 0.000413  [ 5120/11641]\n",
      "loss: 0.001066  [ 7680/11641]\n",
      "loss: 0.004181  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.069027\n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.002346  [    0/11641]\n",
      "loss: 0.003175  [ 2560/11641]\n",
      "loss: 0.013889  [ 5120/11641]\n",
      "loss: 0.001787  [ 7680/11641]\n",
      "loss: 0.011199  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.062624\n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.001890  [    0/11641]\n",
      "loss: 0.014828  [ 2560/11641]\n",
      "loss: 0.007768  [ 5120/11641]\n",
      "loss: 0.001564  [ 7680/11641]\n",
      "loss: 0.000459  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.059802\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.013491  [    0/11641]\n",
      "loss: 0.006355  [ 2560/11641]\n",
      "loss: 0.007684  [ 5120/11641]\n",
      "loss: 0.012423  [ 7680/11641]\n",
      "loss: 0.000688  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.066882\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.002875  [    0/11641]\n",
      "loss: 0.000404  [ 2560/11641]\n",
      "loss: 0.000481  [ 5120/11641]\n",
      "loss: 0.004694  [ 7680/11641]\n",
      "loss: 0.002906  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.070384\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.003565  [    0/11641]\n",
      "loss: 0.002177  [ 2560/11641]\n",
      "loss: 0.007414  [ 5120/11641]\n",
      "loss: 0.015384  [ 7680/11641]\n",
      "loss: 0.003212  [10240/11641]\n",
      "Accuracy: 97.80%, Avg loss: 0.078184\n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.001709  [    0/11641]\n",
      "loss: 0.026054  [ 2560/11641]\n",
      "loss: 0.002952  [ 5120/11641]\n",
      "loss: 0.010656  [ 7680/11641]\n",
      "loss: 0.032509  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.076832\n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.016781  [    0/11641]\n",
      "loss: 0.010215  [ 2560/11641]\n",
      "loss: 0.003222  [ 5120/11641]\n",
      "loss: 0.008691  [ 7680/11641]\n",
      "loss: 0.007625  [10240/11641]\n",
      "Accuracy: 97.59%, Avg loss: 0.108504\n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.021536  [    0/11641]\n",
      "loss: 0.013610  [ 2560/11641]\n",
      "loss: 0.009480  [ 5120/11641]\n",
      "loss: 0.005016  [ 7680/11641]\n",
      "loss: 0.011600  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.070513\n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.002246  [    0/11641]\n",
      "loss: 0.002521  [ 2560/11641]\n",
      "loss: 0.000346  [ 5120/11641]\n",
      "loss: 0.004619  [ 7680/11641]\n",
      "loss: 0.003512  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.052953\n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.019664  [    0/11641]\n",
      "loss: 0.003725  [ 2560/11641]\n",
      "loss: 0.007485  [ 5120/11641]\n",
      "loss: 0.009985  [ 7680/11641]\n",
      "loss: 0.009794  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.046129\n",
      "Model saved\n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.004159  [    0/11641]\n",
      "loss: 0.002700  [ 2560/11641]\n",
      "loss: 0.002755  [ 5120/11641]\n",
      "loss: 0.010224  [ 7680/11641]\n",
      "loss: 0.004449  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.058586\n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.002214  [    0/11641]\n",
      "loss: 0.008483  [ 2560/11641]\n",
      "loss: 0.001581  [ 5120/11641]\n",
      "loss: 0.002766  [ 7680/11641]\n",
      "loss: 0.004744  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.080566\n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.001675  [    0/11641]\n",
      "loss: 0.010497  [ 2560/11641]\n",
      "loss: 0.002623  [ 5120/11641]\n",
      "loss: 0.010968  [ 7680/11641]\n",
      "loss: 0.018269  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.055468\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.009993  [    0/11641]\n",
      "loss: 0.000790  [ 2560/11641]\n",
      "loss: 0.005687  [ 5120/11641]\n",
      "loss: 0.007340  [ 7680/11641]\n",
      "loss: 0.002881  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.060095\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.005638  [    0/11641]\n",
      "loss: 0.022893  [ 2560/11641]\n",
      "loss: 0.001687  [ 5120/11641]\n",
      "loss: 0.001404  [ 7680/11641]\n",
      "loss: 0.006662  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.062690\n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.001703  [    0/11641]\n",
      "loss: 0.002604  [ 2560/11641]\n",
      "loss: 0.006829  [ 5120/11641]\n",
      "loss: 0.021732  [ 7680/11641]\n",
      "loss: 0.001010  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.057198\n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.003993  [    0/11641]\n",
      "loss: 0.001631  [ 2560/11641]\n",
      "loss: 0.002579  [ 5120/11641]\n",
      "loss: 0.002139  [ 7680/11641]\n",
      "loss: 0.001250  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.069862\n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.003963  [    0/11641]\n",
      "loss: 0.001905  [ 2560/11641]\n",
      "loss: 0.006394  [ 5120/11641]\n",
      "loss: 0.000790  [ 7680/11641]\n",
      "loss: 0.013339  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.078704\n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.008295  [    0/11641]\n",
      "loss: 0.014363  [ 2560/11641]\n",
      "loss: 0.004750  [ 5120/11641]\n",
      "loss: 0.001231  [ 7680/11641]\n",
      "loss: 0.011293  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.049353\n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.011322  [    0/11641]\n",
      "loss: 0.000966  [ 2560/11641]\n",
      "loss: 0.002921  [ 5120/11641]\n",
      "loss: 0.005203  [ 7680/11641]\n",
      "loss: 0.005158  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.101762\n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.006839  [    0/11641]\n",
      "loss: 0.002745  [ 2560/11641]\n",
      "loss: 0.004985  [ 5120/11641]\n",
      "loss: 0.001285  [ 7680/11641]\n",
      "loss: 0.008956  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.060586\n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.004968  [    0/11641]\n",
      "loss: 0.002736  [ 2560/11641]\n",
      "loss: 0.012222  [ 5120/11641]\n",
      "loss: 0.017730  [ 7680/11641]\n",
      "loss: 0.003071  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.054765\n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.003619  [    0/11641]\n",
      "loss: 0.002864  [ 2560/11641]\n",
      "loss: 0.001417  [ 5120/11641]\n",
      "loss: 0.000855  [ 7680/11641]\n",
      "loss: 0.001045  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.069800\n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.004136  [    0/11641]\n",
      "loss: 0.022387  [ 2560/11641]\n",
      "loss: 0.003648  [ 5120/11641]\n",
      "loss: 0.006214  [ 7680/11641]\n",
      "loss: 0.016147  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.071336\n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/11641]\n",
      "loss: 0.003935  [ 2560/11641]\n",
      "loss: 0.003640  [ 5120/11641]\n",
      "loss: 0.001370  [ 7680/11641]\n",
      "loss: 0.003201  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.072671\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.007370  [    0/11641]\n",
      "loss: 0.001993  [ 2560/11641]\n",
      "loss: 0.017597  [ 5120/11641]\n",
      "loss: 0.016722  [ 7680/11641]\n",
      "loss: 0.022538  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.071807\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.002040  [    0/11641]\n",
      "loss: 0.006213  [ 2560/11641]\n",
      "loss: 0.002077  [ 5120/11641]\n",
      "loss: 0.001579  [ 7680/11641]\n",
      "loss: 0.029025  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.099330\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000780  [    0/11641]\n",
      "loss: 0.008529  [ 2560/11641]\n",
      "loss: 0.014289  [ 5120/11641]\n",
      "loss: 0.002670  [ 7680/11641]\n",
      "loss: 0.004827  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.062900\n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.003139  [    0/11641]\n",
      "loss: 0.008652  [ 2560/11641]\n",
      "loss: 0.002131  [ 5120/11641]\n",
      "loss: 0.016297  [ 7680/11641]\n",
      "loss: 0.023303  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.069885\n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.001682  [    0/11641]\n",
      "loss: 0.007993  [ 2560/11641]\n",
      "loss: 0.014981  [ 5120/11641]\n",
      "loss: 0.006664  [ 7680/11641]\n",
      "loss: 0.007901  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.066031\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.005699  [    0/11641]\n",
      "loss: 0.003004  [ 2560/11641]\n",
      "loss: 0.010459  [ 5120/11641]\n",
      "loss: 0.018905  [ 7680/11641]\n",
      "loss: 0.028218  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.107979\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.002462  [    0/11641]\n",
      "loss: 0.002192  [ 2560/11641]\n",
      "loss: 0.004931  [ 5120/11641]\n",
      "loss: 0.001070  [ 7680/11641]\n",
      "loss: 0.005883  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.072097\n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.037900  [    0/11641]\n",
      "loss: 0.018977  [ 2560/11641]\n",
      "loss: 0.004005  [ 5120/11641]\n",
      "loss: 0.011342  [ 7680/11641]\n",
      "loss: 0.018583  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.065912\n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.001777  [    0/11641]\n",
      "loss: 0.010989  [ 2560/11641]\n",
      "loss: 0.043474  [ 5120/11641]\n",
      "loss: 0.008165  [ 7680/11641]\n",
      "loss: 0.003894  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.058590\n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.004275  [    0/11641]\n",
      "loss: 0.044911  [ 2560/11641]\n",
      "loss: 0.017005  [ 5120/11641]\n",
      "loss: 0.003204  [ 7680/11641]\n",
      "loss: 0.003944  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.074704\n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.005260  [    0/11641]\n",
      "loss: 0.037379  [ 2560/11641]\n",
      "loss: 0.001356  [ 5120/11641]\n",
      "loss: 0.004092  [ 7680/11641]\n",
      "loss: 0.004862  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.066287\n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.004904  [    0/11641]\n",
      "loss: 0.009349  [ 2560/11641]\n",
      "loss: 0.002840  [ 5120/11641]\n",
      "loss: 0.004194  [ 7680/11641]\n",
      "loss: 0.001493  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.060026\n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.000756  [    0/11641]\n",
      "loss: 0.000692  [ 2560/11641]\n",
      "loss: 0.007185  [ 5120/11641]\n",
      "loss: 0.001915  [ 7680/11641]\n",
      "loss: 0.004743  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.052769\n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.000736  [    0/11641]\n",
      "loss: 0.000363  [ 2560/11641]\n",
      "loss: 0.003172  [ 5120/11641]\n",
      "loss: 0.009017  [ 7680/11641]\n",
      "loss: 0.004211  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.064850\n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.011428  [    0/11641]\n",
      "loss: 0.016770  [ 2560/11641]\n",
      "loss: 0.000907  [ 5120/11641]\n",
      "loss: 0.004773  [ 7680/11641]\n",
      "loss: 0.003606  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.054065\n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.000930  [    0/11641]\n",
      "loss: 0.000252  [ 2560/11641]\n",
      "loss: 0.021543  [ 5120/11641]\n",
      "loss: 0.001382  [ 7680/11641]\n",
      "loss: 0.016840  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.068639\n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.000424  [    0/11641]\n",
      "loss: 0.004191  [ 2560/11641]\n",
      "loss: 0.013289  [ 5120/11641]\n",
      "loss: 0.004144  [ 7680/11641]\n",
      "loss: 0.015570  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.062996\n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.005394  [    0/11641]\n",
      "loss: 0.018135  [ 2560/11641]\n",
      "loss: 0.019230  [ 5120/11641]\n",
      "loss: 0.002963  [ 7680/11641]\n",
      "loss: 0.014222  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056133\n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.001103  [    0/11641]\n",
      "loss: 0.000593  [ 2560/11641]\n",
      "loss: 0.005674  [ 5120/11641]\n",
      "loss: 0.012136  [ 7680/11641]\n",
      "loss: 0.001216  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.089935\n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.014322  [    0/11641]\n",
      "loss: 0.002711  [ 2560/11641]\n",
      "loss: 0.009118  [ 5120/11641]\n",
      "loss: 0.002572  [ 7680/11641]\n",
      "loss: 0.004170  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.080114\n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.000411  [    0/11641]\n",
      "loss: 0.027542  [ 2560/11641]\n",
      "loss: 0.001895  [ 5120/11641]\n",
      "loss: 0.001782  [ 7680/11641]\n",
      "loss: 0.001004  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.068407\n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.003919  [    0/11641]\n",
      "loss: 0.000839  [ 2560/11641]\n",
      "loss: 0.001567  [ 5120/11641]\n",
      "loss: 0.002072  [ 7680/11641]\n",
      "loss: 0.000697  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.065653\n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.002799  [    0/11641]\n",
      "loss: 0.019951  [ 2560/11641]\n",
      "loss: 0.001056  [ 5120/11641]\n",
      "loss: 0.007682  [ 7680/11641]\n",
      "loss: 0.000402  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061127\n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000935  [    0/11641]\n",
      "loss: 0.006744  [ 2560/11641]\n",
      "loss: 0.003025  [ 5120/11641]\n",
      "loss: 0.004506  [ 7680/11641]\n",
      "loss: 0.011871  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.060668\n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.001905  [    0/11641]\n",
      "loss: 0.013445  [ 2560/11641]\n",
      "loss: 0.020931  [ 5120/11641]\n",
      "loss: 0.000971  [ 7680/11641]\n",
      "loss: 0.005666  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.087056\n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.012452  [    0/11641]\n",
      "loss: 0.000459  [ 2560/11641]\n",
      "loss: 0.001620  [ 5120/11641]\n",
      "loss: 0.021140  [ 7680/11641]\n",
      "loss: 0.001688  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.069638\n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.007115  [    0/11641]\n",
      "loss: 0.002726  [ 2560/11641]\n",
      "loss: 0.003168  [ 5120/11641]\n",
      "loss: 0.006286  [ 7680/11641]\n",
      "loss: 0.008452  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.063134\n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.002152  [    0/11641]\n",
      "loss: 0.002850  [ 2560/11641]\n",
      "loss: 0.005220  [ 5120/11641]\n",
      "loss: 0.005630  [ 7680/11641]\n",
      "loss: 0.003482  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.065981\n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000564  [    0/11641]\n",
      "loss: 0.001004  [ 2560/11641]\n",
      "loss: 0.000968  [ 5120/11641]\n",
      "loss: 0.015525  [ 7680/11641]\n",
      "loss: 0.047931  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.060533\n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.001505  [    0/11641]\n",
      "loss: 0.005824  [ 2560/11641]\n",
      "loss: 0.001418  [ 5120/11641]\n",
      "loss: 0.002514  [ 7680/11641]\n",
      "loss: 0.001559  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.079411\n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.021080  [    0/11641]\n",
      "loss: 0.002953  [ 2560/11641]\n",
      "loss: 0.042027  [ 5120/11641]\n",
      "loss: 0.006127  [ 7680/11641]\n",
      "loss: 0.024087  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.063684\n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.026185  [    0/11641]\n",
      "loss: 0.010192  [ 2560/11641]\n",
      "loss: 0.033338  [ 5120/11641]\n",
      "loss: 0.021193  [ 7680/11641]\n",
      "loss: 0.017060  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.087130\n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.019982  [    0/11641]\n",
      "loss: 0.011312  [ 2560/11641]\n",
      "loss: 0.028174  [ 5120/11641]\n",
      "loss: 0.013057  [ 7680/11641]\n",
      "loss: 0.022824  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.051923\n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.003043  [    0/11641]\n",
      "loss: 0.008947  [ 2560/11641]\n",
      "loss: 0.003898  [ 5120/11641]\n",
      "loss: 0.001145  [ 7680/11641]\n",
      "loss: 0.006646  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.086570\n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.011816  [    0/11641]\n",
      "loss: 0.028851  [ 2560/11641]\n",
      "loss: 0.026836  [ 5120/11641]\n",
      "loss: 0.002509  [ 7680/11641]\n",
      "loss: 0.009259  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.075043\n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.015507  [    0/11641]\n",
      "loss: 0.000366  [ 2560/11641]\n",
      "loss: 0.022550  [ 5120/11641]\n",
      "loss: 0.004654  [ 7680/11641]\n",
      "loss: 0.004193  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.079176\n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.003304  [    0/11641]\n",
      "loss: 0.002877  [ 2560/11641]\n",
      "loss: 0.001040  [ 5120/11641]\n",
      "loss: 0.000885  [ 7680/11641]\n",
      "loss: 0.002149  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.063530\n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.001697  [    0/11641]\n",
      "loss: 0.000652  [ 2560/11641]\n",
      "loss: 0.001677  [ 5120/11641]\n",
      "loss: 0.003821  [ 7680/11641]\n",
      "loss: 0.020834  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.067419\n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.017004  [    0/11641]\n",
      "loss: 0.002017  [ 2560/11641]\n",
      "loss: 0.006759  [ 5120/11641]\n",
      "loss: 0.000283  [ 7680/11641]\n",
      "loss: 0.000651  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.056132\n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.007372  [    0/11641]\n",
      "loss: 0.001566  [ 2560/11641]\n",
      "loss: 0.001131  [ 5120/11641]\n",
      "loss: 0.002403  [ 7680/11641]\n",
      "loss: 0.022250  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.051574\n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000359  [    0/11641]\n",
      "loss: 0.010654  [ 2560/11641]\n",
      "loss: 0.006618  [ 5120/11641]\n",
      "loss: 0.000279  [ 7680/11641]\n",
      "loss: 0.000962  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.063865\n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.003161  [    0/11641]\n",
      "loss: 0.015916  [ 2560/11641]\n",
      "loss: 0.025399  [ 5120/11641]\n",
      "loss: 0.024162  [ 7680/11641]\n",
      "loss: 0.000518  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.074920\n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.002379  [    0/11641]\n",
      "loss: 0.000596  [ 2560/11641]\n",
      "loss: 0.003219  [ 5120/11641]\n",
      "loss: 0.000821  [ 7680/11641]\n",
      "loss: 0.000836  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.065338\n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000290  [    0/11641]\n",
      "loss: 0.031655  [ 2560/11641]\n",
      "loss: 0.000721  [ 5120/11641]\n",
      "loss: 0.003973  [ 7680/11641]\n",
      "loss: 0.015898  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.074296\n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000764  [    0/11641]\n",
      "loss: 0.012976  [ 2560/11641]\n",
      "loss: 0.007767  [ 5120/11641]\n",
      "loss: 0.015785  [ 7680/11641]\n",
      "loss: 0.003552  [10240/11641]\n",
      "Accuracy: 97.94%, Avg loss: 0.073901\n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.024667  [    0/11641]\n",
      "loss: 0.050458  [ 2560/11641]\n",
      "loss: 0.014052  [ 5120/11641]\n",
      "loss: 0.012910  [ 7680/11641]\n",
      "loss: 0.011697  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.086338\n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.020182  [    0/11641]\n",
      "loss: 0.022254  [ 2560/11641]\n",
      "loss: 0.002029  [ 5120/11641]\n",
      "loss: 0.003300  [ 7680/11641]\n",
      "loss: 0.004168  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.068196\n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.008825  [    0/11641]\n",
      "loss: 0.003284  [ 2560/11641]\n",
      "loss: 0.003525  [ 5120/11641]\n",
      "loss: 0.013616  [ 7680/11641]\n",
      "loss: 0.015490  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.060381\n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.001692  [    0/11641]\n",
      "loss: 0.008575  [ 2560/11641]\n",
      "loss: 0.003772  [ 5120/11641]\n",
      "loss: 0.000648  [ 7680/11641]\n",
      "loss: 0.004626  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.072815\n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.005109  [    0/11641]\n",
      "loss: 0.027134  [ 2560/11641]\n",
      "loss: 0.003255  [ 5120/11641]\n",
      "loss: 0.001547  [ 7680/11641]\n",
      "loss: 0.000488  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.052521\n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.001606  [    0/11641]\n",
      "loss: 0.000597  [ 2560/11641]\n",
      "loss: 0.001649  [ 5120/11641]\n",
      "loss: 0.004516  [ 7680/11641]\n",
      "loss: 0.000763  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.060282\n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.019721  [    0/11641]\n",
      "loss: 0.004004  [ 2560/11641]\n",
      "loss: 0.007680  [ 5120/11641]\n",
      "loss: 0.058273  [ 7680/11641]\n",
      "loss: 0.014503  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.070322\n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.005580  [    0/11641]\n",
      "loss: 0.001537  [ 2560/11641]\n",
      "loss: 0.000981  [ 5120/11641]\n",
      "loss: 0.001445  [ 7680/11641]\n",
      "loss: 0.001075  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.074383\n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.001490  [    0/11641]\n",
      "loss: 0.001020  [ 2560/11641]\n",
      "loss: 0.002412  [ 5120/11641]\n",
      "loss: 0.004580  [ 7680/11641]\n",
      "loss: 0.000868  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.071291\n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.004195  [    0/11641]\n",
      "loss: 0.000563  [ 2560/11641]\n",
      "loss: 0.003694  [ 5120/11641]\n",
      "loss: 0.004769  [ 7680/11641]\n",
      "loss: 0.001419  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.073120\n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.006095  [    0/11641]\n",
      "loss: 0.001567  [ 2560/11641]\n",
      "loss: 0.001330  [ 5120/11641]\n",
      "loss: 0.009926  [ 7680/11641]\n",
      "loss: 0.005448  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.075397\n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.001680  [    0/11641]\n",
      "loss: 0.010092  [ 2560/11641]\n",
      "loss: 0.000654  [ 5120/11641]\n",
      "loss: 0.000378  [ 7680/11641]\n",
      "loss: 0.005571  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.083338\n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000464  [    0/11641]\n",
      "loss: 0.021988  [ 2560/11641]\n",
      "loss: 0.000956  [ 5120/11641]\n",
      "loss: 0.005168  [ 7680/11641]\n",
      "loss: 0.001586  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.073247\n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.001933  [    0/11641]\n",
      "loss: 0.025540  [ 2560/11641]\n",
      "loss: 0.010813  [ 5120/11641]\n",
      "loss: 0.031916  [ 7680/11641]\n",
      "loss: 0.000558  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.072613\n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.002246  [    0/11641]\n",
      "loss: 0.001693  [ 2560/11641]\n",
      "loss: 0.000554  [ 5120/11641]\n",
      "loss: 0.018864  [ 7680/11641]\n",
      "loss: 0.002012  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.060911\n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.001457  [    0/11641]\n",
      "loss: 0.001899  [ 2560/11641]\n",
      "loss: 0.001429  [ 5120/11641]\n",
      "loss: 0.007131  [ 7680/11641]\n",
      "loss: 0.031756  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.068632\n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.014052  [    0/11641]\n",
      "loss: 0.003731  [ 2560/11641]\n",
      "loss: 0.002119  [ 5120/11641]\n",
      "loss: 0.017791  [ 7680/11641]\n",
      "loss: 0.000512  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.066348\n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.005569  [    0/11641]\n",
      "loss: 0.005386  [ 2560/11641]\n",
      "loss: 0.019238  [ 5120/11641]\n",
      "loss: 0.001329  [ 7680/11641]\n",
      "loss: 0.004962  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.055300\n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.002630  [    0/11641]\n",
      "loss: 0.000595  [ 2560/11641]\n",
      "loss: 0.018455  [ 5120/11641]\n",
      "loss: 0.002182  [ 7680/11641]\n",
      "loss: 0.015230  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.077610\n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.022881  [    0/11641]\n",
      "loss: 0.011561  [ 2560/11641]\n",
      "loss: 0.001266  [ 5120/11641]\n",
      "loss: 0.001420  [ 7680/11641]\n",
      "loss: 0.003258  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.048184\n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000377  [    0/11641]\n",
      "loss: 0.002345  [ 2560/11641]\n",
      "loss: 0.002106  [ 5120/11641]\n",
      "loss: 0.007616  [ 7680/11641]\n",
      "loss: 0.001437  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056493\n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.003168  [    0/11641]\n",
      "loss: 0.001271  [ 2560/11641]\n",
      "loss: 0.004174  [ 5120/11641]\n",
      "loss: 0.001185  [ 7680/11641]\n",
      "loss: 0.000964  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.064798\n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.003064  [    0/11641]\n",
      "loss: 0.000905  [ 2560/11641]\n",
      "loss: 0.000136  [ 5120/11641]\n",
      "loss: 0.000102  [ 7680/11641]\n",
      "loss: 0.000771  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.061151\n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.004485  [    0/11641]\n",
      "loss: 0.001828  [ 2560/11641]\n",
      "loss: 0.011240  [ 5120/11641]\n",
      "loss: 0.001830  [ 7680/11641]\n",
      "loss: 0.000472  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.066266\n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.013809  [    0/11641]\n",
      "loss: 0.000593  [ 2560/11641]\n",
      "loss: 0.004409  [ 5120/11641]\n",
      "loss: 0.002070  [ 7680/11641]\n",
      "loss: 0.005226  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.053510\n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000706  [    0/11641]\n",
      "loss: 0.002822  [ 2560/11641]\n",
      "loss: 0.007680  [ 5120/11641]\n",
      "loss: 0.000198  [ 7680/11641]\n",
      "loss: 0.003099  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.075802\n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.001639  [    0/11641]\n",
      "loss: 0.000378  [ 2560/11641]\n",
      "loss: 0.011541  [ 5120/11641]\n",
      "loss: 0.016296  [ 7680/11641]\n",
      "loss: 0.000938  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.080990\n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.006258  [    0/11641]\n",
      "loss: 0.006474  [ 2560/11641]\n",
      "loss: 0.002568  [ 5120/11641]\n",
      "loss: 0.000750  [ 7680/11641]\n",
      "loss: 0.014493  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.073204\n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.006353  [    0/11641]\n",
      "loss: 0.002127  [ 2560/11641]\n",
      "loss: 0.001763  [ 5120/11641]\n",
      "loss: 0.002401  [ 7680/11641]\n",
      "loss: 0.001120  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.067833\n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.020229  [    0/11641]\n",
      "loss: 0.005171  [ 2560/11641]\n",
      "loss: 0.002939  [ 5120/11641]\n",
      "loss: 0.023500  [ 7680/11641]\n",
      "loss: 0.038822  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.072273\n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000988  [    0/11641]\n",
      "loss: 0.013607  [ 2560/11641]\n",
      "loss: 0.051154  [ 5120/11641]\n",
      "loss: 0.017597  [ 7680/11641]\n",
      "loss: 0.029258  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.063576\n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.000712  [    0/11641]\n",
      "loss: 0.009266  [ 2560/11641]\n",
      "loss: 0.011817  [ 5120/11641]\n",
      "loss: 0.014940  [ 7680/11641]\n",
      "loss: 0.000744  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.070764\n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.001988  [    0/11641]\n",
      "loss: 0.015233  [ 2560/11641]\n",
      "loss: 0.033078  [ 5120/11641]\n",
      "loss: 0.007864  [ 7680/11641]\n",
      "loss: 0.004561  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.068531\n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.013531  [    0/11641]\n",
      "loss: 0.019100  [ 2560/11641]\n",
      "loss: 0.002955  [ 5120/11641]\n",
      "loss: 0.015465  [ 7680/11641]\n",
      "loss: 0.003328  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.078510\n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.018557  [    0/11641]\n",
      "loss: 0.018042  [ 2560/11641]\n",
      "loss: 0.001640  [ 5120/11641]\n",
      "loss: 0.014322  [ 7680/11641]\n",
      "loss: 0.005748  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.083175\n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.014645  [    0/11641]\n",
      "loss: 0.004101  [ 2560/11641]\n",
      "loss: 0.003611  [ 5120/11641]\n",
      "loss: 0.000311  [ 7680/11641]\n",
      "loss: 0.001595  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.062396\n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.009584  [    0/11641]\n",
      "loss: 0.001674  [ 2560/11641]\n",
      "loss: 0.004347  [ 5120/11641]\n",
      "loss: 0.000289  [ 7680/11641]\n",
      "loss: 0.004178  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.064365\n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.002987  [    0/11641]\n",
      "loss: 0.013345  [ 2560/11641]\n",
      "loss: 0.000663  [ 5120/11641]\n",
      "loss: 0.004977  [ 7680/11641]\n",
      "loss: 0.004081  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.085945\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.003304  [    0/11641]\n",
      "loss: 0.016070  [ 2560/11641]\n",
      "loss: 0.005604  [ 5120/11641]\n",
      "loss: 0.004795  [ 7680/11641]\n",
      "loss: 0.022856  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.065229\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.001773  [    0/11641]\n",
      "loss: 0.027291  [ 2560/11641]\n",
      "loss: 0.000421  [ 5120/11641]\n",
      "loss: 0.002867  [ 7680/11641]\n",
      "loss: 0.007590  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.056886\n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.000445  [    0/11641]\n",
      "loss: 0.008153  [ 2560/11641]\n",
      "loss: 0.007024  [ 5120/11641]\n",
      "loss: 0.004466  [ 7680/11641]\n",
      "loss: 0.002212  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.048120\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000792  [    0/11641]\n",
      "loss: 0.009524  [ 2560/11641]\n",
      "loss: 0.000807  [ 5120/11641]\n",
      "loss: 0.008154  [ 7680/11641]\n",
      "loss: 0.002875  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.065471\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.000847  [    0/11641]\n",
      "loss: 0.007616  [ 2560/11641]\n",
      "loss: 0.002023  [ 5120/11641]\n",
      "loss: 0.001815  [ 7680/11641]\n",
      "loss: 0.002009  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.062045\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/11641]\n",
      "loss: 0.003922  [ 2560/11641]\n",
      "loss: 0.000882  [ 5120/11641]\n",
      "loss: 0.006616  [ 7680/11641]\n",
      "loss: 0.000825  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.054317\n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000242  [    0/11641]\n",
      "loss: 0.000350  [ 2560/11641]\n",
      "loss: 0.006253  [ 5120/11641]\n",
      "loss: 0.016368  [ 7680/11641]\n",
      "loss: 0.001022  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.051789\n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.007661  [    0/11641]\n",
      "loss: 0.010778  [ 2560/11641]\n",
      "loss: 0.000839  [ 5120/11641]\n",
      "loss: 0.000344  [ 7680/11641]\n",
      "loss: 0.008717  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.080137\n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.001024  [    0/11641]\n",
      "loss: 0.001511  [ 2560/11641]\n",
      "loss: 0.022176  [ 5120/11641]\n",
      "loss: 0.010729  [ 7680/11641]\n",
      "loss: 0.002964  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.061712\n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.003492  [    0/11641]\n",
      "loss: 0.003646  [ 2560/11641]\n",
      "loss: 0.002342  [ 5120/11641]\n",
      "loss: 0.013688  [ 7680/11641]\n",
      "loss: 0.006398  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.056598\n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/11641]\n",
      "loss: 0.000742  [ 2560/11641]\n",
      "loss: 0.002878  [ 5120/11641]\n",
      "loss: 0.001161  [ 7680/11641]\n",
      "loss: 0.002794  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.049806\n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.002836  [    0/11641]\n",
      "loss: 0.003245  [ 2560/11641]\n",
      "loss: 0.002413  [ 5120/11641]\n",
      "loss: 0.003068  [ 7680/11641]\n",
      "loss: 0.009285  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.070686\n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.000707  [    0/11641]\n",
      "loss: 0.000379  [ 2560/11641]\n",
      "loss: 0.001094  [ 5120/11641]\n",
      "loss: 0.001508  [ 7680/11641]\n",
      "loss: 0.001522  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.082484\n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.000260  [    0/11641]\n",
      "loss: 0.001468  [ 2560/11641]\n",
      "loss: 0.000870  [ 5120/11641]\n",
      "loss: 0.002574  [ 7680/11641]\n",
      "loss: 0.000076  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.073531\n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.003212  [    0/11641]\n",
      "loss: 0.003758  [ 2560/11641]\n",
      "loss: 0.002919  [ 5120/11641]\n",
      "loss: 0.005961  [ 7680/11641]\n",
      "loss: 0.022477  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.066742\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.019614  [    0/11641]\n",
      "loss: 0.002642  [ 2560/11641]\n",
      "loss: 0.003813  [ 5120/11641]\n",
      "loss: 0.002397  [ 7680/11641]\n",
      "loss: 0.000650  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.089881\n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.004256  [    0/11641]\n",
      "loss: 0.001635  [ 2560/11641]\n",
      "loss: 0.002990  [ 5120/11641]\n",
      "loss: 0.000694  [ 7680/11641]\n",
      "loss: 0.011198  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.076453\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.001634  [    0/11641]\n",
      "loss: 0.010433  [ 2560/11641]\n",
      "loss: 0.015105  [ 5120/11641]\n",
      "loss: 0.034778  [ 7680/11641]\n",
      "loss: 0.006140  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.079067\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.014731  [    0/11641]\n",
      "loss: 0.014812  [ 2560/11641]\n",
      "loss: 0.002800  [ 5120/11641]\n",
      "loss: 0.001137  [ 7680/11641]\n",
      "loss: 0.003062  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.074099\n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.003623  [    0/11641]\n",
      "loss: 0.000356  [ 2560/11641]\n",
      "loss: 0.000100  [ 5120/11641]\n",
      "loss: 0.003672  [ 7680/11641]\n",
      "loss: 0.006472  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.073605\n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.006864  [    0/11641]\n",
      "loss: 0.003292  [ 2560/11641]\n",
      "loss: 0.006483  [ 5120/11641]\n",
      "loss: 0.002225  [ 7680/11641]\n",
      "loss: 0.001171  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.083323\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.018202  [    0/11641]\n",
      "loss: 0.005836  [ 2560/11641]\n",
      "loss: 0.007087  [ 5120/11641]\n",
      "loss: 0.006831  [ 7680/11641]\n",
      "loss: 0.001583  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.085083\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.001102  [    0/11641]\n",
      "loss: 0.004970  [ 2560/11641]\n",
      "loss: 0.002738  [ 5120/11641]\n",
      "loss: 0.001612  [ 7680/11641]\n",
      "loss: 0.000448  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.084535\n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.001040  [    0/11641]\n",
      "loss: 0.000409  [ 2560/11641]\n",
      "loss: 0.001269  [ 5120/11641]\n",
      "loss: 0.000866  [ 7680/11641]\n",
      "loss: 0.002488  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.071479\n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.000418  [    0/11641]\n",
      "loss: 0.003779  [ 2560/11641]\n",
      "loss: 0.002829  [ 5120/11641]\n",
      "loss: 0.001115  [ 7680/11641]\n",
      "loss: 0.005727  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.053273\n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.000425  [    0/11641]\n",
      "loss: 0.000990  [ 2560/11641]\n",
      "loss: 0.001712  [ 5120/11641]\n",
      "loss: 0.008231  [ 7680/11641]\n",
      "loss: 0.000164  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.057625\n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.004074  [    0/11641]\n",
      "loss: 0.005352  [ 2560/11641]\n",
      "loss: 0.029812  [ 5120/11641]\n",
      "loss: 0.027575  [ 7680/11641]\n",
      "loss: 0.001066  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.071314\n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/11641]\n",
      "loss: 0.000372  [ 2560/11641]\n",
      "loss: 0.001965  [ 5120/11641]\n",
      "loss: 0.016173  [ 7680/11641]\n",
      "loss: 0.014855  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.089886\n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.000571  [    0/11641]\n",
      "loss: 0.005800  [ 2560/11641]\n",
      "loss: 0.040540  [ 5120/11641]\n",
      "loss: 0.021809  [ 7680/11641]\n",
      "loss: 0.030076  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.081432\n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.004518  [    0/11641]\n",
      "loss: 0.013695  [ 2560/11641]\n",
      "loss: 0.001548  [ 5120/11641]\n",
      "loss: 0.001966  [ 7680/11641]\n",
      "loss: 0.007470  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.073421\n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.002415  [    0/11641]\n",
      "loss: 0.008999  [ 2560/11641]\n",
      "loss: 0.002077  [ 5120/11641]\n",
      "loss: 0.010040  [ 7680/11641]\n",
      "loss: 0.000513  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.075924\n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.030441  [    0/11641]\n",
      "loss: 0.007922  [ 2560/11641]\n",
      "loss: 0.006979  [ 5120/11641]\n",
      "loss: 0.005213  [ 7680/11641]\n",
      "loss: 0.005486  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.055047\n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.013587  [    0/11641]\n",
      "loss: 0.002903  [ 2560/11641]\n",
      "loss: 0.000535  [ 5120/11641]\n",
      "loss: 0.006244  [ 7680/11641]\n",
      "loss: 0.001023  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.057220\n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.000569  [    0/11641]\n",
      "loss: 0.005335  [ 2560/11641]\n",
      "loss: 0.000578  [ 5120/11641]\n",
      "loss: 0.020296  [ 7680/11641]\n",
      "loss: 0.004085  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.065954\n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.006951  [    0/11641]\n",
      "loss: 0.000362  [ 2560/11641]\n",
      "loss: 0.000725  [ 5120/11641]\n",
      "loss: 0.000494  [ 7680/11641]\n",
      "loss: 0.000240  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.056086\n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.000282  [    0/11641]\n",
      "loss: 0.003445  [ 2560/11641]\n",
      "loss: 0.001455  [ 5120/11641]\n",
      "loss: 0.000406  [ 7680/11641]\n",
      "loss: 0.001625  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.058015\n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.005821  [    0/11641]\n",
      "loss: 0.014005  [ 2560/11641]\n",
      "loss: 0.000308  [ 5120/11641]\n",
      "loss: 0.006104  [ 7680/11641]\n",
      "loss: 0.004639  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.070446\n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.003219  [    0/11641]\n",
      "loss: 0.000444  [ 2560/11641]\n",
      "loss: 0.001258  [ 5120/11641]\n",
      "loss: 0.001786  [ 7680/11641]\n",
      "loss: 0.001090  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.084711\n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.001998  [    0/11641]\n",
      "loss: 0.005579  [ 2560/11641]\n",
      "loss: 0.001545  [ 5120/11641]\n",
      "loss: 0.017429  [ 7680/11641]\n",
      "loss: 0.003161  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.066945\n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.018190  [    0/11641]\n",
      "loss: 0.003165  [ 2560/11641]\n",
      "loss: 0.002300  [ 5120/11641]\n",
      "loss: 0.017086  [ 7680/11641]\n",
      "loss: 0.008526  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.069916\n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.001127  [    0/11641]\n",
      "loss: 0.018231  [ 2560/11641]\n",
      "loss: 0.020683  [ 5120/11641]\n",
      "loss: 0.002977  [ 7680/11641]\n",
      "loss: 0.005012  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.080202\n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.011884  [    0/11641]\n",
      "loss: 0.003812  [ 2560/11641]\n",
      "loss: 0.000174  [ 5120/11641]\n",
      "loss: 0.001087  [ 7680/11641]\n",
      "loss: 0.006489  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.069341\n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.002993  [    0/11641]\n",
      "loss: 0.000223  [ 2560/11641]\n",
      "loss: 0.003299  [ 5120/11641]\n",
      "loss: 0.004698  [ 7680/11641]\n",
      "loss: 0.001865  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.082257\n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.015836  [    0/11641]\n",
      "loss: 0.003606  [ 2560/11641]\n",
      "loss: 0.000667  [ 5120/11641]\n",
      "loss: 0.004067  [ 7680/11641]\n",
      "loss: 0.002692  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.052055\n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.019492  [    0/11641]\n",
      "loss: 0.001491  [ 2560/11641]\n",
      "loss: 0.003390  [ 5120/11641]\n",
      "loss: 0.000810  [ 7680/11641]\n",
      "loss: 0.000903  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.058615\n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.000213  [    0/11641]\n",
      "loss: 0.001238  [ 2560/11641]\n",
      "loss: 0.000899  [ 5120/11641]\n",
      "loss: 0.000954  [ 7680/11641]\n",
      "loss: 0.000245  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.061052\n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.003443  [    0/11641]\n",
      "loss: 0.000288  [ 2560/11641]\n",
      "loss: 0.000426  [ 5120/11641]\n",
      "loss: 0.001810  [ 7680/11641]\n",
      "loss: 0.000135  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.066710\n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.001666  [    0/11641]\n",
      "loss: 0.000757  [ 2560/11641]\n",
      "loss: 0.006709  [ 5120/11641]\n",
      "loss: 0.005220  [ 7680/11641]\n",
      "loss: 0.004093  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.066135\n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.002816  [    0/11641]\n",
      "loss: 0.031333  [ 2560/11641]\n",
      "loss: 0.000605  [ 5120/11641]\n",
      "loss: 0.006242  [ 7680/11641]\n",
      "loss: 0.004036  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.069845\n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.003061  [    0/11641]\n",
      "loss: 0.000995  [ 2560/11641]\n",
      "loss: 0.000725  [ 5120/11641]\n",
      "loss: 0.006541  [ 7680/11641]\n",
      "loss: 0.003400  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.055168\n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.000115  [    0/11641]\n",
      "loss: 0.001807  [ 2560/11641]\n",
      "loss: 0.000761  [ 5120/11641]\n",
      "loss: 0.002428  [ 7680/11641]\n",
      "loss: 0.000139  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.041744\n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.005707  [    0/11641]\n",
      "loss: 0.013446  [ 2560/11641]\n",
      "loss: 0.000529  [ 5120/11641]\n",
      "loss: 0.000324  [ 7680/11641]\n",
      "loss: 0.011877  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.076161\n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.000478  [    0/11641]\n",
      "loss: 0.009306  [ 2560/11641]\n",
      "loss: 0.005630  [ 5120/11641]\n",
      "loss: 0.008223  [ 7680/11641]\n",
      "loss: 0.009769  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.078788\n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.018786  [    0/11641]\n",
      "loss: 0.018393  [ 2560/11641]\n",
      "loss: 0.007561  [ 5120/11641]\n",
      "loss: 0.008111  [ 7680/11641]\n",
      "loss: 0.003858  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.063066\n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.002404  [    0/11641]\n",
      "loss: 0.017439  [ 2560/11641]\n",
      "loss: 0.000980  [ 5120/11641]\n",
      "loss: 0.000223  [ 7680/11641]\n",
      "loss: 0.003186  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.085466\n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.000848  [    0/11641]\n",
      "loss: 0.009008  [ 2560/11641]\n",
      "loss: 0.000196  [ 5120/11641]\n",
      "loss: 0.000051  [ 7680/11641]\n",
      "loss: 0.002915  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.065204\n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/11641]\n",
      "loss: 0.000667  [ 2560/11641]\n",
      "loss: 0.007466  [ 5120/11641]\n",
      "loss: 0.001108  [ 7680/11641]\n",
      "loss: 0.013718  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.084733\n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.000660  [    0/11641]\n",
      "loss: 0.001794  [ 2560/11641]\n",
      "loss: 0.000168  [ 5120/11641]\n",
      "loss: 0.000247  [ 7680/11641]\n",
      "loss: 0.002554  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.053304\n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.000621  [    0/11641]\n",
      "loss: 0.000829  [ 2560/11641]\n",
      "loss: 0.000865  [ 5120/11641]\n",
      "loss: 0.008443  [ 7680/11641]\n",
      "loss: 0.017059  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.091929\n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.013444  [    0/11641]\n",
      "loss: 0.001325  [ 2560/11641]\n",
      "loss: 0.005518  [ 5120/11641]\n",
      "loss: 0.013918  [ 7680/11641]\n",
      "loss: 0.003734  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.075931\n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.000945  [    0/11641]\n",
      "loss: 0.002624  [ 2560/11641]\n",
      "loss: 0.021214  [ 5120/11641]\n",
      "loss: 0.010982  [ 7680/11641]\n",
      "loss: 0.007175  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.072429\n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.000619  [    0/11641]\n",
      "loss: 0.020038  [ 2560/11641]\n",
      "loss: 0.011537  [ 5120/11641]\n",
      "loss: 0.000610  [ 7680/11641]\n",
      "loss: 0.029892  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.076706\n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.007417  [    0/11641]\n",
      "loss: 0.004642  [ 2560/11641]\n",
      "loss: 0.020916  [ 5120/11641]\n",
      "loss: 0.000698  [ 7680/11641]\n",
      "loss: 0.006889  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.054154\n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.003244  [    0/11641]\n",
      "loss: 0.000511  [ 2560/11641]\n",
      "loss: 0.000969  [ 5120/11641]\n",
      "loss: 0.001397  [ 7680/11641]\n",
      "loss: 0.000181  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.053105\n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.003797  [    0/11641]\n",
      "loss: 0.006894  [ 2560/11641]\n",
      "loss: 0.002852  [ 5120/11641]\n",
      "loss: 0.009565  [ 7680/11641]\n",
      "loss: 0.006365  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.068080\n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.003932  [    0/11641]\n",
      "loss: 0.021235  [ 2560/11641]\n",
      "loss: 0.000877  [ 5120/11641]\n",
      "loss: 0.005735  [ 7680/11641]\n",
      "loss: 0.013630  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.059336\n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.010600  [    0/11641]\n",
      "loss: 0.000404  [ 2560/11641]\n",
      "loss: 0.009995  [ 5120/11641]\n",
      "loss: 0.006365  [ 7680/11641]\n",
      "loss: 0.002844  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.063833\n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.004003  [    0/11641]\n",
      "loss: 0.001365  [ 2560/11641]\n",
      "loss: 0.000862  [ 5120/11641]\n",
      "loss: 0.001860  [ 7680/11641]\n",
      "loss: 0.000683  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.051134\n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.001161  [    0/11641]\n",
      "loss: 0.001816  [ 2560/11641]\n",
      "loss: 0.000164  [ 5120/11641]\n",
      "loss: 0.004360  [ 7680/11641]\n",
      "loss: 0.001409  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.061995\n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.000242  [    0/11641]\n",
      "loss: 0.006346  [ 2560/11641]\n",
      "loss: 0.003113  [ 5120/11641]\n",
      "loss: 0.000421  [ 7680/11641]\n",
      "loss: 0.004523  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.073554\n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.014389  [    0/11641]\n",
      "loss: 0.000157  [ 2560/11641]\n",
      "loss: 0.001437  [ 5120/11641]\n",
      "loss: 0.000151  [ 7680/11641]\n",
      "loss: 0.001574  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.078000\n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.003820  [    0/11641]\n",
      "loss: 0.002055  [ 2560/11641]\n",
      "loss: 0.000377  [ 5120/11641]\n",
      "loss: 0.000750  [ 7680/11641]\n",
      "loss: 0.001004  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.058320\n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.001859  [    0/11641]\n",
      "loss: 0.001730  [ 2560/11641]\n",
      "loss: 0.002782  [ 5120/11641]\n",
      "loss: 0.012296  [ 7680/11641]\n",
      "loss: 0.007146  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.059705\n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.033337  [    0/11641]\n",
      "loss: 0.002800  [ 2560/11641]\n",
      "loss: 0.008074  [ 5120/11641]\n",
      "loss: 0.000242  [ 7680/11641]\n",
      "loss: 0.000870  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.071340\n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.005823  [    0/11641]\n",
      "loss: 0.017258  [ 2560/11641]\n",
      "loss: 0.002925  [ 5120/11641]\n",
      "loss: 0.015285  [ 7680/11641]\n",
      "loss: 0.001006  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.065153\n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.008532  [    0/11641]\n",
      "loss: 0.009237  [ 2560/11641]\n",
      "loss: 0.013285  [ 5120/11641]\n",
      "loss: 0.010078  [ 7680/11641]\n",
      "loss: 0.022899  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.053576\n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.011603  [    0/11641]\n",
      "loss: 0.002949  [ 2560/11641]\n",
      "loss: 0.008155  [ 5120/11641]\n",
      "loss: 0.003250  [ 7680/11641]\n",
      "loss: 0.001655  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.068775\n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.037758  [    0/11641]\n",
      "loss: 0.032027  [ 2560/11641]\n",
      "loss: 0.001603  [ 5120/11641]\n",
      "loss: 0.005406  [ 7680/11641]\n",
      "loss: 0.012770  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.039173\n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.006137  [    0/11641]\n",
      "loss: 0.001685  [ 2560/11641]\n",
      "loss: 0.003543  [ 5120/11641]\n",
      "loss: 0.001720  [ 7680/11641]\n",
      "loss: 0.002760  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.084094\n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.000939  [    0/11641]\n",
      "loss: 0.001373  [ 2560/11641]\n",
      "loss: 0.013128  [ 5120/11641]\n",
      "loss: 0.001480  [ 7680/11641]\n",
      "loss: 0.024354  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.070577\n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.006654  [    0/11641]\n",
      "loss: 0.001544  [ 2560/11641]\n",
      "loss: 0.013050  [ 5120/11641]\n",
      "loss: 0.000266  [ 7680/11641]\n",
      "loss: 0.015004  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.068209\n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.001113  [    0/11641]\n",
      "loss: 0.002116  [ 2560/11641]\n",
      "loss: 0.007642  [ 5120/11641]\n",
      "loss: 0.012045  [ 7680/11641]\n",
      "loss: 0.000316  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.088441\n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.003541  [    0/11641]\n",
      "loss: 0.007071  [ 2560/11641]\n",
      "loss: 0.000799  [ 5120/11641]\n",
      "loss: 0.000500  [ 7680/11641]\n",
      "loss: 0.005186  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.064678\n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.000536  [    0/11641]\n",
      "loss: 0.000558  [ 2560/11641]\n",
      "loss: 0.012951  [ 5120/11641]\n",
      "loss: 0.010518  [ 7680/11641]\n",
      "loss: 0.005428  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.062302\n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.001038  [    0/11641]\n",
      "loss: 0.007990  [ 2560/11641]\n",
      "loss: 0.023060  [ 5120/11641]\n",
      "loss: 0.011783  [ 7680/11641]\n",
      "loss: 0.002598  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.064956\n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.011304  [    0/11641]\n",
      "loss: 0.000669  [ 2560/11641]\n",
      "loss: 0.002125  [ 5120/11641]\n",
      "loss: 0.005772  [ 7680/11641]\n",
      "loss: 0.000205  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.046531\n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.000242  [    0/11641]\n",
      "loss: 0.001908  [ 2560/11641]\n",
      "loss: 0.000100  [ 5120/11641]\n",
      "loss: 0.000483  [ 7680/11641]\n",
      "loss: 0.001890  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.060782\n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.000643  [    0/11641]\n",
      "loss: 0.000294  [ 2560/11641]\n",
      "loss: 0.000224  [ 5120/11641]\n",
      "loss: 0.000470  [ 7680/11641]\n",
      "loss: 0.000110  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.069435\n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.001927  [    0/11641]\n",
      "loss: 0.000413  [ 2560/11641]\n",
      "loss: 0.002308  [ 5120/11641]\n",
      "loss: 0.000287  [ 7680/11641]\n",
      "loss: 0.002475  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.065519\n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.002606  [    0/11641]\n",
      "loss: 0.001811  [ 2560/11641]\n",
      "loss: 0.000117  [ 5120/11641]\n",
      "loss: 0.000079  [ 7680/11641]\n",
      "loss: 0.002279  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.059913\n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.002627  [    0/11641]\n",
      "loss: 0.000295  [ 2560/11641]\n",
      "loss: 0.000160  [ 5120/11641]\n",
      "loss: 0.001566  [ 7680/11641]\n",
      "loss: 0.000740  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.085736\n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.002637  [    0/11641]\n",
      "loss: 0.003889  [ 2560/11641]\n",
      "loss: 0.002328  [ 5120/11641]\n",
      "loss: 0.000304  [ 7680/11641]\n",
      "loss: 0.003597  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.053242\n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.000664  [    0/11641]\n",
      "loss: 0.029014  [ 2560/11641]\n",
      "loss: 0.001279  [ 5120/11641]\n",
      "loss: 0.011438  [ 7680/11641]\n",
      "loss: 0.006792  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.091159\n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.002495  [    0/11641]\n",
      "loss: 0.030879  [ 2560/11641]\n",
      "loss: 0.000536  [ 5120/11641]\n",
      "loss: 0.027996  [ 7680/11641]\n",
      "loss: 0.016931  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.165095\n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.044278  [    0/11641]\n",
      "loss: 0.001158  [ 2560/11641]\n",
      "loss: 0.002779  [ 5120/11641]\n",
      "loss: 0.001356  [ 7680/11641]\n",
      "loss: 0.012912  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.065937\n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.009669  [    0/11641]\n",
      "loss: 0.008674  [ 2560/11641]\n",
      "loss: 0.009562  [ 5120/11641]\n",
      "loss: 0.000696  [ 7680/11641]\n",
      "loss: 0.001612  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.106425\n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.007425  [    0/11641]\n",
      "loss: 0.003542  [ 2560/11641]\n",
      "loss: 0.004523  [ 5120/11641]\n",
      "loss: 0.001453  [ 7680/11641]\n",
      "loss: 0.000891  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.080338\n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.005393  [    0/11641]\n",
      "loss: 0.001490  [ 2560/11641]\n",
      "loss: 0.000893  [ 5120/11641]\n",
      "loss: 0.018156  [ 7680/11641]\n",
      "loss: 0.000755  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.059577\n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.000104  [    0/11641]\n",
      "loss: 0.011783  [ 2560/11641]\n",
      "loss: 0.011176  [ 5120/11641]\n",
      "loss: 0.001078  [ 7680/11641]\n",
      "loss: 0.005336  [10240/11641]\n",
      "Accuracy: 97.80%, Avg loss: 0.100948\n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.031201  [    0/11641]\n",
      "loss: 0.000652  [ 2560/11641]\n",
      "loss: 0.029679  [ 5120/11641]\n",
      "loss: 0.003229  [ 7680/11641]\n",
      "loss: 0.003874  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.088509\n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.000083  [    0/11641]\n",
      "loss: 0.010889  [ 2560/11641]\n",
      "loss: 0.004446  [ 5120/11641]\n",
      "loss: 0.005164  [ 7680/11641]\n",
      "loss: 0.016484  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.068198\n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.005543  [    0/11641]\n",
      "loss: 0.009377  [ 2560/11641]\n",
      "loss: 0.000146  [ 5120/11641]\n",
      "loss: 0.019734  [ 7680/11641]\n",
      "loss: 0.000265  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.064150\n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.002247  [    0/11641]\n",
      "loss: 0.001314  [ 2560/11641]\n",
      "loss: 0.014656  [ 5120/11641]\n",
      "loss: 0.000719  [ 7680/11641]\n",
      "loss: 0.002444  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.062445\n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.006339  [    0/11641]\n",
      "loss: 0.037583  [ 2560/11641]\n",
      "loss: 0.005612  [ 5120/11641]\n",
      "loss: 0.000435  [ 7680/11641]\n",
      "loss: 0.000178  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.074441\n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.000694  [    0/11641]\n",
      "loss: 0.003471  [ 2560/11641]\n",
      "loss: 0.006987  [ 5120/11641]\n",
      "loss: 0.013062  [ 7680/11641]\n",
      "loss: 0.002973  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.078047\n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.005893  [    0/11641]\n",
      "loss: 0.015867  [ 2560/11641]\n",
      "loss: 0.004926  [ 5120/11641]\n",
      "loss: 0.009229  [ 7680/11641]\n",
      "loss: 0.005080  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.069554\n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.000944  [    0/11641]\n",
      "loss: 0.000913  [ 2560/11641]\n",
      "loss: 0.000947  [ 5120/11641]\n",
      "loss: 0.004988  [ 7680/11641]\n",
      "loss: 0.000424  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.052353\n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.011343  [    0/11641]\n",
      "loss: 0.000454  [ 2560/11641]\n",
      "loss: 0.001535  [ 5120/11641]\n",
      "loss: 0.001977  [ 7680/11641]\n",
      "loss: 0.002708  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.055234\n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.002519  [    0/11641]\n",
      "loss: 0.000479  [ 2560/11641]\n",
      "loss: 0.007259  [ 5120/11641]\n",
      "loss: 0.011941  [ 7680/11641]\n",
      "loss: 0.001275  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.051999\n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.009177  [    0/11641]\n",
      "loss: 0.002033  [ 2560/11641]\n",
      "loss: 0.001921  [ 5120/11641]\n",
      "loss: 0.000681  [ 7680/11641]\n",
      "loss: 0.000587  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.047918\n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.001025  [    0/11641]\n",
      "loss: 0.000365  [ 2560/11641]\n",
      "loss: 0.001202  [ 5120/11641]\n",
      "loss: 0.003539  [ 7680/11641]\n",
      "loss: 0.001833  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.058159\n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.003228  [    0/11641]\n",
      "loss: 0.000398  [ 2560/11641]\n",
      "loss: 0.000218  [ 5120/11641]\n",
      "loss: 0.008351  [ 7680/11641]\n",
      "loss: 0.000268  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.047178\n",
      "Model saved\n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.000589  [    0/11641]\n",
      "loss: 0.002360  [ 2560/11641]\n",
      "loss: 0.001185  [ 5120/11641]\n",
      "loss: 0.006772  [ 7680/11641]\n",
      "loss: 0.008370  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061621\n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/11641]\n",
      "loss: 0.011545  [ 2560/11641]\n",
      "loss: 0.003217  [ 5120/11641]\n",
      "loss: 0.022618  [ 7680/11641]\n",
      "loss: 0.021718  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.056587\n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.000158  [    0/11641]\n",
      "loss: 0.000902  [ 2560/11641]\n",
      "loss: 0.000321  [ 5120/11641]\n",
      "loss: 0.000179  [ 7680/11641]\n",
      "loss: 0.003809  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.062410\n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.012383  [    0/11641]\n",
      "loss: 0.004190  [ 2560/11641]\n",
      "loss: 0.002824  [ 5120/11641]\n",
      "loss: 0.004705  [ 7680/11641]\n",
      "loss: 0.000211  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.059391\n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.000746  [    0/11641]\n",
      "loss: 0.000188  [ 2560/11641]\n",
      "loss: 0.006078  [ 5120/11641]\n",
      "loss: 0.015761  [ 7680/11641]\n",
      "loss: 0.001472  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.042381\n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.000345  [    0/11641]\n",
      "loss: 0.003086  [ 2560/11641]\n",
      "loss: 0.011252  [ 5120/11641]\n",
      "loss: 0.012968  [ 7680/11641]\n",
      "loss: 0.002818  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.058247\n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.000097  [    0/11641]\n",
      "loss: 0.012504  [ 2560/11641]\n",
      "loss: 0.005883  [ 5120/11641]\n",
      "loss: 0.000253  [ 7680/11641]\n",
      "loss: 0.001861  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.056026\n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.000410  [    0/11641]\n",
      "loss: 0.000265  [ 2560/11641]\n",
      "loss: 0.000253  [ 5120/11641]\n",
      "loss: 0.000352  [ 7680/11641]\n",
      "loss: 0.000639  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.083023\n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.000153  [    0/11641]\n",
      "loss: 0.002454  [ 2560/11641]\n",
      "loss: 0.017442  [ 5120/11641]\n",
      "loss: 0.002956  [ 7680/11641]\n",
      "loss: 0.000177  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.050897\n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.000594  [    0/11641]\n",
      "loss: 0.000339  [ 2560/11641]\n",
      "loss: 0.000287  [ 5120/11641]\n",
      "loss: 0.000711  [ 7680/11641]\n",
      "loss: 0.000881  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.085838\n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.000151  [    0/11641]\n",
      "loss: 0.006035  [ 2560/11641]\n",
      "loss: 0.002807  [ 5120/11641]\n",
      "loss: 0.000295  [ 7680/11641]\n",
      "loss: 0.002643  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.054857\n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.001523  [    0/11641]\n",
      "loss: 0.000593  [ 2560/11641]\n",
      "loss: 0.000780  [ 5120/11641]\n",
      "loss: 0.000577  [ 7680/11641]\n",
      "loss: 0.002228  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.060816\n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.002376  [    0/11641]\n",
      "loss: 0.000226  [ 2560/11641]\n",
      "loss: 0.000720  [ 5120/11641]\n",
      "loss: 0.000733  [ 7680/11641]\n",
      "loss: 0.000217  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.044982\n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.000432  [    0/11641]\n",
      "loss: 0.007954  [ 2560/11641]\n",
      "loss: 0.000093  [ 5120/11641]\n",
      "loss: 0.007062  [ 7680/11641]\n",
      "loss: 0.000113  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.061619\n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.010823  [    0/11641]\n",
      "loss: 0.000341  [ 2560/11641]\n",
      "loss: 0.004574  [ 5120/11641]\n",
      "loss: 0.002690  [ 7680/11641]\n",
      "loss: 0.002543  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.055201\n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.006143  [    0/11641]\n",
      "loss: 0.010001  [ 2560/11641]\n",
      "loss: 0.000777  [ 5120/11641]\n",
      "loss: 0.007790  [ 7680/11641]\n",
      "loss: 0.000083  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.067765\n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.000109  [    0/11641]\n",
      "loss: 0.000734  [ 2560/11641]\n",
      "loss: 0.001047  [ 5120/11641]\n",
      "loss: 0.003030  [ 7680/11641]\n",
      "loss: 0.003828  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.088547\n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.000737  [    0/11641]\n",
      "loss: 0.014067  [ 2560/11641]\n",
      "loss: 0.013013  [ 5120/11641]\n",
      "loss: 0.000776  [ 7680/11641]\n",
      "loss: 0.034499  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.046566\n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.008587  [    0/11641]\n",
      "loss: 0.001030  [ 2560/11641]\n",
      "loss: 0.017218  [ 5120/11641]\n",
      "loss: 0.002236  [ 7680/11641]\n",
      "loss: 0.005303  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.072561\n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.002145  [    0/11641]\n",
      "loss: 0.001239  [ 2560/11641]\n",
      "loss: 0.008458  [ 5120/11641]\n",
      "loss: 0.037217  [ 7680/11641]\n",
      "loss: 0.029780  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.051918\n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.005250  [    0/11641]\n",
      "loss: 0.001938  [ 2560/11641]\n",
      "loss: 0.001508  [ 5120/11641]\n",
      "loss: 0.001183  [ 7680/11641]\n",
      "loss: 0.002939  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.041651\n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/11641]\n",
      "loss: 0.000609  [ 2560/11641]\n",
      "loss: 0.017662  [ 5120/11641]\n",
      "loss: 0.007523  [ 7680/11641]\n",
      "loss: 0.000586  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.053935\n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.000395  [    0/11641]\n",
      "loss: 0.000064  [ 2560/11641]\n",
      "loss: 0.000133  [ 5120/11641]\n",
      "loss: 0.005657  [ 7680/11641]\n",
      "loss: 0.001184  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.044892\n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.007559  [    0/11641]\n",
      "loss: 0.000560  [ 2560/11641]\n",
      "loss: 0.001226  [ 5120/11641]\n",
      "loss: 0.009565  [ 7680/11641]\n",
      "loss: 0.000570  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.046668\n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/11641]\n",
      "loss: 0.012159  [ 2560/11641]\n",
      "loss: 0.006315  [ 5120/11641]\n",
      "loss: 0.000511  [ 7680/11641]\n",
      "loss: 0.000072  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.049380\n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.000964  [    0/11641]\n",
      "loss: 0.000182  [ 2560/11641]\n",
      "loss: 0.001815  [ 5120/11641]\n",
      "loss: 0.018691  [ 7680/11641]\n",
      "loss: 0.003056  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.063963\n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.001116  [    0/11641]\n",
      "loss: 0.001557  [ 2560/11641]\n",
      "loss: 0.043406  [ 5120/11641]\n",
      "loss: 0.003122  [ 7680/11641]\n",
      "loss: 0.010428  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.077704\n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.003874  [    0/11641]\n",
      "loss: 0.001869  [ 2560/11641]\n",
      "loss: 0.008895  [ 5120/11641]\n",
      "loss: 0.002247  [ 7680/11641]\n",
      "loss: 0.000398  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061927\n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.000468  [    0/11641]\n",
      "loss: 0.001896  [ 2560/11641]\n",
      "loss: 0.000068  [ 5120/11641]\n",
      "loss: 0.000899  [ 7680/11641]\n",
      "loss: 0.008503  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.058587\n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.000628  [    0/11641]\n",
      "loss: 0.000429  [ 2560/11641]\n",
      "loss: 0.012478  [ 5120/11641]\n",
      "loss: 0.018156  [ 7680/11641]\n",
      "loss: 0.003159  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.064034\n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.007253  [    0/11641]\n",
      "loss: 0.001758  [ 2560/11641]\n",
      "loss: 0.000539  [ 5120/11641]\n",
      "loss: 0.005027  [ 7680/11641]\n",
      "loss: 0.002368  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.042874\n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.023752  [    0/11641]\n",
      "loss: 0.001124  [ 2560/11641]\n",
      "loss: 0.000538  [ 5120/11641]\n",
      "loss: 0.000085  [ 7680/11641]\n",
      "loss: 0.000313  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.050892\n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.000108  [    0/11641]\n",
      "loss: 0.027329  [ 2560/11641]\n",
      "loss: 0.010278  [ 5120/11641]\n",
      "loss: 0.020247  [ 7680/11641]\n",
      "loss: 0.020566  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.055146\n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.010326  [    0/11641]\n",
      "loss: 0.000736  [ 2560/11641]\n",
      "loss: 0.001240  [ 5120/11641]\n",
      "loss: 0.005713  [ 7680/11641]\n",
      "loss: 0.000160  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.058384\n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.001484  [    0/11641]\n",
      "loss: 0.022387  [ 2560/11641]\n",
      "loss: 0.000177  [ 5120/11641]\n",
      "loss: 0.000051  [ 7680/11641]\n",
      "loss: 0.017100  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056856\n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.001496  [    0/11641]\n",
      "loss: 0.001281  [ 2560/11641]\n",
      "loss: 0.000269  [ 5120/11641]\n",
      "loss: 0.002837  [ 7680/11641]\n",
      "loss: 0.001835  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.055927\n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.002232  [    0/11641]\n",
      "loss: 0.000264  [ 2560/11641]\n",
      "loss: 0.000107  [ 5120/11641]\n",
      "loss: 0.000258  [ 7680/11641]\n",
      "loss: 0.004606  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.059480\n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.000356  [    0/11641]\n",
      "loss: 0.001899  [ 2560/11641]\n",
      "loss: 0.002366  [ 5120/11641]\n",
      "loss: 0.002369  [ 7680/11641]\n",
      "loss: 0.017129  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.055272\n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.001473  [    0/11641]\n",
      "loss: 0.013706  [ 2560/11641]\n",
      "loss: 0.000634  [ 5120/11641]\n",
      "loss: 0.009597  [ 7680/11641]\n",
      "loss: 0.009705  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.064702\n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.000614  [    0/11641]\n",
      "loss: 0.000803  [ 2560/11641]\n",
      "loss: 0.001219  [ 5120/11641]\n",
      "loss: 0.000754  [ 7680/11641]\n",
      "loss: 0.003901  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.083990\n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.003742  [    0/11641]\n",
      "loss: 0.028706  [ 2560/11641]\n",
      "loss: 0.001035  [ 5120/11641]\n",
      "loss: 0.010380  [ 7680/11641]\n",
      "loss: 0.018401  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.056277\n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.009709  [    0/11641]\n",
      "loss: 0.011728  [ 2560/11641]\n",
      "loss: 0.004067  [ 5120/11641]\n",
      "loss: 0.000335  [ 7680/11641]\n",
      "loss: 0.002752  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.060413\n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.000429  [    0/11641]\n",
      "loss: 0.003240  [ 2560/11641]\n",
      "loss: 0.001511  [ 5120/11641]\n",
      "loss: 0.000201  [ 7680/11641]\n",
      "loss: 0.001439  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.049262\n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.000885  [    0/11641]\n",
      "loss: 0.023909  [ 2560/11641]\n",
      "loss: 0.001366  [ 5120/11641]\n",
      "loss: 0.003705  [ 7680/11641]\n",
      "loss: 0.000701  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.082152\n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.021015  [    0/11641]\n",
      "loss: 0.000325  [ 2560/11641]\n",
      "loss: 0.005445  [ 5120/11641]\n",
      "loss: 0.012821  [ 7680/11641]\n",
      "loss: 0.000290  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061798\n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.005066  [    0/11641]\n",
      "loss: 0.000473  [ 2560/11641]\n",
      "loss: 0.000034  [ 5120/11641]\n",
      "loss: 0.001339  [ 7680/11641]\n",
      "loss: 0.010301  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.069412\n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.000629  [    0/11641]\n",
      "loss: 0.000704  [ 2560/11641]\n",
      "loss: 0.002352  [ 5120/11641]\n",
      "loss: 0.000973  [ 7680/11641]\n",
      "loss: 0.025460  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.059786\n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.000146  [    0/11641]\n",
      "loss: 0.000700  [ 2560/11641]\n",
      "loss: 0.000564  [ 5120/11641]\n",
      "loss: 0.007175  [ 7680/11641]\n",
      "loss: 0.028044  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.075390\n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.019375  [    0/11641]\n",
      "loss: 0.016411  [ 2560/11641]\n",
      "loss: 0.001220  [ 5120/11641]\n",
      "loss: 0.007249  [ 7680/11641]\n",
      "loss: 0.000875  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.076998\n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.000356  [    0/11641]\n",
      "loss: 0.008360  [ 2560/11641]\n",
      "loss: 0.003124  [ 5120/11641]\n",
      "loss: 0.000405  [ 7680/11641]\n",
      "loss: 0.024387  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.062773\n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.002020  [    0/11641]\n",
      "loss: 0.000322  [ 2560/11641]\n",
      "loss: 0.000520  [ 5120/11641]\n",
      "loss: 0.019535  [ 7680/11641]\n",
      "loss: 0.001053  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.047448\n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.001586  [    0/11641]\n",
      "loss: 0.016348  [ 2560/11641]\n",
      "loss: 0.000464  [ 5120/11641]\n",
      "loss: 0.002364  [ 7680/11641]\n",
      "loss: 0.002766  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.055895\n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.000674  [    0/11641]\n",
      "loss: 0.005598  [ 2560/11641]\n",
      "loss: 0.013000  [ 5120/11641]\n",
      "loss: 0.005222  [ 7680/11641]\n",
      "loss: 0.000080  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.062394\n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.003780  [    0/11641]\n",
      "loss: 0.006821  [ 2560/11641]\n",
      "loss: 0.002924  [ 5120/11641]\n",
      "loss: 0.000365  [ 7680/11641]\n",
      "loss: 0.000732  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.060731\n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.002291  [    0/11641]\n",
      "loss: 0.003038  [ 2560/11641]\n",
      "loss: 0.000225  [ 5120/11641]\n",
      "loss: 0.000237  [ 7680/11641]\n",
      "loss: 0.023321  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.083087\n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.002360  [    0/11641]\n",
      "loss: 0.012154  [ 2560/11641]\n",
      "loss: 0.000810  [ 5120/11641]\n",
      "loss: 0.000527  [ 7680/11641]\n",
      "loss: 0.000992  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.074262\n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/11641]\n",
      "loss: 0.006916  [ 2560/11641]\n",
      "loss: 0.002146  [ 5120/11641]\n",
      "loss: 0.004909  [ 7680/11641]\n",
      "loss: 0.001425  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.067879\n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.001437  [    0/11641]\n",
      "loss: 0.003473  [ 2560/11641]\n",
      "loss: 0.006768  [ 5120/11641]\n",
      "loss: 0.005134  [ 7680/11641]\n",
      "loss: 0.002861  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.077494\n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.000900  [    0/11641]\n",
      "loss: 0.001075  [ 2560/11641]\n",
      "loss: 0.000344  [ 5120/11641]\n",
      "loss: 0.012940  [ 7680/11641]\n",
      "loss: 0.023690  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.060611\n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.000912  [    0/11641]\n",
      "loss: 0.003520  [ 2560/11641]\n",
      "loss: 0.009408  [ 5120/11641]\n",
      "loss: 0.012200  [ 7680/11641]\n",
      "loss: 0.009878  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.065179\n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.000257  [    0/11641]\n",
      "loss: 0.002310  [ 2560/11641]\n",
      "loss: 0.004244  [ 5120/11641]\n",
      "loss: 0.004753  [ 7680/11641]\n",
      "loss: 0.000175  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.085024\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.016629  [    0/11641]\n",
      "loss: 0.002458  [ 2560/11641]\n",
      "loss: 0.001279  [ 5120/11641]\n",
      "loss: 0.017323  [ 7680/11641]\n",
      "loss: 0.008087  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.054772\n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.000199  [    0/11641]\n",
      "loss: 0.000066  [ 2560/11641]\n",
      "loss: 0.009788  [ 5120/11641]\n",
      "loss: 0.000092  [ 7680/11641]\n",
      "loss: 0.008347  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.060860\n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.022488  [    0/11641]\n",
      "loss: 0.055409  [ 2560/11641]\n",
      "loss: 0.008564  [ 5120/11641]\n",
      "loss: 0.000414  [ 7680/11641]\n",
      "loss: 0.001216  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.071396\n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.002823  [    0/11641]\n",
      "loss: 0.009849  [ 2560/11641]\n",
      "loss: 0.000101  [ 5120/11641]\n",
      "loss: 0.000142  [ 7680/11641]\n",
      "loss: 0.000808  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.070682\n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.000082  [    0/11641]\n",
      "loss: 0.008193  [ 2560/11641]\n",
      "loss: 0.005469  [ 5120/11641]\n",
      "loss: 0.001760  [ 7680/11641]\n",
      "loss: 0.005500  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053529\n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.001025  [    0/11641]\n",
      "loss: 0.006819  [ 2560/11641]\n",
      "loss: 0.008470  [ 5120/11641]\n",
      "loss: 0.014042  [ 7680/11641]\n",
      "loss: 0.000362  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.054800\n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.001274  [    0/11641]\n",
      "loss: 0.000338  [ 2560/11641]\n",
      "loss: 0.001193  [ 5120/11641]\n",
      "loss: 0.000527  [ 7680/11641]\n",
      "loss: 0.000553  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.050311\n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.002068  [    0/11641]\n",
      "loss: 0.007882  [ 2560/11641]\n",
      "loss: 0.000191  [ 5120/11641]\n",
      "loss: 0.014048  [ 7680/11641]\n",
      "loss: 0.003075  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.081281\n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.004285  [    0/11641]\n",
      "loss: 0.005161  [ 2560/11641]\n",
      "loss: 0.005051  [ 5120/11641]\n",
      "loss: 0.001603  [ 7680/11641]\n",
      "loss: 0.001326  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.044870\n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.001916  [    0/11641]\n",
      "loss: 0.002247  [ 2560/11641]\n",
      "loss: 0.005758  [ 5120/11641]\n",
      "loss: 0.015694  [ 7680/11641]\n",
      "loss: 0.013434  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.052370\n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.002303  [    0/11641]\n",
      "loss: 0.028335  [ 2560/11641]\n",
      "loss: 0.001326  [ 5120/11641]\n",
      "loss: 0.000296  [ 7680/11641]\n",
      "loss: 0.005587  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.053137\n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.000916  [    0/11641]\n",
      "loss: 0.003709  [ 2560/11641]\n",
      "loss: 0.000089  [ 5120/11641]\n",
      "loss: 0.001073  [ 7680/11641]\n",
      "loss: 0.006099  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.055972\n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/11641]\n",
      "loss: 0.000872  [ 2560/11641]\n",
      "loss: 0.001774  [ 5120/11641]\n",
      "loss: 0.003072  [ 7680/11641]\n",
      "loss: 0.002917  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.057054\n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.002896  [    0/11641]\n",
      "loss: 0.005162  [ 2560/11641]\n",
      "loss: 0.000622  [ 5120/11641]\n",
      "loss: 0.000042  [ 7680/11641]\n",
      "loss: 0.002414  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.057847\n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.010899  [    0/11641]\n",
      "loss: 0.000910  [ 2560/11641]\n",
      "loss: 0.000253  [ 5120/11641]\n",
      "loss: 0.000431  [ 7680/11641]\n",
      "loss: 0.002120  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.062466\n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/11641]\n",
      "loss: 0.002012  [ 2560/11641]\n",
      "loss: 0.000132  [ 5120/11641]\n",
      "loss: 0.000200  [ 7680/11641]\n",
      "loss: 0.000514  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.059127\n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.000248  [    0/11641]\n",
      "loss: 0.003838  [ 2560/11641]\n",
      "loss: 0.001426  [ 5120/11641]\n",
      "loss: 0.000085  [ 7680/11641]\n",
      "loss: 0.000228  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.068732\n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.010715  [    0/11641]\n",
      "loss: 0.000761  [ 2560/11641]\n",
      "loss: 0.000494  [ 5120/11641]\n",
      "loss: 0.001943  [ 7680/11641]\n",
      "loss: 0.000823  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.072250\n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.000299  [    0/11641]\n",
      "loss: 0.000064  [ 2560/11641]\n",
      "loss: 0.000404  [ 5120/11641]\n",
      "loss: 0.000816  [ 7680/11641]\n",
      "loss: 0.000520  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.059798\n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.003925  [    0/11641]\n",
      "loss: 0.000152  [ 2560/11641]\n",
      "loss: 0.002546  [ 5120/11641]\n",
      "loss: 0.002237  [ 7680/11641]\n",
      "loss: 0.001052  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.035371\n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.000071  [    0/11641]\n",
      "loss: 0.000542  [ 2560/11641]\n",
      "loss: 0.000239  [ 5120/11641]\n",
      "loss: 0.000061  [ 7680/11641]\n",
      "loss: 0.000051  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.054823\n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.001195  [    0/11641]\n",
      "loss: 0.004008  [ 2560/11641]\n",
      "loss: 0.001970  [ 5120/11641]\n",
      "loss: 0.000148  [ 7680/11641]\n",
      "loss: 0.003628  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.049875\n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.000455  [    0/11641]\n",
      "loss: 0.001290  [ 2560/11641]\n",
      "loss: 0.001170  [ 5120/11641]\n",
      "loss: 0.000341  [ 7680/11641]\n",
      "loss: 0.001148  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.048044\n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.015181  [    0/11641]\n",
      "loss: 0.000136  [ 2560/11641]\n",
      "loss: 0.013607  [ 5120/11641]\n",
      "loss: 0.000066  [ 7680/11641]\n",
      "loss: 0.000073  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.057347\n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.004955  [    0/11641]\n",
      "loss: 0.000632  [ 2560/11641]\n",
      "loss: 0.000104  [ 5120/11641]\n",
      "loss: 0.000084  [ 7680/11641]\n",
      "loss: 0.000415  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.073880\n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.000440  [    0/11641]\n",
      "loss: 0.002510  [ 2560/11641]\n",
      "loss: 0.003044  [ 5120/11641]\n",
      "loss: 0.005732  [ 7680/11641]\n",
      "loss: 0.000234  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.052355\n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.001103  [    0/11641]\n",
      "loss: 0.001250  [ 2560/11641]\n",
      "loss: 0.000444  [ 5120/11641]\n",
      "loss: 0.004701  [ 7680/11641]\n",
      "loss: 0.001413  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.103580\n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.000705  [    0/11641]\n",
      "loss: 0.001674  [ 2560/11641]\n",
      "loss: 0.009884  [ 5120/11641]\n",
      "loss: 0.022198  [ 7680/11641]\n",
      "loss: 0.010676  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.066485\n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.001442  [    0/11641]\n",
      "loss: 0.000333  [ 2560/11641]\n",
      "loss: 0.008350  [ 5120/11641]\n",
      "loss: 0.003513  [ 7680/11641]\n",
      "loss: 0.001504  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.055500\n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.000442  [    0/11641]\n",
      "loss: 0.001378  [ 2560/11641]\n",
      "loss: 0.001063  [ 5120/11641]\n",
      "loss: 0.003973  [ 7680/11641]\n",
      "loss: 0.024919  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.053258\n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.001603  [    0/11641]\n",
      "loss: 0.000455  [ 2560/11641]\n",
      "loss: 0.000262  [ 5120/11641]\n",
      "loss: 0.001403  [ 7680/11641]\n",
      "loss: 0.002725  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.069135\n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.000956  [    0/11641]\n",
      "loss: 0.003751  [ 2560/11641]\n",
      "loss: 0.035753  [ 5120/11641]\n",
      "loss: 0.000989  [ 7680/11641]\n",
      "loss: 0.016053  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.058858\n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.024105  [    0/11641]\n",
      "loss: 0.001168  [ 2560/11641]\n",
      "loss: 0.022198  [ 5120/11641]\n",
      "loss: 0.018504  [ 7680/11641]\n",
      "loss: 0.010060  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.071236\n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.003160  [    0/11641]\n",
      "loss: 0.010194  [ 2560/11641]\n",
      "loss: 0.000583  [ 5120/11641]\n",
      "loss: 0.013606  [ 7680/11641]\n",
      "loss: 0.002061  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.061549\n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.011887  [    0/11641]\n",
      "loss: 0.001003  [ 2560/11641]\n",
      "loss: 0.004571  [ 5120/11641]\n",
      "loss: 0.000298  [ 7680/11641]\n",
      "loss: 0.003487  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.094431\n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.003297  [    0/11641]\n",
      "loss: 0.001795  [ 2560/11641]\n",
      "loss: 0.004216  [ 5120/11641]\n",
      "loss: 0.001219  [ 7680/11641]\n",
      "loss: 0.000853  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.092815\n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.000705  [    0/11641]\n",
      "loss: 0.000392  [ 2560/11641]\n",
      "loss: 0.001396  [ 5120/11641]\n",
      "loss: 0.000823  [ 7680/11641]\n",
      "loss: 0.001206  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.058952\n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.009055  [    0/11641]\n",
      "loss: 0.000769  [ 2560/11641]\n",
      "loss: 0.001494  [ 5120/11641]\n",
      "loss: 0.000131  [ 7680/11641]\n",
      "loss: 0.000656  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.056950\n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.007384  [    0/11641]\n",
      "loss: 0.000167  [ 2560/11641]\n",
      "loss: 0.001140  [ 5120/11641]\n",
      "loss: 0.002676  [ 7680/11641]\n",
      "loss: 0.001253  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.078165\n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.002535  [    0/11641]\n",
      "loss: 0.000250  [ 2560/11641]\n",
      "loss: 0.002426  [ 5120/11641]\n",
      "loss: 0.001951  [ 7680/11641]\n",
      "loss: 0.008914  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.052438\n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.000784  [    0/11641]\n",
      "loss: 0.000168  [ 2560/11641]\n",
      "loss: 0.028268  [ 5120/11641]\n",
      "loss: 0.000952  [ 7680/11641]\n",
      "loss: 0.008322  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.034681\n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.000707  [    0/11641]\n",
      "loss: 0.000830  [ 2560/11641]\n",
      "loss: 0.016873  [ 5120/11641]\n",
      "loss: 0.000436  [ 7680/11641]\n",
      "loss: 0.015948  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.061049\n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.001962  [    0/11641]\n",
      "loss: 0.000173  [ 2560/11641]\n",
      "loss: 0.001335  [ 5120/11641]\n",
      "loss: 0.003931  [ 7680/11641]\n",
      "loss: 0.000884  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.065655\n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.015426  [    0/11641]\n",
      "loss: 0.000552  [ 2560/11641]\n",
      "loss: 0.013152  [ 5120/11641]\n",
      "loss: 0.009126  [ 7680/11641]\n",
      "loss: 0.006297  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.042347\n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.004286  [    0/11641]\n",
      "loss: 0.003542  [ 2560/11641]\n",
      "loss: 0.001858  [ 5120/11641]\n",
      "loss: 0.000155  [ 7680/11641]\n",
      "loss: 0.001355  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.064703\n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.000813  [    0/11641]\n",
      "loss: 0.001280  [ 2560/11641]\n",
      "loss: 0.022102  [ 5120/11641]\n",
      "loss: 0.000869  [ 7680/11641]\n",
      "loss: 0.000147  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.075104\n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.015296  [    0/11641]\n",
      "loss: 0.002836  [ 2560/11641]\n",
      "loss: 0.003106  [ 5120/11641]\n",
      "loss: 0.001074  [ 7680/11641]\n",
      "loss: 0.002214  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.078995\n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.018014  [    0/11641]\n",
      "loss: 0.007625  [ 2560/11641]\n",
      "loss: 0.001374  [ 5120/11641]\n",
      "loss: 0.000966  [ 7680/11641]\n",
      "loss: 0.001557  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.053265\n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.002567  [    0/11641]\n",
      "loss: 0.013632  [ 2560/11641]\n",
      "loss: 0.009489  [ 5120/11641]\n",
      "loss: 0.003119  [ 7680/11641]\n",
      "loss: 0.002028  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.059571\n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.002824  [    0/11641]\n",
      "loss: 0.015911  [ 2560/11641]\n",
      "loss: 0.021521  [ 5120/11641]\n",
      "loss: 0.000959  [ 7680/11641]\n",
      "loss: 0.000133  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.067476\n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.000936  [    0/11641]\n",
      "loss: 0.001679  [ 2560/11641]\n",
      "loss: 0.007626  [ 5120/11641]\n",
      "loss: 0.002721  [ 7680/11641]\n",
      "loss: 0.000221  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.052766\n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.000397  [    0/11641]\n",
      "loss: 0.001374  [ 2560/11641]\n",
      "loss: 0.003860  [ 5120/11641]\n",
      "loss: 0.002186  [ 7680/11641]\n",
      "loss: 0.000386  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.060346\n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.000647  [    0/11641]\n",
      "loss: 0.008653  [ 2560/11641]\n",
      "loss: 0.005604  [ 5120/11641]\n",
      "loss: 0.001371  [ 7680/11641]\n",
      "loss: 0.006342  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.073476\n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.000881  [    0/11641]\n",
      "loss: 0.011211  [ 2560/11641]\n",
      "loss: 0.007407  [ 5120/11641]\n",
      "loss: 0.000793  [ 7680/11641]\n",
      "loss: 0.000477  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.037759\n",
      "Model saved\n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.000162  [    0/11641]\n",
      "loss: 0.000162  [ 2560/11641]\n",
      "loss: 0.003965  [ 5120/11641]\n",
      "loss: 0.000869  [ 7680/11641]\n",
      "loss: 0.002848  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.046594\n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.005550  [    0/11641]\n",
      "loss: 0.000154  [ 2560/11641]\n",
      "loss: 0.010138  [ 5120/11641]\n",
      "loss: 0.000506  [ 7680/11641]\n",
      "loss: 0.007042  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.053938\n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.001785  [    0/11641]\n",
      "loss: 0.001324  [ 2560/11641]\n",
      "loss: 0.000634  [ 5120/11641]\n",
      "loss: 0.006730  [ 7680/11641]\n",
      "loss: 0.001544  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.064847\n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.002588  [    0/11641]\n",
      "loss: 0.006433  [ 2560/11641]\n",
      "loss: 0.005507  [ 5120/11641]\n",
      "loss: 0.003381  [ 7680/11641]\n",
      "loss: 0.001189  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.031636\n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.033126  [    0/11641]\n",
      "loss: 0.006326  [ 2560/11641]\n",
      "loss: 0.003263  [ 5120/11641]\n",
      "loss: 0.000258  [ 7680/11641]\n",
      "loss: 0.000826  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.039327\n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.001057  [    0/11641]\n",
      "loss: 0.001612  [ 2560/11641]\n",
      "loss: 0.029074  [ 5120/11641]\n",
      "loss: 0.001695  [ 7680/11641]\n",
      "loss: 0.000121  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.052111\n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.000196  [    0/11641]\n",
      "loss: 0.001049  [ 2560/11641]\n",
      "loss: 0.000105  [ 5120/11641]\n",
      "loss: 0.001175  [ 7680/11641]\n",
      "loss: 0.000349  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.048532\n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.002415  [    0/11641]\n",
      "loss: 0.002415  [ 2560/11641]\n",
      "loss: 0.000462  [ 5120/11641]\n",
      "loss: 0.001159  [ 7680/11641]\n",
      "loss: 0.000468  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.050661\n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.001021  [    0/11641]\n",
      "loss: 0.007679  [ 2560/11641]\n",
      "loss: 0.001757  [ 5120/11641]\n",
      "loss: 0.004580  [ 7680/11641]\n",
      "loss: 0.000095  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056728\n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.000282  [    0/11641]\n",
      "loss: 0.007059  [ 2560/11641]\n",
      "loss: 0.014610  [ 5120/11641]\n",
      "loss: 0.002401  [ 7680/11641]\n",
      "loss: 0.001292  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.055442\n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.000121  [    0/11641]\n",
      "loss: 0.000385  [ 2560/11641]\n",
      "loss: 0.002456  [ 5120/11641]\n",
      "loss: 0.003186  [ 7680/11641]\n",
      "loss: 0.001722  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.046442\n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.003183  [    0/11641]\n",
      "loss: 0.005455  [ 2560/11641]\n",
      "loss: 0.008540  [ 5120/11641]\n",
      "loss: 0.001910  [ 7680/11641]\n",
      "loss: 0.000549  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.075493\n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.017473  [    0/11641]\n",
      "loss: 0.001813  [ 2560/11641]\n",
      "loss: 0.000074  [ 5120/11641]\n",
      "loss: 0.003637  [ 7680/11641]\n",
      "loss: 0.000078  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.072525\n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.003132  [    0/11641]\n",
      "loss: 0.001998  [ 2560/11641]\n",
      "loss: 0.000649  [ 5120/11641]\n",
      "loss: 0.002860  [ 7680/11641]\n",
      "loss: 0.001494  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.085003\n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/11641]\n",
      "loss: 0.000147  [ 2560/11641]\n",
      "loss: 0.006317  [ 5120/11641]\n",
      "loss: 0.003336  [ 7680/11641]\n",
      "loss: 0.000826  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.071438\n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.001117  [    0/11641]\n",
      "loss: 0.003038  [ 2560/11641]\n",
      "loss: 0.000965  [ 5120/11641]\n",
      "loss: 0.000674  [ 7680/11641]\n",
      "loss: 0.002458  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.059628\n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.001515  [    0/11641]\n",
      "loss: 0.003320  [ 2560/11641]\n",
      "loss: 0.000646  [ 5120/11641]\n",
      "loss: 0.006109  [ 7680/11641]\n",
      "loss: 0.000406  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.049247\n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.000573  [    0/11641]\n",
      "loss: 0.001059  [ 2560/11641]\n",
      "loss: 0.005449  [ 5120/11641]\n",
      "loss: 0.001022  [ 7680/11641]\n",
      "loss: 0.012856  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.076013\n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.008922  [    0/11641]\n",
      "loss: 0.000497  [ 2560/11641]\n",
      "loss: 0.022325  [ 5120/11641]\n",
      "loss: 0.000215  [ 7680/11641]\n",
      "loss: 0.003735  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.081062\n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.002136  [    0/11641]\n",
      "loss: 0.002297  [ 2560/11641]\n",
      "loss: 0.003539  [ 5120/11641]\n",
      "loss: 0.002203  [ 7680/11641]\n",
      "loss: 0.009836  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.061487\n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.000416  [    0/11641]\n",
      "loss: 0.025212  [ 2560/11641]\n",
      "loss: 0.018463  [ 5120/11641]\n",
      "loss: 0.026715  [ 7680/11641]\n",
      "loss: 0.002325  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.073402\n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.012150  [    0/11641]\n",
      "loss: 0.005916  [ 2560/11641]\n",
      "loss: 0.000716  [ 5120/11641]\n",
      "loss: 0.005020  [ 7680/11641]\n",
      "loss: 0.000947  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.063005\n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.000315  [    0/11641]\n",
      "loss: 0.005314  [ 2560/11641]\n",
      "loss: 0.004504  [ 5120/11641]\n",
      "loss: 0.003935  [ 7680/11641]\n",
      "loss: 0.005008  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.078035\n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.000204  [    0/11641]\n",
      "loss: 0.005521  [ 2560/11641]\n",
      "loss: 0.002643  [ 5120/11641]\n",
      "loss: 0.013749  [ 7680/11641]\n",
      "loss: 0.000393  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056120\n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.000895  [    0/11641]\n",
      "loss: 0.000251  [ 2560/11641]\n",
      "loss: 0.001038  [ 5120/11641]\n",
      "loss: 0.003025  [ 7680/11641]\n",
      "loss: 0.001870  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.051713\n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.001532  [    0/11641]\n",
      "loss: 0.002909  [ 2560/11641]\n",
      "loss: 0.001368  [ 5120/11641]\n",
      "loss: 0.000272  [ 7680/11641]\n",
      "loss: 0.005157  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.062474\n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.004169  [    0/11641]\n",
      "loss: 0.000332  [ 2560/11641]\n",
      "loss: 0.003864  [ 5120/11641]\n",
      "loss: 0.009475  [ 7680/11641]\n",
      "loss: 0.002458  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.048407\n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.000166  [    0/11641]\n",
      "loss: 0.000909  [ 2560/11641]\n",
      "loss: 0.001753  [ 5120/11641]\n",
      "loss: 0.000934  [ 7680/11641]\n",
      "loss: 0.021868  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.078685\n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.004439  [    0/11641]\n",
      "loss: 0.000085  [ 2560/11641]\n",
      "loss: 0.000853  [ 5120/11641]\n",
      "loss: 0.001669  [ 7680/11641]\n",
      "loss: 0.001235  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.081403\n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.000214  [    0/11641]\n",
      "loss: 0.016431  [ 2560/11641]\n",
      "loss: 0.011908  [ 5120/11641]\n",
      "loss: 0.001496  [ 7680/11641]\n",
      "loss: 0.015461  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.075008\n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.018837  [    0/11641]\n",
      "loss: 0.001225  [ 2560/11641]\n",
      "loss: 0.002352  [ 5120/11641]\n",
      "loss: 0.000303  [ 7680/11641]\n",
      "loss: 0.000966  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.063858\n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.002999  [    0/11641]\n",
      "loss: 0.000495  [ 2560/11641]\n",
      "loss: 0.000511  [ 5120/11641]\n",
      "loss: 0.000849  [ 7680/11641]\n",
      "loss: 0.000251  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.076540\n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.000314  [    0/11641]\n",
      "loss: 0.000309  [ 2560/11641]\n",
      "loss: 0.002070  [ 5120/11641]\n",
      "loss: 0.008797  [ 7680/11641]\n",
      "loss: 0.001609  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.073015\n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.000682  [    0/11641]\n",
      "loss: 0.000205  [ 2560/11641]\n",
      "loss: 0.000626  [ 5120/11641]\n",
      "loss: 0.000165  [ 7680/11641]\n",
      "loss: 0.000847  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.051497\n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.000679  [    0/11641]\n",
      "loss: 0.016958  [ 2560/11641]\n",
      "loss: 0.005649  [ 5120/11641]\n",
      "loss: 0.001352  [ 7680/11641]\n",
      "loss: 0.003948  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.068428\n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.000759  [    0/11641]\n",
      "loss: 0.000025  [ 2560/11641]\n",
      "loss: 0.002107  [ 5120/11641]\n",
      "loss: 0.000404  [ 7680/11641]\n",
      "loss: 0.000044  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.056137\n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.000131  [    0/11641]\n",
      "loss: 0.000173  [ 2560/11641]\n",
      "loss: 0.009676  [ 5120/11641]\n",
      "loss: 0.001615  [ 7680/11641]\n",
      "loss: 0.000810  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.085820\n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.006130  [    0/11641]\n",
      "loss: 0.001702  [ 2560/11641]\n",
      "loss: 0.001310  [ 5120/11641]\n",
      "loss: 0.000129  [ 7680/11641]\n",
      "loss: 0.000556  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.086440\n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.000105  [    0/11641]\n",
      "loss: 0.000607  [ 2560/11641]\n",
      "loss: 0.000094  [ 5120/11641]\n",
      "loss: 0.000811  [ 7680/11641]\n",
      "loss: 0.000089  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.068860\n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.000246  [    0/11641]\n",
      "loss: 0.000177  [ 2560/11641]\n",
      "loss: 0.006234  [ 5120/11641]\n",
      "loss: 0.005321  [ 7680/11641]\n",
      "loss: 0.000456  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.062506\n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.008746  [    0/11641]\n",
      "loss: 0.003855  [ 2560/11641]\n",
      "loss: 0.005587  [ 5120/11641]\n",
      "loss: 0.000997  [ 7680/11641]\n",
      "loss: 0.006123  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.046405\n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.001874  [    0/11641]\n",
      "loss: 0.000959  [ 2560/11641]\n",
      "loss: 0.000735  [ 5120/11641]\n",
      "loss: 0.000438  [ 7680/11641]\n",
      "loss: 0.003358  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.067627\n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.000350  [    0/11641]\n",
      "loss: 0.022004  [ 2560/11641]\n",
      "loss: 0.003612  [ 5120/11641]\n",
      "loss: 0.000116  [ 7680/11641]\n",
      "loss: 0.000048  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.081120\n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.000094  [    0/11641]\n",
      "loss: 0.001280  [ 2560/11641]\n",
      "loss: 0.023350  [ 5120/11641]\n",
      "loss: 0.009244  [ 7680/11641]\n",
      "loss: 0.002140  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.067552\n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.000567  [    0/11641]\n",
      "loss: 0.005023  [ 2560/11641]\n",
      "loss: 0.002272  [ 5120/11641]\n",
      "loss: 0.000948  [ 7680/11641]\n",
      "loss: 0.006591  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.073230\n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.000806  [    0/11641]\n",
      "loss: 0.000098  [ 2560/11641]\n",
      "loss: 0.000276  [ 5120/11641]\n",
      "loss: 0.000187  [ 7680/11641]\n",
      "loss: 0.000330  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.055376\n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.005269  [    0/11641]\n",
      "loss: 0.000602  [ 2560/11641]\n",
      "loss: 0.001873  [ 5120/11641]\n",
      "loss: 0.000437  [ 7680/11641]\n",
      "loss: 0.003559  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.046964\n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.000616  [    0/11641]\n",
      "loss: 0.000173  [ 2560/11641]\n",
      "loss: 0.008123  [ 5120/11641]\n",
      "loss: 0.003700  [ 7680/11641]\n",
      "loss: 0.006258  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.059343\n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.012873  [    0/11641]\n",
      "loss: 0.000054  [ 2560/11641]\n",
      "loss: 0.000781  [ 5120/11641]\n",
      "loss: 0.004550  [ 7680/11641]\n",
      "loss: 0.000055  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.076312\n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.000518  [    0/11641]\n",
      "loss: 0.000300  [ 2560/11641]\n",
      "loss: 0.000329  [ 5120/11641]\n",
      "loss: 0.000455  [ 7680/11641]\n",
      "loss: 0.004107  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.057871\n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.000177  [    0/11641]\n",
      "loss: 0.010625  [ 2560/11641]\n",
      "loss: 0.018860  [ 5120/11641]\n",
      "loss: 0.000849  [ 7680/11641]\n",
      "loss: 0.000685  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.071213\n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.005475  [    0/11641]\n",
      "loss: 0.015510  [ 2560/11641]\n",
      "loss: 0.002316  [ 5120/11641]\n",
      "loss: 0.000153  [ 7680/11641]\n",
      "loss: 0.000118  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.063863\n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.006117  [    0/11641]\n",
      "loss: 0.000263  [ 2560/11641]\n",
      "loss: 0.038060  [ 5120/11641]\n",
      "loss: 0.005151  [ 7680/11641]\n",
      "loss: 0.000761  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.076706\n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.003508  [    0/11641]\n",
      "loss: 0.003397  [ 2560/11641]\n",
      "loss: 0.003020  [ 5120/11641]\n",
      "loss: 0.020480  [ 7680/11641]\n",
      "loss: 0.002315  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.075863\n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.006271  [    0/11641]\n",
      "loss: 0.001279  [ 2560/11641]\n",
      "loss: 0.001451  [ 5120/11641]\n",
      "loss: 0.043587  [ 7680/11641]\n",
      "loss: 0.001195  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.077887\n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.007463  [    0/11641]\n",
      "loss: 0.002601  [ 2560/11641]\n",
      "loss: 0.015823  [ 5120/11641]\n",
      "loss: 0.000354  [ 7680/11641]\n",
      "loss: 0.005445  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.069941\n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/11641]\n",
      "loss: 0.000174  [ 2560/11641]\n",
      "loss: 0.000276  [ 5120/11641]\n",
      "loss: 0.001507  [ 7680/11641]\n",
      "loss: 0.017010  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.085253\n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.001233  [    0/11641]\n",
      "loss: 0.000132  [ 2560/11641]\n",
      "loss: 0.001032  [ 5120/11641]\n",
      "loss: 0.002298  [ 7680/11641]\n",
      "loss: 0.001166  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.068138\n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.020390  [    0/11641]\n",
      "loss: 0.002563  [ 2560/11641]\n",
      "loss: 0.003105  [ 5120/11641]\n",
      "loss: 0.001390  [ 7680/11641]\n",
      "loss: 0.002790  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.084886\n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.019458  [    0/11641]\n",
      "loss: 0.000303  [ 2560/11641]\n",
      "loss: 0.025728  [ 5120/11641]\n",
      "loss: 0.002719  [ 7680/11641]\n",
      "loss: 0.002663  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.079659\n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.001995  [    0/11641]\n",
      "loss: 0.027198  [ 2560/11641]\n",
      "loss: 0.010255  [ 5120/11641]\n",
      "loss: 0.008589  [ 7680/11641]\n",
      "loss: 0.003456  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.047596\n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.005782  [    0/11641]\n",
      "loss: 0.003523  [ 2560/11641]\n",
      "loss: 0.005540  [ 5120/11641]\n",
      "loss: 0.000181  [ 7680/11641]\n",
      "loss: 0.001024  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.072444\n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.001038  [    0/11641]\n",
      "loss: 0.001345  [ 2560/11641]\n",
      "loss: 0.001240  [ 5120/11641]\n",
      "loss: 0.000044  [ 7680/11641]\n",
      "loss: 0.004208  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.047269\n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.000347  [    0/11641]\n",
      "loss: 0.004842  [ 2560/11641]\n",
      "loss: 0.000120  [ 5120/11641]\n",
      "loss: 0.000242  [ 7680/11641]\n",
      "loss: 0.011413  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.071277\n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.004351  [    0/11641]\n",
      "loss: 0.001017  [ 2560/11641]\n",
      "loss: 0.000069  [ 5120/11641]\n",
      "loss: 0.001016  [ 7680/11641]\n",
      "loss: 0.000381  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.074559\n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.001047  [    0/11641]\n",
      "loss: 0.001627  [ 2560/11641]\n",
      "loss: 0.010589  [ 5120/11641]\n",
      "loss: 0.003661  [ 7680/11641]\n",
      "loss: 0.006381  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.058546\n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.002295  [    0/11641]\n",
      "loss: 0.001016  [ 2560/11641]\n",
      "loss: 0.001290  [ 5120/11641]\n",
      "loss: 0.014023  [ 7680/11641]\n",
      "loss: 0.000258  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.067232\n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.000268  [    0/11641]\n",
      "loss: 0.003090  [ 2560/11641]\n",
      "loss: 0.011628  [ 5120/11641]\n",
      "loss: 0.004366  [ 7680/11641]\n",
      "loss: 0.002131  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.075017\n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.004344  [    0/11641]\n",
      "loss: 0.001816  [ 2560/11641]\n",
      "loss: 0.000883  [ 5120/11641]\n",
      "loss: 0.004176  [ 7680/11641]\n",
      "loss: 0.000732  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.075018\n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.003177  [    0/11641]\n",
      "loss: 0.020487  [ 2560/11641]\n",
      "loss: 0.001629  [ 5120/11641]\n",
      "loss: 0.002299  [ 7680/11641]\n",
      "loss: 0.000363  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.079749\n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.001429  [    0/11641]\n",
      "loss: 0.001118  [ 2560/11641]\n",
      "loss: 0.000547  [ 5120/11641]\n",
      "loss: 0.006985  [ 7680/11641]\n",
      "loss: 0.004756  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.056390\n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.008919  [    0/11641]\n",
      "loss: 0.045041  [ 2560/11641]\n",
      "loss: 0.014473  [ 5120/11641]\n",
      "loss: 0.000518  [ 7680/11641]\n",
      "loss: 0.000153  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.062117\n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.001189  [    0/11641]\n",
      "loss: 0.000709  [ 2560/11641]\n",
      "loss: 0.032215  [ 5120/11641]\n",
      "loss: 0.000351  [ 7680/11641]\n",
      "loss: 0.006015  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.075635\n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.000681  [    0/11641]\n",
      "loss: 0.000617  [ 2560/11641]\n",
      "loss: 0.003136  [ 5120/11641]\n",
      "loss: 0.000111  [ 7680/11641]\n",
      "loss: 0.000085  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.057553\n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.000446  [    0/11641]\n",
      "loss: 0.001605  [ 2560/11641]\n",
      "loss: 0.000117  [ 5120/11641]\n",
      "loss: 0.002212  [ 7680/11641]\n",
      "loss: 0.000608  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.049553\n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.000409  [    0/11641]\n",
      "loss: 0.002571  [ 2560/11641]\n",
      "loss: 0.001213  [ 5120/11641]\n",
      "loss: 0.000499  [ 7680/11641]\n",
      "loss: 0.000415  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.046138\n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.002922  [    0/11641]\n",
      "loss: 0.000878  [ 2560/11641]\n",
      "loss: 0.000258  [ 5120/11641]\n",
      "loss: 0.000348  [ 7680/11641]\n",
      "loss: 0.000632  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.060624\n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.000248  [    0/11641]\n",
      "loss: 0.003586  [ 2560/11641]\n",
      "loss: 0.000058  [ 5120/11641]\n",
      "loss: 0.001149  [ 7680/11641]\n",
      "loss: 0.000598  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.057082\n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.000156  [    0/11641]\n",
      "loss: 0.000747  [ 2560/11641]\n",
      "loss: 0.000494  [ 5120/11641]\n",
      "loss: 0.000082  [ 7680/11641]\n",
      "loss: 0.001315  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.052549\n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.005705  [    0/11641]\n",
      "loss: 0.000911  [ 2560/11641]\n",
      "loss: 0.000521  [ 5120/11641]\n",
      "loss: 0.000525  [ 7680/11641]\n",
      "loss: 0.007987  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.058933\n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.000490  [    0/11641]\n",
      "loss: 0.001044  [ 2560/11641]\n",
      "loss: 0.000151  [ 5120/11641]\n",
      "loss: 0.002149  [ 7680/11641]\n",
      "loss: 0.000559  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.052707\n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.001136  [    0/11641]\n",
      "loss: 0.000283  [ 2560/11641]\n",
      "loss: 0.000085  [ 5120/11641]\n",
      "loss: 0.002467  [ 7680/11641]\n",
      "loss: 0.001772  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.056018\n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.009696  [    0/11641]\n",
      "loss: 0.000255  [ 2560/11641]\n",
      "loss: 0.001926  [ 5120/11641]\n",
      "loss: 0.000060  [ 7680/11641]\n",
      "loss: 0.008280  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.051357\n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.000358  [    0/11641]\n",
      "loss: 0.000041  [ 2560/11641]\n",
      "loss: 0.000835  [ 5120/11641]\n",
      "loss: 0.000276  [ 7680/11641]\n",
      "loss: 0.000770  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.043722\n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.005238  [    0/11641]\n",
      "loss: 0.000615  [ 2560/11641]\n",
      "loss: 0.023589  [ 5120/11641]\n",
      "loss: 0.000275  [ 7680/11641]\n",
      "loss: 0.017785  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.052889\n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.000543  [    0/11641]\n",
      "loss: 0.000054  [ 2560/11641]\n",
      "loss: 0.009187  [ 5120/11641]\n",
      "loss: 0.003722  [ 7680/11641]\n",
      "loss: 0.001213  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.075152\n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.001689  [    0/11641]\n",
      "loss: 0.000789  [ 2560/11641]\n",
      "loss: 0.007614  [ 5120/11641]\n",
      "loss: 0.007168  [ 7680/11641]\n",
      "loss: 0.001740  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.056130\n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.000158  [    0/11641]\n",
      "loss: 0.002014  [ 2560/11641]\n",
      "loss: 0.000269  [ 5120/11641]\n",
      "loss: 0.000382  [ 7680/11641]\n",
      "loss: 0.003123  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.045898\n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.000392  [    0/11641]\n",
      "loss: 0.000850  [ 2560/11641]\n",
      "loss: 0.000395  [ 5120/11641]\n",
      "loss: 0.007615  [ 7680/11641]\n",
      "loss: 0.007053  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.069469\n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.000147  [    0/11641]\n",
      "loss: 0.002567  [ 2560/11641]\n",
      "loss: 0.000053  [ 5120/11641]\n",
      "loss: 0.000662  [ 7680/11641]\n",
      "loss: 0.031637  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.072237\n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.005487  [    0/11641]\n",
      "loss: 0.001430  [ 2560/11641]\n",
      "loss: 0.006176  [ 5120/11641]\n",
      "loss: 0.001861  [ 7680/11641]\n",
      "loss: 0.000803  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.074831\n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.002668  [    0/11641]\n",
      "loss: 0.000615  [ 2560/11641]\n",
      "loss: 0.001025  [ 5120/11641]\n",
      "loss: 0.011577  [ 7680/11641]\n",
      "loss: 0.013811  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.074873\n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.003359  [    0/11641]\n",
      "loss: 0.000329  [ 2560/11641]\n",
      "loss: 0.002584  [ 5120/11641]\n",
      "loss: 0.000276  [ 7680/11641]\n",
      "loss: 0.001274  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.070472\n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.000479  [    0/11641]\n",
      "loss: 0.002892  [ 2560/11641]\n",
      "loss: 0.000362  [ 5120/11641]\n",
      "loss: 0.002563  [ 7680/11641]\n",
      "loss: 0.001254  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.066652\n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/11641]\n",
      "loss: 0.000183  [ 2560/11641]\n",
      "loss: 0.000112  [ 5120/11641]\n",
      "loss: 0.002051  [ 7680/11641]\n",
      "loss: 0.003320  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.065500\n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.003903  [    0/11641]\n",
      "loss: 0.000415  [ 2560/11641]\n",
      "loss: 0.000589  [ 5120/11641]\n",
      "loss: 0.000324  [ 7680/11641]\n",
      "loss: 0.000136  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.052753\n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.000508  [    0/11641]\n",
      "loss: 0.001664  [ 2560/11641]\n",
      "loss: 0.000275  [ 5120/11641]\n",
      "loss: 0.000015  [ 7680/11641]\n",
      "loss: 0.000094  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.057705\n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.000190  [    0/11641]\n",
      "loss: 0.001224  [ 2560/11641]\n",
      "loss: 0.000262  [ 5120/11641]\n",
      "loss: 0.001508  [ 7680/11641]\n",
      "loss: 0.000075  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.063270\n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.005803  [    0/11641]\n",
      "loss: 0.000255  [ 2560/11641]\n",
      "loss: 0.000212  [ 5120/11641]\n",
      "loss: 0.000227  [ 7680/11641]\n",
      "loss: 0.000253  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.061507\n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.000137  [    0/11641]\n",
      "loss: 0.000838  [ 2560/11641]\n",
      "loss: 0.000009  [ 5120/11641]\n",
      "loss: 0.000027  [ 7680/11641]\n",
      "loss: 0.000888  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.074551\n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.000037  [    0/11641]\n",
      "loss: 0.001542  [ 2560/11641]\n",
      "loss: 0.013184  [ 5120/11641]\n",
      "loss: 0.009209  [ 7680/11641]\n",
      "loss: 0.002822  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053818\n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.000373  [    0/11641]\n",
      "loss: 0.000611  [ 2560/11641]\n",
      "loss: 0.002869  [ 5120/11641]\n",
      "loss: 0.000644  [ 7680/11641]\n",
      "loss: 0.013293  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.066477\n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.000482  [    0/11641]\n",
      "loss: 0.003074  [ 2560/11641]\n",
      "loss: 0.002753  [ 5120/11641]\n",
      "loss: 0.004048  [ 7680/11641]\n",
      "loss: 0.000030  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.063941\n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.000151  [    0/11641]\n",
      "loss: 0.000408  [ 2560/11641]\n",
      "loss: 0.000297  [ 5120/11641]\n",
      "loss: 0.000348  [ 7680/11641]\n",
      "loss: 0.000782  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.059416\n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.000244  [    0/11641]\n",
      "loss: 0.000342  [ 2560/11641]\n",
      "loss: 0.000097  [ 5120/11641]\n",
      "loss: 0.000071  [ 7680/11641]\n",
      "loss: 0.000119  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.067608\n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.005222  [    0/11641]\n",
      "loss: 0.000558  [ 2560/11641]\n",
      "loss: 0.000008  [ 5120/11641]\n",
      "loss: 0.000269  [ 7680/11641]\n",
      "loss: 0.000206  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.076728\n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/11641]\n",
      "loss: 0.000043  [ 2560/11641]\n",
      "loss: 0.000226  [ 5120/11641]\n",
      "loss: 0.000579  [ 7680/11641]\n",
      "loss: 0.001244  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.090847\n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.002452  [    0/11641]\n",
      "loss: 0.001713  [ 2560/11641]\n",
      "loss: 0.001991  [ 5120/11641]\n",
      "loss: 0.000225  [ 7680/11641]\n",
      "loss: 0.006369  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.070198\n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.002845  [    0/11641]\n",
      "loss: 0.005833  [ 2560/11641]\n",
      "loss: 0.000176  [ 5120/11641]\n",
      "loss: 0.000680  [ 7680/11641]\n",
      "loss: 0.002160  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.062295\n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.011820  [    0/11641]\n",
      "loss: 0.000146  [ 2560/11641]\n",
      "loss: 0.010588  [ 5120/11641]\n",
      "loss: 0.001104  [ 7680/11641]\n",
      "loss: 0.001847  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.050589\n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.003170  [    0/11641]\n",
      "loss: 0.004968  [ 2560/11641]\n",
      "loss: 0.001390  [ 5120/11641]\n",
      "loss: 0.017773  [ 7680/11641]\n",
      "loss: 0.000511  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.064937\n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.000416  [    0/11641]\n",
      "loss: 0.004196  [ 2560/11641]\n",
      "loss: 0.000041  [ 5120/11641]\n",
      "loss: 0.000607  [ 7680/11641]\n",
      "loss: 0.000119  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.080260\n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.000300  [    0/11641]\n",
      "loss: 0.000434  [ 2560/11641]\n",
      "loss: 0.003243  [ 5120/11641]\n",
      "loss: 0.000218  [ 7680/11641]\n",
      "loss: 0.000044  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.052764\n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.000191  [    0/11641]\n",
      "loss: 0.000663  [ 2560/11641]\n",
      "loss: 0.003181  [ 5120/11641]\n",
      "loss: 0.000467  [ 7680/11641]\n",
      "loss: 0.017992  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.064144\n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.002963  [    0/11641]\n",
      "loss: 0.002969  [ 2560/11641]\n",
      "loss: 0.004697  [ 5120/11641]\n",
      "loss: 0.015030  [ 7680/11641]\n",
      "loss: 0.001808  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.082970\n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.001647  [    0/11641]\n",
      "loss: 0.017983  [ 2560/11641]\n",
      "loss: 0.003531  [ 5120/11641]\n",
      "loss: 0.001923  [ 7680/11641]\n",
      "loss: 0.022694  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.066298\n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.005388  [    0/11641]\n",
      "loss: 0.012139  [ 2560/11641]\n",
      "loss: 0.003077  [ 5120/11641]\n",
      "loss: 0.006314  [ 7680/11641]\n",
      "loss: 0.001062  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.071205\n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.001007  [    0/11641]\n",
      "loss: 0.006628  [ 2560/11641]\n",
      "loss: 0.002223  [ 5120/11641]\n",
      "loss: 0.058133  [ 7680/11641]\n",
      "loss: 0.000528  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.102223\n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.063886  [    0/11641]\n",
      "loss: 0.001673  [ 2560/11641]\n",
      "loss: 0.000441  [ 5120/11641]\n",
      "loss: 0.001496  [ 7680/11641]\n",
      "loss: 0.026735  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.099822\n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.026140  [    0/11641]\n",
      "loss: 0.002393  [ 2560/11641]\n",
      "loss: 0.005257  [ 5120/11641]\n",
      "loss: 0.002317  [ 7680/11641]\n",
      "loss: 0.001622  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.059631\n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.003475  [    0/11641]\n",
      "loss: 0.004334  [ 2560/11641]\n",
      "loss: 0.000397  [ 5120/11641]\n",
      "loss: 0.006866  [ 7680/11641]\n",
      "loss: 0.001666  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.104638\n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.004997  [    0/11641]\n",
      "loss: 0.000352  [ 2560/11641]\n",
      "loss: 0.002270  [ 5120/11641]\n",
      "loss: 0.000646  [ 7680/11641]\n",
      "loss: 0.003323  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.079671\n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.005249  [    0/11641]\n",
      "loss: 0.000312  [ 2560/11641]\n",
      "loss: 0.000223  [ 5120/11641]\n",
      "loss: 0.006346  [ 7680/11641]\n",
      "loss: 0.000725  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.075709\n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.005269  [    0/11641]\n",
      "loss: 0.000198  [ 2560/11641]\n",
      "loss: 0.001329  [ 5120/11641]\n",
      "loss: 0.000340  [ 7680/11641]\n",
      "loss: 0.006929  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.076364\n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.000460  [    0/11641]\n",
      "loss: 0.000323  [ 2560/11641]\n",
      "loss: 0.000938  [ 5120/11641]\n",
      "loss: 0.001478  [ 7680/11641]\n",
      "loss: 0.002211  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.060399\n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.000224  [    0/11641]\n",
      "loss: 0.000167  [ 2560/11641]\n",
      "loss: 0.000130  [ 5120/11641]\n",
      "loss: 0.001243  [ 7680/11641]\n",
      "loss: 0.000674  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.056019\n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.016235  [    0/11641]\n",
      "loss: 0.000348  [ 2560/11641]\n",
      "loss: 0.004237  [ 5120/11641]\n",
      "loss: 0.005317  [ 7680/11641]\n",
      "loss: 0.000635  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.066245\n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.000590  [    0/11641]\n",
      "loss: 0.012975  [ 2560/11641]\n",
      "loss: 0.000229  [ 5120/11641]\n",
      "loss: 0.010208  [ 7680/11641]\n",
      "loss: 0.000116  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.066110\n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.000092  [    0/11641]\n",
      "loss: 0.003509  [ 2560/11641]\n",
      "loss: 0.001227  [ 5120/11641]\n",
      "loss: 0.000363  [ 7680/11641]\n",
      "loss: 0.000168  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.088763\n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.000240  [    0/11641]\n",
      "loss: 0.005170  [ 2560/11641]\n",
      "loss: 0.016524  [ 5120/11641]\n",
      "loss: 0.002083  [ 7680/11641]\n",
      "loss: 0.002444  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.077219\n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.000244  [    0/11641]\n",
      "loss: 0.000113  [ 2560/11641]\n",
      "loss: 0.000386  [ 5120/11641]\n",
      "loss: 0.000293  [ 7680/11641]\n",
      "loss: 0.001676  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.074235\n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.000989  [    0/11641]\n",
      "loss: 0.001231  [ 2560/11641]\n",
      "loss: 0.017494  [ 5120/11641]\n",
      "loss: 0.000159  [ 7680/11641]\n",
      "loss: 0.000026  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.088468\n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.001040  [    0/11641]\n",
      "loss: 0.001873  [ 2560/11641]\n",
      "loss: 0.000426  [ 5120/11641]\n",
      "loss: 0.005940  [ 7680/11641]\n",
      "loss: 0.000372  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.065820\n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.003141  [    0/11641]\n",
      "loss: 0.000476  [ 2560/11641]\n",
      "loss: 0.003375  [ 5120/11641]\n",
      "loss: 0.006964  [ 7680/11641]\n",
      "loss: 0.000343  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.063143\n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.000218  [    0/11641]\n",
      "loss: 0.000442  [ 2560/11641]\n",
      "loss: 0.000296  [ 5120/11641]\n",
      "loss: 0.013644  [ 7680/11641]\n",
      "loss: 0.003814  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.051035\n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.000269  [    0/11641]\n",
      "loss: 0.000065  [ 2560/11641]\n",
      "loss: 0.000214  [ 5120/11641]\n",
      "loss: 0.002412  [ 7680/11641]\n",
      "loss: 0.002268  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.051609\n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.000221  [    0/11641]\n",
      "loss: 0.000779  [ 2560/11641]\n",
      "loss: 0.012653  [ 5120/11641]\n",
      "loss: 0.003334  [ 7680/11641]\n",
      "loss: 0.000505  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.051737\n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.000172  [    0/11641]\n",
      "loss: 0.000968  [ 2560/11641]\n",
      "loss: 0.000344  [ 5120/11641]\n",
      "loss: 0.000093  [ 7680/11641]\n",
      "loss: 0.000302  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.073708\n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.008731  [    0/11641]\n",
      "loss: 0.000087  [ 2560/11641]\n",
      "loss: 0.004669  [ 5120/11641]\n",
      "loss: 0.000279  [ 7680/11641]\n",
      "loss: 0.000586  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.061649\n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/11641]\n",
      "loss: 0.001975  [ 2560/11641]\n",
      "loss: 0.000051  [ 5120/11641]\n",
      "loss: 0.001073  [ 7680/11641]\n",
      "loss: 0.001386  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.058271\n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.000210  [    0/11641]\n",
      "loss: 0.001623  [ 2560/11641]\n",
      "loss: 0.000584  [ 5120/11641]\n",
      "loss: 0.015482  [ 7680/11641]\n",
      "loss: 0.005893  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.058487\n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.001329  [    0/11641]\n",
      "loss: 0.000149  [ 2560/11641]\n",
      "loss: 0.019813  [ 5120/11641]\n",
      "loss: 0.005282  [ 7680/11641]\n",
      "loss: 0.025702  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.093575\n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/11641]\n",
      "loss: 0.005928  [ 2560/11641]\n",
      "loss: 0.001923  [ 5120/11641]\n",
      "loss: 0.001083  [ 7680/11641]\n",
      "loss: 0.005852  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.088163\n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.000752  [    0/11641]\n",
      "loss: 0.000069  [ 2560/11641]\n",
      "loss: 0.015068  [ 5120/11641]\n",
      "loss: 0.004740  [ 7680/11641]\n",
      "loss: 0.001436  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.059556\n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.000125  [    0/11641]\n",
      "loss: 0.000695  [ 2560/11641]\n",
      "loss: 0.000905  [ 5120/11641]\n",
      "loss: 0.001016  [ 7680/11641]\n",
      "loss: 0.000098  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.053957\n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.000406  [    0/11641]\n",
      "loss: 0.011580  [ 2560/11641]\n",
      "loss: 0.016422  [ 5120/11641]\n",
      "loss: 0.000935  [ 7680/11641]\n",
      "loss: 0.036879  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.064812\n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.001281  [    0/11641]\n",
      "loss: 0.001196  [ 2560/11641]\n",
      "loss: 0.004129  [ 5120/11641]\n",
      "loss: 0.034726  [ 7680/11641]\n",
      "loss: 0.001273  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.041219\n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.000035  [    0/11641]\n",
      "loss: 0.000262  [ 2560/11641]\n",
      "loss: 0.000793  [ 5120/11641]\n",
      "loss: 0.013934  [ 7680/11641]\n",
      "loss: 0.000363  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.065316\n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.006521  [    0/11641]\n",
      "loss: 0.003107  [ 2560/11641]\n",
      "loss: 0.001112  [ 5120/11641]\n",
      "loss: 0.000778  [ 7680/11641]\n",
      "loss: 0.000580  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.066575\n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.000030  [    0/11641]\n",
      "loss: 0.013189  [ 2560/11641]\n",
      "loss: 0.001045  [ 5120/11641]\n",
      "loss: 0.003153  [ 7680/11641]\n",
      "loss: 0.000500  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.066290\n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.013423  [    0/11641]\n",
      "loss: 0.000646  [ 2560/11641]\n",
      "loss: 0.000437  [ 5120/11641]\n",
      "loss: 0.008471  [ 7680/11641]\n",
      "loss: 0.000129  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.073925\n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.000099  [    0/11641]\n",
      "loss: 0.016269  [ 2560/11641]\n",
      "loss: 0.002495  [ 5120/11641]\n",
      "loss: 0.000094  [ 7680/11641]\n",
      "loss: 0.015565  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.081147\n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.008594  [    0/11641]\n",
      "loss: 0.005887  [ 2560/11641]\n",
      "loss: 0.004475  [ 5120/11641]\n",
      "loss: 0.006177  [ 7680/11641]\n",
      "loss: 0.002011  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.079655\n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.000327  [    0/11641]\n",
      "loss: 0.004236  [ 2560/11641]\n",
      "loss: 0.003632  [ 5120/11641]\n",
      "loss: 0.014565  [ 7680/11641]\n",
      "loss: 0.028054  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.066726\n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.001591  [    0/11641]\n",
      "loss: 0.000300  [ 2560/11641]\n",
      "loss: 0.001352  [ 5120/11641]\n",
      "loss: 0.000547  [ 7680/11641]\n",
      "loss: 0.001300  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.063343\n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.015149  [    0/11641]\n",
      "loss: 0.005973  [ 2560/11641]\n",
      "loss: 0.003786  [ 5120/11641]\n",
      "loss: 0.000500  [ 7680/11641]\n",
      "loss: 0.019898  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.059282\n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/11641]\n",
      "loss: 0.000399  [ 2560/11641]\n",
      "loss: 0.012486  [ 5120/11641]\n",
      "loss: 0.000517  [ 7680/11641]\n",
      "loss: 0.003548  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.050677\n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.012569  [    0/11641]\n",
      "loss: 0.000105  [ 2560/11641]\n",
      "loss: 0.000433  [ 5120/11641]\n",
      "loss: 0.003956  [ 7680/11641]\n",
      "loss: 0.000773  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056698\n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.000084  [    0/11641]\n",
      "loss: 0.005384  [ 2560/11641]\n",
      "loss: 0.000475  [ 5120/11641]\n",
      "loss: 0.009730  [ 7680/11641]\n",
      "loss: 0.000092  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.049607\n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.001324  [    0/11641]\n",
      "loss: 0.000055  [ 2560/11641]\n",
      "loss: 0.000652  [ 5120/11641]\n",
      "loss: 0.004057  [ 7680/11641]\n",
      "loss: 0.000448  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.057284\n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.005249  [    0/11641]\n",
      "loss: 0.007352  [ 2560/11641]\n",
      "loss: 0.003223  [ 5120/11641]\n",
      "loss: 0.000017  [ 7680/11641]\n",
      "loss: 0.001311  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.066346\n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.001367  [    0/11641]\n",
      "loss: 0.000215  [ 2560/11641]\n",
      "loss: 0.013109  [ 5120/11641]\n",
      "loss: 0.000045  [ 7680/11641]\n",
      "loss: 0.000125  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.069216\n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.000516  [    0/11641]\n",
      "loss: 0.001157  [ 2560/11641]\n",
      "loss: 0.002496  [ 5120/11641]\n",
      "loss: 0.000296  [ 7680/11641]\n",
      "loss: 0.000135  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.068860\n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.000208  [    0/11641]\n",
      "loss: 0.001465  [ 2560/11641]\n",
      "loss: 0.001864  [ 5120/11641]\n",
      "loss: 0.000578  [ 7680/11641]\n",
      "loss: 0.001404  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.065696\n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.024582  [    0/11641]\n",
      "loss: 0.000011  [ 2560/11641]\n",
      "loss: 0.001246  [ 5120/11641]\n",
      "loss: 0.000209  [ 7680/11641]\n",
      "loss: 0.000074  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.085289\n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.000347  [    0/11641]\n",
      "loss: 0.000106  [ 2560/11641]\n",
      "loss: 0.000145  [ 5120/11641]\n",
      "loss: 0.022823  [ 7680/11641]\n",
      "loss: 0.000599  [10240/11641]\n",
      "Accuracy: 97.87%, Avg loss: 0.125649\n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.004236  [    0/11641]\n",
      "loss: 0.028928  [ 2560/11641]\n",
      "loss: 0.018215  [ 5120/11641]\n",
      "loss: 0.000514  [ 7680/11641]\n",
      "loss: 0.003628  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.055991\n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.002202  [    0/11641]\n",
      "loss: 0.001011  [ 2560/11641]\n",
      "loss: 0.002959  [ 5120/11641]\n",
      "loss: 0.000867  [ 7680/11641]\n",
      "loss: 0.008414  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.063809\n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.003465  [    0/11641]\n",
      "loss: 0.001037  [ 2560/11641]\n",
      "loss: 0.003787  [ 5120/11641]\n",
      "loss: 0.000318  [ 7680/11641]\n",
      "loss: 0.000228  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.065054\n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.005955  [    0/11641]\n",
      "loss: 0.000102  [ 2560/11641]\n",
      "loss: 0.000301  [ 5120/11641]\n",
      "loss: 0.014243  [ 7680/11641]\n",
      "loss: 0.000228  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.067687\n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.000713  [    0/11641]\n",
      "loss: 0.001159  [ 2560/11641]\n",
      "loss: 0.000030  [ 5120/11641]\n",
      "loss: 0.001383  [ 7680/11641]\n",
      "loss: 0.000262  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.068393\n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.000713  [    0/11641]\n",
      "loss: 0.000071  [ 2560/11641]\n",
      "loss: 0.001407  [ 5120/11641]\n",
      "loss: 0.005549  [ 7680/11641]\n",
      "loss: 0.001244  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.072523\n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.002206  [    0/11641]\n",
      "loss: 0.000757  [ 2560/11641]\n",
      "loss: 0.000684  [ 5120/11641]\n",
      "loss: 0.001288  [ 7680/11641]\n",
      "loss: 0.009523  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.099277\n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.009146  [    0/11641]\n",
      "loss: 0.000599  [ 2560/11641]\n",
      "loss: 0.003124  [ 5120/11641]\n",
      "loss: 0.000988  [ 7680/11641]\n",
      "loss: 0.000788  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.049497\n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.000034  [    0/11641]\n",
      "loss: 0.007784  [ 2560/11641]\n",
      "loss: 0.000045  [ 5120/11641]\n",
      "loss: 0.000232  [ 7680/11641]\n",
      "loss: 0.000246  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.061710\n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.010907  [    0/11641]\n",
      "loss: 0.000357  [ 2560/11641]\n",
      "loss: 0.000125  [ 5120/11641]\n",
      "loss: 0.002411  [ 7680/11641]\n",
      "loss: 0.000449  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.073387\n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.000338  [    0/11641]\n",
      "loss: 0.002091  [ 2560/11641]\n",
      "loss: 0.000219  [ 5120/11641]\n",
      "loss: 0.003636  [ 7680/11641]\n",
      "loss: 0.001810  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.063511\n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.000822  [    0/11641]\n",
      "loss: 0.022543  [ 2560/11641]\n",
      "loss: 0.000631  [ 5120/11641]\n",
      "loss: 0.000476  [ 7680/11641]\n",
      "loss: 0.000738  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.072045\n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/11641]\n",
      "loss: 0.003261  [ 2560/11641]\n",
      "loss: 0.000460  [ 5120/11641]\n",
      "loss: 0.000100  [ 7680/11641]\n",
      "loss: 0.000424  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.068228\n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.000431  [    0/11641]\n",
      "loss: 0.000041  [ 2560/11641]\n",
      "loss: 0.000050  [ 5120/11641]\n",
      "loss: 0.000380  [ 7680/11641]\n",
      "loss: 0.002827  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.058958\n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/11641]\n",
      "loss: 0.000133  [ 2560/11641]\n",
      "loss: 0.004339  [ 5120/11641]\n",
      "loss: 0.000140  [ 7680/11641]\n",
      "loss: 0.000635  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.056579\n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.000098  [    0/11641]\n",
      "loss: 0.002569  [ 2560/11641]\n",
      "loss: 0.000563  [ 5120/11641]\n",
      "loss: 0.000244  [ 7680/11641]\n",
      "loss: 0.000127  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.063193\n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.000404  [    0/11641]\n",
      "loss: 0.000391  [ 2560/11641]\n",
      "loss: 0.000568  [ 5120/11641]\n",
      "loss: 0.000103  [ 7680/11641]\n",
      "loss: 0.002979  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.059837\n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/11641]\n",
      "loss: 0.000061  [ 2560/11641]\n",
      "loss: 0.000758  [ 5120/11641]\n",
      "loss: 0.001089  [ 7680/11641]\n",
      "loss: 0.000399  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.056442\n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.000252  [    0/11641]\n",
      "loss: 0.000674  [ 2560/11641]\n",
      "loss: 0.000056  [ 5120/11641]\n",
      "loss: 0.000182  [ 7680/11641]\n",
      "loss: 0.000680  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.064444\n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.001854  [    0/11641]\n",
      "loss: 0.001153  [ 2560/11641]\n",
      "loss: 0.001700  [ 5120/11641]\n",
      "loss: 0.002677  [ 7680/11641]\n",
      "loss: 0.000651  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.057867\n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/11641]\n",
      "loss: 0.000570  [ 2560/11641]\n",
      "loss: 0.000091  [ 5120/11641]\n",
      "loss: 0.000475  [ 7680/11641]\n",
      "loss: 0.000034  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.065248\n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/11641]\n",
      "loss: 0.000038  [ 2560/11641]\n",
      "loss: 0.000167  [ 5120/11641]\n",
      "loss: 0.000033  [ 7680/11641]\n",
      "loss: 0.000045  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.061301\n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.000225  [    0/11641]\n",
      "loss: 0.001808  [ 2560/11641]\n",
      "loss: 0.000095  [ 5120/11641]\n",
      "loss: 0.000033  [ 7680/11641]\n",
      "loss: 0.002841  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.070668\n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.043271  [    0/11641]\n",
      "loss: 0.000153  [ 2560/11641]\n",
      "loss: 0.001149  [ 5120/11641]\n",
      "loss: 0.000508  [ 7680/11641]\n",
      "loss: 0.001574  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.047709\n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.002375  [    0/11641]\n",
      "loss: 0.000022  [ 2560/11641]\n",
      "loss: 0.001904  [ 5120/11641]\n",
      "loss: 0.000146  [ 7680/11641]\n",
      "loss: 0.000511  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.051114\n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.000404  [    0/11641]\n",
      "loss: 0.000237  [ 2560/11641]\n",
      "loss: 0.000069  [ 5120/11641]\n",
      "loss: 0.000243  [ 7680/11641]\n",
      "loss: 0.000188  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.074707\n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.000209  [    0/11641]\n",
      "loss: 0.000513  [ 2560/11641]\n",
      "loss: 0.001927  [ 5120/11641]\n",
      "loss: 0.005813  [ 7680/11641]\n",
      "loss: 0.007342  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.067389\n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.002566  [    0/11641]\n",
      "loss: 0.001460  [ 2560/11641]\n",
      "loss: 0.003360  [ 5120/11641]\n",
      "loss: 0.000781  [ 7680/11641]\n",
      "loss: 0.000482  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.084374\n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.003559  [    0/11641]\n",
      "loss: 0.000939  [ 2560/11641]\n",
      "loss: 0.000047  [ 5120/11641]\n",
      "loss: 0.000521  [ 7680/11641]\n",
      "loss: 0.000735  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.071906\n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.000776  [    0/11641]\n",
      "loss: 0.000426  [ 2560/11641]\n",
      "loss: 0.000628  [ 5120/11641]\n",
      "loss: 0.000121  [ 7680/11641]\n",
      "loss: 0.000063  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.083284\n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.012229  [    0/11641]\n",
      "loss: 0.005188  [ 2560/11641]\n",
      "loss: 0.000066  [ 5120/11641]\n",
      "loss: 0.020032  [ 7680/11641]\n",
      "loss: 0.026409  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.094931\n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.000247  [    0/11641]\n",
      "loss: 0.016887  [ 2560/11641]\n",
      "loss: 0.042246  [ 5120/11641]\n",
      "loss: 0.026291  [ 7680/11641]\n",
      "loss: 0.003947  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.069584\n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.001705  [    0/11641]\n",
      "loss: 0.005311  [ 2560/11641]\n",
      "loss: 0.004141  [ 5120/11641]\n",
      "loss: 0.003805  [ 7680/11641]\n",
      "loss: 0.000942  [10240/11641]\n",
      "Accuracy: 98.14%, Avg loss: 0.095560\n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.000866  [    0/11641]\n",
      "loss: 0.009973  [ 2560/11641]\n",
      "loss: 0.003132  [ 5120/11641]\n",
      "loss: 0.003008  [ 7680/11641]\n",
      "loss: 0.000626  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.077176\n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.002479  [    0/11641]\n",
      "loss: 0.023094  [ 2560/11641]\n",
      "loss: 0.001962  [ 5120/11641]\n",
      "loss: 0.000648  [ 7680/11641]\n",
      "loss: 0.002276  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.053720\n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.000314  [    0/11641]\n",
      "loss: 0.018116  [ 2560/11641]\n",
      "loss: 0.007362  [ 5120/11641]\n",
      "loss: 0.005074  [ 7680/11641]\n",
      "loss: 0.000989  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.083224\n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.006999  [    0/11641]\n",
      "loss: 0.004633  [ 2560/11641]\n",
      "loss: 0.003096  [ 5120/11641]\n",
      "loss: 0.006237  [ 7680/11641]\n",
      "loss: 0.002657  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.063930\n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.000444  [    0/11641]\n",
      "loss: 0.000897  [ 2560/11641]\n",
      "loss: 0.002111  [ 5120/11641]\n",
      "loss: 0.000529  [ 7680/11641]\n",
      "loss: 0.039916  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.046841\n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.003836  [    0/11641]\n",
      "loss: 0.001776  [ 2560/11641]\n",
      "loss: 0.001579  [ 5120/11641]\n",
      "loss: 0.000485  [ 7680/11641]\n",
      "loss: 0.000109  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.068729\n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.007341  [    0/11641]\n",
      "loss: 0.000204  [ 2560/11641]\n",
      "loss: 0.000450  [ 5120/11641]\n",
      "loss: 0.000777  [ 7680/11641]\n",
      "loss: 0.000219  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.056412\n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.000688  [    0/11641]\n",
      "loss: 0.000030  [ 2560/11641]\n",
      "loss: 0.000086  [ 5120/11641]\n",
      "loss: 0.000682  [ 7680/11641]\n",
      "loss: 0.002822  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.049800\n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.013533  [    0/11641]\n",
      "loss: 0.000288  [ 2560/11641]\n",
      "loss: 0.002113  [ 5120/11641]\n",
      "loss: 0.010157  [ 7680/11641]\n",
      "loss: 0.001323  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.057822\n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.003684  [    0/11641]\n",
      "loss: 0.001903  [ 2560/11641]\n",
      "loss: 0.000975  [ 5120/11641]\n",
      "loss: 0.006879  [ 7680/11641]\n",
      "loss: 0.001885  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.061612\n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.006313  [    0/11641]\n",
      "loss: 0.000124  [ 2560/11641]\n",
      "loss: 0.018702  [ 5120/11641]\n",
      "loss: 0.000268  [ 7680/11641]\n",
      "loss: 0.000032  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.069772\n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.000235  [    0/11641]\n",
      "loss: 0.000088  [ 2560/11641]\n",
      "loss: 0.003163  [ 5120/11641]\n",
      "loss: 0.000015  [ 7680/11641]\n",
      "loss: 0.001527  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.066693\n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.005326  [    0/11641]\n",
      "loss: 0.000102  [ 2560/11641]\n",
      "loss: 0.000097  [ 5120/11641]\n",
      "loss: 0.000274  [ 7680/11641]\n",
      "loss: 0.000033  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053617\n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.000315  [    0/11641]\n",
      "loss: 0.000061  [ 2560/11641]\n",
      "loss: 0.000479  [ 5120/11641]\n",
      "loss: 0.017746  [ 7680/11641]\n",
      "loss: 0.028668  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.100330\n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.002973  [    0/11641]\n",
      "loss: 0.000219  [ 2560/11641]\n",
      "loss: 0.000721  [ 5120/11641]\n",
      "loss: 0.000300  [ 7680/11641]\n",
      "loss: 0.010990  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056980\n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.000206  [    0/11641]\n",
      "loss: 0.000191  [ 2560/11641]\n",
      "loss: 0.008585  [ 5120/11641]\n",
      "loss: 0.001812  [ 7680/11641]\n",
      "loss: 0.000090  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.091661\n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.000534  [    0/11641]\n",
      "loss: 0.000183  [ 2560/11641]\n",
      "loss: 0.001747  [ 5120/11641]\n",
      "loss: 0.001025  [ 7680/11641]\n",
      "loss: 0.004488  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.060213\n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.000215  [    0/11641]\n",
      "loss: 0.016975  [ 2560/11641]\n",
      "loss: 0.000006  [ 5120/11641]\n",
      "loss: 0.000211  [ 7680/11641]\n",
      "loss: 0.000016  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.044391\n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.002170  [    0/11641]\n",
      "loss: 0.006996  [ 2560/11641]\n",
      "loss: 0.000209  [ 5120/11641]\n",
      "loss: 0.016827  [ 7680/11641]\n",
      "loss: 0.000068  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.064416\n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.006435  [    0/11641]\n",
      "loss: 0.005401  [ 2560/11641]\n",
      "loss: 0.008298  [ 5120/11641]\n",
      "loss: 0.000476  [ 7680/11641]\n",
      "loss: 0.000735  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.066881\n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.001780  [    0/11641]\n",
      "loss: 0.000099  [ 2560/11641]\n",
      "loss: 0.026690  [ 5120/11641]\n",
      "loss: 0.000824  [ 7680/11641]\n",
      "loss: 0.009859  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.046643\n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/11641]\n",
      "loss: 0.000959  [ 2560/11641]\n",
      "loss: 0.000596  [ 5120/11641]\n",
      "loss: 0.000069  [ 7680/11641]\n",
      "loss: 0.000899  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.085357\n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/11641]\n",
      "loss: 0.008932  [ 2560/11641]\n",
      "loss: 0.003362  [ 5120/11641]\n",
      "loss: 0.006632  [ 7680/11641]\n",
      "loss: 0.001937  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.050666\n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.022440  [    0/11641]\n",
      "loss: 0.000373  [ 2560/11641]\n",
      "loss: 0.000215  [ 5120/11641]\n",
      "loss: 0.003921  [ 7680/11641]\n",
      "loss: 0.004227  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.046080\n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.000845  [    0/11641]\n",
      "loss: 0.001089  [ 2560/11641]\n",
      "loss: 0.000095  [ 5120/11641]\n",
      "loss: 0.000837  [ 7680/11641]\n",
      "loss: 0.002293  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.060484\n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.000119  [    0/11641]\n",
      "loss: 0.000071  [ 2560/11641]\n",
      "loss: 0.002441  [ 5120/11641]\n",
      "loss: 0.004443  [ 7680/11641]\n",
      "loss: 0.002732  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.073283\n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.000599  [    0/11641]\n",
      "loss: 0.006508  [ 2560/11641]\n",
      "loss: 0.000337  [ 5120/11641]\n",
      "loss: 0.000134  [ 7680/11641]\n",
      "loss: 0.011461  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.068714\n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.000209  [    0/11641]\n",
      "loss: 0.000385  [ 2560/11641]\n",
      "loss: 0.000581  [ 5120/11641]\n",
      "loss: 0.000455  [ 7680/11641]\n",
      "loss: 0.000355  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.080433\n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.000584  [    0/11641]\n",
      "loss: 0.000072  [ 2560/11641]\n",
      "loss: 0.000031  [ 5120/11641]\n",
      "loss: 0.004855  [ 7680/11641]\n",
      "loss: 0.000678  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.058499\n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.000460  [    0/11641]\n",
      "loss: 0.001996  [ 2560/11641]\n",
      "loss: 0.000088  [ 5120/11641]\n",
      "loss: 0.000434  [ 7680/11641]\n",
      "loss: 0.000116  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.068140\n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.001029  [    0/11641]\n",
      "loss: 0.022332  [ 2560/11641]\n",
      "loss: 0.000377  [ 5120/11641]\n",
      "loss: 0.000416  [ 7680/11641]\n",
      "loss: 0.008366  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.049402\n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.004979  [    0/11641]\n",
      "loss: 0.001856  [ 2560/11641]\n",
      "loss: 0.003123  [ 5120/11641]\n",
      "loss: 0.001676  [ 7680/11641]\n",
      "loss: 0.000088  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.068387\n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.000398  [    0/11641]\n",
      "loss: 0.001401  [ 2560/11641]\n",
      "loss: 0.001328  [ 5120/11641]\n",
      "loss: 0.001664  [ 7680/11641]\n",
      "loss: 0.000411  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.064570\n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.000560  [    0/11641]\n",
      "loss: 0.000028  [ 2560/11641]\n",
      "loss: 0.000238  [ 5120/11641]\n",
      "loss: 0.001128  [ 7680/11641]\n",
      "loss: 0.004344  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.079889\n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.001058  [    0/11641]\n",
      "loss: 0.005582  [ 2560/11641]\n",
      "loss: 0.002233  [ 5120/11641]\n",
      "loss: 0.000518  [ 7680/11641]\n",
      "loss: 0.001690  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.073888\n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.001266  [    0/11641]\n",
      "loss: 0.000798  [ 2560/11641]\n",
      "loss: 0.000375  [ 5120/11641]\n",
      "loss: 0.009092  [ 7680/11641]\n",
      "loss: 0.008318  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.049240\n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.000204  [    0/11641]\n",
      "loss: 0.007118  [ 2560/11641]\n",
      "loss: 0.012530  [ 5120/11641]\n",
      "loss: 0.000476  [ 7680/11641]\n",
      "loss: 0.000867  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.067014\n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.003835  [    0/11641]\n",
      "loss: 0.001559  [ 2560/11641]\n",
      "loss: 0.009446  [ 5120/11641]\n",
      "loss: 0.001254  [ 7680/11641]\n",
      "loss: 0.016534  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.059990\n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.015114  [    0/11641]\n",
      "loss: 0.000264  [ 2560/11641]\n",
      "loss: 0.001325  [ 5120/11641]\n",
      "loss: 0.008620  [ 7680/11641]\n",
      "loss: 0.000186  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.069451\n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.005681  [    0/11641]\n",
      "loss: 0.000146  [ 2560/11641]\n",
      "loss: 0.004591  [ 5120/11641]\n",
      "loss: 0.000140  [ 7680/11641]\n",
      "loss: 0.000196  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.072168\n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.000573  [    0/11641]\n",
      "loss: 0.000250  [ 2560/11641]\n",
      "loss: 0.004466  [ 5120/11641]\n",
      "loss: 0.009282  [ 7680/11641]\n",
      "loss: 0.015104  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.060418\n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.000379  [    0/11641]\n",
      "loss: 0.000040  [ 2560/11641]\n",
      "loss: 0.000110  [ 5120/11641]\n",
      "loss: 0.000035  [ 7680/11641]\n",
      "loss: 0.000422  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.095394\n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.021326  [    0/11641]\n",
      "loss: 0.008102  [ 2560/11641]\n",
      "loss: 0.032882  [ 5120/11641]\n",
      "loss: 0.000337  [ 7680/11641]\n",
      "loss: 0.000052  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.083891\n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.000035  [    0/11641]\n",
      "loss: 0.000151  [ 2560/11641]\n",
      "loss: 0.003494  [ 5120/11641]\n",
      "loss: 0.001740  [ 7680/11641]\n",
      "loss: 0.004410  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.060944\n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.004491  [    0/11641]\n",
      "loss: 0.000130  [ 2560/11641]\n",
      "loss: 0.003442  [ 5120/11641]\n",
      "loss: 0.001895  [ 7680/11641]\n",
      "loss: 0.001555  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.070403\n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.002401  [    0/11641]\n",
      "loss: 0.002947  [ 2560/11641]\n",
      "loss: 0.004930  [ 5120/11641]\n",
      "loss: 0.004311  [ 7680/11641]\n",
      "loss: 0.000142  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.074727\n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.009170  [    0/11641]\n",
      "loss: 0.006366  [ 2560/11641]\n",
      "loss: 0.003422  [ 5120/11641]\n",
      "loss: 0.001043  [ 7680/11641]\n",
      "loss: 0.008273  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.049621\n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.000230  [    0/11641]\n",
      "loss: 0.000048  [ 2560/11641]\n",
      "loss: 0.002490  [ 5120/11641]\n",
      "loss: 0.001272  [ 7680/11641]\n",
      "loss: 0.000092  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.055653\n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.002817  [    0/11641]\n",
      "loss: 0.011898  [ 2560/11641]\n",
      "loss: 0.000091  [ 5120/11641]\n",
      "loss: 0.006124  [ 7680/11641]\n",
      "loss: 0.004396  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.057104\n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.000106  [    0/11641]\n",
      "loss: 0.000057  [ 2560/11641]\n",
      "loss: 0.000055  [ 5120/11641]\n",
      "loss: 0.001643  [ 7680/11641]\n",
      "loss: 0.000491  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.057975\n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.000533  [    0/11641]\n",
      "loss: 0.001600  [ 2560/11641]\n",
      "loss: 0.000777  [ 5120/11641]\n",
      "loss: 0.000930  [ 7680/11641]\n",
      "loss: 0.000687  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056321\n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/11641]\n",
      "loss: 0.000959  [ 2560/11641]\n",
      "loss: 0.000164  [ 5120/11641]\n",
      "loss: 0.004479  [ 7680/11641]\n",
      "loss: 0.000221  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.067973\n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.000097  [    0/11641]\n",
      "loss: 0.007506  [ 2560/11641]\n",
      "loss: 0.000593  [ 5120/11641]\n",
      "loss: 0.000013  [ 7680/11641]\n",
      "loss: 0.000191  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.063595\n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.001148  [    0/11641]\n",
      "loss: 0.000361  [ 2560/11641]\n",
      "loss: 0.000085  [ 5120/11641]\n",
      "loss: 0.000757  [ 7680/11641]\n",
      "loss: 0.000141  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.060279\n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.000841  [    0/11641]\n",
      "loss: 0.000349  [ 2560/11641]\n",
      "loss: 0.000035  [ 5120/11641]\n",
      "loss: 0.001906  [ 7680/11641]\n",
      "loss: 0.015144  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.095978\n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.000719  [    0/11641]\n",
      "loss: 0.000259  [ 2560/11641]\n",
      "loss: 0.001334  [ 5120/11641]\n",
      "loss: 0.000059  [ 7680/11641]\n",
      "loss: 0.000072  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.076788\n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.000179  [    0/11641]\n",
      "loss: 0.000113  [ 2560/11641]\n",
      "loss: 0.000871  [ 5120/11641]\n",
      "loss: 0.000269  [ 7680/11641]\n",
      "loss: 0.000221  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.066641\n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.006344  [    0/11641]\n",
      "loss: 0.022812  [ 2560/11641]\n",
      "loss: 0.001250  [ 5120/11641]\n",
      "loss: 0.007693  [ 7680/11641]\n",
      "loss: 0.013127  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.081688\n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.000269  [    0/11641]\n",
      "loss: 0.000302  [ 2560/11641]\n",
      "loss: 0.000026  [ 5120/11641]\n",
      "loss: 0.000295  [ 7680/11641]\n",
      "loss: 0.000420  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.076353\n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.004072  [    0/11641]\n",
      "loss: 0.037739  [ 2560/11641]\n",
      "loss: 0.002247  [ 5120/11641]\n",
      "loss: 0.000513  [ 7680/11641]\n",
      "loss: 0.008281  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.067510\n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.013689  [    0/11641]\n",
      "loss: 0.000503  [ 2560/11641]\n",
      "loss: 0.003792  [ 5120/11641]\n",
      "loss: 0.000562  [ 7680/11641]\n",
      "loss: 0.003408  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.094504\n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.022411  [    0/11641]\n",
      "loss: 0.003293  [ 2560/11641]\n",
      "loss: 0.010569  [ 5120/11641]\n",
      "loss: 0.000075  [ 7680/11641]\n",
      "loss: 0.002765  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.069136\n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/11641]\n",
      "loss: 0.000166  [ 2560/11641]\n",
      "loss: 0.001733  [ 5120/11641]\n",
      "loss: 0.000633  [ 7680/11641]\n",
      "loss: 0.007577  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.055885\n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.000448  [    0/11641]\n",
      "loss: 0.000718  [ 2560/11641]\n",
      "loss: 0.003801  [ 5120/11641]\n",
      "loss: 0.012111  [ 7680/11641]\n",
      "loss: 0.013566  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.081026\n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.003681  [    0/11641]\n",
      "loss: 0.000062  [ 2560/11641]\n",
      "loss: 0.000319  [ 5120/11641]\n",
      "loss: 0.002558  [ 7680/11641]\n",
      "loss: 0.004694  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.065033\n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.000317  [    0/11641]\n",
      "loss: 0.013337  [ 2560/11641]\n",
      "loss: 0.016030  [ 5120/11641]\n",
      "loss: 0.001681  [ 7680/11641]\n",
      "loss: 0.009288  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.098693\n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.004762  [    0/11641]\n",
      "loss: 0.000057  [ 2560/11641]\n",
      "loss: 0.008860  [ 5120/11641]\n",
      "loss: 0.002737  [ 7680/11641]\n",
      "loss: 0.000214  [10240/11641]\n",
      "Accuracy: 98.28%, Avg loss: 0.097912\n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.021481  [    0/11641]\n",
      "loss: 0.008955  [ 2560/11641]\n",
      "loss: 0.002792  [ 5120/11641]\n",
      "loss: 0.001195  [ 7680/11641]\n",
      "loss: 0.000153  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.066788\n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.005062  [    0/11641]\n",
      "loss: 0.000876  [ 2560/11641]\n",
      "loss: 0.015898  [ 5120/11641]\n",
      "loss: 0.000206  [ 7680/11641]\n",
      "loss: 0.000350  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.068873\n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.000236  [    0/11641]\n",
      "loss: 0.005153  [ 2560/11641]\n",
      "loss: 0.001579  [ 5120/11641]\n",
      "loss: 0.000448  [ 7680/11641]\n",
      "loss: 0.003534  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.060660\n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.007038  [    0/11641]\n",
      "loss: 0.000254  [ 2560/11641]\n",
      "loss: 0.021419  [ 5120/11641]\n",
      "loss: 0.000838  [ 7680/11641]\n",
      "loss: 0.000050  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.050133\n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.000623  [    0/11641]\n",
      "loss: 0.000609  [ 2560/11641]\n",
      "loss: 0.012505  [ 5120/11641]\n",
      "loss: 0.013138  [ 7680/11641]\n",
      "loss: 0.000087  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.049192\n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.000826  [    0/11641]\n",
      "loss: 0.000163  [ 2560/11641]\n",
      "loss: 0.000210  [ 5120/11641]\n",
      "loss: 0.000303  [ 7680/11641]\n",
      "loss: 0.000223  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.080044\n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.005561  [    0/11641]\n",
      "loss: 0.000043  [ 2560/11641]\n",
      "loss: 0.000159  [ 5120/11641]\n",
      "loss: 0.000704  [ 7680/11641]\n",
      "loss: 0.000219  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.050810\n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.000981  [    0/11641]\n",
      "loss: 0.000765  [ 2560/11641]\n",
      "loss: 0.000819  [ 5120/11641]\n",
      "loss: 0.000090  [ 7680/11641]\n",
      "loss: 0.002013  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.073567\n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/11641]\n",
      "loss: 0.002754  [ 2560/11641]\n",
      "loss: 0.000668  [ 5120/11641]\n",
      "loss: 0.018930  [ 7680/11641]\n",
      "loss: 0.000053  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.045080\n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.000711  [    0/11641]\n",
      "loss: 0.002643  [ 2560/11641]\n",
      "loss: 0.000085  [ 5120/11641]\n",
      "loss: 0.002966  [ 7680/11641]\n",
      "loss: 0.000434  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.069444\n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.001119  [    0/11641]\n",
      "loss: 0.000119  [ 2560/11641]\n",
      "loss: 0.000164  [ 5120/11641]\n",
      "loss: 0.000310  [ 7680/11641]\n",
      "loss: 0.000054  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.079013\n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.000574  [    0/11641]\n",
      "loss: 0.002307  [ 2560/11641]\n",
      "loss: 0.000532  [ 5120/11641]\n",
      "loss: 0.000814  [ 7680/11641]\n",
      "loss: 0.004576  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.090533\n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.000577  [    0/11641]\n",
      "loss: 0.021840  [ 2560/11641]\n",
      "loss: 0.008130  [ 5120/11641]\n",
      "loss: 0.001627  [ 7680/11641]\n",
      "loss: 0.012003  [10240/11641]\n",
      "Accuracy: 98.21%, Avg loss: 0.100416\n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.000569  [    0/11641]\n",
      "loss: 0.000349  [ 2560/11641]\n",
      "loss: 0.015180  [ 5120/11641]\n",
      "loss: 0.045426  [ 7680/11641]\n",
      "loss: 0.011737  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.079019\n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.000153  [    0/11641]\n",
      "loss: 0.002791  [ 2560/11641]\n",
      "loss: 0.011708  [ 5120/11641]\n",
      "loss: 0.011061  [ 7680/11641]\n",
      "loss: 0.003137  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.050659\n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.000150  [    0/11641]\n",
      "loss: 0.014840  [ 2560/11641]\n",
      "loss: 0.006846  [ 5120/11641]\n",
      "loss: 0.006298  [ 7680/11641]\n",
      "loss: 0.009355  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.059086\n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.000826  [    0/11641]\n",
      "loss: 0.017950  [ 2560/11641]\n",
      "loss: 0.035143  [ 5120/11641]\n",
      "loss: 0.001602  [ 7680/11641]\n",
      "loss: 0.000240  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.074668\n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.000207  [    0/11641]\n",
      "loss: 0.000961  [ 2560/11641]\n",
      "loss: 0.000407  [ 5120/11641]\n",
      "loss: 0.000605  [ 7680/11641]\n",
      "loss: 0.003174  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.055357\n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.003429  [    0/11641]\n",
      "loss: 0.000380  [ 2560/11641]\n",
      "loss: 0.000440  [ 5120/11641]\n",
      "loss: 0.000318  [ 7680/11641]\n",
      "loss: 0.000070  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.058998\n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.000192  [    0/11641]\n",
      "loss: 0.012814  [ 2560/11641]\n",
      "loss: 0.000366  [ 5120/11641]\n",
      "loss: 0.000128  [ 7680/11641]\n",
      "loss: 0.003339  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.060152\n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.000231  [    0/11641]\n",
      "loss: 0.000271  [ 2560/11641]\n",
      "loss: 0.000367  [ 5120/11641]\n",
      "loss: 0.000683  [ 7680/11641]\n",
      "loss: 0.000072  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.055346\n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.016659  [    0/11641]\n",
      "loss: 0.000038  [ 2560/11641]\n",
      "loss: 0.003710  [ 5120/11641]\n",
      "loss: 0.000060  [ 7680/11641]\n",
      "loss: 0.000075  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.053341\n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.000223  [    0/11641]\n",
      "loss: 0.003990  [ 2560/11641]\n",
      "loss: 0.000042  [ 5120/11641]\n",
      "loss: 0.000054  [ 7680/11641]\n",
      "loss: 0.016777  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.067477\n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.000150  [    0/11641]\n",
      "loss: 0.000374  [ 2560/11641]\n",
      "loss: 0.000417  [ 5120/11641]\n",
      "loss: 0.003414  [ 7680/11641]\n",
      "loss: 0.000062  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.066174\n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.002803  [    0/11641]\n",
      "loss: 0.000649  [ 2560/11641]\n",
      "loss: 0.002389  [ 5120/11641]\n",
      "loss: 0.002681  [ 7680/11641]\n",
      "loss: 0.000117  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.066070\n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.001325  [    0/11641]\n",
      "loss: 0.000209  [ 2560/11641]\n",
      "loss: 0.009385  [ 5120/11641]\n",
      "loss: 0.000134  [ 7680/11641]\n",
      "loss: 0.000112  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.065419\n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/11641]\n",
      "loss: 0.016109  [ 2560/11641]\n",
      "loss: 0.000177  [ 5120/11641]\n",
      "loss: 0.004064  [ 7680/11641]\n",
      "loss: 0.010694  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.056658\n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.000919  [    0/11641]\n",
      "loss: 0.012420  [ 2560/11641]\n",
      "loss: 0.002685  [ 5120/11641]\n",
      "loss: 0.003718  [ 7680/11641]\n",
      "loss: 0.000483  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.048638\n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.000043  [    0/11641]\n",
      "loss: 0.000515  [ 2560/11641]\n",
      "loss: 0.002633  [ 5120/11641]\n",
      "loss: 0.000082  [ 7680/11641]\n",
      "loss: 0.000161  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.047112\n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.000841  [    0/11641]\n",
      "loss: 0.000133  [ 2560/11641]\n",
      "loss: 0.005734  [ 5120/11641]\n",
      "loss: 0.011316  [ 7680/11641]\n",
      "loss: 0.000053  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.081830\n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.000032  [    0/11641]\n",
      "loss: 0.000046  [ 2560/11641]\n",
      "loss: 0.001455  [ 5120/11641]\n",
      "loss: 0.000226  [ 7680/11641]\n",
      "loss: 0.003042  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.050054\n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.009322  [    0/11641]\n",
      "loss: 0.000111  [ 2560/11641]\n",
      "loss: 0.000250  [ 5120/11641]\n",
      "loss: 0.000070  [ 7680/11641]\n",
      "loss: 0.002048  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.067863\n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.001931  [    0/11641]\n",
      "loss: 0.000258  [ 2560/11641]\n",
      "loss: 0.003784  [ 5120/11641]\n",
      "loss: 0.000464  [ 7680/11641]\n",
      "loss: 0.000993  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.069453\n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.000359  [    0/11641]\n",
      "loss: 0.002004  [ 2560/11641]\n",
      "loss: 0.000115  [ 5120/11641]\n",
      "loss: 0.000066  [ 7680/11641]\n",
      "loss: 0.000775  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.043628\n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/11641]\n",
      "loss: 0.003571  [ 2560/11641]\n",
      "loss: 0.008163  [ 5120/11641]\n",
      "loss: 0.000090  [ 7680/11641]\n",
      "loss: 0.000041  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.067260\n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.000162  [    0/11641]\n",
      "loss: 0.000124  [ 2560/11641]\n",
      "loss: 0.000030  [ 5120/11641]\n",
      "loss: 0.000110  [ 7680/11641]\n",
      "loss: 0.000027  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.057115\n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/11641]\n",
      "loss: 0.000151  [ 2560/11641]\n",
      "loss: 0.000038  [ 5120/11641]\n",
      "loss: 0.004943  [ 7680/11641]\n",
      "loss: 0.001840  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.061222\n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.001259  [    0/11641]\n",
      "loss: 0.000064  [ 2560/11641]\n",
      "loss: 0.003776  [ 5120/11641]\n",
      "loss: 0.000526  [ 7680/11641]\n",
      "loss: 0.000488  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.071040\n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.012265  [    0/11641]\n",
      "loss: 0.000342  [ 2560/11641]\n",
      "loss: 0.002064  [ 5120/11641]\n",
      "loss: 0.000154  [ 7680/11641]\n",
      "loss: 0.002475  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.056905\n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.003162  [    0/11641]\n",
      "loss: 0.011888  [ 2560/11641]\n",
      "loss: 0.024157  [ 5120/11641]\n",
      "loss: 0.000597  [ 7680/11641]\n",
      "loss: 0.000844  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.063162\n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.000879  [    0/11641]\n",
      "loss: 0.006110  [ 2560/11641]\n",
      "loss: 0.005522  [ 5120/11641]\n",
      "loss: 0.000110  [ 7680/11641]\n",
      "loss: 0.000319  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.056982\n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.012204  [    0/11641]\n",
      "loss: 0.000811  [ 2560/11641]\n",
      "loss: 0.000091  [ 5120/11641]\n",
      "loss: 0.003795  [ 7680/11641]\n",
      "loss: 0.000798  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.047895\n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/11641]\n",
      "loss: 0.003817  [ 2560/11641]\n",
      "loss: 0.000183  [ 5120/11641]\n",
      "loss: 0.001321  [ 7680/11641]\n",
      "loss: 0.001750  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.049675\n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.000325  [    0/11641]\n",
      "loss: 0.004894  [ 2560/11641]\n",
      "loss: 0.000582  [ 5120/11641]\n",
      "loss: 0.000094  [ 7680/11641]\n",
      "loss: 0.005126  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061082\n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.000405  [    0/11641]\n",
      "loss: 0.000363  [ 2560/11641]\n",
      "loss: 0.000781  [ 5120/11641]\n",
      "loss: 0.000541  [ 7680/11641]\n",
      "loss: 0.004046  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.057173\n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.000150  [    0/11641]\n",
      "loss: 0.000066  [ 2560/11641]\n",
      "loss: 0.006620  [ 5120/11641]\n",
      "loss: 0.000786  [ 7680/11641]\n",
      "loss: 0.000023  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.071301\n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.000428  [    0/11641]\n",
      "loss: 0.000731  [ 2560/11641]\n",
      "loss: 0.000719  [ 5120/11641]\n",
      "loss: 0.002706  [ 7680/11641]\n",
      "loss: 0.009680  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.085626\n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.005681  [    0/11641]\n",
      "loss: 0.005611  [ 2560/11641]\n",
      "loss: 0.000418  [ 5120/11641]\n",
      "loss: 0.009389  [ 7680/11641]\n",
      "loss: 0.026444  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.079662\n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.009802  [    0/11641]\n",
      "loss: 0.000228  [ 2560/11641]\n",
      "loss: 0.080779  [ 5120/11641]\n",
      "loss: 0.000498  [ 7680/11641]\n",
      "loss: 0.002469  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.058696\n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.001529  [    0/11641]\n",
      "loss: 0.013259  [ 2560/11641]\n",
      "loss: 0.001959  [ 5120/11641]\n",
      "loss: 0.005759  [ 7680/11641]\n",
      "loss: 0.004349  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.083049\n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.013529  [    0/11641]\n",
      "loss: 0.003061  [ 2560/11641]\n",
      "loss: 0.010563  [ 5120/11641]\n",
      "loss: 0.003015  [ 7680/11641]\n",
      "loss: 0.001261  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.055389\n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.001764  [    0/11641]\n",
      "loss: 0.019613  [ 2560/11641]\n",
      "loss: 0.002888  [ 5120/11641]\n",
      "loss: 0.000536  [ 7680/11641]\n",
      "loss: 0.006532  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.042243\n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.005228  [    0/11641]\n",
      "loss: 0.001409  [ 2560/11641]\n",
      "loss: 0.012447  [ 5120/11641]\n",
      "loss: 0.000107  [ 7680/11641]\n",
      "loss: 0.000100  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.075944\n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.003377  [    0/11641]\n",
      "loss: 0.006478  [ 2560/11641]\n",
      "loss: 0.004611  [ 5120/11641]\n",
      "loss: 0.005969  [ 7680/11641]\n",
      "loss: 0.019150  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.056783\n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.000537  [    0/11641]\n",
      "loss: 0.003394  [ 2560/11641]\n",
      "loss: 0.000188  [ 5120/11641]\n",
      "loss: 0.039780  [ 7680/11641]\n",
      "loss: 0.018406  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.078827\n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.000676  [    0/11641]\n",
      "loss: 0.000758  [ 2560/11641]\n",
      "loss: 0.004811  [ 5120/11641]\n",
      "loss: 0.000851  [ 7680/11641]\n",
      "loss: 0.000659  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.055795\n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.000658  [    0/11641]\n",
      "loss: 0.000505  [ 2560/11641]\n",
      "loss: 0.003370  [ 5120/11641]\n",
      "loss: 0.000152  [ 7680/11641]\n",
      "loss: 0.008176  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.065064\n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.000205  [    0/11641]\n",
      "loss: 0.000710  [ 2560/11641]\n",
      "loss: 0.006972  [ 5120/11641]\n",
      "loss: 0.000313  [ 7680/11641]\n",
      "loss: 0.003259  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.067082\n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.000095  [    0/11641]\n",
      "loss: 0.001208  [ 2560/11641]\n",
      "loss: 0.002252  [ 5120/11641]\n",
      "loss: 0.000790  [ 7680/11641]\n",
      "loss: 0.004517  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.058471\n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.001831  [    0/11641]\n",
      "loss: 0.000158  [ 2560/11641]\n",
      "loss: 0.008414  [ 5120/11641]\n",
      "loss: 0.000178  [ 7680/11641]\n",
      "loss: 0.026214  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.070612\n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.024724  [    0/11641]\n",
      "loss: 0.000068  [ 2560/11641]\n",
      "loss: 0.008506  [ 5120/11641]\n",
      "loss: 0.000104  [ 7680/11641]\n",
      "loss: 0.004510  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.080777\n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/11641]\n",
      "loss: 0.000428  [ 2560/11641]\n",
      "loss: 0.008906  [ 5120/11641]\n",
      "loss: 0.002230  [ 7680/11641]\n",
      "loss: 0.007013  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.089262\n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.001109  [    0/11641]\n",
      "loss: 0.005357  [ 2560/11641]\n",
      "loss: 0.001079  [ 5120/11641]\n",
      "loss: 0.004344  [ 7680/11641]\n",
      "loss: 0.002006  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.084317\n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.000321  [    0/11641]\n",
      "loss: 0.000143  [ 2560/11641]\n",
      "loss: 0.008790  [ 5120/11641]\n",
      "loss: 0.000806  [ 7680/11641]\n",
      "loss: 0.004119  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.052428\n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.000149  [    0/11641]\n",
      "loss: 0.000374  [ 2560/11641]\n",
      "loss: 0.005449  [ 5120/11641]\n",
      "loss: 0.000820  [ 7680/11641]\n",
      "loss: 0.000135  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.091044\n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.000112  [    0/11641]\n",
      "loss: 0.003122  [ 2560/11641]\n",
      "loss: 0.009591  [ 5120/11641]\n",
      "loss: 0.023954  [ 7680/11641]\n",
      "loss: 0.002025  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.068798\n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.001012  [    0/11641]\n",
      "loss: 0.034406  [ 2560/11641]\n",
      "loss: 0.034125  [ 5120/11641]\n",
      "loss: 0.001195  [ 7680/11641]\n",
      "loss: 0.004783  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.054821\n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.000107  [    0/11641]\n",
      "loss: 0.000278  [ 2560/11641]\n",
      "loss: 0.000844  [ 5120/11641]\n",
      "loss: 0.001498  [ 7680/11641]\n",
      "loss: 0.009945  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.048850\n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.000262  [    0/11641]\n",
      "loss: 0.000040  [ 2560/11641]\n",
      "loss: 0.020726  [ 5120/11641]\n",
      "loss: 0.010468  [ 7680/11641]\n",
      "loss: 0.011537  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.062310\n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.004535  [    0/11641]\n",
      "loss: 0.000694  [ 2560/11641]\n",
      "loss: 0.000082  [ 5120/11641]\n",
      "loss: 0.002664  [ 7680/11641]\n",
      "loss: 0.000612  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.058992\n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.013453  [    0/11641]\n",
      "loss: 0.003091  [ 2560/11641]\n",
      "loss: 0.002773  [ 5120/11641]\n",
      "loss: 0.039105  [ 7680/11641]\n",
      "loss: 0.000177  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.069679\n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.005635  [    0/11641]\n",
      "loss: 0.002035  [ 2560/11641]\n",
      "loss: 0.006199  [ 5120/11641]\n",
      "loss: 0.000847  [ 7680/11641]\n",
      "loss: 0.000041  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.046128\n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.000389  [    0/11641]\n",
      "loss: 0.000319  [ 2560/11641]\n",
      "loss: 0.000749  [ 5120/11641]\n",
      "loss: 0.000184  [ 7680/11641]\n",
      "loss: 0.000109  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.040081\n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.000372  [    0/11641]\n",
      "loss: 0.000151  [ 2560/11641]\n",
      "loss: 0.000077  [ 5120/11641]\n",
      "loss: 0.000171  [ 7680/11641]\n",
      "loss: 0.000030  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.064643\n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/11641]\n",
      "loss: 0.000318  [ 2560/11641]\n",
      "loss: 0.000039  [ 5120/11641]\n",
      "loss: 0.000385  [ 7680/11641]\n",
      "loss: 0.001194  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.047271\n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.000440  [    0/11641]\n",
      "loss: 0.000164  [ 2560/11641]\n",
      "loss: 0.000074  [ 5120/11641]\n",
      "loss: 0.000132  [ 7680/11641]\n",
      "loss: 0.000027  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.039509\n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.000201  [    0/11641]\n",
      "loss: 0.026594  [ 2560/11641]\n",
      "loss: 0.012326  [ 5120/11641]\n",
      "loss: 0.024608  [ 7680/11641]\n",
      "loss: 0.001432  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.089202\n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.005446  [    0/11641]\n",
      "loss: 0.000222  [ 2560/11641]\n",
      "loss: 0.004090  [ 5120/11641]\n",
      "loss: 0.000057  [ 7680/11641]\n",
      "loss: 0.000007  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061381\n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.000787  [    0/11641]\n",
      "loss: 0.000200  [ 2560/11641]\n",
      "loss: 0.000126  [ 5120/11641]\n",
      "loss: 0.000040  [ 7680/11641]\n",
      "loss: 0.001191  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.073470\n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.006942  [    0/11641]\n",
      "loss: 0.001185  [ 2560/11641]\n",
      "loss: 0.000192  [ 5120/11641]\n",
      "loss: 0.005538  [ 7680/11641]\n",
      "loss: 0.000130  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.052824\n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.006820  [    0/11641]\n",
      "loss: 0.000101  [ 2560/11641]\n",
      "loss: 0.003292  [ 5120/11641]\n",
      "loss: 0.001063  [ 7680/11641]\n",
      "loss: 0.000268  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.061857\n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.000025  [    0/11641]\n",
      "loss: 0.000343  [ 2560/11641]\n",
      "loss: 0.000702  [ 5120/11641]\n",
      "loss: 0.000045  [ 7680/11641]\n",
      "loss: 0.000083  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.054492\n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.000292  [    0/11641]\n",
      "loss: 0.002550  [ 2560/11641]\n",
      "loss: 0.008972  [ 5120/11641]\n",
      "loss: 0.004544  [ 7680/11641]\n",
      "loss: 0.000274  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.042278\n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.003088  [    0/11641]\n",
      "loss: 0.003544  [ 2560/11641]\n",
      "loss: 0.004351  [ 5120/11641]\n",
      "loss: 0.000096  [ 7680/11641]\n",
      "loss: 0.004401  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.076980\n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.000079  [    0/11641]\n",
      "loss: 0.003413  [ 2560/11641]\n",
      "loss: 0.010165  [ 5120/11641]\n",
      "loss: 0.005866  [ 7680/11641]\n",
      "loss: 0.001244  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.063121\n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.001031  [    0/11641]\n",
      "loss: 0.000012  [ 2560/11641]\n",
      "loss: 0.001137  [ 5120/11641]\n",
      "loss: 0.001205  [ 7680/11641]\n",
      "loss: 0.008941  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.053242\n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.000168  [    0/11641]\n",
      "loss: 0.000349  [ 2560/11641]\n",
      "loss: 0.000444  [ 5120/11641]\n",
      "loss: 0.000092  [ 7680/11641]\n",
      "loss: 0.000603  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.059094\n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.000282  [    0/11641]\n",
      "loss: 0.000136  [ 2560/11641]\n",
      "loss: 0.000034  [ 5120/11641]\n",
      "loss: 0.000399  [ 7680/11641]\n",
      "loss: 0.001735  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.060177\n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.000217  [    0/11641]\n",
      "loss: 0.000107  [ 2560/11641]\n",
      "loss: 0.008999  [ 5120/11641]\n",
      "loss: 0.010544  [ 7680/11641]\n",
      "loss: 0.003685  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.051923\n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.004033  [    0/11641]\n",
      "loss: 0.003589  [ 2560/11641]\n",
      "loss: 0.000363  [ 5120/11641]\n",
      "loss: 0.000808  [ 7680/11641]\n",
      "loss: 0.000563  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.049789\n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.007177  [    0/11641]\n",
      "loss: 0.000696  [ 2560/11641]\n",
      "loss: 0.002682  [ 5120/11641]\n",
      "loss: 0.008607  [ 7680/11641]\n",
      "loss: 0.013532  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.062880\n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.000094  [    0/11641]\n",
      "loss: 0.000678  [ 2560/11641]\n",
      "loss: 0.009798  [ 5120/11641]\n",
      "loss: 0.000661  [ 7680/11641]\n",
      "loss: 0.000037  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.049792\n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.000671  [    0/11641]\n",
      "loss: 0.011066  [ 2560/11641]\n",
      "loss: 0.000776  [ 5120/11641]\n",
      "loss: 0.002221  [ 7680/11641]\n",
      "loss: 0.001298  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.061113\n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.001038  [    0/11641]\n",
      "loss: 0.006204  [ 2560/11641]\n",
      "loss: 0.000297  [ 5120/11641]\n",
      "loss: 0.001179  [ 7680/11641]\n",
      "loss: 0.000070  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.048161\n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/11641]\n",
      "loss: 0.005567  [ 2560/11641]\n",
      "loss: 0.000082  [ 5120/11641]\n",
      "loss: 0.000033  [ 7680/11641]\n",
      "loss: 0.000194  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.063789\n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/11641]\n",
      "loss: 0.000089  [ 2560/11641]\n",
      "loss: 0.000687  [ 5120/11641]\n",
      "loss: 0.000329  [ 7680/11641]\n",
      "loss: 0.038229  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.067874\n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.003251  [    0/11641]\n",
      "loss: 0.003508  [ 2560/11641]\n",
      "loss: 0.002454  [ 5120/11641]\n",
      "loss: 0.005714  [ 7680/11641]\n",
      "loss: 0.017552  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.065508\n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.008678  [    0/11641]\n",
      "loss: 0.000464  [ 2560/11641]\n",
      "loss: 0.004791  [ 5120/11641]\n",
      "loss: 0.030507  [ 7680/11641]\n",
      "loss: 0.000045  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.103765\n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.005328  [    0/11641]\n",
      "loss: 0.010775  [ 2560/11641]\n",
      "loss: 0.008279  [ 5120/11641]\n",
      "loss: 0.013806  [ 7680/11641]\n",
      "loss: 0.000250  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.095148\n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.007554  [    0/11641]\n",
      "loss: 0.001571  [ 2560/11641]\n",
      "loss: 0.001997  [ 5120/11641]\n",
      "loss: 0.002464  [ 7680/11641]\n",
      "loss: 0.003872  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.061460\n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.000180  [    0/11641]\n",
      "loss: 0.003818  [ 2560/11641]\n",
      "loss: 0.005518  [ 5120/11641]\n",
      "loss: 0.007618  [ 7680/11641]\n",
      "loss: 0.000224  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.074784\n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.000155  [    0/11641]\n",
      "loss: 0.000478  [ 2560/11641]\n",
      "loss: 0.041845  [ 5120/11641]\n",
      "loss: 0.013538  [ 7680/11641]\n",
      "loss: 0.014542  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.063366\n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.005738  [    0/11641]\n",
      "loss: 0.026808  [ 2560/11641]\n",
      "loss: 0.000066  [ 5120/11641]\n",
      "loss: 0.000041  [ 7680/11641]\n",
      "loss: 0.002101  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.048589\n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.000216  [    0/11641]\n",
      "loss: 0.000515  [ 2560/11641]\n",
      "loss: 0.006387  [ 5120/11641]\n",
      "loss: 0.000764  [ 7680/11641]\n",
      "loss: 0.004402  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.058161\n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.004423  [    0/11641]\n",
      "loss: 0.000339  [ 2560/11641]\n",
      "loss: 0.000042  [ 5120/11641]\n",
      "loss: 0.000129  [ 7680/11641]\n",
      "loss: 0.000033  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.074911\n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.000327  [    0/11641]\n",
      "loss: 0.003646  [ 2560/11641]\n",
      "loss: 0.000352  [ 5120/11641]\n",
      "loss: 0.000180  [ 7680/11641]\n",
      "loss: 0.013773  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.063516\n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.002139  [    0/11641]\n",
      "loss: 0.000680  [ 2560/11641]\n",
      "loss: 0.000425  [ 5120/11641]\n",
      "loss: 0.000283  [ 7680/11641]\n",
      "loss: 0.000554  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.052862\n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.001754  [    0/11641]\n",
      "loss: 0.001259  [ 2560/11641]\n",
      "loss: 0.000163  [ 5120/11641]\n",
      "loss: 0.000076  [ 7680/11641]\n",
      "loss: 0.010763  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053442\n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.000122  [    0/11641]\n",
      "loss: 0.000026  [ 2560/11641]\n",
      "loss: 0.000194  [ 5120/11641]\n",
      "loss: 0.000143  [ 7680/11641]\n",
      "loss: 0.000020  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.084979\n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.000271  [    0/11641]\n",
      "loss: 0.007999  [ 2560/11641]\n",
      "loss: 0.000640  [ 5120/11641]\n",
      "loss: 0.002044  [ 7680/11641]\n",
      "loss: 0.002072  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.055507\n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.001443  [    0/11641]\n",
      "loss: 0.000071  [ 2560/11641]\n",
      "loss: 0.001928  [ 5120/11641]\n",
      "loss: 0.002665  [ 7680/11641]\n",
      "loss: 0.000125  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.074337\n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.000901  [    0/11641]\n",
      "loss: 0.000229  [ 2560/11641]\n",
      "loss: 0.000247  [ 5120/11641]\n",
      "loss: 0.000587  [ 7680/11641]\n",
      "loss: 0.000450  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.060169\n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.000323  [    0/11641]\n",
      "loss: 0.000020  [ 2560/11641]\n",
      "loss: 0.000991  [ 5120/11641]\n",
      "loss: 0.001353  [ 7680/11641]\n",
      "loss: 0.000322  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.069174\n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/11641]\n",
      "loss: 0.000071  [ 2560/11641]\n",
      "loss: 0.001189  [ 5120/11641]\n",
      "loss: 0.000655  [ 7680/11641]\n",
      "loss: 0.002973  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.079407\n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.006448  [    0/11641]\n",
      "loss: 0.001114  [ 2560/11641]\n",
      "loss: 0.000468  [ 5120/11641]\n",
      "loss: 0.000462  [ 7680/11641]\n",
      "loss: 0.002849  [10240/11641]\n",
      "Accuracy: 98.49%, Avg loss: 0.097740\n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.010799  [    0/11641]\n",
      "loss: 0.001328  [ 2560/11641]\n",
      "loss: 0.000133  [ 5120/11641]\n",
      "loss: 0.000519  [ 7680/11641]\n",
      "loss: 0.005796  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.050062\n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/11641]\n",
      "loss: 0.002599  [ 2560/11641]\n",
      "loss: 0.010021  [ 5120/11641]\n",
      "loss: 0.002086  [ 7680/11641]\n",
      "loss: 0.003354  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.062837\n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.001532  [    0/11641]\n",
      "loss: 0.000110  [ 2560/11641]\n",
      "loss: 0.000590  [ 5120/11641]\n",
      "loss: 0.002796  [ 7680/11641]\n",
      "loss: 0.000231  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.049886\n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.000209  [    0/11641]\n",
      "loss: 0.000172  [ 2560/11641]\n",
      "loss: 0.000288  [ 5120/11641]\n",
      "loss: 0.000140  [ 7680/11641]\n",
      "loss: 0.004100  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.072891\n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.024315  [    0/11641]\n",
      "loss: 0.001084  [ 2560/11641]\n",
      "loss: 0.000312  [ 5120/11641]\n",
      "loss: 0.000046  [ 7680/11641]\n",
      "loss: 0.000258  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.051650\n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.000238  [    0/11641]\n",
      "loss: 0.000389  [ 2560/11641]\n",
      "loss: 0.006044  [ 5120/11641]\n",
      "loss: 0.000193  [ 7680/11641]\n",
      "loss: 0.000072  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.061631\n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.000044  [    0/11641]\n",
      "loss: 0.001800  [ 2560/11641]\n",
      "loss: 0.000106  [ 5120/11641]\n",
      "loss: 0.000829  [ 7680/11641]\n",
      "loss: 0.000169  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.072100\n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.006461  [    0/11641]\n",
      "loss: 0.000107  [ 2560/11641]\n",
      "loss: 0.001663  [ 5120/11641]\n",
      "loss: 0.008004  [ 7680/11641]\n",
      "loss: 0.000694  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.052965\n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.009960  [    0/11641]\n",
      "loss: 0.000058  [ 2560/11641]\n",
      "loss: 0.009795  [ 5120/11641]\n",
      "loss: 0.016515  [ 7680/11641]\n",
      "loss: 0.002950  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.074701\n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.000795  [    0/11641]\n",
      "loss: 0.000435  [ 2560/11641]\n",
      "loss: 0.006474  [ 5120/11641]\n",
      "loss: 0.000015  [ 7680/11641]\n",
      "loss: 0.002154  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.048607\n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/11641]\n",
      "loss: 0.003559  [ 2560/11641]\n",
      "loss: 0.000416  [ 5120/11641]\n",
      "loss: 0.001033  [ 7680/11641]\n",
      "loss: 0.000528  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.072889\n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.000884  [    0/11641]\n",
      "loss: 0.000246  [ 2560/11641]\n",
      "loss: 0.004722  [ 5120/11641]\n",
      "loss: 0.018349  [ 7680/11641]\n",
      "loss: 0.000669  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.072546\n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.000361  [    0/11641]\n",
      "loss: 0.002820  [ 2560/11641]\n",
      "loss: 0.003446  [ 5120/11641]\n",
      "loss: 0.000711  [ 7680/11641]\n",
      "loss: 0.000221  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.077631\n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.007003  [    0/11641]\n",
      "loss: 0.000875  [ 2560/11641]\n",
      "loss: 0.000034  [ 5120/11641]\n",
      "loss: 0.001307  [ 7680/11641]\n",
      "loss: 0.000076  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.090723\n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.003237  [    0/11641]\n",
      "loss: 0.002462  [ 2560/11641]\n",
      "loss: 0.005475  [ 5120/11641]\n",
      "loss: 0.000822  [ 7680/11641]\n",
      "loss: 0.003604  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.059149\n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.000211  [    0/11641]\n",
      "loss: 0.000142  [ 2560/11641]\n",
      "loss: 0.002323  [ 5120/11641]\n",
      "loss: 0.000242  [ 7680/11641]\n",
      "loss: 0.001082  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.062459\n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.006148  [    0/11641]\n",
      "loss: 0.000855  [ 2560/11641]\n",
      "loss: 0.000193  [ 5120/11641]\n",
      "loss: 0.000039  [ 7680/11641]\n",
      "loss: 0.000132  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053843\n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.003608  [    0/11641]\n",
      "loss: 0.000187  [ 2560/11641]\n",
      "loss: 0.001371  [ 5120/11641]\n",
      "loss: 0.000438  [ 7680/11641]\n",
      "loss: 0.000499  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.047748\n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.000239  [    0/11641]\n",
      "loss: 0.006441  [ 2560/11641]\n",
      "loss: 0.000538  [ 5120/11641]\n",
      "loss: 0.000986  [ 7680/11641]\n",
      "loss: 0.000117  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.062313\n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.000036  [    0/11641]\n",
      "loss: 0.000646  [ 2560/11641]\n",
      "loss: 0.007584  [ 5120/11641]\n",
      "loss: 0.001164  [ 7680/11641]\n",
      "loss: 0.000319  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.075638\n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.000023  [    0/11641]\n",
      "loss: 0.000207  [ 2560/11641]\n",
      "loss: 0.000170  [ 5120/11641]\n",
      "loss: 0.011731  [ 7680/11641]\n",
      "loss: 0.000216  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.058015\n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.000075  [    0/11641]\n",
      "loss: 0.000459  [ 2560/11641]\n",
      "loss: 0.000139  [ 5120/11641]\n",
      "loss: 0.002146  [ 7680/11641]\n",
      "loss: 0.006081  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.050146\n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.000097  [    0/11641]\n",
      "loss: 0.000055  [ 2560/11641]\n",
      "loss: 0.000346  [ 5120/11641]\n",
      "loss: 0.001014  [ 7680/11641]\n",
      "loss: 0.000757  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.047178\n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/11641]\n",
      "loss: 0.000627  [ 2560/11641]\n",
      "loss: 0.000733  [ 5120/11641]\n",
      "loss: 0.000345  [ 7680/11641]\n",
      "loss: 0.000068  [10240/11641]\n",
      "Accuracy: 99.45%, Avg loss: 0.038697\n",
      "Model saved\n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.000123  [    0/11641]\n",
      "loss: 0.000207  [ 2560/11641]\n",
      "loss: 0.000283  [ 5120/11641]\n",
      "loss: 0.000078  [ 7680/11641]\n",
      "loss: 0.000420  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053218\n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/11641]\n",
      "loss: 0.012445  [ 2560/11641]\n",
      "loss: 0.000533  [ 5120/11641]\n",
      "loss: 0.002461  [ 7680/11641]\n",
      "loss: 0.000246  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.048041\n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.000499  [    0/11641]\n",
      "loss: 0.000171  [ 2560/11641]\n",
      "loss: 0.000176  [ 5120/11641]\n",
      "loss: 0.002279  [ 7680/11641]\n",
      "loss: 0.001585  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.068649\n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.008002  [    0/11641]\n",
      "loss: 0.013931  [ 2560/11641]\n",
      "loss: 0.007068  [ 5120/11641]\n",
      "loss: 0.008357  [ 7680/11641]\n",
      "loss: 0.000180  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.085514\n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.000524  [    0/11641]\n",
      "loss: 0.000144  [ 2560/11641]\n",
      "loss: 0.000685  [ 5120/11641]\n",
      "loss: 0.000411  [ 7680/11641]\n",
      "loss: 0.005704  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.071744\n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/11641]\n",
      "loss: 0.000396  [ 2560/11641]\n",
      "loss: 0.006324  [ 5120/11641]\n",
      "loss: 0.001002  [ 7680/11641]\n",
      "loss: 0.000094  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.062484\n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.000338  [    0/11641]\n",
      "loss: 0.000444  [ 2560/11641]\n",
      "loss: 0.021902  [ 5120/11641]\n",
      "loss: 0.011240  [ 7680/11641]\n",
      "loss: 0.008869  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.048141\n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.002887  [    0/11641]\n",
      "loss: 0.002145  [ 2560/11641]\n",
      "loss: 0.000745  [ 5120/11641]\n",
      "loss: 0.000034  [ 7680/11641]\n",
      "loss: 0.000947  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.044894\n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.000118  [    0/11641]\n",
      "loss: 0.005075  [ 2560/11641]\n",
      "loss: 0.001854  [ 5120/11641]\n",
      "loss: 0.000555  [ 7680/11641]\n",
      "loss: 0.000699  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.056400\n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.010134  [    0/11641]\n",
      "loss: 0.005254  [ 2560/11641]\n",
      "loss: 0.001218  [ 5120/11641]\n",
      "loss: 0.015978  [ 7680/11641]\n",
      "loss: 0.013351  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.066715\n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.017178  [    0/11641]\n",
      "loss: 0.003349  [ 2560/11641]\n",
      "loss: 0.000243  [ 5120/11641]\n",
      "loss: 0.012569  [ 7680/11641]\n",
      "loss: 0.000249  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.045183\n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.004294  [    0/11641]\n",
      "loss: 0.015651  [ 2560/11641]\n",
      "loss: 0.000659  [ 5120/11641]\n",
      "loss: 0.000573  [ 7680/11641]\n",
      "loss: 0.001945  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.052887\n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.000024  [    0/11641]\n",
      "loss: 0.000418  [ 2560/11641]\n",
      "loss: 0.017598  [ 5120/11641]\n",
      "loss: 0.000748  [ 7680/11641]\n",
      "loss: 0.010231  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.082773\n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.001970  [    0/11641]\n",
      "loss: 0.001044  [ 2560/11641]\n",
      "loss: 0.000722  [ 5120/11641]\n",
      "loss: 0.000780  [ 7680/11641]\n",
      "loss: 0.000980  [10240/11641]\n",
      "Accuracy: 98.42%, Avg loss: 0.085479\n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.012842  [    0/11641]\n",
      "loss: 0.004543  [ 2560/11641]\n",
      "loss: 0.001329  [ 5120/11641]\n",
      "loss: 0.001191  [ 7680/11641]\n",
      "loss: 0.000082  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.051139\n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.004172  [    0/11641]\n",
      "loss: 0.001674  [ 2560/11641]\n",
      "loss: 0.014601  [ 5120/11641]\n",
      "loss: 0.000204  [ 7680/11641]\n",
      "loss: 0.002065  [10240/11641]\n",
      "Accuracy: 98.69%, Avg loss: 0.077467\n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.000260  [    0/11641]\n",
      "loss: 0.000323  [ 2560/11641]\n",
      "loss: 0.004742  [ 5120/11641]\n",
      "loss: 0.002969  [ 7680/11641]\n",
      "loss: 0.000392  [10240/11641]\n",
      "Accuracy: 98.35%, Avg loss: 0.073283\n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.000811  [    0/11641]\n",
      "loss: 0.000703  [ 2560/11641]\n",
      "loss: 0.000189  [ 5120/11641]\n",
      "loss: 0.000042  [ 7680/11641]\n",
      "loss: 0.003070  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.050438\n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.000230  [    0/11641]\n",
      "loss: 0.000839  [ 2560/11641]\n",
      "loss: 0.000256  [ 5120/11641]\n",
      "loss: 0.002512  [ 7680/11641]\n",
      "loss: 0.000018  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.058072\n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.000709  [    0/11641]\n",
      "loss: 0.000582  [ 2560/11641]\n",
      "loss: 0.000706  [ 5120/11641]\n",
      "loss: 0.001820  [ 7680/11641]\n",
      "loss: 0.000536  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.047094\n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.000021  [    0/11641]\n",
      "loss: 0.000342  [ 2560/11641]\n",
      "loss: 0.000165  [ 5120/11641]\n",
      "loss: 0.000225  [ 7680/11641]\n",
      "loss: 0.001747  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.045626\n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.000097  [    0/11641]\n",
      "loss: 0.000569  [ 2560/11641]\n",
      "loss: 0.000100  [ 5120/11641]\n",
      "loss: 0.000740  [ 7680/11641]\n",
      "loss: 0.000096  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.044359\n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.000065  [    0/11641]\n",
      "loss: 0.000050  [ 2560/11641]\n",
      "loss: 0.002053  [ 5120/11641]\n",
      "loss: 0.000075  [ 7680/11641]\n",
      "loss: 0.001443  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.059530\n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.000233  [    0/11641]\n",
      "loss: 0.011239  [ 2560/11641]\n",
      "loss: 0.000207  [ 5120/11641]\n",
      "loss: 0.000357  [ 7680/11641]\n",
      "loss: 0.000294  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.066820\n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.001455  [    0/11641]\n",
      "loss: 0.002659  [ 2560/11641]\n",
      "loss: 0.002243  [ 5120/11641]\n",
      "loss: 0.000118  [ 7680/11641]\n",
      "loss: 0.000456  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.058209\n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.002697  [    0/11641]\n",
      "loss: 0.001756  [ 2560/11641]\n",
      "loss: 0.001873  [ 5120/11641]\n",
      "loss: 0.000259  [ 7680/11641]\n",
      "loss: 0.000208  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.046427\n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.000381  [    0/11641]\n",
      "loss: 0.000237  [ 2560/11641]\n",
      "loss: 0.000549  [ 5120/11641]\n",
      "loss: 0.000110  [ 7680/11641]\n",
      "loss: 0.003159  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.068804\n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.000036  [    0/11641]\n",
      "loss: 0.005331  [ 2560/11641]\n",
      "loss: 0.000048  [ 5120/11641]\n",
      "loss: 0.000035  [ 7680/11641]\n",
      "loss: 0.000397  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.063017\n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.000284  [    0/11641]\n",
      "loss: 0.005320  [ 2560/11641]\n",
      "loss: 0.000011  [ 5120/11641]\n",
      "loss: 0.000048  [ 7680/11641]\n",
      "loss: 0.000238  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.052120\n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.000405  [    0/11641]\n",
      "loss: 0.004063  [ 2560/11641]\n",
      "loss: 0.000214  [ 5120/11641]\n",
      "loss: 0.000024  [ 7680/11641]\n",
      "loss: 0.000275  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.066942\n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.021383  [    0/11641]\n",
      "loss: 0.002967  [ 2560/11641]\n",
      "loss: 0.000372  [ 5120/11641]\n",
      "loss: 0.000016  [ 7680/11641]\n",
      "loss: 0.000594  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.062395\n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.008296  [    0/11641]\n",
      "loss: 0.000153  [ 2560/11641]\n",
      "loss: 0.000413  [ 5120/11641]\n",
      "loss: 0.001784  [ 7680/11641]\n",
      "loss: 0.001495  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.064027\n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.000066  [    0/11641]\n",
      "loss: 0.000219  [ 2560/11641]\n",
      "loss: 0.000037  [ 5120/11641]\n",
      "loss: 0.015133  [ 7680/11641]\n",
      "loss: 0.001270  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.070252\n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.000191  [    0/11641]\n",
      "loss: 0.000085  [ 2560/11641]\n",
      "loss: 0.000037  [ 5120/11641]\n",
      "loss: 0.000227  [ 7680/11641]\n",
      "loss: 0.000026  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.042868\n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.013892  [    0/11641]\n",
      "loss: 0.000049  [ 2560/11641]\n",
      "loss: 0.000019  [ 5120/11641]\n",
      "loss: 0.000832  [ 7680/11641]\n",
      "loss: 0.000255  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.053429\n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.004044  [    0/11641]\n",
      "loss: 0.000444  [ 2560/11641]\n",
      "loss: 0.001628  [ 5120/11641]\n",
      "loss: 0.004296  [ 7680/11641]\n",
      "loss: 0.000039  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.081719\n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.000209  [    0/11641]\n",
      "loss: 0.002901  [ 2560/11641]\n",
      "loss: 0.015469  [ 5120/11641]\n",
      "loss: 0.005887  [ 7680/11641]\n",
      "loss: 0.000401  [10240/11641]\n",
      "Accuracy: 98.08%, Avg loss: 0.118607\n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.003146  [    0/11641]\n",
      "loss: 0.008357  [ 2560/11641]\n",
      "loss: 0.001644  [ 5120/11641]\n",
      "loss: 0.001293  [ 7680/11641]\n",
      "loss: 0.000076  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.053279\n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.002288  [    0/11641]\n",
      "loss: 0.000454  [ 2560/11641]\n",
      "loss: 0.000734  [ 5120/11641]\n",
      "loss: 0.001456  [ 7680/11641]\n",
      "loss: 0.005472  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.041461\n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.000321  [    0/11641]\n",
      "loss: 0.000735  [ 2560/11641]\n",
      "loss: 0.000080  [ 5120/11641]\n",
      "loss: 0.011075  [ 7680/11641]\n",
      "loss: 0.000088  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.050792\n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.000089  [    0/11641]\n",
      "loss: 0.001864  [ 2560/11641]\n",
      "loss: 0.000138  [ 5120/11641]\n",
      "loss: 0.001107  [ 7680/11641]\n",
      "loss: 0.000801  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.048751\n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.000327  [    0/11641]\n",
      "loss: 0.000512  [ 2560/11641]\n",
      "loss: 0.000022  [ 5120/11641]\n",
      "loss: 0.002541  [ 7680/11641]\n",
      "loss: 0.001166  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.063283\n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.000109  [    0/11641]\n",
      "loss: 0.000123  [ 2560/11641]\n",
      "loss: 0.000544  [ 5120/11641]\n",
      "loss: 0.004144  [ 7680/11641]\n",
      "loss: 0.013586  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.048487\n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.000039  [    0/11641]\n",
      "loss: 0.004187  [ 2560/11641]\n",
      "loss: 0.001445  [ 5120/11641]\n",
      "loss: 0.018027  [ 7680/11641]\n",
      "loss: 0.003771  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.043529\n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.002061  [    0/11641]\n",
      "loss: 0.002004  [ 2560/11641]\n",
      "loss: 0.002516  [ 5120/11641]\n",
      "loss: 0.009070  [ 7680/11641]\n",
      "loss: 0.000587  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.049944\n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.000214  [    0/11641]\n",
      "loss: 0.000319  [ 2560/11641]\n",
      "loss: 0.003485  [ 5120/11641]\n",
      "loss: 0.005405  [ 7680/11641]\n",
      "loss: 0.012518  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.046526\n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/11641]\n",
      "loss: 0.034943  [ 2560/11641]\n",
      "loss: 0.010835  [ 5120/11641]\n",
      "loss: 0.007890  [ 7680/11641]\n",
      "loss: 0.000027  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.059606\n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.001590  [    0/11641]\n",
      "loss: 0.013939  [ 2560/11641]\n",
      "loss: 0.006242  [ 5120/11641]\n",
      "loss: 0.007070  [ 7680/11641]\n",
      "loss: 0.012863  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.074311\n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.000363  [    0/11641]\n",
      "loss: 0.005896  [ 2560/11641]\n",
      "loss: 0.001838  [ 5120/11641]\n",
      "loss: 0.002159  [ 7680/11641]\n",
      "loss: 0.001017  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.055564\n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.000197  [    0/11641]\n",
      "loss: 0.000268  [ 2560/11641]\n",
      "loss: 0.023884  [ 5120/11641]\n",
      "loss: 0.000228  [ 7680/11641]\n",
      "loss: 0.000423  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.056359\n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.000115  [    0/11641]\n",
      "loss: 0.000966  [ 2560/11641]\n",
      "loss: 0.008523  [ 5120/11641]\n",
      "loss: 0.000036  [ 7680/11641]\n",
      "loss: 0.000618  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.035695\n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.001756  [    0/11641]\n",
      "loss: 0.000285  [ 2560/11641]\n",
      "loss: 0.000435  [ 5120/11641]\n",
      "loss: 0.000908  [ 7680/11641]\n",
      "loss: 0.002909  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.066208\n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.000141  [    0/11641]\n",
      "loss: 0.000121  [ 2560/11641]\n",
      "loss: 0.000109  [ 5120/11641]\n",
      "loss: 0.000023  [ 7680/11641]\n",
      "loss: 0.001986  [10240/11641]\n",
      "Accuracy: 99.45%, Avg loss: 0.036337\n",
      "Model saved\n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.000413  [    0/11641]\n",
      "loss: 0.000060  [ 2560/11641]\n",
      "loss: 0.003059  [ 5120/11641]\n",
      "loss: 0.000015  [ 7680/11641]\n",
      "loss: 0.008463  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.039660\n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.000581  [    0/11641]\n",
      "loss: 0.000038  [ 2560/11641]\n",
      "loss: 0.000118  [ 5120/11641]\n",
      "loss: 0.000353  [ 7680/11641]\n",
      "loss: 0.000818  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.064670\n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.004384  [    0/11641]\n",
      "loss: 0.001746  [ 2560/11641]\n",
      "loss: 0.000867  [ 5120/11641]\n",
      "loss: 0.000144  [ 7680/11641]\n",
      "loss: 0.000117  [10240/11641]\n",
      "Accuracy: 98.56%, Avg loss: 0.058865\n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/11641]\n",
      "loss: 0.025653  [ 2560/11641]\n",
      "loss: 0.000271  [ 5120/11641]\n",
      "loss: 0.000159  [ 7680/11641]\n",
      "loss: 0.002681  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.060636\n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.003318  [    0/11641]\n",
      "loss: 0.000038  [ 2560/11641]\n",
      "loss: 0.000638  [ 5120/11641]\n",
      "loss: 0.000622  [ 7680/11641]\n",
      "loss: 0.000112  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.063980\n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.001977  [    0/11641]\n",
      "loss: 0.001674  [ 2560/11641]\n",
      "loss: 0.001366  [ 5120/11641]\n",
      "loss: 0.000032  [ 7680/11641]\n",
      "loss: 0.003390  [10240/11641]\n",
      "Accuracy: 99.38%, Avg loss: 0.035773\n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.000021  [    0/11641]\n",
      "loss: 0.005132  [ 2560/11641]\n",
      "loss: 0.000053  [ 5120/11641]\n",
      "loss: 0.000053  [ 7680/11641]\n",
      "loss: 0.000111  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.048895\n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.000137  [    0/11641]\n",
      "loss: 0.001999  [ 2560/11641]\n",
      "loss: 0.005391  [ 5120/11641]\n",
      "loss: 0.000238  [ 7680/11641]\n",
      "loss: 0.006883  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.057677\n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.000035  [    0/11641]\n",
      "loss: 0.004054  [ 2560/11641]\n",
      "loss: 0.000025  [ 5120/11641]\n",
      "loss: 0.000178  [ 7680/11641]\n",
      "loss: 0.000005  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.055998\n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.002421  [    0/11641]\n",
      "loss: 0.000327  [ 2560/11641]\n",
      "loss: 0.012154  [ 5120/11641]\n",
      "loss: 0.003517  [ 7680/11641]\n",
      "loss: 0.004084  [10240/11641]\n",
      "Accuracy: 98.63%, Avg loss: 0.054572\n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.000040  [    0/11641]\n",
      "loss: 0.009793  [ 2560/11641]\n",
      "loss: 0.000060  [ 5120/11641]\n",
      "loss: 0.004833  [ 7680/11641]\n",
      "loss: 0.000165  [10240/11641]\n",
      "Accuracy: 99.18%, Avg loss: 0.065885\n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.000432  [    0/11641]\n",
      "loss: 0.001413  [ 2560/11641]\n",
      "loss: 0.000071  [ 5120/11641]\n",
      "loss: 0.019334  [ 7680/11641]\n",
      "loss: 0.003835  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.071835\n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.008721  [    0/11641]\n",
      "loss: 0.000018  [ 2560/11641]\n",
      "loss: 0.000046  [ 5120/11641]\n",
      "loss: 0.001605  [ 7680/11641]\n",
      "loss: 0.004856  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.068868\n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.000531  [    0/11641]\n",
      "loss: 0.005770  [ 2560/11641]\n",
      "loss: 0.000170  [ 5120/11641]\n",
      "loss: 0.001474  [ 7680/11641]\n",
      "loss: 0.006545  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.029670\n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.000073  [    0/11641]\n",
      "loss: 0.002195  [ 2560/11641]\n",
      "loss: 0.001435  [ 5120/11641]\n",
      "loss: 0.001711  [ 7680/11641]\n",
      "loss: 0.000102  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.044893\n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/11641]\n",
      "loss: 0.010968  [ 2560/11641]\n",
      "loss: 0.000993  [ 5120/11641]\n",
      "loss: 0.000118  [ 7680/11641]\n",
      "loss: 0.000620  [10240/11641]\n",
      "Accuracy: 99.31%, Avg loss: 0.044646\n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.000191  [    0/11641]\n",
      "loss: 0.000160  [ 2560/11641]\n",
      "loss: 0.001379  [ 5120/11641]\n",
      "loss: 0.000381  [ 7680/11641]\n",
      "loss: 0.000053  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.041713\n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.001933  [    0/11641]\n",
      "loss: 0.000151  [ 2560/11641]\n",
      "loss: 0.000907  [ 5120/11641]\n",
      "loss: 0.002754  [ 7680/11641]\n",
      "loss: 0.000274  [10240/11641]\n",
      "Accuracy: 99.24%, Avg loss: 0.041332\n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.004581  [    0/11641]\n",
      "loss: 0.000208  [ 2560/11641]\n",
      "loss: 0.006634  [ 5120/11641]\n",
      "loss: 0.000056  [ 7680/11641]\n",
      "loss: 0.007110  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.064122\n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.031470  [    0/11641]\n",
      "loss: 0.000113  [ 2560/11641]\n",
      "loss: 0.000692  [ 5120/11641]\n",
      "loss: 0.000244  [ 7680/11641]\n",
      "loss: 0.000268  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.063228\n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.000249  [    0/11641]\n",
      "loss: 0.000126  [ 2560/11641]\n",
      "loss: 0.001187  [ 5120/11641]\n",
      "loss: 0.000664  [ 7680/11641]\n",
      "loss: 0.000749  [10240/11641]\n",
      "Accuracy: 98.90%, Avg loss: 0.061055\n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.023956  [    0/11641]\n",
      "loss: 0.000508  [ 2560/11641]\n",
      "loss: 0.000055  [ 5120/11641]\n",
      "loss: 0.000107  [ 7680/11641]\n",
      "loss: 0.000042  [10240/11641]\n",
      "Accuracy: 99.04%, Avg loss: 0.047150\n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.000307  [    0/11641]\n",
      "loss: 0.000429  [ 2560/11641]\n",
      "loss: 0.000424  [ 5120/11641]\n",
      "loss: 0.001734  [ 7680/11641]\n",
      "loss: 0.000246  [10240/11641]\n",
      "Accuracy: 98.76%, Avg loss: 0.083342\n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.011143  [    0/11641]\n",
      "loss: 0.006859  [ 2560/11641]\n",
      "loss: 0.005490  [ 5120/11641]\n",
      "loss: 0.002350  [ 7680/11641]\n",
      "loss: 0.002330  [10240/11641]\n",
      "Accuracy: 98.83%, Avg loss: 0.070196\n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.012391  [    0/11641]\n",
      "loss: 0.000687  [ 2560/11641]\n",
      "loss: 0.000384  [ 5120/11641]\n",
      "loss: 0.014788  [ 7680/11641]\n",
      "loss: 0.000096  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.047616\n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.000112  [    0/11641]\n",
      "loss: 0.021353  [ 2560/11641]\n",
      "loss: 0.000229  [ 5120/11641]\n",
      "loss: 0.000391  [ 7680/11641]\n",
      "loss: 0.000221  [10240/11641]\n",
      "Accuracy: 98.97%, Avg loss: 0.057880\n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/11641]\n",
      "loss: 0.000143  [ 2560/11641]\n",
      "loss: 0.002887  [ 5120/11641]\n",
      "loss: 0.003922  [ 7680/11641]\n",
      "loss: 0.000724  [10240/11641]\n",
      "Accuracy: 99.11%, Avg loss: 0.057207\n",
      "\n",
      "Done! Validation accuracy: 99.45%\n",
      "Training took 823.54 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('AFTER dataloading')\n",
    "print(dataloader_train)\n",
    "print(dataloader_val)\n",
    "print(dataloader_test)\n",
    "#X_ptbdb_train, X_ptbdb_val, y_ptbdb_train, y_ptbdb_val = train_test_split(ptbdb.iloc[:,:-1].values, ptbdb.iloc[:,-1].values, test_size=0.2, random_state=42)\n",
    "#X_ptbdb_val, X_ptbdb_test, y_ptbdb_val, y_ptbdb_test  = train_test_split(X_ptbdb_val, y_ptbdb_val, test_size=0.5, random_state=42)\n",
    "print('AFTER DIVISION')\n",
    "#print(X_ptbdb_train.shape)\n",
    "\n",
    "#print(X_ptbdb_val.shape)\n",
    "print(len(dataloader_val))\n",
    "print(len(dataloader_test))\n",
    "print(data.shape)\n",
    "print(data.type())\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"CNN - to be used to front-end transformer. Not used currently. TODO: adopt the dimensions properly\"\"\"\n",
    "    def __init__(self, seq_length, feature_length):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.feature_length = feature_length\n",
    "\n",
    "        #todo not hardcode\n",
    "        self.hiddenLast=18\n",
    "        self.hidden1=64\n",
    "\n",
    "        self.kernel_size=1\n",
    "\n",
    "        self.activation=nn.ReLU()\n",
    "\n",
    "        self.first=True\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=self.hidden1, kernel_size=self.kernel_size),\n",
    "            nn.BatchNorm2d(num_features=self.hidden1),\n",
    "            self.activation,\n",
    "            #nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.convLast = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.hidden1, out_channels=self.hiddenLast, kernel_size=self.kernel_size),\n",
    "            nn.BatchNorm2d(num_features=self.hiddenLast),\n",
    "            self.activation,\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(kernel_size=1)\n",
    "        )\n",
    "        self.fl = nn.Flatten()\n",
    "        #TODO must not hardcode number of layers (2)\n",
    "        #\n",
    "        # weight x height (weight and height are reducted by self.kernel_size-1 each time conv and 1/4 factor due to max pool 2d)\n",
    "        #num_features = (self.feature_length - 2*(self.kernel_size-1)) * (self.seq_length - 2*(self.kernel_size-1)) * self.hiddenLast / 4\n",
    "        #self.fc = nn.Linear(in_features=int(num_features), out_features=NUM_CLASSES)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        # torch expects channel = 1\n",
    "        x = x.to(device=torch.device(\"cuda:0\"))\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        #x = x.squeeze(1)\n",
    "        x = self.convLast(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.fl(x)\n",
    "        #x = self.fc(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        nn.Flatten()\n",
    "        if self.first:\n",
    "            print(x.size())\n",
    "            self.first=False\n",
    "        return x\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Main TransformerModel used\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dmodel : itensor\n",
    "        input tensor\n",
    "    seq_len : int\n",
    "        length of sequence (time dim)\n",
    "    nhead : int\n",
    "        number of heads in nn.MultiheadAttention\n",
    "    d_hid : int\n",
    "        dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    nlayers : int\n",
    "        number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dmodel, seq_len, nhead, d_hid, nlayers):\n",
    "        super().__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.seq_len = seq_len\n",
    "        #self.cnn = CNN(seq_length = seq_len, feature_length = NUM_CLASSES)\n",
    "        self.pos_encoder = PositionalEncoding(dmodel, seq_len)\n",
    "        encoder_layers = TransformerEncoderLayer(dmodel, nhead, d_hid)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        # TODO: Must not hardcode dropout\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(in_features=seq_len * dmodel, out_features=NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.cnn(x)\n",
    "        # 3d: batch, embedding_dim, seq_len\n",
    "        #print('SHAPE OF X')\n",
    "        x = x.permute(2, 0, 1)\n",
    "        #x=x.permute()        \n",
    "        # 3d: seq_len, batch_size, embedding_dim\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        #x = self.dropout(x)\n",
    "        # 3d: seq_len, batch_size, features\n",
    "        #x = x.permute(1, 0, 2)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        # print(x.shape)\n",
    "        # 3d: batch_size, seq_len,features\n",
    "        x = x.reshape(-1, self.seq_len * self.dmodel)\n",
    "        #x = x.reshape(self.seq_len * self.dmodel)\n",
    "        # 2d: batch_size, seq_len*features\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# from pytorch website https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        # pos = torch.arange(seq_len).unsqueeze(1)\n",
    "        # every_second_dim = torch.arange(start=0, end=d_model, step=2)\n",
    "        # TODO must not hardcode\n",
    "        # frequency =10000.0\n",
    "        frequency = 10000.0\n",
    "        # div_term = frequency ** (every_second_dim / d_model)\n",
    "        # pe = torch.zeros(seq_len, 1, d_model)\n",
    "\n",
    "        # pe[:, 0, 0::2] = torch.sin(pos / div_term)\n",
    "        # pe[:, 0, 1::2] = torch.cos(pos / div_term)\n",
    "        # self.register_buffer('pe', pe)\n",
    "\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(frequency) / d_model))\n",
    "        pe = torch.zeros(seq_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        # print(self.d_model)\n",
    "        # x = x * np.sqrt(self.d_model)\n",
    "        # x = x * self.d_model\n",
    "\n",
    "        # print(x.shape)\n",
    "        # print(torch.mean(x))\n",
    "        # x = x + torch.mean(x)*self.pe[:x.size(0)]\n",
    "        x = x.to(device=torch.device(\"cuda:0\"))\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        # x = x + 5*self.pe[:x.size(0)]\n",
    "        # return self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    log_step = 10\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % log_step == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= num_batches\n",
    "    train_losses.append(train_loss.item())\n",
    "    # For loss graph on tensorboard\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.float())\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    validation_loss /= num_batches\n",
    "    val_losses.append(validation_loss)\n",
    "    correct /= size\n",
    "    # For loss graph on tensorboard\n",
    "    writer.add_scalar('Loss/Validation', validation_loss, epoch)\n",
    "    print(f\"Accuracy: {(100*correct):>0.2f}%, Avg loss: {validation_loss:>8f}\")\n",
    "    return (correct, validation_loss)\n",
    "\n",
    "dmodel = 28\n",
    "    #data.shape[1] # NUM_FEATURES\n",
    "print('DATA SHAPE',data.shape[1])\n",
    "d_hid = 250  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "#nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nlayers = 4  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 1  # number of heads in nn.MultiheadAttention\n",
    "model = TransformerModel(dmodel, SEQ_LENGTH, nhead, d_hid, nlayers).to(device)\n",
    "#model = CNN(seq_length = SEQ_LENGTH, feature_length = NUM_CLASSES).to(device)\n",
    "# Add some tensorflow information\n",
    "print('BEFO>rE')\n",
    "#writer.add_graph(model, data.float()[0:1,])\n",
    "\n",
    "# save graph to tensorflow\n",
    "#writer.add_graph(model, data.float()[0:1,])\n",
    "\n",
    "#print model summary for debugging\n",
    "print(summary(model))\n",
    "# empty loss arrays for clean performance figures\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "#model = LSTM(data.shape[2], data.shape[1]).to(device)\n",
    "#model = CNN(data.shape[2], data.shape[1]).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_of_best_accuracy = float('inf')\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "\n",
    "start_time = datetime.now()\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(dataloader_train, model, loss_fn, optimizer, t+1)\n",
    "\n",
    "    accuracy, loss = validation_loop(dataloader_val, model, loss_fn, t+1)\n",
    "    # TODO: make \"best model\" strategy configurable\n",
    "    #if loss < loss_of_best_accuracy:\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and loss < loss_of_best_accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        loss_of_best_accuracy = loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_epoch = t+1\n",
    "        print('Model saved')\n",
    "end_time = datetime.now()\n",
    "print(f\"\\nDone! Validation accuracy: {(100*best_accuracy):>0.2f}%\")\n",
    "print(f\"Training took {(end_time-start_time).total_seconds():>0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c39406a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    # initialise empty tensors for predictions and targets\n",
    "    all_preds = torch.tensor([], device=device, dtype=int)\n",
    "    all_targets = torch.tensor([], device=device, dtype=int)\n",
    "    model.eval()\n",
    "    for batch in loader:\n",
    "        data, labels = batch\n",
    "        preds = model(data.float()).argmax(1)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "        all_targets = torch.cat((all_targets, labels.int()), dim=0)\n",
    "    model.train()    \n",
    "    return all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4362853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  predictions, targets = predict(best_model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bce78632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972527472527473"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions.cpu(), targets.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3883f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets.cpu(), predictions.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b698e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f6590fba650>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd = ConfusionMatrixDisplay(cm, display_labels=encoder.classes_)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce262520",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_norm = np.transpose(np.transpose(cm) / cm.sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9406611d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f65908ae250>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmd_norm = ConfusionMatrixDisplay(cm_norm, display_labels=encoder.classes_)\n",
    "\n",
    "cmd_norm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8798e1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99731903, 0.00268097],\n",
       "       [0.00277008, 0.99722992]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fd45a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 372,    1],\n",
       "       [   3, 1080]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "906e684e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot simple loss graph, see also tensorboard\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(val_losses,label=\"val\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a4f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e9b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
