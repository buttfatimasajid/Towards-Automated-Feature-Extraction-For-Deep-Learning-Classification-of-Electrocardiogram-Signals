{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Oa3NxIdK9dpV"
   },
   "outputs": [],
   "source": [
    "# clear logs from previous runs so that tensorboard only shows current run\n",
    "!rm -rf ./runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gd8ff6R9X4qx",
    "outputId": "43cb2d51-8e6e-4318-85e1-384a8b0d6785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 11 09:20:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    37W / 250W |  30829MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-PCI...  Off  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    35W / 250W |      7MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2907      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    708451      C   ...envs/torch-gpu/bin/python     3187MiB |\n",
      "|    0   N/A  N/A    708512      C   ...envs/torch-gpu/bin/python     2683MiB |\n",
      "|    0   N/A  N/A   2360979      C   ...envs/torch-gpu/bin/python     2275MiB |\n",
      "|    0   N/A  N/A   2367092      C   ...envs/torch-gpu/bin/python     2283MiB |\n",
      "|    0   N/A  N/A   2550284      C   ...envs/torch-gpu/bin/python     2709MiB |\n",
      "|    0   N/A  N/A   3996282      C   ...envs/torch-gpu/bin/python     8871MiB |\n",
      "|    0   N/A  N/A   4007850      C   ...envs/torch-gpu/bin/python     6369MiB |\n",
      "|    0   N/A  N/A   4119069      C   ...envs/torch-gpu/bin/python     2443MiB |\n",
      "|    1   N/A  N/A      2907      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# view GPU information\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mMKvG_oGmrXe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kwM5fSkzZDQU"
   },
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mzu-tOOUnb-K"
   },
   "outputs": [],
   "source": [
    "# Requires 'ECG2(withDA).mat' file to have been uploaded\n",
    "src_dataset = sio.loadmat('ECG2(withDA).mat');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSzTjO3eU09T"
   },
   "source": [
    "# Prepare train, validation and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G4y2pULPnes7"
   },
   "outputs": [],
   "source": [
    "testdata = src_dataset['ECG']\n",
    "data = testdata['Data'][0][0]\n",
    "raw_labels = testdata['label'][0][0]\n",
    "\n",
    "labels = np.empty(len(raw_labels), dtype='U1')\n",
    "for i in range(len(raw_labels)):\n",
    "  labels[i] = raw_labels[i][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULrno-LpJi-N"
   },
   "source": [
    "## Pie Graph to show Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "FkGCrwaaIwWU",
    "outputId": "df1eea91-75a5-42be-e7a3-6cd6965291fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_labels = 'Daily Activities', 'Falling', 'Resting'\n",
    "chart_values = [(labels == 'D').sum(), (labels == 'F').sum(), (labels == 'R').sum()]\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(chart_values, labels=chart_labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "plt.savefig('distribution.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bo7q8BiMreo"
   },
   "source": [
    "## Convert to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UWx4TpynhcW",
    "outputId": "b057d71b-85c3-424b-c5f6-28a27e1d10d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1018, 4000)\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "y = labels.reshape(-1, 1)\n",
    "# labels as digit representation instead of letters\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "# 80/10/10 split\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8, random_state=RANDOM_SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, train_size=0.5, random_state=RANDOM_SEED)\n",
    "print((X_train.shape))\n",
    "np.savetxt(\"X_train.csv\", X_train, delimiter=\",\")\n",
    "np.savetxt(\"X_val.csv\", X_val, delimiter=\",\")\n",
    "np.savetxt(\"X_test.csv\", X_test, delimiter=\",\")\n",
    "np.savetxt(\"y_train.csv\", y_train, delimiter=\",\")\n",
    "np.savetxt(\"y_val.csv\", y_val, delimiter=\",\")\n",
    "np.savetxt(\"y_test.csv\", y_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wdegIE1MYr2",
    "outputId": "85daaace-2c05-4d8c-da53-9a967da5772c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ptr3zT91MZxY"
   },
   "outputs": [],
   "source": [
    "def np_to_dataloader(X, y, device, batch_size):\n",
    "  # X_tensor is 2d: num_samples, num_timestamps (4000) \n",
    "  X_tensor = torch.as_tensor(X.astype(np.float32), device=device)\n",
    "  y_tensor = torch.as_tensor(y, device=device)\n",
    "  # add feature dimension\n",
    "  X_tensor = X_tensor.unsqueeze(dim=1)\n",
    "  dataset = TensorDataset(X_tensor, y_tensor)\n",
    "  # if generator parameter is not set, first run produces different results to subsequent runs!!\n",
    "  return DataLoader(dataset, batch_size=batch_size, shuffle=True, generator=torch.Generator())\n",
    "\n",
    "dataloader_train = np_to_dataloader(X_train, y_train, device, BATCH_SIZE)\n",
    "dataloader_val = np_to_dataloader(X_val, y_val, device, BATCH_SIZE)\n",
    "dataloader_test = np_to_dataloader(X_test, y_test, device, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmA_4KZjUvTR"
   },
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "t3aCSrW9rd9Q"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.hidden_last = hidden\n",
    "        self.hidden1 = 64\n",
    "        self.hidden2 = 128\n",
    "        self.hidden3 = 256\n",
    "        self.hidden4 = 512\n",
    "\n",
    "        self.conv_kernel_size = 3\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.first = True\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=self.hidden1, kernel_size=self.conv_kernel_size),\n",
    "            nn.BatchNorm1d(num_features=self.hidden1),\n",
    "            self.activation,\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.hidden1, out_channels=self.hidden2, kernel_size=self.conv_kernel_size),\n",
    "            nn.BatchNorm1d(num_features=self.hidden2),\n",
    "            self.activation,\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.hidden2, out_channels=self.hidden3, kernel_size=self.conv_kernel_size),\n",
    "            nn.BatchNorm1d(num_features=self.hidden3),\n",
    "            self.activation,\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.hidden3, out_channels=self.hidden4, kernel_size=self.conv_kernel_size),\n",
    "            nn.BatchNorm1d(num_features=self.hidden4),\n",
    "            self.activation,\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv_last = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.hidden4, out_channels=self.hidden_last, kernel_size=self.conv_kernel_size),\n",
    "            nn.BatchNorm1d(num_features=self.hidden_last),\n",
    "            self.activation,\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv_last(x)\n",
    "        if self.first:\n",
    "          print('Size after CNN (batch size/features/seqence length): ', x.size())\n",
    "          self.first = False\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dA7OSYvJPxwR"
   },
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "\n",
    "        self.cnn_output = 1028\n",
    "        self.seq_length_after_cnn = 123\n",
    "        self.hidden_lstm = 64\n",
    "\n",
    "        self.cnn = CNN(hidden=self.cnn_output)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.cnn_output, hidden_size=self.hidden_lstm, batch_first=True, num_layers=3)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=self.hidden_lstm*self.seq_length_after_cnn, out_features=3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3d: batch size, features (1), seq length (4000)\n",
    "        x = self.cnn(x)\n",
    "        # 3d: batch size, features (self.hidden_cnn), seq length after cnn\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # 3d: batch size, seq length, features\n",
    "        x, (h_n, c_n) = self.lstm(x)\n",
    "        # 3d: batch size, seq length, features\n",
    "        x = x.reshape(-1, self.hidden_lstm*self.seq_length_after_cnn)\n",
    "        # 2d: batch size, (features*seq length)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "HGT_BE-rQgQs"
   },
   "outputs": [],
   "source": [
    "model = CNN_LSTM().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHubt8uuUs5E"
   },
   "source": [
    "#Train and save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "7qzmfbmaRuDf"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    log_step = 10\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % log_step == 0:\n",
    "          loss, current = loss.item(), batch * len(X)\n",
    "          print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= num_batches\n",
    "    # For loss graph on tensorboard\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.float())\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    validation_loss /= num_batches\n",
    "    correct /= size\n",
    "    # For loss graph on tensorboard\n",
    "    writer.add_scalar('Loss/Validation', validation_loss, epoch)\n",
    "    print(f\"Accuracy: {(100*correct):>0.2f}%, Avg loss: {validation_loss:>8f}\")\n",
    "    return (correct, validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOF8TsoiR2v3",
    "outputId": "14c58690-e1e8-4ca4-8123-d29f49f5ab23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.138158  [    0/ 1018]\n",
      "loss: 0.012732  [  320/ 1018]\n",
      "loss: 0.070406  [  640/ 1018]\n",
      "loss: 0.040480  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.059678\n",
      "Model saved\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.030964  [    0/ 1018]\n",
      "loss: 0.168368  [  320/ 1018]\n",
      "loss: 0.064871  [  640/ 1018]\n",
      "loss: 0.066181  [  960/ 1018]\n",
      "Accuracy: 96.85%, Avg loss: 0.097152\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.106403  [    0/ 1018]\n",
      "loss: 0.049015  [  320/ 1018]\n",
      "loss: 0.020661  [  640/ 1018]\n",
      "loss: 0.023340  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.039056\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.063263  [    0/ 1018]\n",
      "loss: 0.023269  [  320/ 1018]\n",
      "loss: 0.021171  [  640/ 1018]\n",
      "loss: 0.036048  [  960/ 1018]\n",
      "Accuracy: 96.85%, Avg loss: 0.096505\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.038292  [    0/ 1018]\n",
      "loss: 0.011910  [  320/ 1018]\n",
      "loss: 0.023782  [  640/ 1018]\n",
      "loss: 0.008612  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.032906\n",
      "Model saved\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.032070  [    0/ 1018]\n",
      "loss: 0.020660  [  320/ 1018]\n",
      "loss: 0.007449  [  640/ 1018]\n",
      "loss: 0.036037  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.029980\n",
      "Model saved\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.002223  [    0/ 1018]\n",
      "loss: 0.028803  [  320/ 1018]\n",
      "loss: 0.003548  [  640/ 1018]\n",
      "loss: 0.009927  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.038213\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.010938  [    0/ 1018]\n",
      "loss: 0.030803  [  320/ 1018]\n",
      "loss: 0.002822  [  640/ 1018]\n",
      "loss: 0.045266  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.029673\n",
      "Model saved\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.003493  [    0/ 1018]\n",
      "loss: 0.050519  [  320/ 1018]\n",
      "loss: 0.016759  [  640/ 1018]\n",
      "loss: 0.014930  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.021029\n",
      "Model saved\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.005728  [    0/ 1018]\n",
      "loss: 0.091985  [  320/ 1018]\n",
      "loss: 0.050972  [  640/ 1018]\n",
      "loss: 0.031305  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.018141\n",
      "Model saved\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.003170  [    0/ 1018]\n",
      "loss: 0.006353  [  320/ 1018]\n",
      "loss: 0.018917  [  640/ 1018]\n",
      "loss: 0.006994  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.017137\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.016828  [    0/ 1018]\n",
      "loss: 0.036278  [  320/ 1018]\n",
      "loss: 0.012215  [  640/ 1018]\n",
      "loss: 0.003613  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.022967\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.000409  [    0/ 1018]\n",
      "loss: 0.006741  [  320/ 1018]\n",
      "loss: 0.001540  [  640/ 1018]\n",
      "loss: 0.001818  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.018841\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000992  [    0/ 1018]\n",
      "loss: 0.000730  [  320/ 1018]\n",
      "loss: 0.003775  [  640/ 1018]\n",
      "loss: 0.000606  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.012697\n",
      "Model saved\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000174  [    0/ 1018]\n",
      "loss: 0.027161  [  320/ 1018]\n",
      "loss: 0.000195  [  640/ 1018]\n",
      "loss: 0.001523  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.038739\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.049840  [    0/ 1018]\n",
      "loss: 0.002057  [  320/ 1018]\n",
      "loss: 0.000267  [  640/ 1018]\n",
      "loss: 0.000159  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.013498\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000041  [    0/ 1018]\n",
      "loss: 0.041948  [  320/ 1018]\n",
      "loss: 0.000044  [  640/ 1018]\n",
      "loss: 0.000550  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.009092\n",
      "Model saved\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000454  [    0/ 1018]\n",
      "loss: 0.001565  [  320/ 1018]\n",
      "loss: 0.001195  [  640/ 1018]\n",
      "loss: 0.005079  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.015061\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000147  [    0/ 1018]\n",
      "loss: 0.000588  [  320/ 1018]\n",
      "loss: 0.000291  [  640/ 1018]\n",
      "loss: 0.000324  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.057424\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.001248  [    0/ 1018]\n",
      "loss: 0.000033  [  320/ 1018]\n",
      "loss: 0.001708  [  640/ 1018]\n",
      "loss: 0.001266  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.052803\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.000298  [    0/ 1018]\n",
      "loss: 0.000121  [  320/ 1018]\n",
      "loss: 0.005400  [  640/ 1018]\n",
      "loss: 0.000052  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.063407\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.000242  [    0/ 1018]\n",
      "loss: 0.000211  [  320/ 1018]\n",
      "loss: 0.002481  [  640/ 1018]\n",
      "loss: 0.000145  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.033628\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.000534  [    0/ 1018]\n",
      "loss: 0.066913  [  320/ 1018]\n",
      "loss: 0.002918  [  640/ 1018]\n",
      "loss: 0.000460  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.101232\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.136012  [    0/ 1018]\n",
      "loss: 0.004814  [  320/ 1018]\n",
      "loss: 0.000520  [  640/ 1018]\n",
      "loss: 0.000039  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.027410\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000178  [    0/ 1018]\n",
      "loss: 0.000942  [  320/ 1018]\n",
      "loss: 0.011515  [  640/ 1018]\n",
      "loss: 0.093700  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.037700\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000286  [    0/ 1018]\n",
      "loss: 0.000044  [  320/ 1018]\n",
      "loss: 0.127054  [  640/ 1018]\n",
      "loss: 0.002533  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.101272\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000596  [    0/ 1018]\n",
      "loss: 0.001897  [  320/ 1018]\n",
      "loss: 0.001591  [  640/ 1018]\n",
      "loss: 0.031006  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.032900\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000558  [    0/ 1018]\n",
      "loss: 0.010742  [  320/ 1018]\n",
      "loss: 0.009826  [  640/ 1018]\n",
      "loss: 0.008058  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.064556\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000669  [    0/ 1018]\n",
      "loss: 0.006645  [  320/ 1018]\n",
      "loss: 0.000441  [  640/ 1018]\n",
      "loss: 0.006286  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.038482\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000158  [    0/ 1018]\n",
      "loss: 0.001093  [  320/ 1018]\n",
      "loss: 0.004898  [  640/ 1018]\n",
      "loss: 0.000109  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.036664\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.001075  [    0/ 1018]\n",
      "loss: 0.000322  [  320/ 1018]\n",
      "loss: 0.000346  [  640/ 1018]\n",
      "loss: 0.004175  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.050854\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.000334  [    0/ 1018]\n",
      "loss: 0.000091  [  320/ 1018]\n",
      "loss: 0.000224  [  640/ 1018]\n",
      "loss: 0.000073  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.044290\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.000105  [    0/ 1018]\n",
      "loss: 0.000030  [  320/ 1018]\n",
      "loss: 0.001051  [  640/ 1018]\n",
      "loss: 0.000189  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.044755\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.001717  [    0/ 1018]\n",
      "loss: 0.000134  [  320/ 1018]\n",
      "loss: 0.000336  [  640/ 1018]\n",
      "loss: 0.056408  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.017044\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.000099  [    0/ 1018]\n",
      "loss: 0.000026  [  320/ 1018]\n",
      "loss: 0.000151  [  640/ 1018]\n",
      "loss: 0.005549  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.013776\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.000216  [    0/ 1018]\n",
      "loss: 0.051732  [  320/ 1018]\n",
      "loss: 0.000300  [  640/ 1018]\n",
      "loss: 0.000022  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.031277\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.000447  [    0/ 1018]\n",
      "loss: 0.000083  [  320/ 1018]\n",
      "loss: 0.000641  [  640/ 1018]\n",
      "loss: 0.000065  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.033688\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.001136  [    0/ 1018]\n",
      "loss: 0.000786  [  320/ 1018]\n",
      "loss: 0.000027  [  640/ 1018]\n",
      "loss: 0.000416  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.031968\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.000398  [    0/ 1018]\n",
      "loss: 0.000116  [  320/ 1018]\n",
      "loss: 0.001080  [  640/ 1018]\n",
      "loss: 0.000394  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.032601\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.000030  [    0/ 1018]\n",
      "loss: 0.000162  [  320/ 1018]\n",
      "loss: 0.000557  [  640/ 1018]\n",
      "loss: 0.000038  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.031185\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1018]\n",
      "loss: 0.014246  [  320/ 1018]\n",
      "loss: 0.000158  [  640/ 1018]\n",
      "loss: 0.001241  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.032456\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.002470  [    0/ 1018]\n",
      "loss: 0.002107  [  320/ 1018]\n",
      "loss: 0.000338  [  640/ 1018]\n",
      "loss: 0.000471  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.032828\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 1018]\n",
      "loss: 0.000458  [  320/ 1018]\n",
      "loss: 0.000028  [  640/ 1018]\n",
      "loss: 0.000193  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.025620\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.000027  [    0/ 1018]\n",
      "loss: 0.000163  [  320/ 1018]\n",
      "loss: 0.000082  [  640/ 1018]\n",
      "loss: 0.000029  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.009223\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.000150  [    0/ 1018]\n",
      "loss: 0.000020  [  320/ 1018]\n",
      "loss: 0.000080  [  640/ 1018]\n",
      "loss: 0.000057  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.029384\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1018]\n",
      "loss: 0.000052  [  320/ 1018]\n",
      "loss: 0.004593  [  640/ 1018]\n",
      "loss: 0.000195  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.017222\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.000992  [    0/ 1018]\n",
      "loss: 0.000030  [  320/ 1018]\n",
      "loss: 0.000047  [  640/ 1018]\n",
      "loss: 0.000005  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.033256\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.000014  [    0/ 1018]\n",
      "loss: 0.000312  [  320/ 1018]\n",
      "loss: 0.000259  [  640/ 1018]\n",
      "loss: 0.000006  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.009331\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.000085  [    0/ 1018]\n",
      "loss: 0.000013  [  320/ 1018]\n",
      "loss: 0.000005  [  640/ 1018]\n",
      "loss: 0.000012  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.022660\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.000104  [    0/ 1018]\n",
      "loss: 0.001274  [  320/ 1018]\n",
      "loss: 0.000109  [  640/ 1018]\n",
      "loss: 0.000060  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.005338\n",
      "Model saved\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/ 1018]\n",
      "loss: 0.000044  [  320/ 1018]\n",
      "loss: 0.000024  [  640/ 1018]\n",
      "loss: 0.000059  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.038535\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.000033  [    0/ 1018]\n",
      "loss: 0.000054  [  320/ 1018]\n",
      "loss: 0.000030  [  640/ 1018]\n",
      "loss: 0.000044  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.004759\n",
      "Model saved\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/ 1018]\n",
      "loss: 0.000031  [  320/ 1018]\n",
      "loss: 0.000011  [  640/ 1018]\n",
      "loss: 0.000038  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.055997\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1018]\n",
      "loss: 0.000004  [  320/ 1018]\n",
      "loss: 0.000006  [  640/ 1018]\n",
      "loss: 0.000018  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.031570\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/ 1018]\n",
      "loss: 0.000020  [  320/ 1018]\n",
      "loss: 0.000012  [  640/ 1018]\n",
      "loss: 0.000023  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.020532\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.000016  [    0/ 1018]\n",
      "loss: 0.000007  [  320/ 1018]\n",
      "loss: 0.000013  [  640/ 1018]\n",
      "loss: 0.000008  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.012975\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1018]\n",
      "loss: 0.000051  [  320/ 1018]\n",
      "loss: 0.000037  [  640/ 1018]\n",
      "loss: 0.000008  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.031034\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.000092  [    0/ 1018]\n",
      "loss: 0.000016  [  320/ 1018]\n",
      "loss: 0.000122  [  640/ 1018]\n",
      "loss: 0.000013  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.054820\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1018]\n",
      "loss: 0.000011  [  320/ 1018]\n",
      "loss: 0.000029  [  640/ 1018]\n",
      "loss: 0.000074  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.026748\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1018]\n",
      "loss: 0.000006  [  320/ 1018]\n",
      "loss: 0.000016  [  640/ 1018]\n",
      "loss: 0.000004  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.003617\n",
      "Model saved\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1018]\n",
      "loss: 0.000002  [  320/ 1018]\n",
      "loss: 0.000046  [  640/ 1018]\n",
      "loss: 0.000026  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.007879\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1018]\n",
      "loss: 0.004117  [  320/ 1018]\n",
      "loss: 0.000079  [  640/ 1018]\n",
      "loss: 0.000009  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.015240\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1018]\n",
      "loss: 0.000140  [  320/ 1018]\n",
      "loss: 0.000002  [  640/ 1018]\n",
      "loss: 0.000013  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.028483\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/ 1018]\n",
      "loss: 0.000048  [  320/ 1018]\n",
      "loss: 0.000012  [  640/ 1018]\n",
      "loss: 0.000039  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.013967\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1018]\n",
      "loss: 0.000009  [  320/ 1018]\n",
      "loss: 0.000011  [  640/ 1018]\n",
      "loss: 0.000007  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.013639\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.000179  [    0/ 1018]\n",
      "loss: 0.000005  [  320/ 1018]\n",
      "loss: 0.000018  [  640/ 1018]\n",
      "loss: 0.000013  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.045610\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1018]\n",
      "loss: 0.000002  [  320/ 1018]\n",
      "loss: 0.000108  [  640/ 1018]\n",
      "loss: 0.000007  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.020485\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1018]\n",
      "loss: 0.000034  [  320/ 1018]\n",
      "loss: 0.000003  [  640/ 1018]\n",
      "loss: 0.000104  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.013870\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.001115  [    0/ 1018]\n",
      "loss: 0.000240  [  320/ 1018]\n",
      "loss: 0.000047  [  640/ 1018]\n",
      "loss: 0.000001  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.015960\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1018]\n",
      "loss: 0.000019  [  320/ 1018]\n",
      "loss: 0.000005  [  640/ 1018]\n",
      "loss: 0.000023  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.042827\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1018]\n",
      "loss: 0.000044  [  320/ 1018]\n",
      "loss: 0.000005  [  640/ 1018]\n",
      "loss: 0.000032  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.041343\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1018]\n",
      "loss: 0.000007  [  320/ 1018]\n",
      "loss: 0.000024  [  640/ 1018]\n",
      "loss: 0.000019  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.002696\n",
      "Model saved\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/ 1018]\n",
      "loss: 0.000002  [  320/ 1018]\n",
      "loss: 0.000021  [  640/ 1018]\n",
      "loss: 0.000005  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.000447\n",
      "Model saved\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1018]\n",
      "loss: 0.000026  [  320/ 1018]\n",
      "loss: 0.000003  [  640/ 1018]\n",
      "loss: 0.000003  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.004994\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1018]\n",
      "loss: 0.000159  [  320/ 1018]\n",
      "loss: 0.000007  [  640/ 1018]\n",
      "loss: 0.000070  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.065732\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/ 1018]\n",
      "loss: 0.000459  [  320/ 1018]\n",
      "loss: 0.000137  [  640/ 1018]\n",
      "loss: 0.000004  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.002612\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1018]\n",
      "loss: 0.000018  [  320/ 1018]\n",
      "loss: 0.000026  [  640/ 1018]\n",
      "loss: 0.000036  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.043281\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000024  [    0/ 1018]\n",
      "loss: 0.000013  [  320/ 1018]\n",
      "loss: 0.000070  [  640/ 1018]\n",
      "loss: 0.000010  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.027259\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.000025  [    0/ 1018]\n",
      "loss: 0.000084  [  320/ 1018]\n",
      "loss: 0.000018  [  640/ 1018]\n",
      "loss: 0.000002  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.042880\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000034  [  640/ 1018]\n",
      "loss: 0.000003  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.015755\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000004  [  640/ 1018]\n",
      "loss: 0.000003  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.055100\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000180  [  640/ 1018]\n",
      "loss: 0.000087  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.033228\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000125  [  640/ 1018]\n",
      "loss: 0.000002  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.035140\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000008  [  640/ 1018]\n",
      "loss: 0.000018  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.013471\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000409  [    0/ 1018]\n",
      "loss: 0.000004  [  320/ 1018]\n",
      "loss: 0.000006  [  640/ 1018]\n",
      "loss: 0.000001  [  960/ 1018]\n",
      "Accuracy: 97.64%, Avg loss: 0.071986\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000086  [    0/ 1018]\n",
      "loss: 0.000011  [  320/ 1018]\n",
      "loss: 0.000002  [  640/ 1018]\n",
      "loss: 0.000004  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.037332\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000038  [  640/ 1018]\n",
      "loss: 0.000016  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.030085\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000002  [  640/ 1018]\n",
      "loss: 0.000005  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.004509\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000002  [  640/ 1018]\n",
      "loss: 0.000001  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.017419\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000496  [  640/ 1018]\n",
      "loss: 0.000034  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.008472\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000087  [  640/ 1018]\n",
      "loss: 0.000010  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.050890\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1018]\n",
      "loss: 0.000002  [  320/ 1018]\n",
      "loss: 0.000003  [  640/ 1018]\n",
      "loss: 0.000071  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.046344\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000003  [  640/ 1018]\n",
      "loss: 0.000059  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.022823\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/ 1018]\n",
      "loss: 0.000004  [  320/ 1018]\n",
      "loss: 0.000004  [  640/ 1018]\n",
      "loss: 0.000003  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.040302\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000001  [  640/ 1018]\n",
      "loss: 0.000005  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.047749\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000004  [  640/ 1018]\n",
      "loss: 0.000024  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.029469\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1018]\n",
      "loss: 0.000001  [  320/ 1018]\n",
      "loss: 0.000001  [  640/ 1018]\n",
      "loss: 0.000009  [  960/ 1018]\n",
      "Accuracy: 98.43%, Avg loss: 0.049319\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1018]\n",
      "loss: 0.000007  [  320/ 1018]\n",
      "loss: 0.000013  [  640/ 1018]\n",
      "loss: 0.000001  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.012169\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1018]\n",
      "loss: 0.000003  [  320/ 1018]\n",
      "loss: 0.000001  [  640/ 1018]\n",
      "loss: 0.000002  [  960/ 1018]\n",
      "Accuracy: 100.00%, Avg loss: 0.003763\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1018]\n",
      "loss: 0.000021  [  320/ 1018]\n",
      "loss: 0.000001  [  640/ 1018]\n",
      "loss: 0.000019  [  960/ 1018]\n",
      "Accuracy: 99.21%, Avg loss: 0.041641\n",
      "\n",
      "Done! Validation accuracy: 100.00%\n",
      "Training took 80.56 seconds\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "%xmode Verbose\n",
    "\n",
    "loss_of_best_accuracy = float('inf')\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "start_time = datetime.now()\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(dataloader_train, model, loss_fn, optimizer, t+1)\n",
    "    accuracy, loss = validation_loop(dataloader_val, model, loss_fn, t+1)\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and loss < loss_of_best_accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        loss_of_best_accuracy = loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print('Model saved')\n",
    "end_time = datetime.now()\n",
    "print(f\"\\nDone! Validation accuracy: {(100*best_accuracy):>0.2f}%\")\n",
    "print(f\"Training took {(end_time-start_time).total_seconds():>0.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ane49AUY-x"
   },
   "source": [
    "# Load model and test with new test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "eLFl03JEJMgG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/conda/envs/torch-gpu/lib/python3.7/site-packages/torch/nn/modules/rnn.py:692: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    # initialise empty tensors for predictions and targets\n",
    "    all_preds = torch.tensor([], device=device, dtype=int)\n",
    "    all_targets = torch.tensor([], device=device, dtype=int)\n",
    "    for batch in loader:\n",
    "        data, labels = batch\n",
    "        preds = model(data).argmax(1)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "        all_targets = torch.cat((all_targets, labels.int()), dim=0)\n",
    "    return all_preds, all_targets\n",
    "\n",
    "with torch.no_grad():\n",
    "  predictions, targets = predict(best_model, dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4QVrh_aUn30"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Zc6q_bozJuGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.22%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7efbd7544590>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAEGCAYAAAAJ73JAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZwklEQVR4nO3de5gddZ3n8fenO517OveEJtwxchEkYOQiLgQYBHVmA66MuMrGWdzIDgzujM5OHN1hhEeGXR11BBTj5TGjcl1lgqiQkIDIrGBICHdClEuANCRpyD0k3ae/+8epDk3Slzqd032qqj+v56mnT1XX+dU3FfLld6tfKSIwM8u7uloHYGZWDU5mZlYITmZmVghOZmZWCE5mZlYIQ2odwJ7qx4yKIZPG1zqMzBr2wvZah2A59ybb2BU7tS9lnHPGqGh5vZTq3OWP7bw7Is7dl+ulkblkNmTSeJquvLTWYWTW9Dkrah2C5dxDsWSfy9jweomH7j4g1bkNTX+ctM8XTCFzyczM8iAoRXutg3gbJzMzq1gA7WRrwr2TmZn1STuumZlZzgVBq5uZZpZ3AZSq2MyU9AKwBSgBbRExU9IE4BbgEOAF4M8j4o3uyvA8MzPrk3Yi1VaBMyJiRkTMTPbnAUsiYjqwJNnvlpOZmVUsgFJEqm0fzAYWJJ8XAOf1dLKTmZn1SXvKDZgk6eFO29wuigtgkaTlnX4/NSKaAZKfU3qKx31mZlaxICrpM9vQqenYnVMjYq2kKcBiSc9UGpOTmZlVLAJaqzjNLCLWJj/XSbodOBF4TVJTRDRLagLW9VSGm5lm1geilHLrtSRplKQxHZ+BDwBPAHcAc5LT5gALeyrHNTMzq1gA7dWrmU0FbpcE5Zx0Y0TcJWkZcKuki4E1wAU9FeJkZmZ9kqbWlUZEPAcc18XxFuCstOU4mZlZxcqTZquTzKrFyczMKhZAa2Sry93JzMwqFohSxsYPnczMrE/aw81MM8s595mZWUGIkvvMzCzvyivNOpmZWc5FiF1RX+sw3sbJzMz6pN19ZmaWd+UBADczzSz3PABgZgXgAQAzK4ySJ82aWd4FojWylT6yFY2Z5YIHAMysEAK5mWlmxeABgAzTrnYOuPpZ1BZQCra+dxyvf2R/6ra20fTt5xmyYRdtk4bSfOmhtI/yrZs5azOXXLWW+rrg1zdN4NbrptY6pMwp6j2KYPBMzZBUAh4HGoA2yi/x/GZEtPfXNfdVNIiX500nhtdDW3DgV1ax/d1jGbX8DbYfPYY3/nQ/xt/5KuPvfI2Wj02rdbg1VVcXXHr1K3zhwsPY0NzAtb9azYN3j2XN6uG1Di0zinyPygMA2XqcqT9T647kVevvAs4GPgRc0Y/X23dSOZEBKpVrZyEYvWITm98/EYDN75/I6BUbaxhkNhxx/HbWvjCUV9cMo621jvsWjuOUczbVOqxMKfo9KlGXahsoA3KliFgHzAUuU/IKlsxqDw76X09z2F89xvZ3NbLz8FHUb26jNK4BgNK4Buo3t9U4yNqbuF8r69cO3b2/obmBSU2tNYwoe4p8jwLRHum2gTJgHT8R8ZykOsqvWH9toK5bsTqx5qqjqNvWRtO3nmPoyztqHVEmdfW/pKjiS2GLoOj3aLBPzegyTUuaS7nmRv3EcQMZT7faRw1hx5FjGPnYZkqNQ6jf2FqulW1spdTozv8NzQ1M3n/X7v1JTa20vNpQw4iyp8j3qPzezGwlswGLRtJhQIkuXrEeEfMjYmZEzKwfM2qgQtpL/eZW6raVm5Da1c7IpzbTuv9wth0/lsYHWgBofKCFrSeMrVmMWbFq5UimHbqLqQfuZEhDO7Nmb+TBRb4vnRX7HlXvjebVMiBVDEmTgRuA6yKyW9Gu39jK1O+9iNoDAraeOJ5tM8ay4x2jaLr+eRrvb6FtYnlqxmDXXhLXf3EaV9/4HHX1sOjmCbz4bP5H6aqpyPeo/Kq5bI1m9mcyGyFpJW9Nzfgx8PV+vN4+23XQSF666qi9jrePHsIrfze9BhFl27KljSxb2ljrMDKtqPcoQplrZvZbMovIWNo2s6oaNJNmzay4yuuZZWuWlZOZmfWBV5o1swIoT81wzczMci6Lz2Y6mZlZn2RtCaBsRWNmuVBeAkiptjQk1Ut6RNKdyf4ESYslrU5+ju+tDCczM+uTKj9o/lng6U7784AlETEdWJLs98jJzMwqVl41oy7V1htJBwAfBr7f6fBsymsgkvw8r7dy3GdmZhUrP85UtbrQN4H/CYzpdGxqRDQDRESzpCm9FeKamZn1QUU1s0mSHu60zd1divSnwLqIWL6vEblmZmZ9UsETABsiYmY3vzsV+I+SPgQMBxol/QR4TVJTUitroovVdvbkmpmZVaxao5kR8YWIOCAiDgEuBJZGxCeBO4A5yWlzgIW9xeSamZn1ST+vmnENcKuki4E1wAW9fcHJzMwq1vEOgKqWGXEfcF/yuQU4q5LvO5mZWcUCaPOD5mZWBINmcUYzK7ABfo1cGk5mZlYxL85oZoXhmpmZ5Z4XZzSzQghEW7sHAMysANxnZmb5F25mmlkBuM/MzArDyczMci8QJQ8AmFkReADAzHIvPABgZkURTmZmln9+0NzMCsI1s14Me3EH7/z0E7UOI7PuWruy1iFk3jn7z6h1CIUXAaV2JzMzKwCPZppZ7gVuZppZIXgAwMwKIqLWEbydk5mZ9YmbmWaWe+XRTD+baWYF4GammRWCm5lmlnuBnMzMrBgy1sp0MjOzPggIP85kZkXgZqaZFUJuRjMlXUsPzeKIuLxfIjKzzMvbs5kPD1gUZpYvAeQlmUXEgs77kkZFxLb+D8nM8qBazUxJw4H7gWGUc9L/jYgrJE0AbgEOAV4A/jwi3uiunF6fR5B0iqSngKeT/eMkfXuf/wRmlmMi2tNtKewEzoyI44AZwLmSTgbmAUsiYjqwJNnvVpqHq74JnAO0AETEo8BpaSI0swKLlFtvxZRtTXYbki2A2UBHC3EBcF5P5aR6UjQiXtrjUCnN98ysoKI8AJBmAyZJerjTNnfP4iTVS1oJrAMWR8RDwNSIaAZIfk7pKaQ0UzNekvQ+ICQNBS4naXKa2SCWvs9sQ0TM7LGoiBIwQ9I44HZJx1QaTpqa2SXApcA04BXKbdpLK72QmRWNUm7pRcRG4D7gXOA1SU0Ayc91PX2312QWERsi4hMRMTUiJkfEJyOipaIIzax42lNuvZA0OamRIWkE8CfAM8AdwJzktDnAwp7KSTOaeZikX0haL2mdpIWSDus9RDMrrI55Zmm23jUB90p6DFhGuc/sTuAa4GxJq4Gzk/1upekzuxG4Hjg/2b8QuAk4KU2UZlZM1ZpnFhGPAcd3cbwFOCttOWn6zBQRP46ItmT7Cdlb/cPMBlqVpmZUS0/PZk5IPt4raR5wM+XQPgb8cgBiM7Msy8vjTMByysmrI+LPdPpdAFf1V1Bmln3KWPusp2czDx3IQMwsR0KQx8UZkwlsRwPDO45FxL/2V1BmlgN5qZl1kHQFMItyMvsV8EHgAcDJzGwwy1gySzOa+VHKw6OvRsRfAMdRXqrDzAazvIxmdrIjItoltUlqpPxIQeEnzf71V5/npDM3srGlgUs+UPFjYoX1X048mhGjS9TVQf2Q4Lq7nuV7V+7Pg4sbaRgaNB28k8994yVGj/VaBAAzZ23mkqvWUl8X/PqmCdx63dRah1QdGVycMU3N7OHkUYPvUR7hXAH8Pu0FJJUkrey0HdKnSAfY4tsm8aU576x1GJn0f277A9+5ZxXX3fUsACectoX59z7DDUtWMe2wndx8bY+LGwwadXXBpVe/wpc+cSj/bdYRnDF7IwdNf7PWYVWNIt02UHqtmUXEXyYfb5B0F9CYzNhNa0dEzOhLcLX0xO/HMPWAnbUOIxfeM2vL7s9HvWc7v71zbA2jyY4jjt/O2heG8uqacq/MfQvHcco5m1izengv38yJjPWZ9TRp9oSefhcRK/onJMs0BX//8cNB8OGLWvjQJ9++5sDdN03g9NkbaxNbxkzcr5X1a4fu3t/Q3MCRJ2yvYUTVlZt5ZsA/9/C7AM5MeY0RyaJrAM9HxPl7npAs1jYXYDgjUxZrtfCNhauZuF8bGzcMYd6Fh3PgO97k2JPLr4a48V+mUj8kOPMj3S7TPqioiy6lrL2ebZ9krM+sp0mzZ1TpGr02MyNiPjAfoLFuYpH+ugtn4n5tAIyb1Map527imUdGcuzJ21h863h+f08j19zyhy7/EQ9GG5obmLz/rt37k5paaXm1oYYRVdEAj1SmkWrZbDOAN7fXsX1r3e7Py38zhkOOfJNl947h1uun8o8/eo7hIzP2X3gNrVo5kmmH7mLqgTsZ0tDOrNkbeXBRgfoTczg1Y1Ca960/8u5TttA4vo0fP7iSn3xjGnffMrnWYdXUG+uH8OWLy0+5ldrgjPM38t4ztvCp9x1F607xhY+9A4Aj37ONz/7vl2sZaia0l8T1X5zG1Tc+R109LLp5Ai8+W5DOf0ApFl4cSE5m3bjm8sNrHULmNB28ixvuWbXX8R/9P78SojvLljaybGljrcPoHxmrhKdZaVaSPinpH5L9gySdmPYCETF6XwI0s+xJO8dsIEc80/SZfRs4Bfh4sr+F8sqzZjaYVW/Z7KpI08w8KSJOkPQIQES8kbxyzswGs4w1M9Mks1ZJ9SShS5pMqneumFmR5WnSbIdvAbcDUyR9hfIqGl/q16jMLNsih6OZEfFTScspLwMk4LyI8PCV2WCXt5qZpIOA7cAvOh+LiDX9GZiZZVzekhnlNzF1vNhkOHAosAp4Vz/GZWYZl7s+s4g4tvN+sprGZ7o53cysJip+AiAiVkh6b38EY2Y5kreamaS/6bRbB5wArO+3iMws+/I4mgmM6fS5jXIf2s/6Jxwzy4081cySybKjI+JvBygeM8sBkaMBAElDIqKtp+WzzWwQy0syo/wGphOAlZLuAG4DtnX8MiJ+3s+xmVlWDfCKGGmk6TObALRQXvO/Y75ZAE5mZoNZjgYApiQjmU/wVhLrkLGcbGYDLWs1s57WM6sHRifbmE6fOzYzG8yq9A4ASQdKulfS05KelPTZ5PgESYslrU5+ju+pnJ5qZs0RcWWaP5OZDTLVfVlJG/C5ZEL+GGC5pMXAp4AlEXGNpHnAPODvuiukp5qZXxhmZt2q1rLZEdHc8VLxiNgCPA1MA2YDC5LTFgDn9VROTzWzs3oPw8wGrfQ1s0mSHu60Pz95V+5eJB0CHA88BEyNiGYoJzxJU3q6SE8vAX49dahmNuhU8DjThoiY2Wt50mjKTxf9j4jYrArfJu2XAJtZ5dJ2/qesvUlqoJzIftppDutrkpqS3zcB63oqw8nMzCqmCrZeyypXwX4APB0RX+/0qzuAOcnnOcDCnsrxS4DNrG+qN5p5KnAR8LiklcmxvweuAW6VdDGwBrigp0KczMysT6o1aTYiHqD7SlzqgUgnMzPrm4w9AeBkZmaVy+nijGZme3PNzMyKIGsPmjuZmVnfOJn1IoJo3VXrKDLrnP1n1DqEzPuLVS/WOoRM++NHdlalHNfMzCz/glwtzmhm1qVcvdDEzKxHTmZmVgSKbGUzJzMzq1x1V5qtCiczM+sT95mZWSH4cSYzKwbXzMws93L6RnMzs705mZlZ3nnSrJkVhtqzlc2czMyscp5nZmZF4akZZlYMrpmZWRF4AMDM8i8AP2huZkXgPjMzyz3PMzOzYohwM9PMisE1MzMrBiczMysC18zMLP8CKGUrmzmZmVmfuGZmZsXg0UwzK4Ks1czqah2AmeVQVLD1QtIPJa2T9ESnYxMkLZa0Ovk5vrdynMzMrGICVIpUWwo/As7d49g8YElETAeWJPs9cjIzsz5RRKqtNxFxP/D6HodnAwuSzwuA83orx31mZla5ylaanSTp4U778yNifi/fmRoRzQAR0SxpSm8XcTLrwcxZm7nkqrXU1wW/vmkCt143tdYhZYrvT9faS/CL/9TEyKltnP3d9Txy7VievXU0wyeUl5k44W/e4MDT36xxlPuqomczN0TEzP6MBvo5mUkqAY8n13keuCgiNvbnNaulri649OpX+MKFh7GhuYFrf7WaB+8ey5rVw2sdWib4/nTvqX8dw7jDW9m1VbuPHf2pLRx78eYaRlV9/Tya+ZqkpqRW1gSs6+0L/d1ntiMiZkTEMZTbxJf28/Wq5ojjt7P2haG8umYYba113LdwHKecs6nWYWWG70/Xtr1az8v3jWD6R7fWOpT+17FyRm9b39wBzEk+zwEW9vaFgRwA+B0wbQCvt08m7tfK+rVDd+9vaG5gUlNrDSPKFt+frj109Xhm/u1GVPf2f8TP/HQM//ZnTTzwhYns3FSAcbeo3mimpJso54cjJL0s6WLgGuBsSauBs5P9Hg1In5mkeuAs4AcDcb1qkPY+lrEJzzXl+7O3l+4dwYgJ7Uw6ZhfNDw3bffzIj2/huL/chAQr/mUcy64Zz/v/qaWGkVZJlf6+I+Lj3fzqrErK6e9kNkLSSuAQYDmwuKuTJM0F5gIMZ2Q/h5TOhuYGJu+/a/f+pKZWWl5tqGFE2eL7s7fXVgxjzdIRvHz/NEo7xa6t4jefn8jpX3srcb3zgi3cc0mvA3O5kGbaxUAakD4z4GBgKN30mUXE/IiYGREzGxjW1SkDbtXKkUw7dBdTD9zJkIZ2Zs3eyIOLxtY6rMzw/dnbzM9t5GP3v8IFS1/h9K+vp+nkNzn9ay1sX1e/+5w194xk/PSCNMf7t8+sYgPSzIyITZIuBxZK+k5EZP5vs70krv/iNK6+8Tnq6mHRzRN48VmP1HXw/Unv4a+Oo+WZoQgYPa2N91255/zQHApgsL7QJCIekfQocCHw44G67r5YtrSRZUsbax1GZvn+dK/ppJ00nbQegNO+WoD+sT2IdLP7B1K/JrOIGL3H/p/15/XMbAC1Z6tq5icAzKxyg7mZaWbFMqiamWZWYE5mZpZ/fgmwmRWB385kZkXhPjMzKwYnMzPLvQDanczMLPc8AGBmReFkZma5F0ApW48AOJmZWR8EhJOZmRWBm5lmlnsezTSzwnDNzMwKwcnMzHIvAkqlWkfxNk5mZtY3rpmZWSE4mZlZ/oVHM82sAALCk2bNrBD8OJOZ5V6EXzVnZgXhAQAzK4JwzczM8s+LM5pZEfhBczMrggAiY48z1dU6ADPLoUgWZ0yzpSDpXEmrJP1B0ry+hOSamZn1SVSpmSmpHrgeOBt4GVgm6Y6IeKqSclwzM7O+qV7N7ETgDxHxXETsAm4GZlcajiJjIxKS1gMv1jqOTiYBG2odRMb5HvUsa/fn4IiYvC8FSLqL8p8rjeHAm53250fE/E5lfRQ4NyI+nexfBJwUEZdVElPmmpn7epOrTdLDETGz1nFkme9Rz4p4fyLi3CoWp64uUWkhbmaaWa29DBzYaf8AYG2lhTiZmVmtLQOmSzpU0lDgQuCOSgvJXDMzg+b3fsqg53vUM9+fHkREm6TLgLuBeuCHEfFkpeVkbgDAzKwv3Mw0s0JwMjOzQnCfWRcklYDHgQagDVgAfDOytk5wjXW6Tx3Oi4gXahRO5nS6P0OA54GLImJjTYMqMPeZdUHS1ogYnXyeAtwI/HtEXFHbyLKl832yve3x39EC4NmI+EqNwyosNzN7ERHrgLnAZZK6mtxnlsbvgGm1DqLInMxSiIjnKN+rKbWOJWNGSFqZbLfXOpisSh6kPos+zJ2y9Nxnlp5rZXvbEREzah1Eho2QtBI4BFgOLK5pNAXnmlkKkg4DSsC6WsdiudKR7A8GhgKX1jacYnMy64WkycANwHXh0RLrg4jYBFwOfF5SQ63jKSons6519AU9CdwDLAK+XOOYLMci4hHgUcrPHVo/8NQMMysE18zMrBCczMysEJzMzKwQnMzMrBCczMysEJzMckZSKZk28oSk2ySN3IeyfpS8GQdJ35d0dA/nzpL0vj5c4wVJe73Fp7vje5yztcJr/aOkz1caoxWDk1n+7IiIGRFxDLALuKTzL5PnACsWEZ/u5aWrs4CKk5nZQHEyy7ffAu9Iak33SroReFxSvaSvSlom6TFJnwFQ2XWSnpL0Szo9OC/pPkkzk8/nSloh6VFJSyQdQjlp/nVSK/wPkiZL+llyjWWSTk2+O1HSIkmPSPouKZ5plfRvkpZLelLS3D1+989JLEuSpzGQdLiku5Lv/FbSkVW5m5ZrftA8pyQNAT4I3JUcOhE4JiKeTxLCpoh4r6RhwL9LWgQcDxwBHAtMBZ4CfrhHuZOB7wGnJWVNiIjXJd0AbI2IryXn3Qh8IyIekHQQ5ZdRHAVcATwQEVdK+jDl5ZN681+Ta4wAlkn6WUS0AKOAFRHxOUn/kJR9GeUXhFwSEaslnQR8GzizD7fRCsTJLH86VmKAcs3sB5Sbf7+PiOeT4x8A3t3RHwaMBaYDpwE3RUQJWCtpaRflnwzc31FWRLzeTRx/AhzdaYm3Rkljkmt8JPnuLyW9keLPdLmk85PPByaxtgDtwC3J8Z8AP5c0Ovnz3tbp2sNSXMMKzsksf/Zadif5R72t8yHgryLi7j3O+xC9vylaKc6BchfFKRGxo4tYUj8jJ2kW5cR4SkRsl3QfMLyb0yO57kYvPWR7cp9ZMd0N/PeOFRokvVPSKOB+4MKkT60JOKOL7/4OOF3Socl3JyTHtwBjOp23iHKTj+S8GcnH+4FPJMc+CIzvJdaxwBtJIjuScs2wQx3QUbv8z5Sbr5uB5yVdkFxDko7r5Ro2CDiZFdP3KfeHrZD0BPBdyrXw24HVlF+y8R3gN3t+MSLWU+7n+rmkR3mrmfcL4PyOAQDKS9rMTAYYnuKtUdUvA6dJWkG5ubuml1jvAoZIegy4Cniw0++2Ae+StJxyn9iVyfFPABcn8T0JzE5xT6zgvGqGmRWCa2ZmVghOZmZWCE5mZlYITmZmVghOZmZWCE5mZlYITmZmVgj/H8ZvjpW6fRzOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(targets.cpu(), predictions.cpu())\n",
    "test_correct = 0\n",
    "for i in range(3):\n",
    "  test_correct += cm[i][i]\n",
    "test_accuracy = test_correct/len(predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:>0.2f}%\")\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=encoder.classes_)\n",
    "cmd.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN_LSTM                                 --\n",
      "CNN: 1-1                               --\n",
      "    ReLU: 2-1                         --\n",
      "    Sequential: 2-2                   --\n",
      "        Conv1d: 3-1                  256\n",
      "        BatchNorm1d: 3-2             128\n",
      "        ReLU: 3-3                    --\n",
      "        MaxPool1d: 3-4               --\n",
      "    Sequential: 2-3                   --\n",
      "        Conv1d: 3-5                  24,704\n",
      "        BatchNorm1d: 3-6             256\n",
      "        ReLU: 3-7                    --\n",
      "        MaxPool1d: 3-8               --\n",
      "    Sequential: 2-4                   --\n",
      "        Conv1d: 3-9                  98,560\n",
      "        BatchNorm1d: 3-10            512\n",
      "        ReLU: 3-11                   --\n",
      "        MaxPool1d: 3-12              --\n",
      "    Sequential: 2-5                   --\n",
      "        Conv1d: 3-13                 393,728\n",
      "        BatchNorm1d: 3-14            1,024\n",
      "        ReLU: 3-15                   --\n",
      "        MaxPool1d: 3-16              --\n",
      "    Sequential: 2-6                   --\n",
      "        Conv1d: 3-17                 1,580,036\n",
      "        BatchNorm1d: 3-18            2,056\n",
      "        ReLU: 3-19                   --\n",
      "        Dropout: 3-20                --\n",
      "        MaxPool1d: 3-21              --\n",
      "LSTM: 1-2                              346,624\n",
      "Linear: 1-3                            23,619\n",
      "=================================================================\n",
      "Total params: 2,471,503\n",
      "Trainable params: 2,471,503\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "from torchinfo import summary\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axbt5gtfBRyF"
   },
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IR5Ns8PIBRFf"
   },
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Implementation1-CNN-LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
