\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{url}
\usepackage{xurl}
\usepackage{lipsum}  
\usepackage{float}
\usepackage{makecell}
\usepackage{silence}
\WarningFilter{caption}{Unknown document class}
\usepackage{subcaption}
%\usepackage[title,titletoc]{appendix} 

\setlength {\marginparwidth }{2cm}

%workaround for clash of todonotes package, see 
\newcommand{\todo}[1]{\textbf{\ \textcolor{red}{#1}}}

% get algorithm to work, see
% https://tex.stackexchange.com/questions/219816/algorithm-in-ieee-format
\usepackage{algorithmic}

\makeatletter
\newcommand\fs@norules{\def\@fs@cfont{\bfseries}\let\@fs@capt\floatc@ruled
  \def\@fs@pre{}%
  \def\@fs@post{}%
  
  \def\@fs@mid{\kern3pt}%
  \let\@fs@iftopcapt\iftrue}
\makeatother
%\floatstyle{norules}
%\restylefloat{algorithm}
\usepackage[ruled,vlined]{algorithm2e}


\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother

\usepackage{amsmath,amssymb,amsfonts}

\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage[all]{xy}				
% xy-pic for commutative diagrams etc
\def\N#1{*++[o][F-]{#1}}
\def\Nbs#1{*+++[o][F-]{#1}}
\def\Nb#1{*++++[o][F-]{#1}}
\def\NB#1{*+++++[o][F-]{#1}}
\def\diag#1#2#3{\dodiag{#1}{#2}{#3}{\Large}}
\def\diags#1#2#3{\dodiag{#1}{#2}{#3}{\small}}
\def\dodiag#1#2#3#4{
\begin{center}\leavevmode %\leavemode hack is necessary to make center work!
\begin{equation*}
\begin{xy}
#4%The (font) size
\xymatrixcolsep{#1}\xymatrixrowsep{#2}
\xymatrix {#3}
\end{xy}
\end{equation*}
\end{center}
}
\newcommand{\orcid}[1]{\href{https://orcid.org/#1}{\includegraphics[width=8pt]{Definitions/preview.png}}}

\newtheorem{remark}{Remark}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\doi{10.1109/ACCESS.2017.DOI}

\title{Towards Automated Feature Extraction For Deep Learning Classification of Electrocardiogram Signals}
\author{\uppercase{Fatima Sajid Butt}\orcid{0000-0002-9111-7305}\authorrefmark{1,2},
\uppercase{Matthias F Wagner}\orcid{0000-0002-8702-9257}\authorrefmark{3}\IEEEmembership{Member, IEEE},
\uppercase{Jörg Schäfer}\orcid{0000-0003-4797-0306}\authorrefmark{4}\IEEEmembership{Member, IEEE},
\uppercase{David Gomez Ullate}\orcid{0000-0002-6890-6584}\authorrefmark{5,6}}
\address[1]{Frankfurt University of Applied Sciences, Nibelungenpl. 1, 60318 Frankfurt am Main, Germany (e-mail: fbutt@fb2.fra-uas.de)}
\address[2]{Escuela Superior de Ingeniería, Universidad de Cádiz, 11001 Cádiz, Spain (e-mail: fatima.sajidbutt@alum.uca.es)}
\address[3]{Frankfurt University of Applied Sciences, Nibelungenpl. 1, 60318 Frankfurt am Main, Germany (e-mail: jschaefer@fb2.fra-uas.de9}
\address[4]{Frankfurt University of Applied Sciences, Nibelungenpl. 1, 60318 Frankfurt am Main, Germany (e-mail: mfwagner@fb2.fra-uas.de)}
\address[5]{Escuela Superior de Ingeniería, Universidad de Cádiz, 11001 Cádiz, Spain (e-mail: david.gomezullate@uca.es)}
\address[6]{School of Science and Technology, IE University, Madrid, Spain (e-mail: david.gomezullate@ie.edu)}

\tfootnote{This work was supported in part by the PhD-research program of the  Faculty of Computer Science and Engineering Fb2 of Frankfurt University of Applied Sciences.}

\markboth
{Butt \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
{Butt \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Fatima Sajid Butt (e-mail: \url{fatima.butt@fb2.fra-uas.de})}

\begin{abstract}
Many recent studies have focused on the automatic classification of electrocardiogram (ECG) signals using deep learning (DL) methods. Most rely on existing complex DL methods, such as transfer learning or providing the models with carefully designed extracted features based on domain knowledge. A common assumption is that the deeper and more complex the DL model is, the better it learns. In this study, we propose two different DL models for automatic feature extraction from ECG signals for classification tasks: A CNN-LSTM hybrid model and an attention/transformer-based model with wavelet transform for the dimensional embedding. Both of the models extract the features from time series at the initial layers of the neural networks and can obtain performance at least equal to, if not greater than, many contemporary deep neural networks. To validate our hypothesis, we used three publicly available data-sets to evaluate the proposed models. Our model achieved a benchmark accuracy of 99.92\% for fall detection and 99.93\% for the PTB database for myocardial infarction versus normal heartbeat classification.
\end{abstract}


\begin{IEEEkeywords}Electrocardiograph; benchmark testing; fall detection; time series analysis; machine learning; deep learning; LSTM; CNN; attention; transformer; PTB XL\end{IEEEkeywords}

\titlepgskip=-15pt

\maketitle

{According to} \cite{cdc}, in the United States of America alone, the leading cause of death for men and women irrespective of the racial and ethnic groups is heart disease. Hence, a timely and accurate diagnosis of the heart conditions is of vital importance. An Electrocardiogram (ECG) is a well-grounded method used for measuring and evaluating the performance of the cardiovascular system. Several techniques exist in both literature and practice to evaluate the ECG signals in different manners. It is one of the most important parameters that indicate a person's physiological well-being and is extensively used to evaluate the cardiac situation of the patients. It has been widely used for different purposes such as to get an overview of the health of a human heart, for bio-metric purposes, and for fall detection and prevention as described in \cite{fallcardio}.
ECG is a non-invasive method for evaluating the health of the human cardiovascular system. It can detect many heart diseases such as atrial fibrillation, myocardial infarction, AV block, and ventricular tachycardia, etc. It provides an insight into the central nervous system, particularly the autonomic nervous system.
Many of the automatic classification techniques using deep learning for ECG use either very deep neural networks or a pre-trained neural network that require either the weights set up to a configuration after being trained on an immense amount of similar data sets. Another approach is to pre-process the data sets by applying some filtration or feature extraction which is based on data domain knowledge and then fed into a neural network to train this. All of the above--mentioned steps involve an explicit understanding of the domain and the pre-process itself. \cite{karpagachelvi2010ecg} overviews the many ECG feature extraction techniques present in the literature.

Our work is motivated by the desire to design novel and simple models that avoid \emph{any} feature selection and complex data pre-processing which necessitates domain knowledge, while on the other hand requiring \emph{less} computation power but achieving at least state-of-the-art accuracy. In this paper we propose two architectures to achieve these goals including out-performance of benchmarks and analysis of the statistical evidence of our claims.
\section{Electrocardiogram - A time Series}
This section presents an introduction to ECG signals and the importance of using automatic ECG classification techniques.
An ECG is a physiological signal that is measured as the potential difference between the electrodes placed on the body surface. The cardiac impulse passes through the heart causing the electrical current to spread
from the heart to adjacent tissues. A small current extends to the surface of the body. The electrodes placed on the skin can effectively detect the current on opposite sides of the heart, and record the electrical potentials generated by the current. A normal ECG consists of five major deflections called P, Q, R, S, and T waves, which constitute a single cardiac rhythm as shown in Fig. \ref{fig:ECG}. The P wave lasts about 0.08 s and is the smallest, followed by the large QRS complex which lasts between 0.08 s and 0.10 s. The end of the cardiac cycle is marked by a T wave that lasts approximately 0.16 s. A single waveform varies depending on the size of the heart and the conductive properties of the body which in turn gives the waveform a unique pattern per person \cite{7164783}. ECG has not only been used to monitor and evaluate the cardiovascular system but has also been used as a biometric identifier \cite{9123339}, a predictor of gender and age as described in \cite{cite-key}, and for detecting fall activities as in \cite{2021}.
\begin{figure}[ht]	
\caption{A Normal ECG} %\cite{ecgbook}}
\label{fig:ECG}
\centerline{\includegraphics[width=18.5pc]{Definitions/ecgNormal.png}}
%{Images/ecg.png}}
%\widefigure
%\includegraphics[width=15 cm]{Definitions/PTB_training.png}
%\todo{must check copyright}
\end{figure}

The disruption of blood flow to the muscle layer of the heart causes a cardiovascular condition called a myocardial infarction (MI). This disruption is mostly due to the build-up of the plaques in the arteries which result in reduced blood flow to that part of the heart muscle. MI is called a silent heart attack because the patient is not aware of the condition unless they suffer from a heart attack. An early diagnosis of MI is therefore of vital importance as it would help the patients to get timely treatment hence preventing the high percentage of mortality associated with it. 
Due to the small amplitude (millivolts), the manual interpretation of ECG signals is time-consuming and prone to errors. This limitation can be mitigated by an automatic diagnosis of heart conditions based on the signals. Our study aims to work towards automation of the cardiovascular disease diagnosis from ECG signals.

In this study, we propose two methods to automatically extract features from a time series and then feed those features into another deep learning model for classification.
First, a hybrid model for multiple ECG classification tasks is proposed as an alternative to many complex models that require many pre-processing steps before the actual training. We experimented with a robust hybrid deep learning model for the ECG classification tasks, which proved to outperform many state-of-the-art complex models and achieve similar or even better accuracy with no pre-processing steps. The CNN placed in front of a LSTM also known as CNN-LSTM, has recently been used for multiple classification tasks; however, its use for ECG classification has not been systematically explored. The CNN model first searches for the features in high-dimensional input data and then after converting it into one-dimensional data, it is fed as an input to the LSTM model. The role of a CNN in this context is to act as an automatic feature extractor.
Secondly, a novel attention/transformer model using wavelets for dimensional embedding is introduced to improve the efficiency of the classification process. As it has less trainable parameters than CNN-LSTM it has advantages in terms of (training) performance as shown in Table~\ref{tbl:paramvssota}. As a bonus, we also evaluated both models also on the data for fall detection.

\section{Related Work and Our Contribution}

Several recent studies have focused on automatic ECG classification. Among the several different techniques present for ECG classification, deep learning has gained popularity in recent times. This is mainly owing to its automatic feature learning and the availability of large public data sets. Many deep learning techniques use feature extraction as an essential pre-processing step before feeding the data to the neural network. 
The most common feature extraction techniques for ECG classification are continuous wavelet transform (CWT), discrete cosine transform (DCT) \cite{article2}, Pan-Tompkins algorithm \cite{7019490} and discrete wavelet transform (DWT) {\cite{article}}. One of the major disadvantages of using wavelet transform as a feature extractor is that the complexity of the process increases with the increase in decomposition level. All feature extraction processes require some domain knowledge in order to efficiently extract relevant features from the data. Therefore, we aim to explore the research question of whether a similar state-of-the art result can be achieved with no pre-processing and with a simpler model architecture in an efficient manner in terms of resources and computation. 

Our contributions to this study are twofold: First, we introduce a CNN-LSTM architecture that surpasses many complex and pre-trained  models that have been optimized for single data sets on multiple data sets at the same time. Second, to further optimize the automatic feature extraction, we introduce a novel embedding technique for an attention/transformer encoder architecture that uses discrete wavelet transform to extract features from the ECG time series and feeds them to the attention mechanism. In addition, we provide statistical evidence for the significance of the performance figures reported by the two models proposed by us.

In the following sub-sections, we present the state of the art in the related work and highlight our contributions.

\subsection{CNN-LSTM Architectures}

Jambukia et al. (2015) \cite{7164783} presented an overview of the ECG classification of different types of arrhythmias. Another current review on deep learning methods for ECG arrhythmia classification \cite{EBRAHIMI2020100033} deduced that among the many deep learning models, CNNs and LSTMs were among the most effective for learning arrhythmia in ECG classification tasks.
The use of the CNN-LSTM architecture for classification is not entirely novel. Socher et al. \cite{NIPS2012_3eae62bb} proposed a model for 3d object classification that combines a CNN with an RNN. They concluded that the CNN provides the translation variance for lower-level features whereas RNNs can learn the interactions and compositional features in the data. Zheng et al \cite{zheng}, transformed the data acquired by a three-axis accelerometer into an image format and then used a CNN with three convolution layers to classify human activities. XIA et al. (2020), \cite{xia} used CNN after a LSTM layer to classify human activity recognition (HAR) with an accuracy of 95.85\%. Ordóñez et al. (2016),\cite{ordonez} proposed an activity recognition classifier that combines a deep CNN and dense layers. In \cite{YildirimEtAl} the authors proposed a 1-D CNN for the classification of cardiac arrhythmia, and in \cite{HannunEtAl}, a 34-layer convolutional neural network is used for classification of cardiac arrhythmia exceeding the performance of board-certified cardiologists.
However, few studies have focused on hybrid CNN-LSTM models for ECG classification. Studies like \cite{8419425},\cite{2019},\cite{WANG2021106006}, and \cite{e23010119} have implemented CNNs and their variants for ECG classifications. \cite{saadat} used RNNs to classify the ECG signals. The use of LSTM-based approaches is also beneficial for other cardiac signal analyses. \cite{GAO202082} construct a bidirectional LSTM for the analysis of blood flow dynamics from static CT angiographic images. In \cite{MathewsEtAl} a restricted Boltzmann machine and deep belief networks were used for detection of ventricular and supraventricular heartbeats using single-lead ECGs. For a general overview of deep-learning techniques in cardiovascular image analysis, see the survey \cite{LitjensEtAl}.

In our study, we not only performed multiple classifications with CNN-LSTM model for ECG but also worked with three different ECG data sets including data for fall detection to present a proof of concept that CNN placed in front of LSTM surpasses many complex and pre-trained models.

\subsection{Attention and Transformer Architectures}
The seminal paper by Vaswani et al.~``Attention is All you Need" \cite{VaswaniEtAl} has triggered an enormous number of successful applications of attention mechanisms and transformer architectures in deep learning. 

The main idea behind attention-based transformer architectures is to replace the recurrence mechanisms used in LSTMs and the convolutions used in convolution networks to extract features entirely using an alternative so-called self-attention mechanism. This mechanism is shown in eq.\ (\ref{eq:attention}) and computes the correlation between the input values among each other and can be interpreted as an associative memory using ideas from statistical physics,  see \cite{RamsauerEtAl}. Replacing the (serial) recurrence mechanism with the standard matrix algebra of the (self-) attention mechanism has a number of advantages for parallelization capabilities and the performance of classification tasks.

However, the vast majority of research has been and still is focused on the natural language processing (NLP) domain. Little research has been carried out on the application of attention-based architectures in other domains, such as time series analysis. One of the first papers in this regard is LSTNet by Lai et al.~\cite{LaiEtAl}, where the authors introduced long- and short-term time-series networks (LSTNet) using the convolutional neural networks and  recurrent neural networks to extract short-term local dependency patterns and to discover long-term patterns for time series trends. Shih et al.~\cite{ShunYaoEtAl} applied an attention mechanism to multivariate time series data in three medical domains. Song et al.\cite{SongEtAl} have applied attention models to clinical time series analysis. A systematic and comprehensive analysis and study of utilizing attention mechanisms, however, in the time-series domain is still required. The application of transformers in the domain of ECG classification can be found in \cite{YanEtAl}.

One of the shortcomings of the self-attention mechanism preventing its application for e.g.,\ time-series is the  ${\cal O}(n^2)$ complexity with regards to the length of the input vector, i.e.,\ the length of the time series in our case. To address this problem LinFormer has been introduced by Wang et al.\ in \cite{WangEtAl}. Linformer is the first theoretically proven linear-time transformer architecture and henceforth might be suitable also for long time series. The linear scaling is achieved by discovering that self-attention is low rank, and henceforth projecting information on a low rank constant sub-dimensions achieves to decouple from the ${\cal O}(n^2)$ scaling. Recently Rabe and Staats \cite{RabeStaats} have proposed an algorithmic solution to at least reduce the memory (but not the time) complexity from  ${\cal O}(n^2)$ to  ${\cal O}(n)$.

In this paper, we propose a novel attention architecture using projection on discrete wavelet components as a means to address the ${\cal O}(n^2)$ problem and for dimensional embedding. Moreover, the results show that using this technique, \emph{attention-only} architecture is on par with or even outperforms more complex models and has several additional advantages such as e.g.,\ better run-time performance.


\section{Algorithms}
This section provides a brief overview of the algorithms and the technologies that were used during the course of this study and also presents the state of the art in the respective technologies.

\subsection{CNN-LSTM Model}
We define some basic terms related to the convolutional neural network and LSTM for clarity in the following section.
\subsubsection{CNNs and LSTMs }
Convolutional neural networks, introduced as LeNet in 1989 by LeCunn, have revolutionized the field of image recognition and are among the most prominently used deep neural networks. They were named after the linear matrix operation called convolution. Since convolution is a linear operation, the convolution layer is often followed by a non-linear layer. Although introduced earlier, it gained popularity after its application as the first deep neural network applied for object recognition in the ImageNet Large Scale Visual Recognition Competition (ILSVRC) in 2012. AlexNet was proven to excel on the largest computer vision data set as compared to contemporary methods. Recently, \cite{cite-key1} presented a state-of-the-art review of the recent deep CNNs architectures. The individual CNN components were explained in \cite{8308186} in a structured way.
The most common architectures of CNNs include an input layer, a convolution layer followed by a pooling layer, a drop-out layer, and a fully connected layer followed by an output layer. The number of layers and their layout can change depending on different problem sets. The convolution operation\footnote{in the two dimensional case--the one-dimensional case is analogous} itself is given by:
\begin{align*}
V_{i,j}= X*W_{i,j}+b    &= \sum_{L}X^L*W^L_{i,j}+b \\
                        &=  \sum_{L}\sum_{k,l} X^L_{kl}*W^L_{i+k,j+l}+b
\end{align*}
where $X$ or $X^L$ resp.\ denote the $L$-th input matrix. $W$ is the convolution kernel matrix, $b$ is the bias, and $V_{i,j}$ is the output matrix after convolution. %\cite{zhang}. 

CNN's are known for their excellent feature extraction capability. One of the most salient features of CNN is its translation invariance. Therefore, it can extract features irrespective of the spatial context. Though it has proven to be beneficial in image recognition, its application and usefulness in time series are yet to be fully exploited. Cases, where the historical context is relevant for classification, would not work well with CNN alone, as it does not carry any information about the history of the time series. The CNNs initially extract the local features in the sub-regions of the time series and then the information is merged in later stages to detect the higher order features. We applied 1D convolution to the time series using both univariate and multivariate data sets. The ECG Human activity recognition (HAR) data set and PTB diagnostic data set contained one feature each, so the 2D convolutional operation would not be suitable as it will incorrectly convolve across multiple time series. 
Long short-term memory (LSTM) networks--a variation of recurrent neural networks (RNNs)--were introduced by Hochreiter \cite{LSTM} in 1997. They tend to present a solution to the common problem associated with RNNs called vanishing and exploding gradients. In principle, classical RNNs can keep track of long-term dependencies in the sequences. However, in practice, during the backpropagation phase of training, these long-term gradients either vanish or explode owing to the successive multiplicative operations. An LSTM consists of a chained loop structure. Each LSTM unit is made up of an input gate, an output gate and a forget gate. The LSTMs keep the long-term memory by maintaining a cell state that sustains a part of the information from earlier states by forgetting and/or applying increment operations on the previous states. Adding a CNN in front of an LSTM helps to feed the LSTM the features from CNN which were extracted from the time series.
\subsubsection{CNN-LSTM Architecture and Algorithm}

%Fig.~\ref{fig:CNN-LSTM} depicts the overall architecture of our model;
Fig.~\ref{fig:CNN-LSTM} and Fig.~\ref{fig:cnnlstmArchitecture} provide a more graphical overview of our model. Initially (1*N) time series with N time stamps are convolved with k filters each of size M*1. Subsequently, the k feature maps each of size (N-M)+1 time stamps are generated which are passed through a dropout layer followed by the max pooling layer and later fed into the LSTM layer where the encoded extracted features are fed into it from the CNN. The LSTM unit is followed by a fully connected or dense layer that applies softmax as an output function to classify the input time series into one of the output classes.
\begin{figure}[!ht]
\includegraphics[width=0.5\textwidth]{Images/cnn-lstm.png}
\caption{CNN-LSTM Model for PTB DB}
\label{fig:CNN-LSTM}
\end{figure} 

%\begin{figure}[ht]	
%\centerline{\includegraphics[width=18.5pc]{Definitions/CNN-LSTM.jpg}}
%\caption{A layout of the CNN-LSTM model: (a) A (1*N) time series with N time stamps convolved with k filters each of size M*1, (b) k feature maps each of size (N-M)+1 time stamps, (c)Max pooling followed by (d) dropout and later fed into (e) time distributed layer which feeds the encoded extracted features maps from CNN to (f) LSTM unit. LSTM unit is followed by a fully connected or Dense layer which applies Softmax as an output function to classify the input time series into one of the output classes  \label{fig:CNNModel}}
%\label{fig:CNN-LSTM2}
%\end{figure}

\begin{figure}[ht]
\centerline{\includegraphics[width=18.5pc]{Definitions/final-cnnlstm-arch.png}}
%\includegraphics[width=10.5 cm]{Definitions/final-cnnlstm-arch.png}
\caption{Final CNN-LSTM Architecture for Fall and HAR using ECG signals}
\label{fig:cnnlstmArchitecture}
\end{figure}  




\begin{algorithm}
 \caption{Classification of ECG signals with Raw Signals using CNN-LSTM}
  \label{alg:algorithm1}
 \begin{algorithmic}[1]
 \renewcommand{\algorithmicrequire}{\textbf{Input:} A time series ECG raw data $ts$}
 \renewcommand{\algorithmicensure}{\textbf{Output:} The classified label $l$}
 \REQUIRE 
 \ENSURE  

\STATE $ts \leftarrow$  RAW\_VALUE\_EXTRACTION($ts$)
\STATE $features \leftarrow$ CNN($ts$)
\STATE $l \leftarrow$ LSTM\_CLASSIFICATION($features$)
 \RETURN $l$
\end{algorithmic}
\end{algorithm}
Algorithm \ref{alg:algorithm1} outlines the algorithms for extracting features from the ECG signal and classifying them using a CNN-LSTM model. The number of CNNs and LSTMs can be varied but we used a maximum of five 1-d convolution layers in front of the three LSTM layers.
\subsection{Attention Model}
For reader's convenience, we recall the basic definitions of the attention mechanism following \cite{VaswaniEtAl} and the notation therein.

\subsubsection{Attention}
\newcommand {\softmax}{\mathop{}\,\mathrm{softmax}}

Attention is defined as
\begin{equation}\label{eq:attention}
Attention(Q, K, V)=\softmax \left(\frac{QK^T}{\sqrt{d_k}} \right) V,
\end{equation}
where $Q$, $K$ and $V\in \mathbb{R}^{n\times d_k}$ are input embedding matrices, $n$ is the length of the (time) series, and $d_k$ is the embedding dimension, resp.

The transformer uses Multi-Head Self-Attention (MHA) allowing the model to jointly attend to information at different positions of the time-series or different semantics of the domain. MHA is defined as 
\begin{align} 
&\text{MultiHead}(Q, K, V) = \\
&\text{Concat}\left(\text{head}_1, \text{head}_2, \ldots, \text{head}_h \right)  W^O, 
\end{align} 


where $h$ is the number of heads. Each head is defined as

\begin{align} 
\text{head}_i 	&= \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \\
			&= \softmax \left[\frac{QW_i^Q(KW_i^K)^T}{\sqrt{d_k}} \right] VW_i^V,
\end{align} 
where $W_i^Q$, $W_i^K \in \mathbb{R}^{d_m\times d_k}$, $W_i^V \in \mathbb{R}^{d_m\times d_v}$, and $W^O \in \mathbb{R}^{hd_v\times d_m}$ (projection onto the output) are learned matrices and $d_k$, $d_v$ are hidden dimensions of projection subspaces. For simplicity in the sequel, we drop the differentiation between $d_m$, $d_k$ and $d_v$ and refer to them by $d$. 

The matrices $Q$, $K$ and $V$ are usually referred to as query, key and value matrices to remind of the associative memory architecture of a transform, compare e.g.,\ also the analysis in \cite{RamsauerEtAl}.

\subsubsection{Attention and Dimensional Embedding}
For applying the attention mechanism to time-series one has to decide on the proper dimensional embedding, i.e.,\ on the dimension of the embedding subspace and on the embedding transformation. We recall that in the domain of ECG the ``natural'' dimension is small. For instance, the signals are one-dimensional if a one-dimensional channel (single lead) is used (as is the case in this paper for the attention/transformer model, i.e.,\ Algorithm~\ref{alg:algorithm2}). Even if multi-channel ECGs are used usually the number of channels is limited to a small number of 3 to maximally 12 channels. Henceforth, if we used the channel as the embedding, the dimension would be $1$ in our case, i.e.,\ $d=1$. This is way too small to capture interesting patterns and, indeed, a test showed that the gradient descent does not converge, but stays constant after one or two initial updates. Furthermore, as depicted in the previous section, the self-attention suffers from an  ${\cal O}(n^2)$ problem. We propose the following architecture to solve both problems simultaneously:
\begin{enumerate}
\item Assuming $m \ll n$. For simplicity of the notation, we assume without loss of generality that $n$ is divisible by $m$, i.e.,\ $n = mw$. This effectively segments the time-series $n$ into $n_m$  ``windowed'' segments of length $w$, where $m\in 1, \ldots k$ with $k:=n/w$. If $n$ is not divisible without remainder, we could fill the time series with zeros (padding).
\item For each ``windowed'' sub- time-series $t_{n_k}$ we calculate the decomposition to a chosen (fixed) wavelet by performing a discrete wavelet transformation (DWT), see below. Assuming that the result of applying the DWT is in dimension $p$, we have transformed the input from $\mathbb{R}^{n}$ into $\mathbb{R}^{m\times p}$ depicted in Fig.~\ref{fig:dimEmbedding}.
\end{enumerate}

\begin{figure}[!ht]
\includegraphics[width=0.5\textwidth]{Images/DimEmbedding}
\caption{Dimensional Embedding\label{fig:dimEmbedding}}
\end{figure}   

\begin{remark} In this paper, we propose a deterministic embedding using DWT rather than a learned, randomly initialized embedding, which is an alternative approach that has been used in other attention architectures in the past. This should--in theory--require less training data--a conjecture that we want to validate in future work using synthesized data.
\end{remark} 
\begin{remark} Note, that within the context of dictionary-based learning, a deterministic embedding using DWT could be considered as a ``predefined analytical dictionary'' \cite{Mathews}. Contrary to a fixed feature design using wavelet components, however, an embedding with an attention/transformer architecture has a flavor of learning the representation dynamically from the data as the proper amount of \emph{attention} is learned from the data indeed. A systematic investigation of these aspects is deferred to future work, too.
\end{remark} 

\subsubsection{Discrete Wavelet Transformation (DWT) for Dimensional Embedding}
For the reader's convenience, we recall a few well-known definitions and theorems wavelet theory following \cite{Daubechies} and \cite{MallatEtAl} and using the notation from \cite{Ryan}.
%\todo{Look into the notation of mother wavelet with t as denominator - done and confirmed, but added the details such as integration constant to make more obvious. Note, that the admissibility condition implies \psi(0)=0 as it should be}
We consider signals as real-valued functions. We call a function $\psi\in L^2(\mathbb{R})$ an orthonormal wavelet if dyadic translations and dilations of $\psi _{{jk}}(x)=2^{{\frac  {j}{2}}}\psi \left(2^{j}x-k\right)$ constitute a Hilbert space and if in addition, it satisfies a regularity (admissibility) condition, namely $\int_0^\infty |\psi(t)|^2 \frac{dt}{t}<\infty$, ensuring convergence and $\int \psi(t)\, dt =0$. The function  $\psi$ is usually called the \emph{mother wavelet} and its child wavelets are defined as 
$\psi_{j,k}(t)= \frac{1}{\sqrt{2^j}} \psi \left( \frac{t - k 2^j}{2^j} \right)$. A projection of a function $x(t)$ onto $\psi_{j,k}$ is then given by
\begin{equation}
 \gamma_{jk} = \int_{-\infty}^{\infty} x(t)  \frac{1}{\sqrt{2^j}} \psi \left( \frac{t - k 2^j}{2^j} \right) dt.
\end{equation}
The crucial idea is to decompose the space $L^2(\mathbb{R})$ into resolution spaces of different resolutions. First, the \emph{resolution space} $V_0$ is defined as the space of piece wise constant functions on subintervals of $[n, n+1]$ with $n=0,\ldots, N$. If we define the corresponding step function  

\begin{equation}
\phi(t)=\begin{cases}
1, & if\quad  0\leq t<1 \\
0 & otherwise,
\end{cases}
\end{equation}
%
then $V_0$ has dimension $N$, and the $N$ functions $\boldsymbol\phi_0 := \{\phi (t-j)\}_{j=0,\ldots, N-1} $ constitute an orthogonal basis. Analogously the \emph{refined resolution spaces} $V_k$ are defined as the spaces of functions constant on each sub-interval $[n/2^k, (n+1)/2^k]$. This yields a nested sequence of embedded spaces
\begin{equation}
V_0 \subset V_1 \subset V_2 \subset \ldots \subset V_k.
\label{eq:waveletDecomposition}
\end{equation}
We denote the orthogonal complements of $V_{k-1}$ in $V_k$ as $W_{k-1}$, i.e.,\ $V_k= V_{k-1}\oplus W_{k-1}$ and call it the \emph{detail space}. This yields an orthogonal decomposition at level $k$ as follows:
\begin{equation}
V_k = V_0\oplus W_0 \oplus W_1 \oplus \ldots \oplus W_{k-1}
\label{eq:waveletDecomposition2}
\end{equation} 

Then the $k$-level \emph{discrete wavelet transformation} (DWT) is defined as the change of coordinates from $\boldsymbol\phi_k$ to $(\boldsymbol\phi_0, \boldsymbol\psi_0, \boldsymbol\psi_1, \ldots, \boldsymbol\psi_{k-1}$), where $\boldsymbol\phi_k := \{\phi_{jk}\}_{j=0,\ldots, N-1}$ and $\boldsymbol\psi_k := \{\psi_{jk}\}_{j=0,\ldots, N-1}$, resp. denote the family of functions obtained from the mother wavelet.

This yields a filter bank interpretation of DWT, wherein each step the signal is decomposed into an averaged and a detailed signal using low-pass and a high-pass filter depicted graphically in Fig.~\ref{fig:waveletTransformPyramid}.
\begin{figure}[ht]
	\centering
	\diags{1.5em}{0.5em}{
	V_m\ar[r]\ar[ddr]	&V_{m-1}\ar[r]\ar[ddr]&\ldots\ar[r] 	&V_{2}\ar[r] \ar[ddr]	&V_{1}\ar[r] \ar[ddr]	&V_0\cr
					&\oplus			&\oplus		&\oplus			&\oplus			&\oplus\cr
					&W_{m-1}			&W_{m-2}		& \ldots			&W_{1}			&W_0\cr
}
	\caption{Wavelet Transform Pyramid}
	\label{fig:waveletTransformPyramid}
\end{figure}

Thus, any signal can be decomposed into an averaged and a detailed signal, namely $V_0$ and $W_0$. Due to the recursive nature, this can be extended to any desired level $k$. Please note, that due to the dyadic nature the data size is reduced by a factor of $2$ in each step. For further details, we refer to \cite{Daubechies} and \cite{{MallatEtAl}} as well as e.g.\ \cite{Ryan}. 

We used Haar and Daubechies wavelets as well as symlets (symmetrized version of Daubechies wavelets) as mother wavelet. 

\subsubsection{Transformer Architecture and Algorithm}
The DWT can be used not only for dimensional embedding but also, for noise reduction as one can ignore some or all coefficients for the detailed spaces. To explore the impact, we tried several configurations, see Table~\ref{tbl:atttentionModels}\footnote{Frequency refers to the frequency of the positional encoding. It should be remarked, that model \textsc{att5} differs from \textsc{att4} by an additional residual connection.}. 

\begin{table}[!ht]
\caption{Attention Models}
\label{tbl:atttentionModels}
\centering
\scriptsize
{%
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{cccccccc}
		&{\rotatebox[origin=l]{90}{Wavelet}}&{\rotatebox[origin=l]{90}{Spaces}}&{\rotatebox[origin=l]{90}{Dim Embedding}}&{\rotatebox[origin=l]{90}{Hid Dim}}&{\rotatebox[origin=l]{90}{Frequency}}&{\rotatebox[origin=l]{90}{Epochs}}&{\rotatebox[origin=l]{90}{Accuracy}}\\
\textsc{att2}		&db8 					&$V_0$				    	&13				&150		&0.1k			&1k		&98.14\\
\textsc{att3}		&db8 					&$V_0$				    	&12 			&150		&0.1k			&1k		&98.83\\
\textsc{att4}		&db8					&$V_0\oplus W_0$	    	&24 			&150		&0.1k			&1k		&99.18\\
\textsc{att5}		&db8 					&$V_0\oplus W_0$	    	&24 			&150		&0.1k			&1k		&99.11\\
\textsc{att6}		&db8					&$V_0\oplus W_0$	    	&26 			&250		&0.1k			&1k		&99.45\\
\textsc{att7}		&sym6 					&$V_0\oplus W_0$	    	&22 			&250		&0.1k			&1k		&99.38\\
\textsc{att8}		&db8					&$V_0\oplus W_0$		    &26 			&250		&10k			&1k		&99.59\\
\textsc{att9}		&db8					&$V_0\oplus W_0$	       	&26 			&250		&10k			&2k		&99.59\\
\textsc{att10}		&db5					&$V_0\oplus W_0$	    	&20				&250		&10k			&1k		&99.24\\
\textsc{att11}		&db5 					&$V_0\oplus W_0\oplus W_1$  &28 			&250		&10k			&1k		&99.73\\
\end{tabular}
\medskip	
}
\end{table}

We deployed a transformer architecture with one head, four transformer encoder layers, and a dimension of 150 or 250 hidden units of the feed-forward network. The network's architecture of the best model, \textsc{att11}, is illustrated in Fig.~\ref{fig:transformerArchitecture}.
\begin{figure}[!ht]
\includegraphics[width=0.5\textwidth]{Images/TransformerArchitecture}
\caption{Transformer Architecture of Model \textsc{att11}}
\label{fig:transformerArchitecture}
\end{figure}   

The original input tensor has a dimension of $[14552, 1, 187]$ corresponding to $14522$ data rows, $1$ feature, and a sequence length of $187$. The sequence was split into $17$ chunks, with a window length of $11$. Each subsequence of length $11$ was converted using the DWT. For instance, for db8 for \textsc{att7}, this leads to a transformed tensor of $[14552, 22, 17]$. (Note, that due to boundary effects, the embedding dimension is not always a multiple of $11$.).

As a positional encoding, we tried the usual Fourier encoding and used frequencies $f$ of $f=100$ and $f=10.000$, resp. While adding positional encoding is questionable after embedding using DWT, we experimentally found the results to be  improved by a small amount.%sub percentage usually.

All models were trained with a batch size of $256$ and a learning rate of $0.001$ using the Adam optimizer \cite{Adam}.
Algorithm~\ref{alg:algorithm2}\footnote{Note, that for simplicity of  notation we use the expression $(V_0\oplus \ldots \oplus W_m)$ from the decomposition in equation~\ref{eq:waveletDecomposition2} generically, i.e., some of the components of $(V_0\oplus \ldots \oplus W_m)$ might be empty.} layouts the algorithms for extracting features from ECG data and classifying them using a transformer/attention model. 

 \begin{algorithm}
 \caption{Classification of ECG signals with Raw Signals using Attention/Transformer}
  \label{alg:algorithm2}
 \begin{algorithmic}[1]
 \renewcommand{\algorithmicrequire}{\textbf{Input:} A time series ECG raw data $ts$}
 \renewcommand{\algorithmicensure}{\textbf{Output:} The classified label $l$}
 \REQUIRE 
 \ENSURE  

\STATE $X$ $\leftarrow$ RAW\_VALUE\_EXTRACTION($ts$)
\STATE $(V_0\oplus W_0 \oplus W_1 \oplus \ldots \oplus W_m) \leftarrow$ DWT($X$)
\STATE $(V_0\oplus \ldots \oplus W_m) \leftarrow  (V_0\oplus \ldots \oplus W_m)   + POS\_ENC(V_0\oplus \ldots \oplus W_m)$	
\FOR{$i \in \mathrm{Layers}$}
        \STATE $X \leftarrow$ TRANSFORMER$_i (V_0\oplus \ldots \oplus W_m)$
\ENDFOR
\STATE $l \leftarrow$ LINEAR\_FEED\_FORWARD($X$)
\RETURN $l$
 \end{algorithmic}
 \end{algorithm}
 
 \subsection{Complexity Analysis}
\subsubsection{Runtime Complexity Analysis}
In general, the runtime complexity for attention based RNN/LSTM and CNN architectures are known as depicted in Table~\ref{tbl:genericRuntimeComplexityAnalysis}, see e.g.~\cite{VaswaniEtAl}\footnote{Note, that we have added the complexity caused by the query matrices which were omitted in \cite{VaswaniEtAl}.}, where $n$ denotes the sequence length, $d$ the embedding dimension, and $k$ the size of the kernel (in case of CNN).

\begin{table}[!ht]
    \centering%
    \caption{Generic Runtime Complexity Analysis
    \label{tbl:genericRuntimeComplexityAnalysis}}

    \small
    \begin{tabular}{*{5}{c|cccc}}
          \toprule
    \textbf{Layer Type} &\textbf{Layer Compl.} &\textbf{Seq.\ Ops} &\textbf{Max Path Length}
      \\\midrule
	Attention		& ${\cal O} (n^2 d+ n d^2)$	& ${\cal O} (1)$	& ${\cal O} (1)$\\
	RNN/LSTM	& ${\cal O} ( n d^2)$			& ${\cal O} (n)$	& ${\cal O} (n)$\\
	CNN			& ${\cal O} (k n d^2)$		& ${\cal O} (1)$	& ${\cal O} (\log_k (n))$\\
         \bottomrule
    \end{tabular}    
\end{table}
Note, that the maximum path length measures the maximum length between any two input and output positions in the networks.  Shorter path length makes it easier to learn long-range dependencies.

Considering, that the dimensional embedding using wavelets is of ${\cal O} (n)$ and has to be computed only once and henceforth can be ignored compared to ${\cal O} (n^2 d+ n d^2)$, we conclude from Table~\ref{tbl:genericRuntimeComplexityAnalysis} the complexity of our algorithms as depicted in Table~\ref{tbl:runtimeComplexityAnalysisConmbined}.
\begin{table}[!ht]
    \centering%
    \caption{Runtime Complexity Analysis for Algorithms~\ref{alg:algorithm1} and~\ref{alg:algorithm2}}

    \label{tbl:runtimeComplexityAnalysisConmbined}

    \small  
    \begin{tabular}{*{5}{c|ccc}}
          \toprule
    \textbf{Algorithm} &\textbf{Total Complexity}  &\textbf{Max Path Length}
      \\\midrule
	Alg~\ref{alg:algorithm1} 	& ${\cal O} (n^2 d^2)$		& ${\cal O} (n + \log_k (n))={\cal O} (n) $\\
	Alg~\ref{alg:algorithm2}	& ${\cal O} (n^2 d+ n d^2 )$	& ${\cal O} (1)$\\
         \bottomrule
    \end{tabular}    
\end{table}

From this analysis, we can conclude that Alg~\ref{alg:algorithm1} is always inferior to Alg~\ref{alg:algorithm2} in terms of algorithmic complexity. In addition, the transformer can be easily paralleled (typically on a GPU), contrary to a CNN-LSTM.

Please note, that the above analysis assumes that the matrix multiplication of two matrices $\mathbf{A}\in\mathbb{R}^{nm}$ and $\mathbf{B}\in\mathbb{R}^{ml}$ is in  ${\cal O} (nml)$, which corresponds to a naive implementation of matrix multiplication. Although this can be improved, compare Strassen's algorithm \cite{Strassen}, and--more recently--Josh Alman and Virginia Vassilevska Williams algorithm \cite{JoshEtAl}, these algorithms are normally \emph{not} implemented in the machine learning frameworks used and henceforth the naive implementation as the usual convention is assumed.

\subsubsection{Memory Complexity Analysis}
As for backpropagation, the weights optimized have to be kept in memory, to optimize the algorithms efficiently, we have essentially the same space as time complexity, particularly space complexity of any attention-based model of ${\cal O} (n^2)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Preparation and Experimental Setup}
Since our study includes multiple data sets, therefore this section explains the preparation steps taken for each data set and the overall experimental setup.
Experiments were performed using a GPU server. All the experiments were implemented using the PyTorch library because of its supportive architecture with GPUs. The main aim of the experiments was fall and MI detection using ECG signals in an automated and efficient manner. 
\subsection{ECG data set for fall detection}
To the best of our knowledge, the ECG HAR data set is the only one for the detection of different human activities including falls, using ECG signals. It was originally collected by \cite{2021}, as an experiment that was part of the study by \cite{9233318}. It originally consisted of two classes: one for the ECG of a person falling from the bed and another one for the ECG of a resting person. It was later augmented with two more data sets, \cite{ysnc-gc65-20} and \cite{ECGdb}, by up-sampling the original data set. In addition to that, another augmentation method called slicing was applied to the data set. Slicing has been explained in detail in \cite{cui2016multiscale}. After the addition of new data sets, the final version has three classes namely: fall, rest, and daily activities. 


The overview of the final class distribution in data set is depicted in Table~\ref{tbl:HARDataset}.

\begin{table}[!ht]
    \centering%
    \caption{Total Number of Samples in the ECG HAR Data Set
    \label{tbl:HARDataset}
    \cite{2021}}

    \small
    \begin{tabular}{*{3}{p{.25\linewidth}}}
          \toprule
    \textbf{Label} &\textbf{Total Count}
      \\\midrule
    Fall & 500\\
      %\\\midrule
     Rest &474\\
       %\\\midrule
     DA &296\\
     %\\ \midrule 
     Total& 1270\\
    
     %\\ \midrule
     \bottomrule
    \end{tabular}
    
\end{table}

In the previous experiments, the data set was filtered, converted to wavelet transform, and later to 3-D images called scalograms. These scalograms were first used to fine-tune and then train, a pre-trained AlexNet and GoogLeNet. The state-of-the art validation accuracy obtained for classification with this data set is 98.44\%. This accuracy was obtained after applying extensive pre-processing to the data set. Our current model outperforms the state-of-the-art validation accuracy and achieves a 99.21\% accuracy with no pre-processing and only fine tuning the ensemble model.  


\subsection{PTB Diagnostics Data Set}
%https://iopscience.iop.org/article/10.1088/1742-6596/2115/1/012042/pdf
After working with the ECG for falls and daily activities, the model had to be tested on a standardized data set that is publicly available. In the second set of experiments, a publicly available data set called the PTB diagnostic was used, which is freely available but is used as a standard for ECG classification tasks.

The original PTB data set consists of 549 records from 290 subjects which were aged 17 to 87 years, with a mean age of 57.2. A total of 209 subjects were males with a mean age of 55.5 and 81 females with a mean age of 61.6 (for 1 female and 14 male subjects; age was not recorded). Each record has 15 measured signals: the conventional 12 leads (i, ii, iii, avr, avl, avf, v1, v2, v3, v4, v5 and v6) together with the 3 Frank lead ECGs (vx, vy and vz). The data from lead II were used to train the model which outperforms the databases which even use all 12 lead data \cite{ptb}. ECG beats were extracted using the method described in \cite{8419425}. The data set used was divided into two classes: normal and abnormal (myocardial infarction).
In the previous prominent study \cite{10.1007/978-3-030-64610-3_40}, all 12 leads were separately evaluated to determine which leads contributed the most to the classification. We used lead II of the data set to differentiate between healthy controls and that with myocardial infarction. 
Since only one lead of ECG was used in the previous two experimental phases, we used another publicly available data set and used all 12 of its leads to reaffirm the usefulness of the ensemble model for both uni-variate and multivariate data sets.


\subsection{PTB XL Diagnostics}
PTB-XL is one of the largest freely accessible ECG data sets available. It was collected over a span of seven years between 1989-1996. It was made publicly available in 2020 in a structured database by Physikalisch-Technische Bundesanstalt (PTB). The data set consists of a total of 21837 records of 12-lead ECG each comprising of 10 s. It is a gender-balanced data set with 52\% male and 48\% female records and an age range of 0-95 years. The data set consisted of various diagnoses and a large number of healthy controls as well \cite{9190034}. 
PTB XL has a standardized set of pre-processing instructions for the data set. Because different labels are heavily imbalanced and imbalanced classes can introduce bias in the trained model, it is important to divide the data set in a way that each of the classes is represented equally in each subset. Stratified sampling was used to divide it into training-validation-testing data sets. The data set has multiple classification categories as shown in Fig. \ref{fig:CD-ptbxl}. The goal is to classify MI from other heart conditions, and models were trained for diagnostic superclass and myocardial infarction detection using Algorithm \ref{alg:algorithm1}.  
%%%%%
%width=0.5\textwidth,
\begin{figure}[!ht]
\includegraphics[scale=0.35]{Definitions/ptb-xl.jpeg}
\caption{Class Distribution for PTB-XL Data Set}
\label{fig:CD-ptbxl}
\end{figure} 


\section{Results}
Several methods to evaluate a DL classifier exist in the literature. We evaluated our classifiers using the accuracy, area under the curve (AUC), confusion matrix, sensitivity, and specificity. The details of the results obtained by applying each of the algorithms and the respective data set is explained in this section. 
%%%%%%
In the sequel, we present the results acquired for each data set and also compare our results to the other state-of-the-art work. An overview of the section is presented in Table \ref{tbl:overview}.

\subsection{ECG HAR Data Set}\label{sec:ecgHarDataSet}
The data set was initially trained using a plain LSTM to compare the model performance with the previous experiments. The data were fed into the model without any pre-processing. The LSTM initially yielded an accuracy of 49.80\% which was increased to 54\% by fine-tuning the hyperparameters. In the previous experiments, extensive pre-processing was carried out to extract the related features and then those features were fed into the model. Although that approach yields excellent accuracy, it is not automated. LSTMs have been shown to have a sense of previous timestamps or history in the time series, but CNNs have a superior feature extraction capability. To test our hypothesis, a CNN was placed on top of the LSTM layer. The accuracy immediately improved to 93\%. After some fine tuning the hyperparameters and adjusting the number of CNN layers, the validation accuracy got better than the state-of-the-art results. A testing accuracy of 99.21\%--100\% was achieved and a validation accuracy of 99.21\% was achieved.
For the first data set, the results were almost perfect with a validation accuracy of 99.21\% and a testing accuracy of 99.21\%--100\%. The previous work achieved similar accuracy but with transfer learning and pre-processing the signals by converting them into wavelet transforms and then into scalograms. This model achieves similar accuracy even by avoiding all those steps.
The following Table~\ref{tbl:conf} depicts the confusion matrix for the testing data set showing an almost perfect accuracy of 99.22\%.

\begin{table}[!ht]
	\caption{Confusion Matrix for Fall Detection ECG Data Set using CNN-LSTM (Algorithm~\ref{alg:algorithm1})}
	\label{tbl:conf}
	\tiny
	\centering
	\scriptsize
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{cr|ccc}
		\multicolumn{2}{c}{}
		&   \multicolumn{3}{c}{Actual} \\
		&        
		&\rotatebox{90}{ DA} 
		&\rotatebox{90}{ Fall} 
		&\rotatebox{90}{ Rest} 
	
	 \\	
		\cline{2-5}
		\multirow{3}{*}{\rotatebox[origin=c]{90}{Predicted}}
		%&DA    & 30    &0     &0  	\\ 
		%&Fall  & 0     &53     &0  	 \\ 
		%&Rest  & 0     &0  	& 45	  \\ 
	    &DA    & 30    &0     &0  	\\ 
		&Fall  & 1     &52     &0  	 \\ 
		&Rest  & 0     &0  	& 45	  \\ 
		
		%\cline{2-6}
	\end{tabular}
% % Original data from :http://10.18.2.21:8888/notebooks/Implementation1_CNN_LSTM_original.ipynb
\end{table}

Fall detection using ECG signals was also performed by applying Algorithm~\ref{alg:algorithm2} to the HAR data set. Each sequence in the data set consists of 4000 time stamps. The initial tensor size was [1273, 1, 4000], which is in the format [total Sequences, number of features, sequence length]. Each of the ECG sequences was divided into 100 chunks of 40 time stamps each, and then the wavelet transform was calculated for each chunk resulting in a final dimension of [1273, 108, 40]. The model was trained in 403.39 s. This result was again achieved without any manual feature extraction or transfer learning model. 
The following Table~\ref{tbl:confatt} depicts the confusion matrix for the testing data set showing also the accuracy of 95.31\% %97.66\%.
%\begin{figure}[H]
%\centerline{\includegraphics[width=18.5pc]{Definitions/cm-100.png}}
%\includegraphics[width=10.5 cm]{Definitions/cm-100.png}
%\caption{Confusion Matrix for Fall Detection ECG data set showing a Testing Accuracy of 100\% \label{fig4}}
%\end{figure}   
%%%%
\begin{table}[!ht]
    % Original data from http://10.18.2.21:8888/notebooks/Attention_HAR.ipynb
	\caption{Confusion Matrix for Fall Detection ECG Data Set using Attention (Algorithm~\ref{alg:algorithm2})}
	\label{tbl:confatt}
	\tiny
	\centering
	\scriptsize
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{cr|ccc}
		\multicolumn{2}{c}{}
		&   \multicolumn{3}{c}{Actual} \\
		&        
		&\rotatebox{90}{ DA} 
		&\rotatebox{90}{ Fall} 
		&\rotatebox{90}{ Rest} 
	
	 \\	
		\cline{2-5}
		\multirow{3}{*}{\rotatebox[origin=c]{90}{Predicted}}
		&DA    &29  &1   &0 \\ 
		&Fall  &2   &49 &2  \\ 
		&Rest  &0   &0  &44 \\ 
		%\cline{2-6}
	\end{tabular}
\end{table}
\subsection{PTB Diagnostics} 

Algorithm~\ref{alg:algorithm1}, i.e.,\ CNN-LSTM was used to model the PTB diagnostic to differentiate normal from abnormal heartbeats. Previous studies have emphasized feature extraction before feeding into the neural network, or transfer learning where the model is initially trained with an existing data set and later on trained with the same learned weights on the desired data set such as in \cite{9630333}. In the current benchmark for MI classification using PTB diagnostic, ConvNetQuake neural network model was adapted to achieve an accuracy of 99.44\%. Similarly, heavy pre-processing, such as wavelet transformation \cite{ACHARYA2017190}, data balancing \cite{latest}, and transfer learning \cite{8419425}, are used in the literature to achieve higher accuracy for ECG signal classification. In our study, no pre-processing of the individual readings was applied, and the model achieving 99.66\% accuracy, exceeded the state-of-the-art accuracy for normal versus abnormal classification, which was previously 99.43\%. 

Algorithm~\ref{alg:algorithm2}, i.e.,\ the attention /transformer model was also used to model the PTB diagnostic to differentiate between normal and abnormal heartbeats. This yielded an accuracy of 99.73\%, a precision of 99.73\%, a sensitivity of 99.2\%, and a specificity of 99.91\%.

The confusion matrices of both algorithms are depicted in Table~\ref{tbl:ConfusionMatrixPTB} below. %and \ref{tbl:ConfusionMatrixPTBPercentage}

\begin{table}[!ht]
	\caption{Confusion Matrices for PTB Data Set}
	\label{tbl:ConfusionMatrixPTB}
\centering
\scriptsize
{%
	\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{cr|r r | r r}
		\multicolumn{2}{c}{}
		&   \multicolumn{4}{c}{Predicted}\\
		\multicolumn{2}{c|}{}
		&   \multicolumn{2}{c|}{Algorithm~\ref{alg:algorithm1}} &   \multicolumn{2}{c}{Algorithm~\ref{alg:algorithm2}}\\
		\cline{3-6}
		&	&\multicolumn{1}{c}{\rotatebox{90}{NORMAL}} &\multicolumn{1}{c|}{\rotatebox{90}{ABNORMAL }}&\multicolumn{1}{c}{\rotatebox{90}{NORMAL}} &\multicolumn{1}{c}{\rotatebox{90}{ABNORMAL }}\\
		\cline{2-6}
		\multirow{2}{*}{\rotatebox[origin=c]{90}{Actual}}
		& NORMAL 	&371	&1		&372	&1	\\	
		& ABNORMAL 	&2	    &1081	&3		&1080\\ 
	\end{tabular}
}
%Original data from http://10.18.2.21:8888/notebooks/ptb_cnn_lstm.ipynb
\end{table}

%%%CM with percentages
%\begin{table}[!ht]
%	\caption{Confusion Matrix for PTB data set using CNN-LSTM (Algorithm~\ref{alg:algorithm1}) Percentage}
%	\label{tbl:ConfusionMatrixPTBCNNLSTMPercentage}
%\centering
%\scriptsize

%{%
%	\renewcommand{\arraystretch}{1.5}
%	\begin{tabular}{cr|r r}
%		\multicolumn{2}{c|}{}
%		&   \multicolumn{2}{c}{Predicted}\\
%		&	&\multicolumn{1}{c}{\rotatebox{90}{NORMAL}} &\multicolumn{1}{c}{\rotatebox{90}{ ABNORMAL}}\\
%		\cline{2-4}
%		\multirow{2}{*}{\rotatebox[origin=c]{90}{Actual}}
%		& NORMAL 	&99.73	&0.27	\\	
%		& ABNORMAL 	&0.28	&99.72\\ 
%	\end{tabular}
%}
%\end{table}
%%%%%%%

In comparison to CNN-LSTM, i.e.,\ Algorithm~\ref{alg:algorithm1}, the attention model with wavelet embedding has been shown to be more efficient as it uses fewer parameters and less training time as compared to the CNN-LSTM model as shown in Table~\ref{tbl:paramvssota}. However, the time and number of parameters for Algorithm~\ref{alg:algorithm2} might increase eventually with the increase in the number of attention heads and encoder layers.
\begin{table*}[!ht]
\centering
\caption{Parameter Comparison between State of the Art and Our Work}
\label{tbl:paramvssota}
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
\thead{Work} & \thead{Total\\Parameters} & Learning Rate  & Time to Train         &\makecell{Training \\Hardware}& Batch Size & Epochs & Optimizer                                \\ \hline
 Liu et al.\cite{liu}  & NA & 0.001 - 0.000001   & 3557.26 s   & 2 NVIDIA Titan
Xp GPUs         & 32         & 100    & NA                        \\ \hline
Feng et al.\cite{feng} & NA& 0.1 - 0.0001  & 1500s              &  Intel Core i5-4590@3.30GHz  & 32         & 100    & \makecell{Adam, rmsProp, \\SGD}                 \\ \hline
 Wang et al.\cite{WANG2021106006}    & NA &0.001         & NA  & 2 NVIDIA 2080Ti GPUs    & 12         & 10     & NA             \\ \hline
Rai et al. \cite{latest}  & NA & 0.001         & 1263 s - 2285 s & i5 core, NVIDIA graphics card & 128        & 100    & Adam                      \\ \hline
\begin{tabular}[c]{@{}l@{}}Our work (HAR): Alg. 2\end{tabular}        &   \textbf{461,583}          &  0.00002                      &   \textbf{403.39}        & NVIDIA A100-PCIE-40GB & 20     &       500            &   Adam       \\ \hline

\begin{tabular}[c]{@{}l@{}}Our work (HAR): Alg. 1 \end{tabular}       & 2,471,503            &          0.001              &  80.56s      & NVIDIA A100-PCIE-40GB   &   64     &       100            &   Adam               \\ \hline

\begin{tabular}[c]{@{}l@{}}Our work (PTB): Alg. 2\end{tabular}       & \textbf{61762}      &    0.001                    &    \textbf{823.54s}       &NVIDIA A100-PCIE-40GB &  256     &    1000               &  Adam          \\ \hline

\begin{tabular}[c]{@{}l@{}}Our work (PTB): Alg. 1 \end{tabular}       &  210,025           &     0.001                   &      1923.87s   &NVIDIA A100-PCIE-40GB   &    64    &    1000               &   Adam             \\ \hline
\end{tabular}
\end{table*}
%\begin{table}[!ht]
%\centering
%\caption{Comparison between Attention model with wavelet embedding and CNN-LSTM hyper parameters and performance
%\label{tbl:attvscnnlstm}}
%\begin{tabular}{ll|l|l|l|l|}
%\cline{3-6}
%\multicolumn{2}{l|}{}                                                   & {\rotatebox{90}{Total Parameters}} & {\rotatebox{90}{Training Time}} & {\rotatebox{90} {Learning Rate}} & {\rotatebox{90} {Epochs}} \\ \hline
%\multicolumn{1}{|l|}{\multirow{2}{*}{HAR}}            & Attention Model &  \textbf{ 461,583}               &   \textbf{403.39 s}            &     0.00002         & 500        \\ \cline{2-6} 
%\multicolumn{1}{|l|}{}                                & CNN-LSTM        &      2,471,503            &       80.56 s          &     0.001       & 100        \\ \hline
%\multicolumn{1}{|l|}{\multirow{2}{*}{PTB}} & Attention Model &  \textbf{61762}              &   \textbf{823.54s}            &       0.001        &     1000   \\ \cline{2-6} 
%\multicolumn{1}{|l|}{}                                & CNN-LSTM        &         210,025         &   1923.87 s            &   0.001            & 1000       \\ \hline
%\end{tabular}
%\end{table}
A comparison between the reference parameters used across the state-of-the-art similar work and our work is shown in Table \ref{tbl:paramvssota}. However, it must be noted that Table \ref{tbl:paramvssota} is not complete because not all parameters can be found for all related work and NA in the table refers to not available.



Multiple metrics were used to evaluate the model performance. The terms $tp$, $fp$, $tn$, and $fn$ refer to the true positives, false positives, true negatives, and false negatives respectively. In medical terminology, true positive would refer to the medical condition being diagnosed, so $tp$ in our context refers to the diagnosis of MI. The performance metrics were calculated using the following formulas:
\begin{align*} 
%paper to be referred: A systematic analysis of performance measures for classification tasks
Accuracy    &=(tp + tn)/(tp + fp + fn + tn)   \\
Precision   &=tp/(tp + fp)                   \\
Sensitivity &=tp/(tp + fn)               \\
Specificity &=tn/(tn + fp)    
\end{align*}

 
The results for our leading models are summarized in Table~\ref{tbl:kpis}.
\begin{table}[!ht]
\caption{Metrics for Leading CNN-LSTM and Attention}
\label{tbl:kpis}
\centering
\scriptsize
{%
	\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{cr|r r}
		\multicolumn{2}{c|}{}
		&   \multicolumn{2}{c}{Predicted}\\
		&	&\multicolumn{1}{c}{\rotatebox{90}{CNN-LSTM}} &\multicolumn{1}{c}{\rotatebox{90}{ ATTENTION}}\\
		\cline{2-4}
		\multirow{2}{*}{\rotatebox[origin=c]{90}{Actual}}
		& Accuracy 	    &99.79	    &	99.73\\	
		& Precision 	&99.91	    &	99.91\\	
		& Sensitivity 	&99.81	    &	99.72\\	
		& Specificity 	&99.73	    &	99.73\\	
	\end{tabular}
\medskip	
}
\end{table}

Fig.~\ref{fig:trainigValidationGraph} and Fig.~\ref{fig:trainingAndValidationLossAttentionModel} show examples of the training accuracy and losses for the PTB data set, respectively.
\begin{figure}[!ht]	
\caption{Training and Validation Graph over Epochs for the PTB Data Set for Algorithm~\ref{alg:algorithm1}}
\label{fig:trainigValidationGraph}
\centerline{\includegraphics[width=18.5pc]{Definitions/PTB_training.png}}
%\widefigure
%\includegraphics[width=15 cm]{Definitions/PTB_training.png}
\end{figure}


\begin{figure}[!ht] % from http://10.18.2.21:8888/notebooks/attenstion-ptb11.ipynb
\includegraphics[width=0.45\textwidth]{Images/TrainingValidationLossAttention}
\caption{Training and Validation Loss for the PTB Data Set for Algorithm~\ref{alg:algorithm2}}
\label{fig:trainingAndValidationLossAttentionModel}
\end{figure}    

\subsection{PTB XL Diagnostics}
Since PTB XL is a relatively new data set, many recent studies using this data set have adapted it for different classification tasks such as super diagnostic, sub-diagnostic, and form etc. In our study, five super diagnostic (SD) classes were classified. A validation accuracy of 75.70\% and a testing accuracy of 74.33\% were achieved. An AUC score of 0.8395 was obtained, see Table~\ref{tbl:perfIndicators}. 

%\lipsum[2-5]
\begin{table}[!ht]
\caption{Performance Indicators}
\label{tbl:perfIndicators}
\centering
 \begin{tabular}{|c c c c|} 
 \hline
 Classification classes & \rotatebox{90}{Val. Accuracy} & \rotatebox{90}{Testing Accuracy} &\rotatebox{90}{AUC score} \\ [0.5ex] 
 \hline\hline
 Super-diagnostic Classes  & 75.70\% & 74.33\% & 0.8395 \\ 
 %Sub diagnositic Classes  & -- & -- & -- \\
 MI vs. Normal Class & 90.94\% & 89.1\% & 0.87 \\
 MI vs. Super-diagnostic classes & 91.07\% & 90.2\% & 0.762 \\
  [1ex] 
 \hline
 \end{tabular}
\end{table}

\bigskip
 A direct comparison to the state-of-the-art is not very straightforward for PTB-XL mainly because it is a newer data set and many new studies that use it focus on different classification tasks. Although our results for this data set do not exceed the state-of-the-art accuracy, they are still comparable. Virginia et al.~\cite{S2021102779} and Martin et.al~\cite{MARTIN2021102179} achieved accuracies of 90.8\% and 77.12\%, respectively,  for MI classification respectively. Similarly, Śmigielet et al.~\cite{s21248174} achieved an accuracy of 78.0–75.2\% for five-class classification. 
 
 Our Algorithm~\ref{alg:algorithm1} applied for myocardial infarction detection using the PTB XL data set, yields a validation accuracy of 90.94\% when it is MI versus the normal class in super diagnostic, and 91.27\% when it is MI vs other four superclasses. Please note the AUC as a metric was calculated only for PTB-XL data set as it is widely used for comparison of this particular data set in the literature. 
The experiment with Algorithm~\ref{alg:algorithm2} on multi-lead data sets such as PTB XL is still in a preliminary stage and requires further investigation on how to merge the natural domain dimension of multi-lead with the dimensional embedding technique. However, similar results for another research project of ours yield promising results for the Algorithm~\ref{alg:algorithm2} with a multidimensional or multi-featured data set, see \cite{Schaefer}. Henceforth these experiments have not been mentioned and as work in progress will be published in a future contribution.


\subsection{Statistical Analysis}
To assess the statistical validity of the results, we computed a five-fold cross-validation for both algorithms and all data sets, see Table~\ref{tbl:fiveFoldValidation}. For PTB-XL data set the k-fold validation was done only for super-diagnostic classes.
 
\begin{table}[!ht]
\centering
\caption{Five Fold Cross-Validations}
\label{tbl:fiveFoldValidation}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{c|c|c|c|c|c|c|c}
					&					&\multicolumn{5}{c|}{Fold}&\\
Data	            &Alg.   &0      &1      &2      &3      &4      & Avg\\ \hline
\multirow{2}{*}{ECG HAR}	&1   	&97.26 &98.43 &98.43 &98.03 &98.82 &98.19 \\\cline{2-8}	%97.25490196078431	&98.4313725490196  	&98.4313725490196	&98.03149606299213	&98.81889763779527	&98.19360815192218 
					&2   	&94.90 &90.59 &91.37 &93.70 &93.31 &92.77 \\\hline	        %94.90196078431372 	&90.58823529411765 	&91.37254901960785 	&93.7007874015748 	&93.30708661417323 	&92.77412382275745 
\multirow{2}{*}{PTB}&1   	&99.00 &99.56 &99.28 &99.07 &99.31 &99.24 \\\cline{2-8}	    %99.00377877018207 	&99.55341806939197 	&99.27835051546393 	&99.0721649484536 	&99.3127147766323	&99.24408541602479
				   	&2	    &96.39 &97.11 &97.49 &96.25 &96.49 &96.75 \\\hline	        %96.39299209893507  &97.11439367914807  &97.4914089347079   &96.25429553264605  &96.49484536082474  &96.74958712125236 
%97.11439367914807 &97.4914089347079 &96.25429553264605 &96.49484536082474 &96.74958712125236 
PTB XL				&1	    &76.22  &75.42  &75.38  &74.00  &76.49  &75.50 \\		        %76.22119815668202 	&75.42242703533026	&75.3841425937308 	&74.00122925629994 	&76.49047326367547 	&75.50389406114371

\end{tabular}
\end{table}


As one can see, the results are consistent with the findings in sub section \ref{sec:ecgHarDataSet}, the difference in the average results from the reduced training in case of five fold cross validation. 


However, to assess the statistical meaningfulness, a more sophisticated approach is required. In a seminal paper \cite{Dietterich}, Dietterich analyzed five approximate statistical tests for determining whether one learning algorithm outperforms another on a particular learning task. It includes the well-known McNemar’s test for a single pass validation and also proposes a new 5x2cv test designed for algorithms where at least 10 validations can be carried out. In the paper, Dietterich shows that the null-hypothesis of the two algorithms to compare having the same performance, the off-diagonal elements of the confusion matrix should be the same, which can be checked statistically for significance using a $\chi^2$ test or a test for $t$ statistics.
	
Although Dietterich's paper has been very well received and is cited many thousand times, in the practice of machine learning--contrary to other disciplines like e.g.,\ the medical sciences--, statistical analysis of significance is still not common and is therefore usually not included in publications, unfortunately. This limits not only the interpretation of published results but also limits the ability to rigorously compare benchmarks. For instance, the tests proposed in \cite{Dietterich} assume the availability of the data set backing the confusion matrix. In particular, to apply any of the tests in order to compare two algorithms $A_1$ and $A_2$, one must determine the incorrectly classified samples from $A_1$ and check whether these are correctly classified by algorithm $A_2$ and vice versa in order to determine the statistical parameters needed for the test. Even if the data are publicly available, information on which sub samples are incorrectly classified is usually \emph{not} available from the publication. In our case, these data are clearly not available for any of the bench marking publications. Therefore, we could only compare our algorithms~\ref{alg:algorithm1} and \ref{alg:algorithm2} against each other, but \emph{not} against any of the bench marked algorithms. 
	
The implementation of the statistical analysis and the results are discussed in the next sub section. 

       %TODO  include results 
\subsubsection{McNemar's test}
The McNemar's test is a standard paired test used in the medical field for the verification of usability of the new drugs etc. However, it is not very commonly applied in the field of deep learning for model comparison. Because we used biomedical data in this study, McNemar's test was used to verify the statistical significance of the results obtained using the proposed algorithms.
To apply McNemar's test, our data set was partitioned into training and testing sets, called \emph{R} and \emph{T}, respectively. After training both models $A_1$ (Algorithm \ref{alg:algorithm1}) and $A_2$ (Algorithm \ref{alg:algorithm2}) on $t$, the classifiers were tested on each instance of \emph{R} and eventually the following statistics are collected:
\begin{itemize}
    \item $n_{00}$ : Number of classes misclassified by both classifiers $A_1$ and $A_2$.
    \item $n_{01}$ : Number of data instances misclassified by $A_1$ but not $A_2$.
    \item $n_{10}$ : Number of data instances misclassified by $A_2$ but not $A_1$. 
    \item $n_{11}$: Number of data instances misclassified by neither $A_1$ nor $A_2$.
\end{itemize}
Additionally, $n_{00}$+$n_{01}$+$n_{10}$+$n_{11}$ = \emph{n}, where \emph{n} is the total data instances in the test set T. The contingency table layout for McNemar's test is presented in Table \ref{tbl:mcnemar}. 

\begin{table}[ht]
    \caption{McNemar's Contingency Tables}
    \label{tab:temps}
    \begin{subtable}[t]{.3\linewidth}
        \centering
        \begin{tabular}{lllll}
            \cline{1-2}
            \multicolumn{1}{|l|}{$n_{00}$}  & \multicolumn{1}{l|}{$n_{10}$} & &  &  \\ \cline{1-2}
            \multicolumn{1}{|l|}{$n_{01}$}  & \multicolumn{1}{l|}{$n_{11}$} & &  \\ \cline{1-2}
                                            &                               &  &  &  \\
                                            &                               &  &  & 
        \end{tabular}
        \caption{Layout\hspace*{\fill}}
        \label{tbl:mcnemar}
    \end{subtable}%
    \hfil
    \begin{subtable}[t]{.3\linewidth}
        \centering
        \begin{tabular}{lllll}
            \cline{1-2}
            \multicolumn{1}{|l|}{6}   & \multicolumn{1}{l|}{31}   & &  &  \\ \cline{1-2}
            \multicolumn{1}{|l|}{1}     & \multicolumn{1}{l|}{217}    & &  \\ \cline{1-2}
                                        &                           &  &  &  \\
                                        &                           &  &  & 
        \end{tabular}
        \caption{ECG Data Set\hspace*{\fill}}
        \label{tbl:mcnemarECGfall}
     \end{subtable}%
     \hfil
    \begin{subtable}[t]{.3\linewidth}
        \centering
        \begin{tabular}{lllll}
            \cline{1-2}
                \multicolumn{1}{|l|}{1}  & \multicolumn{1}{l|}{11}   & &  &  \\ \cline{1-2}
                \multicolumn{1}{|l|}{4}     & \multicolumn{1}{l|}{1440}    & &  \\ \cline{1-2}
                                            &                           &  &  &  \\
                                            &                           &  &  & 
        \end{tabular}
        \caption{PTB Data Set\hspace*{\fill}}
        \label{tbl:mcnemarPTB}
    \end{subtable}%
\end{table}

The McNemar's test was performed for both PTB and ECG HAR data set. The null hypothesis (H$_0$) is that both algorithms have the same error rate, i.e., $n_{01}$ = $n_{10}$. The confidence interval for all tests was 95\%. The statistics obtained for the ECG HAR data set are presented in Table~\ref{tbl:mcnemarECGfall}.

For an alpha value of 0.05, the p-value is calculated to be numerically 0.000, which implies that our test is significant enough to reject the H$_0$ and we conclude that both models have different proportions of errors and are significantly different in this data set. 
The same test was repeated for the PTB data set and the obtained statistics are listed in Table~\ref{tbl:mcnemarPTB}.

The p-value obtained for this test was 0.118 which is greater than 0.05 hence, there was no significant evidence to reject H$_0$.

\subsubsection{The 5x2 cv \emph{t} test}
The 5x2 cv $t$ test is introduced in Dietterich \cite{Dietterich} and recommended therein: ``For algorithms that can be executed ten times, the 5x2 cv test is recommended as it is slightly more powerful and because it directly measures the variance due to the choice of training set''.  For this test, two-fold cross validation was performed for five repetitions. During every repetition, the data set was randomly partitioned into two equal-sized sets $S_1$ and $S_2$. Both algorithms were trained on each set and tested on the other set. This results in four error estimates: $P_{A_1}^{(1,2)}$ and $P_{A_2}^{(1,2)}$ with $A_1$ or $A_2$, resp.\ trained on $S_1$ and tested on $S_2$ and $P_{A_1}^{(2,1)}$ and $P_{A_2}^{(2,1)}$ with $A_1$ or $A_2$, resp.\ trained on $S_2$ and tested on $S_1$. Estimated differences are obtained by subtracting the corresponding error estimates $P^{(1,2)}$= \emph{P}$_{A_1}^{(1,2)}$ - $P_{A_2}^{(1,2)}$ and $P^{(2,1)}$= $P_{A_1}^{(2,1)}$ - $P_{A_2}^{(2,1)}$. From these differences, the estimated variance $\sigma^2$ is calculated as $\sigma^2 = (P^{(1,2)} - \bar{P})^2+ (P^{(2,1)}- \bar{P})^2$, where \emph{$\bar{P}$} = (\emph{P}$^{(1,2)}$ + \emph{P}$^{(2,1)}$) /2 . Let $\sigma_i^{2}$ be the variance calculated from the $i$-th replication. Then the 5x2cv $\bar{t}$ statistic is calculated as follows:
\begin{equation*}
\bar{t}= \frac{P_1^{(1,2)}}{\sqrt{\frac{1}{5} \sum_{i=1}^{5} \sigma_{i}^{2}}}
\end{equation*}

Under the H$_0$, $\bar{t}$ has approximately a $t$ distribution with five degrees of freedom. 
The calculated t statistic for PTB data set and ECG HAR data set is 3.002 and 3.286 respectively. Detailed tables for the five repetitions are presented in Appendix \ref{appendix:raw} in Table~\ref{tbl:appen1} and Table~\ref{tbl:appen2}. As both would have a corresponding p value of 0.030 and 0.0218 respectively, it clearly shows that both models are significantly different from each other with different error estimates. 
\subsubsection{Interpretation}
Taking the results from both the McNemar and the more powerful 5x2 cv $t$ test we can conclude that our algorithms differ significantly and that the obtained Key Performance Indicator (KPIs) are statistically meaningful for the standard confidence interval of 95\%.

\subsection{Summary}
As seen in Table~\ref{tbl:tbl3}, our model leads to almost all of the evaluation criteria for the classification of PTB data set.

%\section{Theoretical Explanation for the CNN-LSTM prediction- A proposal }
\begin{table*}[t]
    \centering%
    \caption{Our Result Compared with other similar Studies in Literature which used PTB Database (Built upon \cite{10.1007/978-3-030-64610-3_40})}
    \label{tbl:tbl3}
    \small
    \begin{tabular}{*{5}{p{.16\textwidth}}}
          \toprule
    \textbf{Work} &\textbf{Accuracy(\%)} &  \textbf{Sensitivity(\%)} &\textbf{Specificity(\%)} &\textbf{Precision(\%)}
      \\\midrule
    Acharya et al. \cite{ACHARYA2017190} & 93.5 & 93.7 & - & 92.8\\
      %\\\midrule
     Safdarian et al. \cite{safdarain} &94.7 & - & - & -\\
       %\\\midrule
     Kojuri et al. \cite{kojuri}&95.6 & 93.3 & - & 97.9 \\
     %\\ \midrule 
     Sun et al. \cite{sun} & - & 92.6 & - & 82.4\\
      Liu et al. \cite{Liu94}& 94.4 & - & - & -\\
      Sharma et al. \cite{Sharma2018InferiorMI}& 96 & 93 & - & 99\\
      Kachuee et al. \cite{8419425}& 95.9 & 95.1 & - & 95.2\\
      Remya et al. \cite{remya}& 93.61 & 93.22 & 94.28 & -\\
    Reasat et al. \cite{reasat}& 84.54 & 85.33 & 84.09 & -\\
     Zewdie et al. \cite{zewdie2014fully}& 98.3 & 98.7 & 96.4 & -\\
      Feng et al. \cite{feng}& 95.4 & 98.2 & 86.5 & -\\
      Strodthoff et al. & - & 93.3 & 89.7 & -\\
      Huang et al.& 96.96 & 99.89 & 92.51 & 95.35\\
      Liu et al. \cite{liu} & 98.59 & 99.53 & 94.50 & -\\
     Gupta et al.\cite{10.1007/978-3-030-64610-3_40} & 99.43 & 99.40 & 99.45 & 99.46\\
     Ours (CNN-LSTM)& \textbf{99.93} & \textbf{99.81} & 99.73 & \textbf{99.91}\\
     Ours (Attention) & \textbf{99.73} & 99.72 & \textbf{99.73} & \textbf{99.91}\\    
     %\\ \midrule
     \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}[!ht]
    \centering%
    \caption{Overview of the Experiments with Different Data Sets and the
Acquired Performances}
    \label{tbl:overview}
    \small
    \begin{tabular}{*{5}{p{.16\textwidth}}}
          \toprule
    \textbf{Classification task} &\textbf{Data set} &  \textbf{Achieved Accuracy} &\textbf{Algorithm} &\textbf{State-of-the-art accuracy}
      \\\midrule
     Fall detection & ECG HAR  & 99.21\% & Attention & 98.44\% \cite{2021}\\
      %\\\midrule
     Fall detection & ECG HAR  & 99.21\% & CNN-LSTM & 98.44\%\cite{2021}\\
     MI detection & PTB  & 99.73\% & Attention & 99.44\%\cite{10.1007/978-3-030-64610-3_40}  \\
     MI detection & PTB  & 99.93\% & CNN-LSTM & 99.44\%\cite{10.1007/978-3-030-64610-3_40} \\
       %\\\midrule
    SD Class & PTB XL & 75.70\% & CNN-LSTM & - \\
     %\\ \midrule 
     MI detection & PTB XL & 91.07\% & CNN-LSTM & -\\
      
      
     %\\ \midrule
     \bottomrule
    \end{tabular}
\end{table*}
%DONE\todo{compare and cosolidate metrics from table 9 and table 7}
\section{Discussion}
As mentioned earlier, state-of-the-art accuracies were achieved using the CNN-LSTM model for three data sets and the attention model for PTB data set. In similar previous studies, mostly one set of experiments is performed with a single database to prove the usability of the models. However, we worked on three data sets separately. The first data set was used to classify human activities including falls. The second one consists of extracted heartbeats for the classification of MI vs normal heartbeats. The third data set consists of a 12-lead ECG data set for multiple cardiovascular conditions. The success of our proposed algorithms on all three data sets generalizes their usefulness for ECG classifications over multiple tasks.

Hybrid models help to combine the features of the base models. This is often more powerful than very deep models with hundreds of layers because deeper models tend to over-fit for medium-sized data sets. An LSTM model keeps track of the past trends in the time series and can also help in the prediction of the next time stamps. In our study, the results of the CNN-LSTM model have shown to be always better than both of the models implemented individually. This was verified for the HAR data set by \cite{Pusch} and we compare the results from Table~\ref{tbl:tbl3} for PTB data set where multiple variations of CNN and LSTMs have been applied separately in the previous works.
The performance of the model on the HAR data set is observed to increase up to a certain level with the increase in a) the number of filters in the conv1d layer for CNN-LSTM and b) the number of dimensions in the dimensional embedding with the attention model. Since the data set is not very large, a final conclusion cannot be drawn at this stage but it merits further investigation. 
The attention algorithm clearly has a computational advantage over the CNN-LSTM algorithm as seen in Table~\ref{tbl:paramvssota}. It takes less time to converge and even has fewer parameters to train than the CNN-LSTM algorithm.
Our study had the following advantages:
\begin{itemize}
  \item A hybrid CNN-LSTM model and attention with a discrete wavelet transformation as an embedding are proposed.
  \item No or very little manual feature extraction is required for training the model.
  \item Three publicly available data sets were used separately for the training using the proposed models.
  \item State-of-the-art accuracy of 99.86\% and 99.44\% is achieved for the PTB data set and ECG for HAR classification respectively without any feature extraction or pre-processing.
  \item Multiple standard statistical analysis techniques were applied to the acquired results to statistically support our algorithms.

\end{itemize}
Hence, we addressed our research question and achieved results equivalent to many recent studies without any pre-processing or feature extraction. We have also shown to train the models in an efficient manner computationally.

As part of the future work, the authors would like to explore the difference between the two algorithms using explainable AI. Looking deeper into the gradients for each layer would shed light into the learning process.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

\section{CONCLUSION}

The models proposed and explained in this paper aim to better classify ECG time series for different conditions using minimum pre-processing steps. Publicly available data sets have made it possible to verify the robustness and usefulness of the proposed models by achieving state-of-the-art accuracy using multiple data sets. This would eventually help medical practitioners to identify multiple heart conditions automatically with minimum feature extraction. Specifically for the MI classification, because the results are close to 100\%, the model is ready to be deployed for medical evaluation. 


\appendices
\appendix 
\subsection{Data and Code Availability}
The data sets used are publicly available and present in the corresponding repositories:
\begin{itemize}
\item ECG HAR data set : \cite{ info12020063-20}
\item PTB DB data set : \cite{ptb}
\item PTB XL : \cite{ptbxl}
\end{itemize}

The code is available on GitHub at \url{https://github.com/buttfatimasajid/Towards-Automated-Feature-Extraction-For-Deep-Learning-Classification-of-Electrocardiogram-Signals}.

\subsection{5x2 cv t-test table}\label{appendix:raw}
The tables including full details of the two 5x2 cv $t$-tests, Table~\ref{tbl:appen1} and Table~\ref{tbl:appen2}, resp.
\begin{table*}[!ht]
\centering
\caption{5x2 cv Test Contingency Table for PTB Data Set}
\label{tbl:appen1}
\begin{tabular}{l|l|l|l|l|l|}
\cline{2-6}
                              & Rep 1                                            & Rep 2 & Rep 3 & Rep 4 & Rep 5 \\ \hline
\multicolumn{1}{|l|}{Model A} & \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.9915\\ \emph{P}$_A^{(2)}$ = 0.9922\end{tabular} &  \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.9923\\ \emph{P}$_A^{(2)}$ = 0.9904\end{tabular}   &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.9934\\ \emph{P}$_A^{(2)}$ = 0.9889\end{tabular}    &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.9934\\ \emph{P}$_A^{(2)}$=0.9927\end{tabular}    &  \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.9929\\ \emph{P}$_A^{(2)}$ = 0.9894\end{tabular}     \\ \hline
\multicolumn{1}{|l|}{Model B} & \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.9786\\ \emph{P}$_B^{(2)}$ = 0.9839 \end{tabular} &  \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.9839\\ \emph{P}$_B^{(2)}$= 0.9733 \end{tabular}     &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.9778\\ \emph{P}$_B^{(2)}$ = 0.9812\end{tabular}    &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.9799\\ \emph{P}$_B^{(2)}$ = 0.9805 \end{tabular}    &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.9759\\ \emph{P}$_B^{(2)}$ = 0.9789\end{tabular}    \\ \hline
\end{tabular}

\end{table*}


\begin{table*}[!ht]
\centering
\caption{5x2 cv Test Contingency Table for ECG Data Set}
\label{tbl:appen2}
\begin{tabular}{l|l|l|l|l|l|}
\cline{2-6}
                              & Rep 1                                            & Rep 2 & Rep 3 & Rep 4 & Rep 5 \\ \hline
\multicolumn{1}{|l|}{Model A} & \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.96860\\ \emph{P}$_A^{(2)}$ = 0.96698\end{tabular} &  \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.95918\\ \emph{P}$_A^{(2)}$ = 0.977987\end{tabular}   &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.97327\\ \emph{P}$_A^{(2)}$ = 0.96232\end{tabular}    &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.9545\\ \emph{P}$_A^{(2)}$=0.9733\end{tabular}    &  \begin{tabular}[c]{@{}l@{}}\emph{P}$_A^{(1)}$ = 0.96232\\ \emph{P}$_A^{(2)}$ = 0.9733\end{tabular}     \\ \hline
\multicolumn{1}{|l|}{Model B} & \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.86656\\ \emph{P}$_B^{(2)}$ = 0.8522 \end{tabular} &  \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.8477\\ \emph{P}$_B^{(2)}$= 0.8805 \end{tabular}     &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.8349\\ \emph{P}$_B^{(2)}$ = 0.85714\end{tabular}    &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.85714\\ \emph{P}$_B^{(2)}$ = 0.88522 \end{tabular}    &   \begin{tabular}[c]{@{}l@{}}\emph{P}$_B^{(1)}$ = 0.85714\\ \emph{P}$_B^{(2)}$ = 0.8349\end{tabular}    \\ \hline
\end{tabular}

\end{table*}
\section{ACKNOWLEDGMENT}

The authors thank Kylie Pusch who contributed some ideas in her bachelor thesis \cite{Pusch}. This work was supported in part by the PhD-research program of the Faculty of Computer Science and Engineering Fb2 of Frankfurt University of Applied Sciences. The research of DGU is supported in part by the Spanish Agencia Estatal de Investigaci\'on under grants PID2021-122154NB-I00 and TED2021-129455B-I00, and by a 2021 BBVA Foundation project for research in Mathematics. He also acknowledges support from the EU under the 2014-2020 ERDF Operational Programme and the Department of Economy, Knowledge, Business and University of the Regional Government of Andalusia (project FEDER-UCA18-108393).
%=====================================
% References, variant A: external bibliography
%=====================================




\begin{thebibliography}{1}

\bibitem{cdc}Centers for Disease Control and \& Prevention ,Underlying Cause of Death, 1999-2020 Request,  \url{https://wonder.cdc.gov/ucd-icd10.html}
\bibitem{fallcardio}Tan, M. \& Kenny, R. Cardiovascular Assessment of Falls in Older People. {\em Clinical Interventions In Aging}. \textbf{1} pp. 57-66 (2006,2)

\bibitem{karpagachelvi2010ecg}Karpagachelvi, S., Arthanari, M. \& Sivakumar, M. ECG Feature Extraction Techniques - A Survey Approach. (arXiv,2010), \url{https://arxiv.org/abs/1005.0957}
\bibitem{7164783} Jambukia, S., Dabhi, V. \& Prajapati, H. Classification of ECG signals using machine learning techniques: A survey. {\em 2015 International Conference On Advances In Computer Engineering And Applications}. pp. 714-721 (2015)
\bibitem{9123339}Ingale, M., Cordeiro, R., Thentu, S., Park, Y. \& Karimian, N. ECG Biometric Authentication: A Comparative Analysis. {\em IEEE Access}. \textbf{8} pp. 117853-117866 (2020)

\bibitem{cite-key}Wagner, P., Strodthoff, N., Bousseljot, R., Kreiseler, D., Lunze, F., Samek, W. \& Schaeffter, T. PTB-XL, a large publicly available electrocardiography dataset. {\em Scientific Data}. \textbf{7}, 154 (2020), \url{https://doi.org/10.1038/s41597-020-0495-6}
\bibitem{2021}Butt, F., La Blunda, L., Wagner, M., Schäfer, J., Medina-Bulo, I. \& Gómez-Ullate, D. Fall Detection from Electrocardiogram (ECG) Signals and Classification by Deep Transfer Learning. {\em Information}. \textbf{12}, 63 (2021,2), \url{http://dx.doi.org/10.3390/info12020063}
\bibitem{article2}Khorrami, H. \& Moavenian, M. A comparative study of DWT, CWT and DCT transformations in ECG arrhythmias classification. {\em Expert Syst. Appl.}. \textbf{37} pp. 5751-5757 (2010,8)

\bibitem{7019490}Sathyapriya, L., Murali, L. \& Manigandan, T. Analysis and detection R-peak detection using Modified Pan-Tompkins algorithm. {\em 2014 IEEE International Conference On Advanced Communications, Control And Computing Technologies}. pp. 483-487 (2014)

\bibitem{article}Dallali, A., Kachouri, A. \& Samet, M. A Classification of Cardiac Arrhythmia Using WT, HRV, and Fuzzy C-Means Clustering. {\em Signal Processing: An International Journal (SPJI)}. \textbf{Volume (5)} pp. 101-108 (2011,1)

\bibitem{EBRAHIMI2020100033}Ebrahimi, Z., Loni, M., Daneshtalab, M. \& Gharehbaghi, A. A review on deep learning methods for ECG arrhythmia classification. {\em Expert Systems With Applications: X}. \textbf{7} pp. 100033 (2020), \url{https://www.sciencedirect.com/science/article/pii/S2590188520300123}
\bibitem{NIPS2012_3eae62bb}Socher, R., Huval, B., Bath, B., Manning, C. \& Ng, A. Convolutional-Recursive Deep Learning for 3D Object Classification. {\em Advances In Neural Information Processing Systems}. \textbf{25} (2012), \url{https://proceedings.neurips.cc/paper/2012/file/ 3eae62bba9ddf64f69d49dc48e2dd214-Paper.pdf}

\bibitem{zheng}Zheng Y., Liu Q., Chen E., Ge Y., Zhao J.L. (2014) Time Series Classification Using Multi-Channels Deep Convolutional Neural Networks. In: Li F., Li G., Hwang S., Yao B., Zhang Z. (eds) Web-Age Information Management. WAIM 2014. Lecture Notes in Computer Science, vol 8485. {\em Springer}, Cham. \url{https://doi.org/10.1007/978-3-319-08010-9_33}


\bibitem{xia} K. Xia, J. Huang and H. Wang, "LSTM-CNN Architecture for Human Activity Recognition," in {\em IEEE Access}, vol. 8, pp. 56855-56866, 2020, doi: 10.1109/ACCESS.2020.2982225.

\bibitem{ordonez} Ordóñez, F.J.; Roggen, D. Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition. {\em Sensors} 2016, 16, 115. \url{https://doi.org/10.3390/s16010115}

\bibitem{YildirimEtAl}Yıldırım Ö, Pławiak P, Tan RS, Acharya UR. Arrhythmia detection using deep convolutional neural network with long duration ECG signals. Comput Biol Med. 2018 Nov 1;102:411-420. doi: 10.1016/j.compbiomed.2018.09.009. Epub 2018 Sep 15. PMID: 30245122.

\bibitem{HannunEtAl}Hannun, Awni Y., Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H. Tison, Codie Bourn, Mintu P. Turakhia and A. Ng. Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network. Nature Medicine 25 (2019): 65-69.

\bibitem{8419425}Kachuee, M., Fazeli, S. \& Sarrafzadeh, M. ECG Heartbeat Classification: A Deep Transferable Representation. {\em 2018 IEEE International Conference On Healthcare Informatics (ICHI)}. pp. 443-444 (2018)

\bibitem{2019}Strodthoff, N. \& Strodthoff, C. Detecting and interpreting myocardial infarction using fully convolutional neural networks. {\em Physiological Measurement}. \textbf{40}, 015001 (2019,1), \url{http://dx.doi.org/10.1088/1361-6579/aaf34d}

\bibitem{WANG2021106006} Wang, J., Qiao, X., Liu, C., Wang, X., Liu, Y., Yao, L. \& Zhang, H. Automated ECG classification using a non-local convolutional block attention module. {\em Computer Methods And Programs In Biomedicine}. \textbf{203} pp. 106006 (2021), \url{https://www.sciencedirect.com/science/article/pii/S016926072100081X}

\bibitem{e23010119}Wang, T., Lu, C., Sun, Y., Yang, M., Liu, C. \& Ou, C. Automatic ECG Classification Using Continuous Wavelet Transform and Convolutional Neural Network. {\em Entropy}. \textbf{23} (2021), \url{https://www.mdpi.com/1099-4300/23/1/119}

\bibitem{saadat}S. Saadatnejad, M. Oveisi and M. Hashemi, "LSTM-Based ECG Classification for Continuous Monitoring on Personal Wearable Devices," in {\em IEEE Journal of Biomedical and Health Informatics}, vol. 24, no. 2, pp. 515-523, Feb. 2020, doi: 10.1109/JBHI.2019.2911367.

\bibitem{GAO202082}Gao, Z., Wang, X., Sun, S., Wu, D., Bai, J., Yin, Y., Liu, X., Zhang, H. \& De Albuquerque, V. Learning physical properties in complex visual scenes: An intelligent machine for perceiving blood flow dynamics from static CT angiography imaging. {\em Neural Networks}. \textbf{123} pp. 82-93 (2020), https://www.sciencedirect.com/science/article/pii/S0893608019303764

\bibitem{MathewsEtAl}Mathews, SM; Kambhamettu, C; Barner, KE. A novel application of deep learning for single-lead ECG classification. Comput Biol Med. 2018 Aug 1;99:53-62. doi: 10.1016/j.compbiomed.2018.05.013. Epub 2018 Jun 4. PMID: 29886261.

\bibitem{LitjensEtAl}Litjens G, Ciompi F, Wolterink JM, de Vos BD, Leiner T, Teuwen J, Išgum I. State-of-the-Art Deep Learning in Cardiovascular Image Analysis. JACC Cardiovasc Imaging. 2019 Aug;12(8 Pt 1):1549-1565. doi: 10.1016/j.jcmg.2019.06.009. PMID: 31395244.

\bibitem{VaswaniEtAl}Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A., Kaiser, Ł. \& Polosukhin, I. Attention is All you Need. {\em Advances In Neural Information Processing Systems}. \textbf{30} (2017), \url{https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}

\bibitem{RamsauerEtAl}Ramsauer, H., Schäfl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., Gruber, L., Holzleitner, M., Pavlović, M., Sandve, G., Greiff, V., Kreil, D., Kopp, M., Klambauer, G., Brandstetter, J. \& Hochreiter, S. Hopfield Networks is All You Need.  (2021)

\bibitem{LaiEtAl}Lai, G., Chang, W., Yang, Y. \& Liu, H. Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks. {\em CoRR}. \textbf{abs/1703.07015} (2017), \url{http://arxiv.org/abs/1703.07015}

\bibitem{ShunYaoEtAl}Shih, S., Sun, F. \& Lee, H. Temporal pattern attention for multivariate time series forecasting.. {\em Mach. Learn.}. \textbf{108}, 1421-1441 (2019), \url{http://dblp.uni-trier.de/db/journals/ml/ml108.html#ShihSL19}


\bibitem{SongEtAl}Song, H., Rajan, D., Thiagarajan, J. \& Spanias, A. Attend and diagnose: Clinical time series analysis using attention models. {\em 32nd AAAI Conference On Artificial Intelligence, AAAI 2018}. pp. 4091-4098 (2018)

\bibitem{YanEtAl}Yan, G., Liang, S., Zhang, Y. \& Liu, F. Fusing Transformer Model with Temporal Features for ECG Heartbeat Classification. {\em 2019 IEEE International Conference On Bioinformatics And Biomedicine (BIBM)}. pp. 898-905 (2019)

\bibitem{WangEtAl}Wang, S., Li, B., Khabsa, M., Fang, H. \& Ma, H. Linformer: Self-Attention with Linear Complexity. (arXiv,2020), \url{https://arxiv.org/abs/2006.04768}

\bibitem{RabeStaats}Rabe, M. \& Staats, C. Self-attention Does Not Need $O(n^2)$ Memory.  (2021)

\bibitem{cite-key1}Khan, A., Sohail, A., Zahoora, U. \& Qureshi, A. A survey of the recent architectures of deep convolutional neural networks. {\em Artificial Intelligence Review}. \textbf{53}, 5455-5516 (2020), \url{https://doi.org/10.1007/s10462-020-09825-6}


\bibitem{8308186}Albawi, S., Mohammed, T. \& Al-Zawi, S. Understanding of a convolutional neural network. {\em 2017 International Conference On Engineering And Technology (ICET)}. pp. 1-6 (2017)

\bibitem{LSTM}S. Hochreiter and J. Schmidhuber. 1997. Long Short-Term Memory. Neural Comput. 9, 8 (November 15, 1997), 1735–1780.

\bibitem{Mathews}Mathews, S.M., Dictionary and deep learning algorithms with applications to remote health monitoring systems, PhD thesis, 2017, University of Delaware, http://udspace.udel.edu/handle/19716/21241


\bibitem{Daubechies}Daubechies, I. Ten Lectures on Wavelets. (Society for Industrial,1992)
\bibitem{MallatEtAl}Mallat, S. \& Zhong, S. Characterization of signals from multiscale edges. {\em IEEE Transactions On Pattern Analysis And Machine Intelligence}. \textbf{14}, 710-732 (1992)
\bibitem{Ryan}Ryan, Ø. Linear Algebra, Signal Processing, and Wavelets - A Unified Approach: Python Version.  (2019,1)

\bibitem{Adam}Kingma, D. \& Ba, J. Adam: A Method for Stochastic Optimization.  (2014), \url{http://arxiv.org/abs/1412.6980}, cite arxiv:1412.6980Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015
 DOI:\url{https://doi.org/10.1162/neco.1997.9.8.1735}

\bibitem{Strassen}Strassen, V Gaussian elimination is not optimal. Numerische Mathematik. 13 (4): 354–356. (Aug 1969) doi:10.1007/BF02165411. S2CID 121656251

\bibitem{JoshEtAl}Alman, J; Williams, V.\ V. A Refined Laser Method and Faster Matrix Multiplication, (2020), 32nd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2021), arXiv:2010.05846


\bibitem{9233318}Blunda, L., Gutiérrez-Madroñal, L., Wagner, M. \& Medina-Bulo, I. A Wearable Fall Detection System Based on Body Area Networks. {\em IEEE Access}. \textbf{8} pp. 193060-193074 (2020)

\bibitem{ysnc-gc65-20}Kher, R. Wearable Ambulatory Electrocardiogram (ECG) and EEG dataset. (IEEE Dataport,2020), \url{https://dx.doi.org/10.21227/ysnc-gc65}

\bibitem{ECGdb}Kim, Y., Shin, D., Park, M., Lee, S., Jeon, M., Yoon, D. \& Park, R. ECG-ViEW II, a freely accessible electrocardiogram database. {\em PloS One}. \textbf{12}, e0176222 (2017), \url{https://europepmc.org/articles/PMC5402933}


\bibitem{cui2016multiscale}Cui, Z., Chen, W. \& Chen, Y. Multi-Scale Convolutional Neural Networks for Time Series Classification.  {\em ArXiv}. \textbf{abs/1603.06995}(2016)

\bibitem{ptb}Bousseljot R, Kreiseler D, Schnabel, A. Nutzung der EKG-Signaldatenbank CARDIODAT der PTB über das Internet. Biomedizinische Technik, Band 40, Ergänzungsband 1 (1995) S 317 \url{https://doi.org/10.13026/C28C71}

\bibitem{10.1007/978-3-030-64610-3_40}Gupta, A., Huerta, E., Zhao, Z. \& Moussa, I. Deep Learning for Cardiologist-Level Myocardial Infarction Detection in Electrocardiograms. {\em 8th European Medical And Biological Engineering Conference}. pp. 341-355 (2021)

\bibitem{9190034}Strodthoff, N., Wagner, P., Schaeffter, T. \& Samek, W. Deep Learning for ECG Analysis: Benchmarks and Insights from PTB-XL. {\em IEEE Journal Of Biomedical And Health Informatics}. \textbf{25}, 1519-1528 (2021)


\bibitem{9630333}Yang, F., Wang, G., Luo, C. \& Ding, Z. Improving Automatic Detection of ECG Abnormality with Less Manual Annotations using Siamese Network. {\em 2021 43rd Annual International Conference Of The IEEE Engineering In Medicine Biology Society (EMBC)}. pp. 1120-1123 (2021)


\bibitem{ACHARYA2017190}Acharya, U., Fujita, H., Oh, S., Hagiwara, Y., Tan, J. \& Adam, M. Application of deep convolutional neural network for automated detection of myocardial infarction using ECG signals. {\em Information Sciences}. \textbf{415-416} pp. 190-198 (2017), \url{https://www.sciencedirect.com/science/article/pii/S0020025517308009}

\bibitem{latest}Rai, H. \& Chatterjee, K. Hybrid CNN-LSTM deep learning model and ensemble technique for automatic detection of myocardial infarction using big ECG data. {\em Applied Intelligence}. \textbf{52}, 5366-5384 (2022), \url{https://doi.org/10.1007/s10489-021-02696-6}


\bibitem{S2021102779}S., C. \& E., R. A Novel Deep Learning based Gated Recurrent Unit with Extreme Learning Machine for Electrocardiogram (ECG) Signal Recognition. {\em Biomedical Signal Processing And Control}. \textbf{68} pp. 102779 (2021), \url{https://www.sciencedirect.com/science/article/pii/S1746809421003761}

\bibitem{MARTIN2021102179}Martin, H., Morar, U., Izquierdo, W., Cabrerizo, M., Cabrera, A. \& Adjouadi, M. Real-time frequency-independent single-Lead and single-beat myocardial infarction detection. {\em Artificial Intelligence In Medicine}. \textbf{121} pp. 102179 (2021), \url{https://www.sciencedirect.com/science/article/pii/S093336572100172X}

\bibitem{s21248174}Śmigiel, S., Pałczyński, K. \& Ledziński, D. Deep Learning Techniques in the Classification of ECG Signals Using R-Peak Detection Based on the PTB-XL Dataset. {\em Sensors}. \textbf{21} (2021), \url{https://www.mdpi.com/1424-8220/21/24/8174}

\bibitem{Schaefer}Jörg Schäfer, Human Activity Recognition With CSI Data -- Attention Is All You Need, pre-print, Frankfurt University of Applied Sciences, 2022

\bibitem{liu}Liu, N., Wang, L., Chang, Q., Xing, Y. \& Zhou, X. A Simple and Effective Method for Detecting Myocardial Infarction Based on Deep Convolutional Neural Network. {\em Journal Of Medical Imaging And Health Informatics}. \textbf{8} pp. 1508-1512 (2018,9)

\bibitem{feng}Feng, K., Pi, X., Liu, H. \& Sun, K. Myocardial Infarction Classification Based on Convolutional Neural Network and Recurrent Neural Network. {\em Applied Sciences}. \textbf{9} pp. 1879 (2019,5)

\bibitem{Dietterich}Dietterich, T. Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms. {\em Neural Computation}. \textbf{10}, 1895-1923 (1998,10), https://doi.org/10.1162/089976698300017197

\bibitem{Pusch}Pusch, K. ECG Classification Using Different Machine Learning Models for Human Activity Recognition, Bachelor Thesis, Frankfurt University of Applied Sciences, 2021

\bibitem{safdarain} Safdarian, N. , Dabanloo, N. and Attarodi, G., A New Pattern Recognition Method for Detection and Localization of Myocardial Infarction Using T-Wave Integral and Total Integral as Extracted Features from One Cycle of ECG Signal.(2014) {\em Journal of Biomedical Science and Engineering} , 7, 818-824. doi: 10.4236/jbise.2014.710081

\bibitem{kojuri}Kojuri, J., Boostani, R., Dehghani, P., Nowroozipour, F. \& Saki, N. Prediction of acute myocardial infarction with artificial neural networks in patients with nondiagnostic electrocardiogram. {\em Journal Of Cardiovascular Disease Research}. \textbf{6} pp. 51-59 (2015,5)

\bibitem{sun}Sun, L., Lu, Y., Yang, K. \& Li, S. ECG Analysis Using Multiple Instance Learning for Myocardial Infarction Detection. {\em IEEE Transactions On Biomedical Engineering}. \textbf{59}, 3348-3356 (2012)

\bibitem{Liu94}Liu, B., Liu, J., Wang, G., Huang, K., Li, F., Zheng, Y., Luo, Y. \& Zhou, F. A novel electrocardiogram parameterization algorithm and its application in myocardial infarction detection. {\em Computers In Biology And Medicine}. \textbf{61} (2014,8)

%NOT refered
%\bibitem{article3}Korürek, M. \& Doğan, B. ECG beat classification using particle swarm optimization and radial basis function neural network. {\em Expert Systems With Applications}. \textbf{37} pp. 7563-7569 (2010,12)








%\bibitem{zhang}Zhang, P., Cheng, J. \& Zhao, Y. Classification of ECG Signals Based on LSTM and CNN. {\em Artificial Intelligence And Security}. pp. 278-289 (2020)




.



\bibitem{Sharma2018InferiorMI}Sharma, L. \& Sunkaria, R. Inferior myocardial infarction detection using stationary wavelet transform and machine learning approach. {\em Signal, Image And Video Processing}. \textbf{12} pp. 199-206 (2018)
\bibitem{remya}Remya, R., Indiradevi, K. \& Babu, K. Classification of Myocardial Infarction Using Multi Resolution Wavelet Analysis of ECG. {\em Procedia Technology}. \textbf{24} pp. 949-956 (2016,12)

\bibitem{reasat}Tahsin, R. \& Shahnaz, C. Detection of Inferior Myocardial Infarction using Shallow Convolutional Neural Networks.  (2017,12)

\bibitem{zewdie2014fully}Zewdie, G. \& Xiong, M. Fully Automated Myocardial Infarction Classification using Ordinary Differential Equations. \url{https://arxiv.org/abs/1410.6984} (2014)


%%%%%




%\bibitem{WangEtAl}Wang, S., Li, B., Khabsa, M., Fang, H. \& Ma, H. Linformer: Self-Attention with Linear Complexity.  (2020)






%NOT cited because not used anymore
%\bibitem{ecgbook} A. C. Guyton and J. E. Hall, {\em Textbook of medical physiology}, 11th edition London, England: W B Saunders, (2006).



\bibitem{info12020063-20}Butt, F., La Blunda, L., Wagner, M., Schäfer, J., Medina-Bulo, I. \& Oteiza, D. ECG data for deep transfer learning. (IEEE Dataport,2020), https://dx.doi.org/10.3390/info12020063

\bibitem{ptbxl}Wagner, P., Strodthoff, N., Bousseljot, R., Samek, W., and Schaeffter, T.,PTB-XL, a large publicly available electrocardiography dataset (version 1.0.0). PhysioNet, (2020),\url{https://doi.org/10.13026/qgmg-0d46}



\end{thebibliography}

%clears hyperref warning, see https://tex.stackexchange.com/questions/364010/hyperref-and-titlesec-conflict-and-warning
\phantomsection 
\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Images/Butt.jpeg}}]
{Fatima Sajid Butt} is a doctoral candidate for Engineering Informatics at the University of Cádiz, Spain and a research assistant at Frankfurt university of Applied sciences, Frankfurt, Germany. She received her Bachelors in Information Technology from University of the Punjab, Lahore, Pakistan and her Masters in High Integrity Systems (HIS) from Frankfurt University of Applied Sciences, Germany in 2010 and 2019 respectively. 
She is a part of the research group Industrial Data Sciences (INDAS) along with Jörg Schäfer, Matthias Wagner and Dirk Stegelmeyer at Frankfurt University of Applied Sciences, Germany. Her research interests includes time series analysis for classification and application of machine learning algorithms for industrial problems such as predictive maintenance. 
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Images/Wagner_Portrait.jpg}}]
{MATTHIAS WAGNER} received a Diploma and a Dr. rer.nat. in Physics from the Johannes Gutenberg - Universität Mainz (Germany). He was head of Measuring Technology Software Development at Hottinger Baldwin Messtechnik (HBM) in Darmstadt (Germany) from 1990 until 2002. In 2002, he was appointed as Professor of Computer Science at the Frankfurt University of Applied Sciences in Frankfurt am Main (Germany). Since 2005, he has been the Program Director of the international M.Sc. program “High Integrity Systems”. From 2017 to March 2020, he served as Vice-Dean for Research and International Relations of the FB2, Department of Computer Science and Engineering. Since 2010, he has been head of the Research Group Wireless Sensor Networks and Internet of Things (WSN \& IoT). His research interests cover safety critical computer systems, smart sensors and actuator networks, Software and Systems Engineering and Computational Science are supported by research stays at the UCASE Software Engineering Research Group of the Universidad de Cádiz (Spain) and the Dipartimento di Fisica e Astronomia of the Università degli Studi di Firenze (Italy). 
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Images/DSC_2004-09-26T14-30-01_mod4.jpg}}]{Jörg Schäfer} is a professor of Computer Science at Frankfurt University of Applied Sciences. He received his PhD degree from Bochum University (Germany) in Mathematical Physics in 1992. After spending more than 10 years working as a principal architect in IT consulting for large international companies he was  appointed as full professor of Computer Science at Frankfurt University of Applied Sciences in 2009. Since 2012 he served as the chairman of the computer science B.Sc.\ program. 
His  main research interest is in theoretical understanding of deep learning architectures and applying machine learning and probabilistic models in ubiquitous computing applications. He runs a research group on human activity recognition (HAR) and channel state information (CSI) and jointly with Matthias Wagner and Dirk Stegelmeyer the research group industrial data science (INDAS). He is collaborating with UCASE Software Engineering Research Group of the Universidad de Cádiz (Spain). 
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Images/david.png}}]{David G\'omez-Ullate} received his PhD in Physics from Universidad Complutense de Madrid in 2001. He is a Distinguished Researcher at University of Cádiz, where he founded and serves as Director of \href{http://datalab.uca.es/}{UCA Datalab}. He is Professor of Applied Mathematics on leave from Complutense University of Madrid, Adjunct Professor at IE Business School and Visiting Professor of Mathematics and Data Science at the University of Loughborough (United Kingdom). 
His research interests span a wide range of topics, ranging from mathematical physics and approximation theory to applied machine learning and data science. His major contribution is the theory of exceptional orthogonal polynomials, which has earned him international recognition expressed as plenary talks in the main conferences of the field, and invited seminars at Cambridge, Harvard, Edinburgh, Stockholm, Copenhagen and Rome, among others. For the past 10 years he has specialized in knowledge transfer of mathematics to industry. He is currently President of the Knowledge Transfer Commission of the Royal Spanish Mathematical Society, and a member of its Governing Board. In 2016 he received a Leonardo Scholarship from the BBVA Foundation for a project on credit card fraud detection.  He has coordinated 8 knowledge transfer contracts with industry in the financial, fisheries, biomedical, legaltech and aeronautical sectors. He is co-founder and scientific advisor of the technological startup \href{https://komorebi.ai/}{Komorebi AI}.
\end{IEEEbiography}
\EOD
%\pagebreak
\end{document}
