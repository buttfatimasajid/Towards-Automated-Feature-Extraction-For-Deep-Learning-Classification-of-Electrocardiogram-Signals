{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e998011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(126, 4000) (127, 4000) (1017, 4000) [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "BATCH_SIZE =20\n",
    "X_train= pd.read_csv(\"X_train.csv\",header=0)\n",
    "X_test = pd.read_csv(\"X_test.csv\",header=0)\n",
    "X_val = pd.read_csv(\"X_val.csv\",header=0)\n",
    "y_train= pd.read_csv(\"y_train.csv\",header=0)\n",
    "y_test = pd.read_csv(\"y_test.csv\",header=0)\n",
    "y_val = pd.read_csv(\"y_val.csv\",header=0)\n",
    "X_train=X_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "X_val=X_val.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "y_val=y_val.to_numpy()\n",
    "print(type(X_train))\n",
    "print(X_val.shape,X_test.shape,X_train.shape,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4897068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dwt(X):  \n",
    "    res = []\n",
    "    for x in X:   \n",
    "        #print(x.shape)\n",
    "        coeffs = pywt.wavedec(x, 'db5', level=1) \n",
    "        #x = smooth(x, level=4)\n",
    "        #coeffs = pywt.wavedec(x, 'sym6', level=4) \n",
    "        #cA4, cD4, cD3, cD2, cD1 = coeffs\n",
    "        cA1, cD1 = coeffs\n",
    "        #print(cD1.shape)\n",
    "        #interleaved = [val for pair in zip(cA4, cD4) for val in pair]\n",
    "        #res.append(torch.from_numpy(interleaved)))\n",
    "        res.append(torch.from_numpy(np.concatenate([cA1, cD1], axis=2)))\n",
    "        #print(len(cA4))\n",
    "        #print(len(cD3))\n",
    "    tensors = torch.stack(res)\n",
    "    #print(tensors.shape)\n",
    "    return(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "80895e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOO - must not hardcode\n",
    "# takes input tensor and splits it into (20 hardcoded) chunks of smaller window size\n",
    "# each is transformed using discrete wavelet tramsformation - we only keep cA component \n",
    "# TODO we could inlucde more components (also high frequency cDn's) and should use flexible levels\n",
    "# This way, we create a dim embedding using the dimension n = number of cA's. \n",
    "#\n",
    "# With the current hardcoded setup we reduce time steps fomr 187 to 19 but increase features from 1 to 13, \n",
    "# henceforth we map (14552, 1, 187) to (14552, 13, 19). This creates a dim_embedding of 13 which is high enough \n",
    "# to preserve information and enable grad descent for attention / transformer using also res connections, compare\n",
    "# line x = x + self.transformer_encoder(x) (instead of x = self.transformer_encoder(x)) in transformer \n",
    "# forward method (TODO check whether still necessary)\n",
    "# TODO check whether posioitonal encoding beneficial\n",
    "#\n",
    "\n",
    "def dim_embedding(x):\n",
    "    print(\"x.shape\")\n",
    "    print(x.shape)\n",
    "\n",
    "    #chunks = torch.split(x, 400, dim=2)\n",
    "    chunks = torch.split(x, 100, dim=2)\n",
    "    print(len(chunks))\n",
    "\n",
    "    # transform using dwt\n",
    "    # skip last chunk because it is shorter\n",
    "\n",
    "    chunks_dwt = torch.flatten(compute_dwt(chunks[0:40]), start_dim=2, end_dim=3)\n",
    "\n",
    "    # reshape tensor to match batch x features x seq_length\n",
    "    print(chunks_dwt.shape)\n",
    "    chunks_dwt = chunks_dwt.permute(1, 2, 0)\n",
    "    print(chunks_dwt.shape)    \n",
    "    return chunks_dwt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7587d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOTHER TEST\n",
      "\n",
      "[ 0.13010374  0.12903515  0.12843709 ... -0.01056404 -0.00841191\n",
      " -0.00676641]\n",
      "[ 0.05717091  0.05290546  0.04705899 ... -0.04251642 -0.04288942\n",
      " -0.04598525]\n",
      "[ 0.0618437   0.06669518  0.07160966 ... -0.01078869 -0.0126396\n",
      " -0.01421023]\n",
      "[ 0.08172338  0.0743877   0.0669621  ...  0.00173056 -0.00028088\n",
      " -0.00578568]\n",
      "[ 0.03089662  0.03000439  0.03157153 ...  0.00246478 -0.00065092\n",
      " -0.00380063]\n",
      "[0.0650791  0.09711858 0.12480386 ... 0.00618    0.00642284 0.01152746]\n",
      "[-0.04670826 -0.13294739 -0.20020828 ... -0.17111204 -0.24937462\n",
      " -0.33902387]\n",
      "[ 0.05129943  0.05040793  0.04812815 ...  0.01642095  0.00824113\n",
      " -0.011762  ]\n",
      "[-0.03769445 -0.03393589 -0.03027924 ... -0.01847831 -0.02415525\n",
      " -0.02966073]\n",
      "[ 0.04885025  0.02112133 -0.00603097 ... -0.05368848 -0.04783625\n",
      " -0.04061886]\n",
      "[-0.03617706 -0.03573326 -0.03659578 ... -0.00535033 -0.00981523\n",
      " -0.01386185]\n",
      "[ 0.01044384  0.01590507  0.0209979  ... -0.1064899  -0.0918571\n",
      " -0.07144494]\n",
      "[-0.01908593 -0.02136752 -0.02276394 ...  0.01305702  0.00551933\n",
      " -0.00110691]\n",
      "[-0.01406223 -0.0140335  -0.01321407 ... -0.02485553 -0.02670508\n",
      " -0.02765447]\n",
      "[-0.01472327 -0.013301   -0.01184368 ... -0.00180061 -0.00524303\n",
      " -0.0081493 ]\n",
      "[-0.01637007 -0.01674995 -0.01709375 ... -0.02470374 -0.02752973\n",
      " -0.03046557]\n",
      "[-0.01154884 -0.0133525  -0.01490465 ... -0.00886179 -0.00556786\n",
      " -0.0019248 ]\n",
      "[-0.00470598 -0.0044654  -0.00422459 ...  0.01865478  0.00611231\n",
      " -0.00516226]\n",
      "[0.00487874 0.0063972  0.00716564 ... 0.01713838 0.0191927  0.02039391]\n",
      "[0.23319081 0.17710577 0.09593345 ... 0.06329376 0.06533263 0.06009155]\n",
      "[-0.51484119 -0.47423043 -0.42326466 ...  0.0411614   0.04538867\n",
      "  0.05030528]\n",
      "[-0.02213479 -0.02474943 -0.02992774 ...  0.00193006  0.00379234\n",
      "  0.00449853]\n",
      "[ 0.12674257  0.14178201  0.13657183 ... -0.01643893 -0.0122537\n",
      " -0.00649994]\n",
      "[-0.05771182 -0.02655088  0.0048727  ...  0.05437487  0.05643118\n",
      "  0.05879582]\n",
      "[0.02917481 0.02697831 0.02386677 ... 0.00469604 0.00553295 0.00613068]\n",
      "[ 0.01606392  0.01225597  0.00869919 ... -0.08440436 -0.08546348\n",
      " -0.08629775]\n",
      "[-0.02645016 -0.02546702 -0.02480977 ... -0.06291545 -0.0589358\n",
      " -0.06076038]\n",
      "[-0.00686746 -0.00829941 -0.00958258 ... -0.00208275 -0.00177884\n",
      " -0.00136464]\n",
      "[-0.01842319 -0.00830373  0.00135528 ...  0.11576062  0.05369197\n",
      " -0.00984203]\n",
      "[-0.02779062 -0.01822763 -0.00996031 ... -0.0173337  -0.02057767\n",
      " -0.02506376]\n",
      "[-0.04670318 -0.05678879 -0.06384536 ... -0.04532419 -0.05001402\n",
      " -0.05298133]\n",
      "[0.00842408 0.00559857 0.00380333 ... 0.00938141 0.00951772 0.00945248]\n",
      "[-0.01356231 -0.01379602 -0.013042   ... -0.0119354  -0.00962961\n",
      " -0.00735407]\n",
      "[ 0.00446973  0.005256    0.00531801 ... -0.02599997 -0.02983817\n",
      " -0.03233413]\n",
      "[-0.04580277 -0.04243694 -0.03910885 ... -0.04882501 -0.03947745\n",
      " -0.03116138]\n",
      "[ 0.02125842  0.023744    0.02692708 ... -0.01916    -0.01969012\n",
      " -0.01994538]\n",
      "[-0.00050982  0.00165998  0.00428341 ...  0.12818797  0.13026939\n",
      "  0.13091756]\n",
      "[ 2.53358819e-03  1.29785762e-03 -7.39947193e-05 ... -5.40711605e-04\n",
      " -5.81197280e-03 -3.16909082e-03]\n",
      "[-0.00701556 -0.00731874 -0.00651979 ...  0.00561879  0.00337352\n",
      "  0.00142675]\n",
      "[-0.04068629 -0.03621984 -0.0397565  ...  0.00488848  0.00442154\n",
      "  0.00564699]\n",
      "[-0.033652   -0.03173823 -0.03182459 ...  0.0945082   0.09890255\n",
      "  0.09987613]\n",
      "[-0.01409717 -0.01568802 -0.01822282 ... -0.01213742 -0.0123111\n",
      " -0.01280779]\n",
      "[-0.0025311   0.00052472  0.0039556  ... -0.0148667  -0.01570713\n",
      " -0.01647416]\n",
      "[ 0.09939007  0.14086426  0.17584334 ...  0.00432019  0.00106523\n",
      " -0.00278367]\n",
      "[0.40351876 0.32759337 0.32151594 ... 0.04174748 0.0411187  0.03498382]\n",
      "[-0.02395306 -0.01957835 -0.01654558 ... -0.0025251  -0.00194079\n",
      " -0.00071128]\n",
      "[ 0.12349012  0.12120421  0.12172016 ... -0.03576604 -0.03937397\n",
      " -0.03713546]\n",
      "[0.02084715 0.02383406 0.02671897 ... 0.18550453 0.19482047 0.19169424]\n",
      "[-0.06966492 -0.06487264 -0.05993632 ... -0.11124031 -0.10493321\n",
      " -0.08598544]\n",
      "[-0.83778599 -0.95750688 -0.99860939 ... -0.02014931 -0.01768874\n",
      " -0.01469505]\n",
      "[-0.04030705 -0.04985149 -0.05630759 ... -0.00963544 -0.01368265\n",
      " -0.01670722]\n",
      "[ 0.02450951  0.02298318  0.02134064 ... -0.00401017 -0.00475011\n",
      " -0.00522113]\n",
      "[0.00757146 0.01079493 0.01391109 ... 0.02216939 0.02236991 0.02608945]\n",
      "[-0.04237447 -0.03915969 -0.03588447 ... -0.02069021 -0.01775173\n",
      " -0.01402546]\n",
      "[ 1.23876777e-01  1.30846463e-01  1.35898626e-01 ...  1.57448042e-03\n",
      " -3.38766810e-05 -5.23046777e-05]\n",
      "[0.74608814 0.70133586 0.65295276 ... 0.1031444  0.12019315 0.12619143]\n",
      "[-0.0566986  -0.04564665 -0.03702158 ...  0.05046723  0.06177789\n",
      "  0.07749061]\n",
      "[-0.01874911 -0.02281555 -0.02529078 ... -0.00125189 -0.00116856\n",
      " -0.00033257]\n",
      "[-0.01658375 -0.02266374 -0.0282866  ...  0.02667649  0.02480593\n",
      "  0.02208956]\n",
      "[ 0.03387507  0.08963387  0.14631178 ...  0.00120606 -0.00063871\n",
      " -0.00277381]\n",
      "[ 0.00787135  0.0127997   0.01348438 ... -0.09267007 -0.08418682\n",
      " -0.07660997]\n",
      "[-0.01961981 -0.01761687 -0.01009235 ... -0.10410636 -0.1018021\n",
      " -0.08926637]\n",
      "[-0.13652882 -0.16055038 -0.15830976 ...  0.24115341  0.24551138\n",
      "  0.23025313]\n",
      "[-0.09339193 -0.00242489  0.09312294 ... -0.00684687 -0.00702691\n",
      " -0.006488  ]\n",
      "[ 0.08545209  0.06316336  0.0330507  ... -0.00588827 -0.00670094\n",
      " -0.00656361]\n",
      "[0.01184151 0.00992263 0.00859901 ... 0.08206433 0.06411518 0.04459987]\n",
      "[ 0.00627427  0.00578662  0.00496227 ... -0.00767034 -0.00939516\n",
      " -0.010206  ]\n",
      "[ 0.01243357  0.01123764  0.01010514 ... -0.00648545 -0.00477271\n",
      " -0.00227752]\n",
      "[-5.40716672e-04 -1.94130943e-04  1.50228101e-04 ... -1.91826188e-01\n",
      " -2.02437325e-01 -2.01588125e-01]\n",
      "[-0.02901252 -0.02810461 -0.02809511 ...  0.01481262  0.01237044\n",
      "  0.0091117 ]\n",
      "[ 0.00070991 -0.0005204  -0.00188847 ... -0.00849589 -0.00741435\n",
      " -0.00570868]\n",
      "[-0.02504385 -0.02610714 -0.02682475 ... -0.92378621 -0.91496794\n",
      " -0.92651183]\n",
      "[-0.01681131 -0.01499806 -0.01087007 ...  0.04342541  0.06049906\n",
      "  0.070147  ]\n",
      "[-0.02048402 -0.01801149 -0.0169312  ...  0.00903225  0.01643793\n",
      "  0.02410617]\n",
      "[ 0.04756458  0.03997069  0.03186691 ... -0.00188837 -0.00434078\n",
      " -0.00747175]\n",
      "[ 0.00811968  0.01474188  0.0197425  ... -0.04278724 -0.04241334\n",
      " -0.03977505]\n",
      "[-3.22089117e-05 -5.96297290e-04 -1.50819598e-03 ...  1.10974873e-03\n",
      " -1.01873475e-02 -2.28434768e-02]\n",
      "[0.08642324 0.09190781 0.0966147  ... 0.01383924 0.0165818  0.01938268]\n",
      "[-0.06976839 -0.07067027 -0.06690352 ... -0.01419628 -0.01565581\n",
      " -0.02028087]\n",
      "[0.00021098 0.00053719 0.001666   ... 0.0006294  0.00082057 0.00088877]\n",
      "[ 0.10304218  0.17042138  0.24488406 ... -0.02132251 -0.01957469\n",
      " -0.02113882]\n",
      "[-0.0525828  -0.05541263 -0.05872479 ...  0.0024019  -0.00142428\n",
      " -0.00548062]\n",
      "[ 0.15135294  0.11118177  0.08066414 ... -0.00949369 -0.01288456\n",
      " -0.01615784]\n",
      "[-0.01596712 -0.01680349 -0.01725402 ... -0.06873021 -0.04663866\n",
      " -0.01618754]\n",
      "[ 0.00577492  0.00392881  0.00312813 ... -0.00429081 -0.00162294\n",
      "  0.00115595]\n",
      "[-0.00260237 -0.00587645 -0.00901546 ...  0.02757654  0.02891425\n",
      "  0.02954865]\n",
      "[-0.00949259 -0.01155823 -0.01360994 ...  0.01997815  0.01799354\n",
      "  0.01758298]\n",
      "[-0.00336601 -0.0049862  -0.00665762 ... -0.01182026 -0.01435382\n",
      " -0.01638059]\n",
      "[ 0.00862022  0.00684981  0.00507635 ... -0.00124858 -0.00130259\n",
      " -0.001349  ]\n",
      "[-0.07033835 -0.06853032 -0.06791876 ...  0.10442415  0.09586764\n",
      "  0.08099271]\n",
      "[ 0.00429582  0.00214738 -0.00090753 ... -0.05815023 -0.04532576\n",
      " -0.02059229]\n",
      "[0.6388837  0.64083565 0.64012499 ... 0.01369203 0.01564664 0.02673865]\n",
      "[-0.01609339 -0.01531292 -0.01269423 ...  0.01173292  0.00176617\n",
      " -0.00721024]\n",
      "[-0.00600456 -0.01951509 -0.02180371 ...  0.0150557   0.01393632\n",
      "  0.01243347]\n",
      "[ 0.18500554  0.2744095   0.27905746 ... -0.00601697 -0.00855588\n",
      " -0.01499322]\n",
      "[-0.02452198 -0.02541998 -0.02634024 ...  0.13677526  0.19715122\n",
      "  0.24359982]\n",
      "[-0.01328045 -0.00204255  0.01232917 ... -0.01388486 -0.01010322\n",
      " -0.0061987 ]\n",
      "[-0.36675852 -0.39567772 -0.41818212 ... -0.0576083  -0.06093423\n",
      " -0.06364243]\n",
      "[-0.03102169 -0.03173283 -0.03017459 ... -0.07996082 -0.0815617\n",
      " -0.08250097]\n",
      "[-0.03042483 -0.02826643 -0.02434476 ...  0.2443138   0.13284162\n",
      "  0.04624168]\n",
      "[-0.01975673 -0.01309399 -0.00522042 ... -0.00499905 -0.00620703\n",
      " -0.00712155]\n",
      "[-0.28842072 -0.27875814 -0.25388205 ... -0.00542286 -0.0059133\n",
      " -0.00631426]\n",
      "[-0.02702885 -0.02273282 -0.01757238 ...  0.03285404  0.03179502\n",
      "  0.02289789]\n",
      "[ 0.02592658  0.0238324   0.02137773 ... -0.05450842 -0.04964635\n",
      " -0.04263762]\n",
      "[-0.00052826  0.00087529  0.00225006 ...  0.00347119  0.00206649\n",
      "  0.00389086]\n",
      "[ 0.069041    0.03821283  0.01457716 ... -0.00370567 -0.00422374\n",
      " -0.00434639]\n",
      "[-0.01647762 -0.01634238 -0.01584153 ... -0.039243   -0.03972134\n",
      " -0.04020877]\n",
      "[0.5196358  0.52025695 0.51400839 ... 0.03040853 0.03395102 0.03818368]\n",
      "[ 0.55587197  0.55888719  0.55703956 ... -0.21739699 -0.38296861\n",
      " -0.57694625]\n",
      "[-0.34188644 -0.30049117 -0.23614281 ...  0.01376478  0.01525505\n",
      "  0.01737434]\n",
      "[-0.00580626  0.00521553  0.01445313 ... -0.08556868 -0.10907307\n",
      " -0.12474811]\n",
      "[-0.01388651 -0.01096654 -0.01169935 ... -0.02504355 -0.02502018\n",
      " -0.02678514]\n",
      "[-0.025806   -0.02806647 -0.03036388 ... -0.18427161 -0.16515968\n",
      " -0.13002099]\n",
      "[0.06421155 0.0813709  0.09728316 ... 0.00052754 0.00104039 0.00148528]\n",
      "[-0.00258581 -0.00275534 -0.00224159 ...  0.17623821  0.12247068\n",
      "  0.06852512]\n",
      "[-0.01628471 -0.01761136 -0.02217432 ...  0.00276412  0.00411158\n",
      "  0.00545316]\n",
      "[-0.00732655 -0.00889367 -0.01022324 ... -0.06427393 -0.06494152\n",
      " -0.06427776]\n",
      "[ 0.01288367  0.01599814  0.01949851 ... -0.05754585 -0.07231237\n",
      " -0.0829847 ]\n",
      "[-0.00891959 -0.00963344 -0.01071705 ...  0.01838075  0.01277086\n",
      "  0.00694506]\n",
      "[0.27568475 0.21488532 0.12943253 ... 0.00893531 0.00689763 0.00514604]\n",
      "[ 0.01932454  0.01793647  0.01649175 ... -0.01497786 -0.01100941\n",
      " -0.00780245]\n",
      "[-0.02404975 -0.02037597 -0.01696127 ...  0.02673567 -0.01154216\n",
      " -0.04716267]\n",
      "[-0.06217805 -0.06011058 -0.05791017 ... -0.062003   -0.05956073\n",
      " -0.05684538]\n",
      "[0.03572524 0.03148083 0.02696626 ... 0.09753565 0.09035588 0.08426163]\n",
      "[-0.0644282  -0.0602992  -0.05630831 ...  0.006261    0.00829444\n",
      "  0.00864639]\n",
      "[-0.04295289 -0.03459568 -0.03221933 ...  0.05619998  0.05838232\n",
      "  0.06637695]\n",
      "[-0.08886599 -0.08312916 -0.07748817 ... -0.02991977 -0.02830139\n",
      " -0.02662229]\n",
      "[-0.01375012 -0.0168724  -0.0183405  ... -0.01369432 -0.01127762\n",
      " -0.00881465]\n",
      "[0.01203426 0.01056609 0.00905367 ... 0.03010267 0.02384546 0.01629127]\n",
      "[-0.00019327  0.00033251  0.00090036 ... -0.01417231 -0.01530295\n",
      " -0.01564073]\n",
      "[-0.01890689 -0.01969084 -0.02026719 ... -0.02289303 -0.01981959\n",
      " -0.01720659]\n",
      "[-1.02528191 -1.24212242 -1.36348847 ...  0.00345035  0.00278249\n",
      "  0.00226842]\n",
      "[0.03396871 0.03903332 0.04519656 ... 0.03954253 0.03173214 0.02678217]\n",
      "[0.04107608 0.03955454 0.03743443 ... 0.00295057 0.00371823 0.00556743]\n",
      "[0.0029685  0.00511185 0.00564462 ... 0.02107118 0.01436143 0.00594253]\n",
      "[0.01765884 0.02022664 0.02310293 ... 0.01924399 0.01656814 0.0139046 ]\n",
      "[0.10435636 0.10249926 0.10340809 ... 0.01118568 0.01050343 0.00865985]\n",
      "[ 0.0278278   0.02579878  0.02470587 ... -0.06924355 -0.06419884\n",
      " -0.05882455]\n",
      "[ 0.07591192  0.07368453  0.07235551 ... -0.02557601 -0.02847705\n",
      " -0.03083387]\n",
      "[-0.03988062 -0.04354757 -0.0468644  ...  0.01086672  0.01374436\n",
      "  0.01774534]\n",
      "[ 0.02377257  0.01923207  0.01480117 ... -0.00465072 -0.00440584\n",
      " -0.00414953]\n",
      "[-0.07891678 -0.07163439 -0.06343795 ... -0.06754673 -0.06589818\n",
      " -0.06410821]\n",
      "[-0.02825341 -0.03157369 -0.03432689 ... -0.05404831 -0.03838933\n",
      " -0.03309972]\n",
      "[ 0.06578899  0.06769335  0.06830079 ... -0.02973066 -0.02441227\n",
      " -0.01891565]\n",
      "[ 0.01630808  0.02455557  0.03332656 ... -0.10659531 -0.10061111\n",
      " -0.09469612]\n",
      "[-0.03755448 -0.05140764 -0.05538058 ...  0.11348155  0.1136752\n",
      "  0.11532342]\n",
      "[-0.06449438 -0.05542586 -0.03879048 ... -0.02125212 -0.02456155\n",
      " -0.02727366]\n",
      "[0.00482674 0.00743464 0.0115731  ... 0.03814651 0.03529407 0.03069494]\n",
      "[0.02082933 0.01854063 0.01720594 ... 0.01012821 0.01164644 0.01262569]\n",
      "[-0.00839952 -0.00925118 -0.00952508 ... -0.01531889 -0.01566252\n",
      " -0.01561568]\n",
      "[-0.04569919 -0.04032919 -0.03858891 ... -0.01921244 -0.01814684\n",
      " -0.01712022]\n",
      "[ 0.01276981  0.00918359  0.00931888 ... -0.04878583 -0.04910327\n",
      " -0.04934158]\n",
      "[0.01804674 0.0151977  0.01101868 ... 0.21321898 0.20986415 0.19788676]\n",
      "[-0.01625829 -0.01373835 -0.01156534 ... -0.00341525 -0.00458916\n",
      " -0.00539667]\n",
      "[ 0.00295335  0.00665378  0.01082746 ... -0.03833152 -0.03202859\n",
      " -0.02493424]\n",
      "[-0.01757434 -0.01475523 -0.01141466 ... -0.01892064 -0.01777863\n",
      " -0.01635868]\n",
      "[ 0.02639324  0.02630975  0.02508078 ... -0.00278196 -0.00127449\n",
      " -0.00028108]\n",
      "[0.01671877 0.01749408 0.02040637 ... 0.00165074 0.00138026 0.00229306]\n",
      "[-0.05048538 -0.0331096  -0.02520105 ... -0.03193504 -0.0310887\n",
      " -0.03013933]\n",
      "[ 0.02350405  0.02092682  0.01764683 ... -0.02271491 -0.02072642\n",
      " -0.01812729]\n",
      "[ 0.00775197  0.00182358 -0.00423664 ... -0.02990985 -0.02651231\n",
      " -0.02321517]\n",
      "[-0.02349808 -0.0207305  -0.01750154 ... -0.0130136  -0.01124425\n",
      " -0.00837304]\n",
      "[-0.01145704 -0.01846182 -0.02455728 ... -0.05591389 -0.04679798\n",
      " -0.03724539]\n",
      "[-0.03009351 -0.08888945 -0.15286739 ...  0.06524792  0.04025927\n",
      "  0.02380082]\n",
      "[ 0.0649186   0.06686266  0.06935927 ... -0.00528459 -0.00570738\n",
      " -0.00595863]\n",
      "[0.0236529  0.02690417 0.02990452 ... 0.01065946 0.00738955 0.00400178]\n",
      "[-0.04865461 -0.06793926 -0.0696586  ... -0.30155847 -0.33376829\n",
      " -0.34922594]\n",
      "[-0.12363121 -0.12190438 -0.11953873 ... -0.02238005 -0.02094107\n",
      " -0.01901037]\n",
      "[ 0.05467999  0.05405017  0.05341835 ... -0.00887432 -0.00739157\n",
      " -0.00595015]\n",
      "[-0.00974334 -0.01564068 -0.02288    ...  0.0240239   0.02076569\n",
      "  0.01649702]\n",
      "[-0.07877876 -0.10490638 -0.12609446 ... -0.02419222 -0.00698883\n",
      "  0.02442919]\n",
      "[-0.02612277 -0.02543352 -0.02631891 ... -0.00475385 -0.00568789\n",
      " -0.00502305]\n",
      "[0.03483674 0.02858198 0.02386055 ... 0.01635678 0.01289575 0.007755  ]\n",
      "[ 0.03403131  0.02399212  0.02284914 ... -0.00938183 -0.01427573\n",
      " -0.01905195]\n",
      "[-0.00515952 -0.0043975  -0.00292141 ...  0.00529836  0.00611717\n",
      "  0.00650007]\n",
      "[-0.03135768 -0.02757852 -0.02284037 ... -0.19935083 -0.2531246\n",
      " -0.33771432]\n",
      "[0.056987   0.05705205 0.05698286 ... 0.00643616 0.00295551 0.00103729]\n",
      "[-1.11391528e-04 -3.89778835e-04  7.58386855e-04 ... -2.76666734e-01\n",
      " -3.31599079e-01 -3.85650029e-01]\n",
      "[-0.18292811 -0.10918885 -0.04637495 ... -0.00552385 -0.00458454\n",
      " -0.00331975]\n",
      "[-0.03544697 -0.03187129 -0.03297218 ...  0.00757446  0.00524931\n",
      " -0.0027948 ]\n",
      "[0.01990081 0.01652406 0.01594853 ... 0.11652362 0.11847952 0.12225959]\n",
      "[ 0.02395548  0.02117456  0.01742562 ... -0.00479055  0.00023783\n",
      "  0.00492919]\n",
      "[-0.10722505 -0.11138488 -0.11367305 ... -0.00117437 -0.00121724\n",
      " -0.00126004]\n",
      "[0.00692122 0.00467163 0.00562649 ... 0.00636534 0.00631583 0.00141403]\n",
      "[ 0.00745719  0.00913855  0.01094648 ... -0.04250423 -0.04091612\n",
      " -0.03945826]\n",
      "[ 0.01961921  0.02909657  0.0392649  ... -0.01814105 -0.01346767\n",
      " -0.01046521]\n",
      "[0.01495751 0.03006323 0.0470343  ... 0.02124883 0.03262265 0.05096508]\n",
      "[-0.00783856 -0.00902142 -0.01006715 ...  0.03899293  0.03690731\n",
      "  0.03513253]\n",
      "[-0.02982855 -0.01563637 -0.01553621 ...  0.45891699  0.45628113\n",
      "  0.4080641 ]\n",
      "[-0.03360324 -0.02981002 -0.02486946 ...  0.00538228  0.00034517\n",
      " -0.00275692]\n",
      "[-0.0079751  -0.00542893 -0.00611565 ... -0.02302173 -0.02332348\n",
      " -0.02248901]\n",
      "[0.01456286 0.00764887 0.00046323 ... 0.18065315 0.19109468 0.18740131]\n",
      "[-0.04112427 -0.02893404 -0.01578365 ...  0.03846017  0.03765534\n",
      "  0.03491271]\n",
      "[-0.03423794 -0.04540742 -0.05679961 ...  0.08801712  0.08009853\n",
      "  0.06712913]\n",
      "[-0.00623726 -0.00879326 -0.01165789 ... -0.57252222 -0.53137694\n",
      " -0.45563153]\n",
      "[-0.08918963 -0.0886473  -0.0808473  ...  0.0160343   0.01734913\n",
      "  0.01855078]\n",
      "[0.05595492 0.052827   0.04692191 ... 0.04899024 0.03914417 0.02770574]\n",
      "[-0.00845824 -0.01243429 -0.01727871 ... -0.00653242 -0.00452062\n",
      " -0.00287265]\n",
      "[0.02808576 0.0210818  0.00649699 ... 0.00787947 0.00764795 0.00738866]\n",
      "[-0.02303048 -0.03359878 -0.04189439 ...  0.00492961  0.00832876\n",
      "  0.00880029]\n",
      "[-0.02851428 -0.0304576  -0.03158723 ...  0.15149842  0.1444086\n",
      "  0.12554486]\n",
      "[-0.04884241 -0.0455038  -0.04217524 ... -0.06421007 -0.05860577\n",
      " -0.04960692]\n",
      "[ 0.08332115  0.0838202   0.08409199 ... -0.09529561 -0.09073448\n",
      " -0.08528085]\n",
      "[-0.01004414 -0.00884072 -0.00707862 ...  0.02436901  0.02377284\n",
      "  0.02329158]\n",
      "[ 0.00087969 -0.0010216  -0.00376504 ... -0.01219908 -0.02636185\n",
      " -0.03818897]\n",
      "[-0.82045633 -0.79684835 -0.7763987  ...  0.10225521  0.00517344\n",
      " -0.08315225]\n",
      "[ 0.13010374  0.12903515  0.12843709 ... -0.01056404 -0.00841191\n",
      " -0.00676641]\n",
      "[-0.0562782  -0.04794868 -0.04310482 ... -0.0017542  -0.0012694\n",
      "  0.01117527]\n",
      "[-0.02686837 -0.03167139 -0.0371046  ...  0.00153289  0.00062346\n",
      " -0.0007403 ]\n",
      "[0.02003698 0.0171496  0.01496269 ... 0.00620641 0.0074926  0.00951456]\n",
      "[0.03092645 0.0237689  0.01535759 ... 0.04077369 0.05844677 0.09546346]\n",
      "[-0.03093525 -0.03200684 -0.03149262 ... -0.03033715 -0.03446207\n",
      " -0.03751914]\n",
      "[0.00960139 0.01036166 0.01183889 ... 0.21415491 0.15799588 0.09802432]\n",
      "[-0.00718223 -0.00811099 -0.00804886 ... -0.01210409 -0.00763749\n",
      " -0.00354392]\n",
      "[ 0.023475    0.00709606 -0.00746926 ... -0.11807564 -0.07496014\n",
      " -0.02756783]\n",
      "[-0.0047504  -0.00491495 -0.00516698 ... -0.0464694  -0.04523154\n",
      " -0.04427565]\n",
      "[ 0.04117215  0.04301632  0.04315119 ... -0.00170119  0.00015647\n",
      " -0.00119095]\n",
      "[0.02073202 0.01915229 0.01734228 ... 0.00207895 0.00121823 0.00103847]\n",
      "[-0.07360851 -0.0895569  -0.10562649 ...  0.00563371 -0.0077807\n",
      " -0.0177511 ]\n",
      "[-0.03274763 -0.03779467 -0.04223974 ... -0.00543328 -0.0073133\n",
      " -0.00795107]\n",
      "[-0.02930416 -0.03362637 -0.03512846 ...  0.03123035  0.03862072\n",
      "  0.04336755]\n",
      "[0.24956391 0.20324377 0.1398403  ... 0.00960389 0.01076923 0.01101872]\n",
      "[-0.00903119 -0.01097892 -0.01237105 ... -0.01900087 -0.01908692\n",
      " -0.01911944]\n",
      "[-0.00826116 -0.00580194 -0.00206884 ... -0.02718213 -0.02677912\n",
      " -0.02555667]\n",
      "[ 0.12580913  0.10328936  0.09513388 ... -0.0146924  -0.01603519\n",
      " -0.01504402]\n",
      "[-0.01795677 -0.01224651 -0.00845668 ... -0.00047291 -0.0118045\n",
      " -0.02290782]\n",
      "[-0.08900279 -0.0654594  -0.04885449 ... -0.03177195 -0.02426113\n",
      " -0.01625084]\n",
      "[ 0.00846989  0.00972109  0.01097497 ... -0.10302223 -0.10243391\n",
      " -0.10060041]\n",
      "[-0.02032379 -0.02087351 -0.02141102 ...  0.01172565  0.01123628\n",
      "  0.01077686]\n",
      "[-0.04283016 -0.04249374 -0.04217065 ... -0.0225283  -0.02326082\n",
      " -0.02392771]\n",
      "[-0.0483539  -0.04308937 -0.04139264 ...  0.00422732  0.00813044\n",
      "  0.01270848]\n",
      "[0.14418258 0.19520975 0.2380545  ... 0.08187023 0.05582422 0.03094923]\n",
      "[-0.00066182 -0.00178979 -0.00314339 ...  0.01157951  0.01326464\n",
      "  0.01483204]\n",
      "[-0.02641185 -0.01798316 -0.00582327 ... -0.00089476 -0.00922343\n",
      " -0.01750299]\n",
      "[ 0.00375106  0.00024554 -0.00416773 ... -0.00281125 -0.0006504\n",
      "  0.00121813]\n",
      "[-0.01560832 -0.01561968 -0.0153273  ... -0.00939163 -0.00906321\n",
      " -0.00949274]\n",
      "[-0.02838926 -0.01817299  0.00344981 ... -0.0562767  -0.05341454\n",
      " -0.04980899]\n",
      "[ 0.04574898  0.04369118  0.04169649 ... -0.00070614  0.00112059\n",
      "  0.00267331]\n",
      "[-0.13246727 -0.12594    -0.11927119 ... -0.03945438 -0.03786854\n",
      " -0.03629171]\n",
      "[ 0.26864076  0.25565717  0.2207042  ... -0.02322976 -0.02120649\n",
      " -0.01914811]\n",
      "[0.18674724 0.14981855 0.10493576 ... 0.01013959 0.00934292 0.0076191 ]\n",
      "[ 0.00173093 -0.00795544 -0.01727733 ...  0.01917377  0.0227352\n",
      "  0.02461994]\n",
      "[ 0.00037866  0.00114775  0.00235161 ... -0.03072369 -0.03139258\n",
      " -0.03219883]\n",
      "[-0.0432947  -0.0428139  -0.0411937  ...  0.01598224  0.01464791\n",
      "  0.01266484]\n",
      "[ 0.00712601  0.00926361  0.01136743 ... -0.00201108 -0.00091664\n",
      "  0.00013558]\n",
      "[ 0.07030373  0.07050017  0.06869595 ... -0.06515853 -0.06537583\n",
      " -0.06039605]\n",
      "[0.00374301 0.00286026 0.00230054 ... 0.02301913 0.02222954 0.02152143]\n",
      "[-0.04914803 -0.04965115 -0.04953878 ... -0.00707642 -0.00896565\n",
      " -0.01106794]\n",
      "[ 2.80462221e-04  1.80635847e-05 -4.46486657e-04 ... -3.38212471e-02\n",
      " -3.38741263e-02 -3.42281954e-02]\n",
      "[-0.02920344 -0.02454323 -0.01799509 ... -0.00624098 -0.00787733\n",
      " -0.00865625]\n",
      "[0.01282619 0.017327   0.01987062 ... 0.06045626 0.06030812 0.05020094]\n",
      "[-0.00746805 -0.00550179 -0.0019484  ... -0.0016669  -0.0011792\n",
      " -0.00068014]\n",
      "[ 0.00206054  0.00186385  0.00095977 ... -0.00403955 -0.00541394\n",
      " -0.00668379]\n",
      "[-0.02450649 -0.02631649 -0.02512153 ...  0.0865851   0.06135664\n",
      "  0.03607886]\n",
      "[-0.04147233 -0.03963282 -0.03741517 ... -0.00443091 -0.00765162\n",
      " -0.01014857]\n",
      "[-0.98619945 -0.98417225 -0.96673111 ... -0.01965043 -0.02297215\n",
      " -0.02521308]\n",
      "[ 1.70552930e-03  7.40387567e-04 -2.48872585e-05 ... -2.21847536e-02\n",
      " -2.32436004e-02 -2.32130220e-02]\n",
      "[-0.0086369  -0.01039411 -0.01023538 ... -0.01365078 -0.0134703\n",
      " -0.00507531]\n",
      "[0.00711084 0.0045156  0.00189841 ... 0.48255876 0.44795224 0.40337434]\n",
      "[ 0.02810831  0.03383754  0.04060506 ... -0.04092379 -0.04356511\n",
      " -0.04766834]\n",
      "[-0.00797646 -0.00868912 -0.00854141 ...  0.02278384  0.02679102\n",
      "  0.0294227 ]\n",
      "[-0.01610844 -0.01589504 -0.0192589  ... -0.09017652 -0.08967857\n",
      " -0.01483582]\n",
      "[-0.02906384 -0.02818119 -0.02705347 ...  0.01085646  0.01320672\n",
      "  0.01522093]\n",
      "[0.00497507 0.00364332 0.00257257 ... 0.02268191 0.02374029 0.02467762]\n",
      "[ 0.00154836  0.00221822  0.00128556 ... -0.00415507 -0.00469613\n",
      " -0.00200267]\n",
      "[-0.00962345 -0.01371383 -0.018801   ...  0.12710566  0.15664026\n",
      "  0.17996934]\n",
      "[ 0.09205812  0.05859222  0.02438125 ... -0.10773562 -0.11596331\n",
      " -0.12042373]\n",
      "[-0.04353186 -0.04416669 -0.04192902 ... -0.09864824 -0.09872596\n",
      " -0.09059637]\n",
      "[ 0.23477076  0.16903491  0.09067978 ... -0.31760931 -0.32240821\n",
      " -0.33859777]\n",
      "[0.01750194 0.01495224 0.01299232 ... 0.01865015 0.02018157 0.02119829]\n",
      "[-0.01413683 -0.01341051 -0.01425067 ... -0.00289234 -0.00315365\n",
      " -0.0018129 ]\n",
      "[ 0.03069563  0.02503797  0.01825659 ... -0.00327622 -0.00377687\n",
      " -0.00359183]\n",
      "[ 0.49141412  0.50423145  0.50916625 ... -0.00330129 -0.00906429\n",
      " -0.01305951]\n",
      "[ 0.18143434  0.13145843  0.0813885  ... -0.00455154 -0.00559094\n",
      " -0.00712843]\n",
      "[-1.33053420e-02 -8.43482645e-03 -1.72256579e-03 ...  4.15859051e-03\n",
      "  8.40615964e-04  4.65939014e-05]\n",
      "[-0.00535652 -0.00606765 -0.00709343 ...  0.02318468  0.02620275\n",
      "  0.02833173]\n",
      "[-0.00877848 -0.00873536 -0.00869811 ... -0.02110389 -0.0128516\n",
      " -0.00772108]\n",
      "[-4.62347565e-03 -2.49785165e-03 -1.19489262e-05 ... -4.60550510e-02\n",
      " -3.25665898e-02 -1.67629975e-02]\n",
      "[-0.02274697 -0.01164429  0.00533085 ... -0.01813752 -0.01602859\n",
      " -0.01121741]\n",
      "[ 0.00052945 -0.00217062 -0.00645793 ... -0.00420296  0.00165322\n",
      "  0.00759237]\n",
      "[-0.01123265 -0.01418007 -0.01678049 ... -0.03926354 -0.03899483\n",
      " -0.03898678]\n",
      "[ 0.00262135  0.00313456  0.00293392 ... -0.00149979 -0.00439247\n",
      " -0.00660729]\n",
      "[0.02618192 0.02510762 0.0222632  ... 0.04327415 0.04578219 0.04862583]\n",
      "[-0.01132727 -0.01344636 -0.01907773 ...  0.00040603  0.00111262\n",
      "  0.00177655]\n",
      "[ 0.04972236  0.04719757  0.04469444 ... -0.01419809  0.00699015\n",
      "  0.0248209 ]\n",
      "[-0.01365407 -0.01485856 -0.01693012 ... -0.0253551  -0.0274491\n",
      " -0.02920064]\n",
      "[ 0.00127274 -0.00629747 -0.01262524 ... -0.02064456  0.00372086\n",
      "  0.0282545 ]\n",
      "[-0.09096874 -0.09265981 -0.09351425 ... -0.00029244  0.00013908\n",
      " -0.00018734]\n",
      "[-0.02486899 -0.02895642 -0.03184397 ... -0.01394202  0.05441657\n",
      "  0.11363474]\n",
      "[-0.01014642 -0.00840196 -0.0063545  ... -0.03562391 -0.0294925\n",
      " -0.01832154]\n",
      "[-0.32163637 -0.37105318 -0.41660564 ...  0.02710626  0.02653338\n",
      "  0.02564112]\n",
      "[0.00963466 0.01074416 0.01188961 ... 0.02384712 0.02433431 0.02471167]\n",
      "[-0.01075303 -0.01140819 -0.01141553 ... -0.00711477 -0.00067374\n",
      "  0.00420973]\n",
      "[0.02107228 0.02074902 0.02046617 ... 0.00850996 0.00751407 0.00704557]\n",
      "[-0.04928998 -0.05086218 -0.05229884 ...  0.01468759  0.01033855\n",
      "  0.00646965]\n",
      "[0.01179689 0.00930536 0.00659417 ... 0.01958194 0.01792652 0.01496728]\n",
      "[-0.00183546 -0.0001434   0.00363462 ... -0.00037569 -0.00280095\n",
      " -0.00445979]\n",
      "[-0.00815773 -0.00134453  0.00524056 ... -0.04635466 -0.04671509\n",
      " -0.05189556]\n",
      "[-0.08410926 -0.07759337 -0.07326275 ... -0.89357125 -0.86881182\n",
      " -0.84365092]\n",
      "[-0.00726002  0.00214429  0.00795547 ... -0.11249957 -0.11527768\n",
      " -0.11031426]\n",
      "[ 0.05852085  0.06643404  0.07328716 ... -0.05980763 -0.05204478\n",
      " -0.04422484]\n",
      "[-0.01489398 -0.01669327 -0.01921042 ...  0.10113362  0.11615006\n",
      "  0.13032949]\n",
      "[ 0.02154697  0.01774961  0.01399637 ... -0.00388156 -0.00271596\n",
      " -0.00077164]\n",
      "[-0.01985684 -0.04643851 -0.0746642  ...  0.02080905  0.01674594\n",
      "  0.01058986]\n",
      "[ 0.00133217 -0.00457692 -0.01085231 ... -0.0294015   0.00372385\n",
      "  0.04783671]\n",
      "[-0.00206417  0.00024689  0.0024071  ... -0.02582813 -0.02361167\n",
      " -0.02118328]\n",
      "[-0.01547852 -0.01642408 -0.01702873 ... -0.03212617 -0.05051828\n",
      " -0.06655752]\n",
      "[ 0.07858817  0.07221314  0.06568299 ... -0.02419437 -0.02374165\n",
      " -0.02334953]\n",
      "[0.02329612 0.03886993 0.05728838 ... 0.0373062  0.03450733 0.03038658]\n",
      "[-0.01162393 -0.01030585 -0.00893797 ...  0.04778552  0.11966685\n",
      "  0.18695329]\n",
      "[ 2.05074159e-01  1.66166738e-01  1.18024000e-01 ... -6.62027603e-03\n",
      " -3.46911412e-03 -1.92094499e-04]\n",
      "[-0.24290443 -0.22490741 -0.20821294 ...  0.01901516 -0.29750759\n",
      " -0.59500317]\n",
      "[-0.50193436 -0.57753941 -0.65221963 ... -0.00865776 -0.00940117\n",
      " -0.01006483]\n",
      "[-0.10775559 -0.1115206  -0.11528784 ...  0.01168458  0.0130384\n",
      "  0.0140672 ]\n",
      "[-0.03220113 -0.038882   -0.04489933 ...  0.05694824  0.05618104\n",
      "  0.0553815 ]\n",
      "[ 0.26120691  0.27336191  0.26576397 ... -0.00466256 -0.00362603\n",
      " -0.00315437]\n",
      "[ 0.03304259  0.02690818  0.02041415 ... -0.10100535 -0.02322532\n",
      "  0.07002545]\n",
      "[-0.00093161 -0.00344518 -0.0052134  ...  0.06704264  0.12115831\n",
      "  0.16979802]\n",
      "[0.0258064  0.01527649 0.0035071  ... 0.22100563 0.20590701 0.17104809]\n",
      "[ 0.01039911  0.01192495  0.01173532 ... -0.02076127 -0.02312535\n",
      " -0.02661103]\n",
      "[-0.09499965 -0.0890014  -0.08637737 ... -0.0596062  -0.05666824\n",
      " -0.05396905]\n",
      "[ 0.02764976  0.02172616  0.02443519 ... -0.00930699 -0.01279687\n",
      " -0.01264561]\n",
      "[-0.07490819 -0.07721469 -0.07325994 ...  0.05153123  0.05813175\n",
      "  0.06010538]\n",
      "[-0.00964771 -0.00997627 -0.01076097 ... -0.00626374 -0.00852209\n",
      " -0.01023381]\n",
      "[0.01176112 0.02273291 0.02319094 ... 0.0839663  0.08016567 0.0808021 ]\n",
      "[ 0.0191461   0.02928659  0.03558083 ... -0.28321512 -0.26111125\n",
      " -0.23896134]\n",
      "[-0.04649584 -0.02989754 -0.01715271 ... -0.02111056 -0.02162852\n",
      " -0.02357121]\n",
      "[-0.02453396 -0.02508529 -0.02558805 ...  0.02153829  0.02542952\n",
      "  0.02566832]\n",
      "[0.00840511 0.01099419 0.01450404 ... 0.00332067 0.00271661 0.00197755]\n",
      "[ 0.00995252  0.01115549  0.01283476 ... -0.02055642 -0.02220377\n",
      " -0.02373762]\n",
      "[-0.05546185  0.03489997  0.13767228 ... -0.01280253 -0.0508844\n",
      " -0.08378069]\n",
      "[ 0.00490402  0.00710581  0.00942443 ... -0.02696207 -0.02439868\n",
      " -0.0213326 ]\n",
      "[-0.02446428 -0.02274734 -0.02115378 ... -0.0007691   0.00091939\n",
      "  0.00261835]\n",
      "[ 0.03848946  0.03593196  0.03179976 ... -0.03725639  0.00068951\n",
      "  0.04455692]\n",
      "[ 0.00809504  0.01234997  0.01672261 ... -0.00168158 -0.0014327\n",
      " -0.00091509]\n",
      "[-0.01740512 -0.05639203 -0.09265717 ... -0.00783701 -0.01689221\n",
      " -0.02750717]\n",
      "[-0.08971799 -0.08510299 -0.07889945 ... -0.00729641 -0.00826918\n",
      " -0.01014005]\n",
      "[-0.00687075 -0.00424316 -0.00107412 ...  0.11925274  0.07664533\n",
      "  0.02600162]\n",
      "[-0.00958523 -0.00998145 -0.01049833 ... -0.49021113 -0.42401049\n",
      " -0.35208045]\n",
      "[ 0.00796815  0.00795315  0.00746819 ... -0.01122552 -0.00797495\n",
      " -0.00421758]\n",
      "[0.06002125 0.0649414  0.06926409 ... 0.0212665  0.02260956 0.02472203]\n",
      "[-0.02104455 -0.02116029 -0.0220345  ... -0.02260731 -0.01340526\n",
      "  0.003995  ]\n",
      "[0.02305586 0.02712954 0.03029493 ... 0.01156345 0.00545965 0.00069447]\n",
      "[-0.01117216 -0.01556901 -0.01933755 ... -0.0106069  -0.00957224\n",
      " -0.00778034]\n",
      "[ 0.03038755  0.03053519  0.03055727 ... -0.02592072 -0.0223516\n",
      " -0.0191293 ]\n",
      "[-0.01274002 -0.01369209 -0.01408383 ...  0.00255072 -0.00466318\n",
      " -0.01093378]\n",
      "[-0.01252973 -0.01429043 -0.01493002 ... -0.0268003  -0.02418874\n",
      " -0.02116928]\n",
      "[ 0.00224263  0.00178984  0.00127195 ... -0.13475872 -0.1312256\n",
      " -0.10591562]\n",
      "[0.03758136 0.03483736 0.0351798  ... 0.00777724 0.00954999 0.00809299]\n",
      "[-0.01140245 -0.01207847 -0.01271527 ... -0.0032423  -0.00469807\n",
      " -0.00589846]\n",
      "[ 0.01123596  0.00860414  0.0059781  ... -0.00324825 -0.00276532\n",
      "  0.00096406]\n",
      "[0.04217762 0.04900624 0.05723081 ... 0.19366728 0.22811942 0.24405714]\n",
      "[ 0.02064513 -0.0016394  -0.0185383  ... -0.02712146 -0.02716494\n",
      " -0.0267632 ]\n",
      "[-0.06043946 -0.06646132 -0.0701356  ...  0.01378146  0.0159512\n",
      "  0.01797617]\n",
      "[-0.02044504 -0.02003129 -0.02082309 ...  0.04759151  0.05229993\n",
      "  0.05704793]\n",
      "[-0.02668547 -0.02686925 -0.02519993 ... -0.01124439 -0.0116227\n",
      " -0.00970377]\n",
      "[-0.04127498 -0.04021549 -0.04110753 ... -0.04469866 -0.0425575\n",
      " -0.03972748]\n",
      "[ 0.06380035  0.07079176  0.06214509 ... -0.15013969 -0.12530475\n",
      " -0.09525666]\n",
      "[-0.00884472 -0.01106384 -0.01301902 ... -0.01131092 -0.01306387\n",
      " -0.01358581]\n",
      "[-0.08958169 -0.06604278 -0.03741506 ... -0.02257384 -0.0239042\n",
      " -0.02524067]\n",
      "[ 0.00041322  0.02498985  0.05476015 ... -0.00314782  0.00033386\n",
      "  0.0032386 ]\n",
      "[-0.01656427 -0.01667908 -0.01641033 ... -0.00070089  0.00132514\n",
      "  0.00431047]\n",
      "[ 0.00677287  0.0080695   0.00913405 ...  0.00153365 -0.00179279\n",
      " -0.00559908]\n",
      "[-0.01895021 -0.02175799 -0.02388272 ... -0.1217231  -0.04910046\n",
      "  0.02160867]\n",
      "[0.06956935 0.13835703 0.20630719 ... 0.02277171 0.02359921 0.02395892]\n",
      "[0.00365113 0.0047549  0.00524767 ... 0.21434848 0.19935607 0.17170005]\n",
      "[0.01239694 0.01276947 0.01246132 ... 0.02564559 0.02302416 0.02142781]\n",
      "[ 0.01542186  0.0248595   0.02899908 ... -0.01725115 -0.01861379\n",
      " -0.01388016]\n",
      "[ 0.0100735   0.00645787  0.00270447 ... -0.00541089 -0.00596526\n",
      " -0.00596097]\n",
      "[-0.13502    -0.1417076  -0.15125321 ... -0.00918079 -0.00422197\n",
      " -0.00242345]\n",
      "[-7.87342300e-03 -8.01609135e-03 -6.61376542e-03 ...  1.53245310e-03\n",
      "  8.76029428e-05 -1.41887719e-03]\n",
      "[-0.00314542 -0.00228632 -0.00085805 ... -0.01507561 -0.01166687\n",
      " -0.00866331]\n",
      "[ 0.00062976  0.00013516 -0.00049147 ...  0.00798918  0.01274491\n",
      "  0.01793354]\n",
      "[-0.03475614 -0.03741802 -0.0395248  ... -0.02093528 -0.02498018\n",
      " -0.02900612]\n",
      "[-0.06479213 -0.06344672 -0.05828879 ... -0.42635691 -0.26977153\n",
      " -0.1159501 ]\n",
      "[ 0.00772266  0.00881252  0.01469797 ... -0.01142748 -0.01058801\n",
      " -0.00810855]\n",
      "[-0.01123641 -0.00414326  0.00034217 ... -0.00456375 -0.00689354\n",
      " -0.00821956]\n",
      "[ 0.02551548  0.02903905  0.03249445 ... -0.04937275 -0.05440819\n",
      " -0.05080525]\n",
      "[-0.01802799 -0.02001308 -0.02174252 ... -0.04757873 -0.04332353\n",
      " -0.04219726]\n",
      "[ 0.12399737  0.09504915  0.05818936 ... -0.02075247 -0.02331298\n",
      " -0.02603123]\n",
      "[0.02525573 0.0190428  0.01284942 ... 0.22356466 0.23259931 0.24056932]\n",
      "[-0.07925096 -0.03789949  0.01891977 ...  0.01645629  0.03555748\n",
      "  0.05029746]\n",
      "[ 0.02294173  0.01332396  0.00444224 ... -0.04734821 -0.04713343\n",
      " -0.04601653]\n",
      "[ 0.01027399  0.00935695  0.00837803 ... -0.00152981 -0.00217664\n",
      " -0.00250516]\n",
      "[0.01269953 0.00855524 0.00365181 ... 0.00010244 0.00221943 0.00378098]\n",
      "[-0.04157725 -0.04436203 -0.04668114 ...  0.03316026  0.03319072\n",
      "  0.03334181]\n",
      "[-0.02285118 -0.02444277 -0.02495156 ... -0.01082437 -0.01145738\n",
      " -0.01195594]\n",
      "[ 0.00234757 -0.00468386 -0.00912147 ... -0.00774318  0.00364587\n",
      "  0.01273772]\n",
      "[ 0.00737317  0.00859713  0.0107527  ... -0.03195971 -0.02287444\n",
      " -0.00946429]\n",
      "[ 0.00567385  0.00336327 -0.00056176 ... -0.05463082 -0.01294485\n",
      "  0.03117647]\n",
      "[-0.00915287 -0.00917328 -0.01318065 ...  0.00240264  0.00456759\n",
      "  0.00561714]\n",
      "[-0.01357978 -0.01668834 -0.01326769 ...  0.00557559  0.00467592\n",
      "  0.00212036]\n",
      "[0.00631051 0.00632329 0.00636918 ... 0.01130679 0.01082047 0.01052628]\n",
      "[-0.24664855 -0.24091551 -0.22589874 ... -0.11621386 -0.13665158\n",
      " -0.15144002]\n",
      "[ 0.01525719  0.03136357  0.04577452 ... -0.00835252 -0.00582557\n",
      " -0.00457744]\n",
      "[ 0.01601611  0.01644181  0.01690118 ...  0.00294596  0.00106469\n",
      " -0.00456328]\n",
      "[-0.0144593  -0.01346346 -0.01274865 ...  0.14456416  0.18609013\n",
      "  0.20740882]\n",
      "[-0.00698548 -0.01216504 -0.01695931 ...  0.01455267  0.01638775\n",
      "  0.01777901]\n",
      "[-0.0143893   0.0124291   0.04414    ...  0.01234428  0.01028974\n",
      "  0.008827  ]\n",
      "[-0.02658384 -0.02734813 -0.02870874 ...  0.00451813  0.0007318\n",
      " -0.00292582]\n",
      "[0.01802489 0.02014517 0.02244692 ... 0.00744489 0.00772892 0.00800201]\n",
      "[0.02335245 0.02482541 0.02687505 ... 0.01690346 0.02062691 0.02400786]\n",
      "[0.06853326 0.07695432 0.07901424 ... 0.09753258 0.09991312 0.1026812 ]\n",
      "[0.06273878 0.06239964 0.05891465 ... 0.0401154  0.02843656 0.01667858]\n",
      "[ 0.00206159  0.00244243  0.00253453 ...  0.06312667 -0.01028998\n",
      " -0.05876657]\n",
      "[ 0.02724093  0.02453309  0.02073528 ... -0.05134949 -0.00237198\n",
      "  0.06396275]\n",
      "[ 0.00808802  0.00782165  0.00737375 ... -0.03905783 -0.04071174\n",
      " -0.03864119]\n",
      "[0.02277539 0.02164796 0.01562949 ... 0.00285152 0.00377923 0.00471795]\n",
      "[-0.01219891 -0.00892359 -0.00540198 ... -0.00532051 -0.01024242\n",
      " -0.01364619]\n",
      "[-0.00176029 -0.00021147  0.00146327 ... -0.0346606  -0.03043165\n",
      " -0.02612278]\n",
      "[-0.00850159 -0.01392708 -0.02003075 ...  0.01758458  0.01828325\n",
      "  0.01959066]\n",
      "[-0.00038932 -0.00293098 -0.00591169 ... -0.03290383 -0.02475444\n",
      " -0.01594683]\n",
      "[ 0.01347265  0.01308544  0.01234571 ... -0.71585042 -0.72172678\n",
      " -0.72730874]\n",
      "[-0.03877493 -0.05085617 -0.06082476 ... -0.00207201 -0.00376796\n",
      " -0.00506571]\n",
      "[ 0.44648451  0.19243721 -0.11628208 ...  0.33376205  0.33914349\n",
      "  0.36157845]\n",
      "[-0.09410696 -0.10047617 -0.10125912 ...  0.01654019  0.01483467\n",
      "  0.01356313]\n",
      "[ 0.01428684  0.00781031  0.00186697 ... -0.10479401 -0.06355677\n",
      " -0.02351282]\n",
      "[-0.01981993 -0.01883914 -0.01786369 ...  0.04154922  0.02071707\n",
      "  0.00015633]\n",
      "[-0.02257321 -0.01830011 -0.00952375 ... -0.01954052 -0.01235858\n",
      " -0.00586958]\n",
      "[-0.04172033 -0.02648823 -0.01932449 ... -0.02066252 -0.01905121\n",
      " -0.01715983]\n",
      "[ 0.01250928  0.01284408  0.01327684 ... -0.00129342  0.00082952\n",
      "  0.00281637]\n",
      "[-0.00098375 -0.00319574 -0.0055537  ... -0.01332161 -0.01612613\n",
      " -0.01857302]\n",
      "[-0.03076293 -0.0320734  -0.03325788 ...  0.00028861  0.0097909\n",
      "  0.02332229]\n",
      "[ 0.05193098  0.04436146  0.03475917 ... -0.09442653 -0.08617348\n",
      " -0.0777059 ]\n",
      "[ 0.01001148  0.01625286  0.01887989 ... -0.17304061 -0.12887482\n",
      " -0.0708088 ]\n",
      "[-0.00253563  0.00234013  0.00834989 ... -0.02430519 -0.01835674\n",
      " -0.011031  ]\n",
      "[ 0.00520466  0.0043384   0.00261803 ... -0.07164553 -0.05949599\n",
      " -0.04609414]\n",
      "[-0.02642786 -0.02921366 -0.03147038 ...  0.0470023   0.05561935\n",
      "  0.05942625]\n",
      "[0.0032717  0.00599303 0.00703348 ... 0.38968062 0.43466954 0.46856288]\n",
      "[-0.43661862 -0.48377719 -0.52415045 ...  0.01427675  0.01869935\n",
      "  0.02160626]\n",
      "[-0.00489458 -0.00722106 -0.00471339 ...  0.0010734   0.00177942\n",
      "  0.00411819]\n",
      "[0.27656767 0.36362852 0.44382057 ... 0.04624281 0.04885071 0.04827889]\n",
      "[-0.08981269 -0.0755767  -0.07412865 ...  0.08612906  0.08965079\n",
      "  0.18066724]\n",
      "[-0.03867221 -0.03720272 -0.03588188 ... -0.01926669 -0.02022314\n",
      " -0.02015642]\n",
      "[-0.01034354 -0.00718318 -0.00533753 ... -0.10274598 -0.10373676\n",
      " -0.10518685]\n",
      "[ 0.11534132  0.10149052  0.08043098 ... -0.12040478 -0.10044553\n",
      " -0.07588876]\n",
      "[-0.08018966 -0.09138195 -0.10012096 ... -0.01894737 -0.01231903\n",
      " -0.00556908]\n",
      "[ 0.00557013 -0.00393205 -0.01201707 ...  0.0223125   0.02548502\n",
      "  0.0281975 ]\n",
      "[0.00161946 0.00128533 0.00253226 ... 0.00215758 0.00410014 0.00441979]\n",
      "[ 0.00413849  0.00493047  0.00648015 ... -0.00591288 -0.00665695\n",
      " -0.00692771]\n",
      "[-2.48598204e-02 -2.28320369e-02 -2.08781276e-02 ...  6.63157855e-06\n",
      "  2.29027713e-03  4.94902155e-03]\n",
      "[-0.00939846 -0.00735624 -0.00601991 ...  0.01032262  0.01180112\n",
      "  0.01455032]\n",
      "[ 0.14384337  0.17375365  0.19498401 ... -0.06638113 -0.05396766\n",
      " -0.044372  ]\n",
      "[-0.0275279  -0.02648428 -0.0243121  ...  0.01346183  0.01749036\n",
      "  0.02041437]\n",
      "[0.07536961 0.0872476  0.09607759 ... 0.02831591 0.02803656 0.03006319]\n",
      "[ 0.03952535  0.039628    0.03887372 ... -0.05847439 -0.05780815\n",
      " -0.05695232]\n",
      "[-0.02448977 -0.0285843  -0.03095459 ... -0.01519776 -0.01391878\n",
      " -0.01220299]\n",
      "[ 0.09696848  0.0598859   0.02103229 ... -0.03273501 -0.03273389\n",
      " -0.03250129]\n",
      "[-0.02043537 -0.02545818 -0.02916769 ...  0.01724928  0.02255082\n",
      "  0.02732556]\n",
      "[ 0.01268343  0.01191616  0.01129704 ... -0.02741242 -0.03272899\n",
      " -0.03747739]\n",
      "[-0.02449308 -0.02739468 -0.03121105 ... -0.02274064 -0.02569261\n",
      " -0.02928395]\n",
      "[-0.00973741 -0.0055657  -0.00128068 ... -0.00419055 -0.00375707\n",
      " -0.00338203]\n",
      "[-0.12565392 -0.10431642 -0.07960792 ...  0.02900792  0.02650496\n",
      "  0.02432179]\n",
      "[-0.02290793 -0.01724511 -0.0118014  ... -0.00196993  0.01825825\n",
      "  0.05573701]\n",
      "[-0.0266012  -0.02603948 -0.02500383 ...  0.02186207  0.0227093\n",
      "  0.02345358]\n",
      "[ 0.03930481  0.02469485  0.02758162 ... -0.00432517 -0.00057526\n",
      "  0.09368097]\n",
      "[-0.13444216 -0.13098649 -0.1274192  ... -0.04112815 -0.03879051\n",
      " -0.03492187]\n",
      "[-0.05551926 -0.05528628 -0.05213553 ... -0.02252646 -0.02540125\n",
      " -0.02811833]\n",
      "[-0.02488288 -0.02308397 -0.02122682 ... -0.04896064 -0.05814588\n",
      " -0.06557292]\n",
      "[-0.01257013  0.07584897  0.07968414 ...  0.0022477   0.00643684\n",
      "  0.01555045]\n",
      "[ 0.10832343  0.1854821   0.26009799 ... -0.05554319 -0.05613696\n",
      " -0.05650129]\n",
      "[ 0.00105471 -0.00023807 -0.00083272 ...  0.01932562  0.02393194\n",
      "  0.02829373]\n",
      "[-0.15644719 -0.17052935 -0.16405481 ... -0.26076279 -0.25141772\n",
      " -0.24091993]\n",
      "[-0.02155741 -0.01843721 -0.01577235 ... -0.04985629 -0.01425909\n",
      "  0.02862622]\n",
      "[-0.03965527 -0.04050957 -0.04121934 ...  0.02407196  0.02265374\n",
      "  0.01940919]\n",
      "[-0.02054133 -0.01845909 -0.01648556 ...  0.00125581  0.00151971\n",
      "  0.00175851]\n",
      "[ 0.01053724  0.0078334   0.00496575 ... -0.05005703 -0.04602758\n",
      " -0.03204008]\n",
      "[-0.00541129 -0.00403681 -0.00211506 ...  0.02779875  0.02589789\n",
      "  0.02338796]\n",
      "[ 0.0028095   0.00374207  0.00511994 ... -0.02276112 -0.01910396\n",
      " -0.01426974]\n",
      "[ 0.06213374  0.04848552  0.03188246 ... -0.02598799 -0.0268383\n",
      " -0.02459904]\n",
      "[-0.05398608 -0.05058484 -0.04665702 ... -0.03508148 -0.03613018\n",
      " -0.0363309 ]\n",
      "[ 0.03367533  0.03197382  0.03068419 ... -0.01720449 -0.01697501\n",
      " -0.01678173]\n",
      "[ 0.05879756  0.0612057   0.06247274 ... -0.02996877 -0.0313363\n",
      " -0.0311212 ]\n",
      "[ 0.0495574   0.03707491  0.03605469 ... -0.07283064 -0.06940803\n",
      " -0.07339272]\n",
      "[-0.01159032 -0.01584176 -0.02061177 ...  0.00440411  0.0005013\n",
      " -0.00301845]\n",
      "[ 0.03516405  0.03567346  0.04459645 ... -0.00339165 -0.00709548\n",
      " -0.01039501]\n",
      "[-0.04186287 -0.04191287 -0.04165325 ...  0.00056053 -0.00111483\n",
      " -0.00302599]\n",
      "[-0.02307864 -0.01172506  0.00634426 ...  0.00097114  0.00684964\n",
      "  0.01289469]\n",
      "[-0.01206017 -0.01001473 -0.00835163 ...  0.00860997  0.00755686\n",
      "  0.00512541]\n",
      "[-0.79834146 -0.77953099 -0.69091216 ...  0.04962196  0.03310481\n",
      "  0.02363848]\n",
      "[-0.00229644 -0.00028408  0.00193463 ...  0.00912463  0.00802517\n",
      "  0.00671168]\n",
      "[0.01780903 0.01305738 0.00750199 ... 0.04115539 0.04028223 0.04027664]\n",
      "[-0.00041268  0.00135756  0.00261433 ...  0.07006309  0.05876865\n",
      "  0.03782477]\n",
      "[-0.05403163 -0.04904023 -0.04301731 ...  0.00117946  0.00123139\n",
      "  0.00083578]\n",
      "[ 0.00127341 -0.00153641 -0.00440792 ...  0.0115307   0.01171808\n",
      "  0.0119118 ]\n",
      "[-0.03546121 -0.03206068 -0.02860614 ... -0.00284954 -0.00026729\n",
      "  0.00242885]\n",
      "[ 0.16110782  0.17162412  0.18196421 ... -0.03620221 -0.03377142\n",
      " -0.03146145]\n",
      "[-0.01741106 -0.01182227 -0.00701199 ... -0.10436258 -0.08880477\n",
      " -0.07223012]\n",
      "[-0.00480866  0.01372481  0.01890224 ...  0.01072161  0.00756124\n",
      "  0.00346439]\n",
      "[0.06933058 0.06578245 0.0624837  ... 0.02267227 0.01789439 0.01293657]\n",
      "[ 0.0073126   0.00788211  0.00864187 ... -0.07897984 -0.07670028\n",
      " -0.07354345]\n",
      "[-0.02554866 -0.02718297 -0.02874629 ... -0.01783995 -0.01928285\n",
      " -0.02135782]\n",
      "[-0.01884511 -0.01777337 -0.01632764 ... -0.00102707  0.00364089\n",
      "  0.00754466]\n",
      "[ 0.01901862  0.02705707  0.02733832 ... -0.00805259 -0.00584431\n",
      " -0.00036316]\n",
      "[-0.16828386 -0.16224412 -0.14855418 ...  0.09946094  0.10038219\n",
      "  0.08498746]\n",
      "[0.01533503 0.01347132 0.01071891 ... 0.00844654 0.00602945 0.00265529]\n",
      "[ 0.00809347  0.00871392  0.00928234 ... -0.04009401 -0.04348659\n",
      " -0.04316648]\n",
      "[ 0.01197781  0.01412512  0.01593112 ... -0.00655215 -0.00581353\n",
      " -0.00409183]\n",
      "[ 0.00586327  0.0028075  -0.00068338 ... -0.04633273 -0.04590525\n",
      " -0.04463481]\n",
      "[ 0.02482546  0.02450188  0.02349636 ... -0.0311434  -0.03335038\n",
      " -0.03531248]\n",
      "[ 0.00018098 -0.00208501 -0.00904921 ... -0.01172026 -0.01269058\n",
      " -0.01251028]\n",
      "[ 0.01026886  0.01249429  0.01307315 ...  0.00026652  0.00028938\n",
      " -0.00132509]\n",
      "[ 0.00540857  0.00314504  0.00011154 ... -0.0705649  -0.06698303\n",
      " -0.05190966]\n",
      "[-0.04913894 -0.05401179 -0.05712678 ...  0.03768692  0.03793051\n",
      "  0.04840675]\n",
      "[0.02594358 0.02626416 0.03031426 ... 0.02550335 0.0277255  0.02611565]\n",
      "[-0.04653958 -0.03006896 -0.02110039 ...  0.00743115  0.00950091\n",
      "  0.0115978 ]\n",
      "[-0.01827058 -0.01730771 -0.01547973 ... -0.00203699 -0.00319032\n",
      " -0.00323342]\n",
      "[ 0.05435852  0.02736511 -0.00384537 ...  0.29119127  0.17812145\n",
      "  0.06218507]\n",
      "[0.04749023 0.06868184 0.07254186 ... 0.00236921 0.00375421 0.01302823]\n",
      "[ 0.04616294  0.06403817  0.08530812 ... -0.09320992 -0.08997327\n",
      " -0.08681229]\n",
      "[-0.00255128  0.00726205  0.01692132 ...  0.00831808  0.01196319\n",
      "  0.01581451]\n",
      "[-0.00489507 -0.01024411 -0.0120427  ... -0.07811761 -0.07169462\n",
      " -0.0545987 ]\n",
      "[-0.26178159 -0.14475945  0.0198048  ... -0.00461643 -0.00638157\n",
      " -0.00807203]\n",
      "[-0.0464615  -0.04859723 -0.04544682 ...  0.0771976   0.06824707\n",
      "  0.05171984]\n",
      "[-0.02582668 -0.02515456 -0.02363159 ... -0.14582087 -0.22664497\n",
      " -0.27172577]\n",
      "[-0.04803548 -0.04768769 -0.05118692 ...  0.49082106  0.52476324\n",
      "  0.52814386]\n",
      "[-0.01805257 -0.01536422 -0.01285828 ...  0.00717363  0.00676251\n",
      "  0.0068381 ]\n",
      "[ 0.02898268  0.03036807  0.03182731 ... -0.04196638 -0.04345871\n",
      " -0.04389717]\n",
      "[-0.00649533 -0.00657045 -0.00822049 ... -0.00581274 -0.00256402\n",
      "  0.0007427 ]\n",
      "[-0.00182534 -0.00247534 -0.00350747 ...  0.00911804  0.00812987\n",
      "  0.00671019]\n",
      "[-0.00685143 -0.00538104 -0.00468787 ...  0.00079987  0.00301898\n",
      "  0.0048923 ]\n",
      "[-0.46100831 -0.44958738 -0.43074941 ... -0.04278331 -0.04089092\n",
      " -0.03764551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/conda/envs/torch-gpu/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/test/conda/envs/torch-gpu/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02856568 -0.02891664 -0.02830183 ... -0.04911984 -0.05754158\n",
      " -0.06555812]\n",
      "[0.00144073 0.0061534  0.00695976 ... 0.00247972 0.00588978 0.01130825]\n",
      "[ 0.04570149  0.03384536  0.02312188 ... -0.05007528 -0.03200164\n",
      " -0.01386891]\n",
      "[-0.01458214 -0.01814681 -0.02185481 ... -0.0273624  -0.0258124\n",
      " -0.02486965]\n",
      "[-0.0865523  -0.08393314 -0.08150474 ...  0.0184804   0.01063716\n",
      "  0.00291402]\n",
      "[-0.00619537 -0.00658492 -0.00770205 ... -0.0019202  -0.03943557\n",
      " -0.06302422]\n",
      "[ 0.00598947  0.00603209  0.00587819 ... -0.01099436 -0.01351561\n",
      " -0.0151002 ]\n",
      "[0.00197816 0.00218537 0.00238776 ... 0.01621244 0.01629517 0.01268196]\n",
      "[0.00887492 0.00986681 0.01145628 ... 0.00291314 0.00147761 0.00026194]\n",
      "[-0.00734975 -0.00760802 -0.00768883 ... -0.02627442 -0.0290663\n",
      " -0.03196841]\n",
      "[-0.01312055 -0.01570924 -0.01756272 ...  0.01471096  0.01506208\n",
      "  0.01544326]\n",
      "[ 0.00103353 -0.00209196 -0.0041564  ... -0.03916478 -0.04933426\n",
      " -0.05497138]\n",
      "[0.1022325  0.08330141 0.06315465 ... 0.05066674 0.05613235 0.06138165]\n",
      "[ 0.22974721  0.06532724 -0.14605129 ... -0.00619934 -0.01093188\n",
      " -0.014808  ]\n",
      "[0.02951679 0.02892537 0.02774528 ... 0.0138807  0.01422386 0.01398272]\n",
      "[-0.03433601 -0.04000444 -0.04565533 ... -0.00162858 -0.00241823\n",
      " -0.00321205]\n",
      "[-0.04891808 -0.05090276 -0.05093008 ... -0.00521517 -0.00501416\n",
      " -0.00333211]\n",
      "[-0.10765902 -0.1127943  -0.1187947  ...  0.03272136  0.02950093\n",
      "  0.0248541 ]\n",
      "[ 0.27998758  0.20663093  0.1113685  ... -0.0237273  -0.02565326\n",
      " -0.02737932]\n",
      "[-0.03501096 -0.03953476 -0.04324263 ...  0.01007543  0.01111252\n",
      "  0.01214765]\n",
      "[-0.01993678 -0.02001298 -0.01974156 ... -0.02069866 -0.02038386\n",
      " -0.01954773]\n",
      "[-0.00451609 -0.00449499 -0.0035058  ... -0.01201378 -0.01425417\n",
      " -0.01478843]\n",
      "[ 0.19669354  0.17259901  0.12109062 ... -0.00647384 -0.00609012\n",
      " -0.00574332]\n",
      "[ 0.01101601  0.00719203  0.00696126 ... -0.12429352 -0.12547727\n",
      " -0.12754796]\n",
      "[0.02471299 0.02547193 0.02617899 ... 0.00715696 0.00300722 0.00043171]\n",
      "[-2.23925299e-05 -1.17571696e-03 -3.07590835e-03 ... -2.32138921e-02\n",
      " -1.89735369e-02 -1.61698424e-02]\n",
      "[0.07668966 0.07682238 0.07249734 ... 0.01743071 0.02242915 0.04296533]\n",
      "[0.04821868 0.04874297 0.0480562  ... 0.01522345 0.01529971 0.01114074]\n",
      "[-0.04228467 -0.0379861  -0.03255562 ...  0.00395558  0.00039793\n",
      " -0.00269961]\n",
      "[-0.04359186 -0.04430568 -0.04454466 ... -0.00674845 -0.00350001\n",
      " -0.0001299 ]\n",
      "[-0.01591726 -0.01675089 -0.0154515  ... -0.02987481 -0.00450495\n",
      "  0.01241275]\n",
      "[-0.0240684   0.02148437  0.07427768 ...  0.01608954  0.01175721\n",
      "  0.00826162]\n",
      "[-0.00376206 -0.00601503 -0.00754086 ... -0.0193502  -0.01870141\n",
      " -0.01850087]\n",
      "[-0.00069307 -0.00270243 -0.00506481 ...  0.00988402  0.00795149\n",
      "  0.00631414]\n",
      "[-0.00124694  0.00842358  0.01481092 ...  0.01232392  0.01520491\n",
      "  0.01759291]\n",
      "[-0.05580474 -0.05291481 -0.04490669 ... -0.00080027 -0.00308827\n",
      " -0.00510303]\n",
      "[0.03162892 0.0338683  0.03429947 ... 0.20842659 0.19745435 0.17009896]\n",
      "[-0.01413425 -0.01960388 -0.02614447 ... -0.01797794 -0.01486534\n",
      " -0.01102961]\n",
      "[-0.010987   -0.01483423 -0.01857575 ... -0.04544072 -0.05630275\n",
      " -0.0649396 ]\n",
      "[-0.02927541 -0.02721786 -0.02874202 ... -0.05243246 -0.0559698\n",
      " -0.05960863]\n",
      "[ 0.00588521  0.00155463 -0.00135217 ...  0.02627215  0.02718119\n",
      "  0.02748664]\n",
      "[-0.00021703 -0.00309847 -0.0062986  ...  0.00522228  0.00855532\n",
      "  0.0119418 ]\n",
      "[-4.76010960e-02 -5.09244787e-02 -5.37420963e-02 ... -1.62991977e-03\n",
      " -6.12116766e-05  1.53429890e-03]\n",
      "[ 0.01191116  0.01192119  0.01171594 ... -0.01100167 -0.01568588\n",
      " -0.019763  ]\n",
      "[-0.01973592 -0.01642586 -0.00819498 ...  0.01447222  0.01221987\n",
      "  0.01060663]\n",
      "[ 0.04509761  0.01316498 -0.02546467 ...  0.10209721  0.0984901\n",
      "  0.09034994]\n",
      "[-0.01595296 -0.01339548 -0.01256586 ... -0.03158348 -0.03031493\n",
      " -0.02839327]\n",
      "[ 0.04852106 -0.0069964  -0.04615971 ... -0.0090228  -0.00435715\n",
      " -0.00242066]\n",
      "[-0.04918453 -0.04887101 -0.0520814  ...  0.03242897  0.03907838\n",
      "  0.04903178]\n",
      "[-0.04760169 -0.04756856 -0.04895562 ... -0.00899701 -0.00972392\n",
      " -0.00724039]\n",
      "[-0.0837271  -0.08071035 -0.07774754 ...  0.09312061  0.0907882\n",
      "  0.08478713]\n",
      "[-0.16369366 -0.16683197 -0.16857525 ... -0.10784624 -0.11342978\n",
      " -0.10519383]\n",
      "[ 0.0122162  -0.05178973 -0.1234648  ...  0.02352319  0.02500587\n",
      "  0.02682005]\n",
      "[ 0.01427671  0.01787393  0.01771669 ... -0.02283301 -0.01783151\n",
      " -0.01672338]\n",
      "[-0.05599094 -0.05306174 -0.04980488 ...  0.04142132  0.04024237\n",
      "  0.03800793]\n",
      "[-0.00743118 -0.00985868 -0.0151438  ...  0.00383134 -0.00126941\n",
      " -0.00645557]\n",
      "[-0.03727478 -0.03205024 -0.0289693  ...  0.00297968  0.0049753\n",
      "  0.00733419]\n",
      "[ 0.01423439  0.01246311  0.01047842 ... -0.01277088 -0.01179792\n",
      " -0.01033555]\n",
      "[-0.01409545 -0.01757446 -0.01975079 ... -0.05593518 -0.06954762\n",
      " -0.08113381]\n",
      "[0.01406708 0.01458016 0.01517486 ... 0.03872232 0.0379243  0.03537176]\n",
      "[ 0.00879749  0.01041494  0.01110756 ... -0.00262079 -0.00899326\n",
      " -0.01486594]\n",
      "[ 0.01420713  0.01408241  0.01987084 ... -0.00472283 -0.00335835\n",
      " -0.0019514 ]\n",
      "[0.44132832 0.5361346  0.55381706 ... 0.00684158 0.00824855 0.0082063 ]\n",
      "[0.10891862 0.11069996 0.10878795 ... 0.12881522 0.15195242 0.16927541]\n",
      "[-0.08022033 -0.08173049 -0.08244593 ... -0.01111183 -0.01303291\n",
      " -0.01468797]\n",
      "[-0.02520088 -0.03127667 -0.03667053 ... -0.0659956  -0.04704176\n",
      " -0.02638908]\n",
      "[0.00109057 0.00438437 0.00765278 ... 0.0128226  0.00981066 0.0073835 ]\n",
      "[-0.03193088 -0.0304095  -0.02718312 ...  0.59448757  0.61581819\n",
      "  0.57126894]\n",
      "[ 0.04468954  0.04256572  0.04029921 ... -0.04664839 -0.04666762\n",
      " -0.0455954 ]\n",
      "[-0.00622626 -0.00917945 -0.0125683  ... -0.00734322 -0.00855959\n",
      " -0.01102345]\n",
      "[-0.0228387  -0.02260416 -0.02383044 ...  0.07182479  0.07308799\n",
      "  0.07518254]\n",
      "[-0.00768805 -0.01368639 -0.0188213  ...  0.03364587  0.03279477\n",
      "  0.03203729]\n",
      "[-0.01413652 -0.01526962 -0.01648627 ...  0.03216061  0.03486083\n",
      "  0.03693184]\n",
      "[ 0.02151723  0.02113134  0.01954419 ... -0.00456612 -0.00328467\n",
      " -0.00139363]\n",
      "[ 0.09511042  0.09839573  0.10015626 ... -0.08380338 -0.08968339\n",
      " -0.09222337]\n",
      "[0.03508079 0.03960833 0.04403194 ... 0.12588765 0.08859224 0.04858268]\n",
      "[-0.03100576 -0.02807405 -0.02477407 ...  0.00833445  0.00655981\n",
      "  0.00497782]\n",
      "[ 0.00092552 -0.0005784  -0.00189138 ... -0.02863593 -0.02711381\n",
      " -0.02539196]\n",
      "[-0.07387271 -0.07908556 -0.07155537 ... -0.01059425 -0.01101559\n",
      " -0.01126615]\n",
      "[ 0.69749178  0.58153611  0.45730805 ... -0.00534301 -0.00556032\n",
      " -0.00568864]\n",
      "[-0.15076319 -0.13825966 -0.13411319 ... -0.00776584 -0.00579979\n",
      "  0.00682009]\n",
      "[-0.00482548 -0.00233792  0.00086627 ...  0.01378311  0.01420406\n",
      "  0.01434354]\n",
      "[-0.01988806 -0.02080825 -0.02147139 ...  0.07770859  0.07541623\n",
      "  0.07253657]\n",
      "[-0.00412189  0.00502435  0.0159491  ...  0.00518208 -0.00660927\n",
      " -0.01339601]\n",
      "[0.03781755 0.03929673 0.03940996 ... 0.00384878 0.00524922 0.00680523]\n",
      "[ 0.00131213 -0.00121334 -0.00439828 ... -0.01672954 -0.01566124\n",
      " -0.01466066]\n",
      "[-0.00583816 -0.0059157  -0.00563294 ... -0.03867816 -0.0401226\n",
      " -0.04147006]\n",
      "[-0.01194106 -0.01101446 -0.00894537 ... -0.05998524 -0.06497679\n",
      " -0.07011038]\n",
      "[-0.0048803   0.00124052  0.00767816 ...  0.01234331  0.01344785\n",
      "  0.01442897]\n",
      "[-0.06288528 -0.06143896 -0.06174026 ...  0.00066497  0.00242918\n",
      "  0.00436151]\n",
      "[-0.00241967 -0.00205411 -0.00127542 ... -0.02246141 -0.02569602\n",
      " -0.02846862]\n",
      "[ 0.00734315  0.0099247   0.00511914 ... -0.05825694 -0.05680506\n",
      " -0.05179163]\n",
      "[-0.00740161 -0.00736311 -0.00726955 ...  0.06132115  0.07583641\n",
      "  0.09042897]\n",
      "[ 0.00517843  0.01611835  0.02593505 ... -0.04706808 -0.04840548\n",
      " -0.05024493]\n",
      "[ 0.01138649  0.01424346  0.01773041 ... -0.0377304  -0.03810274\n",
      " -0.03989037]\n",
      "[-0.00859066 -0.00265377  0.00321051 ... -0.04108873 -0.0359016\n",
      " -0.03097106]\n",
      "[-0.03026249 -0.03186328 -0.0323892  ... -0.01235377 -0.01297604\n",
      " -0.01231737]\n",
      "[ 0.03206322  0.03157126  0.04709658 ... -0.00091419 -0.00126569\n",
      " -0.00124608]\n",
      "[-0.0150484  -0.01822329 -0.02111768 ...  0.00525016  0.00671585\n",
      "  0.00817624]\n",
      "[ 0.01951797  0.01555178  0.01230543 ... -0.04030799 -0.04022212\n",
      " -0.04128832]\n",
      "[-0.05258732 -0.05300724 -0.04370166 ... -0.00563572 -0.00876011\n",
      " -0.01098834]\n",
      "[-0.06342395 -0.07893823 -0.08803278 ...  0.00237232  0.00268426\n",
      "  0.00284081]\n",
      "[ 0.02997227  0.02520657  0.02034436 ... -0.02627201 -0.02784448\n",
      " -0.02934708]\n",
      "[0.0230277  0.02298011 0.0217764  ... 0.0641773  0.07205077 0.07954555]\n",
      "[-0.41907885 -0.18921325  0.08751779 ... -0.22536115 -0.1505404\n",
      " -0.06561879]\n",
      "[0.0456101  0.03991127 0.03634158 ... 0.00143292 0.00189471 0.00216747]\n",
      "[-0.00373417 -0.00357051 -0.0028963  ... -0.00115302 -0.00361436\n",
      " -0.00563437]\n",
      "[-0.01706721 -0.01925137 -0.02002214 ... -0.00861416 -0.00706654\n",
      " -0.0048927 ]\n",
      "[ 0.07470791  0.07122235  0.06771492 ... -0.05889608 -0.05524409\n",
      " -0.05196488]\n",
      "[0.00328494 0.00397972 0.00504445 ... 0.03404923 0.03673434 0.03856099]\n",
      "[-0.03247062 -0.0346003  -0.03563914 ...  0.00189489  0.00343829\n",
      "  0.00486265]\n",
      "[-0.01515875 -0.01176866 -0.01290369 ... -0.01290594 -0.01448112\n",
      " -0.0127112 ]\n",
      "[0.18589859 0.16658049 0.1274435  ... 0.0178944  0.01411947 0.01144124]\n",
      "[-0.00975713 -0.0142442  -0.01893266 ... -0.08862915 -0.0938566\n",
      " -0.09830805]\n",
      "[0.0130779  0.01081403 0.00941019 ... 0.04263089 0.04658134 0.0507523 ]\n",
      "[-0.01852796 -0.01719067 -0.01666215 ... -0.00290693 -0.00224536\n",
      " -0.00169897]\n",
      "[0.17802236 0.27670807 0.36526407 ... 0.00330562 0.00296302 0.00295055]\n",
      "[-0.03615389 -0.03486367 -0.03354935 ...  0.00199571  0.00371436\n",
      "  0.00553751]\n",
      "[ 0.00146237  0.00439884  0.00809679 ... -0.03463657 -0.03515181\n",
      " -0.03557602]\n",
      "[ 0.01002628  0.00942629  0.00731615 ... -0.03915046 -0.03501866\n",
      " -0.03100376]\n",
      "[ 0.00570285  0.00720137  0.00863249 ... -0.0010824  -0.00287877\n",
      " -0.00451331]\n",
      "[ 0.02119607  0.02222799  0.0230766  ...  0.00276383 -0.00465829\n",
      " -0.01464566]\n",
      "[-0.03449947 -0.03299493 -0.03232652 ... -0.03320514 -0.03577418\n",
      " -0.03742059]\n",
      "[-0.00601892 -0.00793768 -0.0088917  ... -0.00244576 -0.00380114\n",
      " -0.0048529 ]\n",
      "[ 0.00379099 -0.00144211 -0.00312807 ... -0.00637277 -0.00272541\n",
      "  0.00076022]\n",
      "[0.00382106 0.00417321 0.00399504 ... 0.01488175 0.02119155 0.0275879 ]\n",
      "[ 0.00956347  0.01068195  0.01251253 ... -0.14805486 -0.14430508\n",
      " -0.13964404]\n",
      "[ 0.02036905  0.02470439  0.02955934 ... -0.12668614 -0.12628664\n",
      " -0.12526064]\n",
      "[ 0.03158762  0.05088016  0.07400275 ... -0.02284682 -0.02563031\n",
      " -0.02604673]\n",
      "[-0.01514117 -0.02380992 -0.03116546 ...  0.01659202  0.01840533\n",
      "  0.0202486 ]\n",
      "[-0.02538453 -0.02195532 -0.01769607 ...  0.01197141  0.01278596\n",
      "  0.01304698]\n",
      "[0.08501152 0.22519289 0.3456142  ... 0.09197771 0.06943227 0.0491551 ]\n",
      "[-0.00578311 -0.00401256 -0.00364188 ...  0.02140414  0.02533102\n",
      "  0.02885198]\n",
      "[-0.22485132 -0.16832832 -0.09233221 ...  0.67441527  0.63621531\n",
      "  0.55535266]\n",
      "[ 0.02938223  0.02882461  0.02653644 ... -0.02457218 -0.02483586\n",
      " -0.02441253]\n",
      "[-0.02964947 -0.02796864 -0.02680501 ...  0.01924285  0.01965912\n",
      "  0.01991167]\n",
      "[-0.06338931 -0.06170771 -0.06023909 ...  0.00187788  0.00324692\n",
      "  0.00390731]\n",
      "[0.00908095 0.00830253 0.00746748 ... 0.01307472 0.0092321  0.00494722]\n",
      "[-0.12909193 -0.13257067 -0.13462335 ...  0.05448528  0.05740904\n",
      "  0.03648755]\n",
      "[-0.01334272 -0.01102157 -0.00874323 ... -0.00655587 -0.00801558\n",
      " -0.0095168 ]\n",
      "[-0.01879314 -0.02454741 -0.0223103  ... -0.01949453 -0.01079504\n",
      " -0.00120907]\n",
      "[-0.00549629 -0.00496693 -0.00516968 ... -0.00992004 -0.00423246\n",
      "  0.00200602]\n",
      "[ 0.00475207 -0.00222237 -0.00586793 ... -0.01393933 -0.01209164\n",
      " -0.010281  ]\n",
      "[ 0.00095378 -0.0043197  -0.00993875 ... -0.10048684 -0.10991987\n",
      " -0.11580797]\n",
      "[-0.02314956 -0.01962809 -0.01520024 ...  0.02686131  0.02767228\n",
      "  0.02792625]\n",
      "[-0.00653333 -0.00776871 -0.00841998 ... -0.02413598 -0.02111229\n",
      " -0.01710044]\n",
      "[-0.01716308 -0.01776942 -0.01828903 ... -0.04962029 -0.04553624\n",
      " -0.04156041]\n",
      "[0.07615063 0.07501356 0.07565053 ... 0.02212897 0.02234334 0.01511697]\n",
      "[ 0.07383832  0.08529983  0.08698    ... -0.00414135 -0.00356706\n",
      "  0.00392769]\n",
      "[-0.01016256 -0.01143713 -0.01250899 ... -0.02431802 -0.0265169\n",
      " -0.02790792]\n",
      "[-0.03903406 -0.03947636 -0.03941033 ... -0.05298401 -0.05266332\n",
      " -0.05165784]\n",
      "[ 0.08521509  0.07617429  0.07693442 ... -0.03282059 -0.03457343\n",
      " -0.03400129]\n",
      "[-0.00120062 -0.00125525 -0.0010239  ... -0.00480555 -0.00300602\n",
      " -0.0012988 ]\n",
      "[-0.04322773 -0.05115432 -0.05492912 ... -0.00232803 -0.00340268\n",
      " -0.00412435]\n",
      "[-0.02458754 -0.0195149  -0.0168671  ... -0.012136   -0.00644526\n",
      "  0.00257958]\n",
      "[-0.0155639  -0.01579173 -0.01502608 ... -0.09074104 -0.08673967\n",
      " -0.08733148]\n",
      "[-4.81842120e-03  2.34593157e-04  6.41246581e-03 ...  2.68445202e-01\n",
      "  1.69898277e-01  6.06888059e-02]\n",
      "[0.02283226 0.02316777 0.02362179 ... 0.03882376 0.03364461 0.03004204]\n",
      "[-0.0038734  -0.00477239 -0.00562809 ...  0.01101434  0.01200715\n",
      "  0.0124042 ]\n",
      "[0.00130278 0.00829616 0.01540976 ... 0.04929894 0.04423631 0.03881813]\n",
      "[0.05049666 0.05246801 0.05400944 ... 0.03562901 0.03812904 0.0340602 ]\n",
      "[-0.02011562 -0.02180445 -0.02361914 ... -0.01926632 -0.02843886\n",
      " -0.03691843]\n",
      "[-0.02535669 -0.02967699 -0.03261571 ...  0.01389583  0.0146631\n",
      "  0.0160631 ]\n",
      "[-0.00255618 -0.00630801 -0.0100298  ... -0.00957502 -0.01263735\n",
      " -0.01501699]\n",
      "[ 0.00694222 -0.03984924 -0.08996603 ...  0.01945257  0.02398021\n",
      "  0.02830957]\n",
      "[0.07507585 0.07851933 0.08091342 ... 0.29555052 0.29405599 0.255482  ]\n",
      "[ 0.14359519  0.15587478  0.16711237 ... -0.06807721 -0.0648979\n",
      " -0.0565145 ]\n",
      "[-0.00652455 -0.00914881 -0.01070556 ...  0.01959228  0.02084589\n",
      "  0.02170538]\n",
      "[ 0.00573482  0.00510471  0.00510137 ... -0.04862115 -0.03193589\n",
      " -0.0043882 ]\n",
      "[ 0.04402669  0.04423913  0.04742443 ... -0.01694402 -0.00904249\n",
      "  0.00066492]\n",
      "[-0.03797696 -0.03592549 -0.033768   ... -0.00301319 -0.00572071\n",
      " -0.0083505 ]\n",
      "[ 0.06373522  0.05258707  0.03955596 ... -0.00475933 -0.005904\n",
      " -0.00720864]\n",
      "[-0.03352195 -0.03473738 -0.03561106 ...  0.02128186  0.01275489\n",
      "  0.00660893]\n",
      "[-0.00555233 -0.00650593 -0.00732181 ... -0.02221872 -0.02537443\n",
      " -0.0289442 ]\n",
      "[ 0.01585999  0.01693844  0.01734728 ... -0.03071315 -0.02831542\n",
      " -0.02621501]\n",
      "[ 0.14234304  0.16633834  0.1787704  ... -0.00300882 -0.00273659\n",
      " -0.00265626]\n",
      "[ 0.00260836 -0.00022303  0.00173609 ... -0.01781307 -0.00985791\n",
      " -0.0034134 ]\n",
      "[0.05530617 0.06131125 0.06355684 ... 0.06087838 0.05830983 0.05227563]\n",
      "[-0.02014817 -0.01808281 -0.01609858 ...  0.02764895  0.02851348\n",
      "  0.02918753]\n",
      "[-0.03284549 -0.03262689 -0.0327698  ... -0.05280248 -0.05101309\n",
      " -0.04893296]\n",
      "[-0.01308489 -0.01249422 -0.01065163 ... -0.30717598 -0.32430817\n",
      " -0.34451032]\n",
      "[ 0.04819313  0.06527576  0.08100631 ... -0.00636883 -0.01590874\n",
      " -0.0242733 ]\n",
      "[0.22065248 0.19363175 0.16630186 ... 0.0271673  0.02639813 0.02536429]\n",
      "[-0.01534889 -0.01525761 -0.0158668  ...  0.00041437  0.00039137\n",
      "  0.00076374]\n",
      "[0.03104218 0.03122856 0.03078374 ... 0.01957424 0.02276758 0.02581205]\n",
      "[-0.02617678 -0.0217181  -0.01715049 ... -0.02620962 -0.0255552\n",
      " -0.02422935]\n",
      "[-0.0158208  -0.01318015 -0.01062696 ... -0.01791152 -0.01705657\n",
      " -0.01575808]\n",
      "[-0.00128844  0.00124508  0.00389502 ... -0.02292214 -0.02050492\n",
      " -0.01783392]\n",
      "[-0.03525893 -0.03895646 -0.03791337 ...  0.04250743  0.04673575\n",
      "  0.05005893]\n",
      "[-0.21685028 -0.39403252 -0.52950252 ...  0.25836748  0.50227887\n",
      "  0.69538378]\n",
      "[-0.09485319 -0.10814373 -0.12272602 ...  0.12237068  0.12319772\n",
      "  0.1588862 ]\n",
      "[0.01528676 0.01602152 0.01663384 ... 0.09809008 0.09183133 0.08495566]\n",
      "[ 1.12559378e-02  6.24162150e-03 -6.92742918e-05 ... -8.09694951e-03\n",
      " -6.30795104e-03 -4.03866906e-03]\n",
      "[-4.98738335e-03  9.62549158e-05 -2.81185139e-05 ... -1.62161392e-02\n",
      " -2.12635266e-02 -4.09965648e-02]\n",
      "[ 0.01263669  0.0103338   0.00712616 ... -0.00775551 -0.00694172\n",
      " -0.00603259]\n",
      "[ 9.33488920e-04  7.18777428e-04  9.95313753e-05 ... -3.96849274e-03\n",
      " -4.16401545e-03 -3.66086335e-03]\n",
      "[-0.01535906 -0.01228658 -0.00934381 ...  0.05321294  0.04661473\n",
      "  0.04204527]\n",
      "[-0.03350103 -0.03662583 -0.0398298  ...  0.02126614  0.01874519\n",
      "  0.01598431]\n",
      "[-0.01501386 -0.01669951 -0.01940267 ... -0.0394624  -0.03839624\n",
      " -0.03606741]\n",
      "[ 0.2530794   0.19964647  0.19660315 ... -0.01297956 -0.01769243\n",
      " -0.04095772]\n",
      "[0.02463973 0.02514326 0.02649265 ... 0.01136669 0.01344422 0.01594626]\n",
      "[-0.01388134 -0.01267611 -0.01068402 ... -0.01141706 -0.0106201\n",
      " -0.0098128 ]\n",
      "[-0.07123773 -0.0751166  -0.077223   ... -0.00541064 -0.00518016\n",
      " -0.00494475]\n",
      "[-0.02045243 -0.01953045 -0.01872966 ... -0.03555865 -0.03262445\n",
      " -0.03060507]\n",
      "[-0.01212569 -0.01142459 -0.00723336 ...  0.00608596  0.00675986\n",
      "  0.00743609]\n",
      "[-0.01515291 -0.01324283 -0.01163338 ...  0.0054978   0.00452352\n",
      "  0.00341635]\n",
      "[-0.058912   -0.058808   -0.05635043 ... -0.60907534 -0.60358842\n",
      " -0.54945788]\n",
      "[-0.01848618 -0.01856745 -0.01779867 ... -0.06875524 -0.07441399\n",
      " -0.07618263]\n",
      "[-0.01408996 -0.01684747 -0.017195   ...  0.05197093  0.0531314\n",
      "  0.05159353]\n",
      "[ 0.00349163  0.00107966 -0.00291156 ...  0.00527853  0.00729114\n",
      "  0.00879222]\n",
      "[-0.00141183 -0.00449913 -0.00810875 ... -0.00985024 -0.01689223\n",
      " -0.02454019]\n",
      "[-0.03312923 -0.03767746 -0.04144154 ... -0.01297922 -0.01400856\n",
      " -0.01435856]\n",
      "[-0.00171937  0.0008226   0.00308365 ... -0.04153974 -0.0311715\n",
      " -0.02222019]\n",
      "[-0.00643649 -0.00679411 -0.0060463  ... -0.06037315 -0.05527146\n",
      " -0.04767446]\n",
      "[-0.00869999 -0.00776666 -0.00708249 ... -0.0304981  -0.02934959\n",
      " -0.0274067 ]\n",
      "[-0.0155753  -0.02203983 -0.02798911 ... -0.11437612 -0.08463156\n",
      " -0.05044269]\n",
      "[-0.03305266 -0.03654252 -0.03988528 ...  0.00309812  0.00411472\n",
      "  0.00517312]\n",
      "[0.01856962 0.01365388 0.00840151 ... 0.00888466 0.00607509 0.00354665]\n",
      "[-0.00795457 -0.00746113 -0.00644307 ...  0.01927674  0.02082481\n",
      "  0.02260122]\n",
      "[-0.00627627 -0.00658078 -0.00586574 ... -0.03739335 -0.03696627\n",
      " -0.03517897]\n",
      "[0.00202216 0.00741176 0.0129868  ... 0.00705152 0.00612917 0.0036438 ]\n",
      "[-0.01098777 -0.01019662 -0.00877656 ...  0.20229195  0.19309583\n",
      "  0.18355944]\n",
      "[-0.01092758 -0.01298068 -0.01286328 ...  0.02397713  0.01762904\n",
      "  0.00971669]\n",
      "[0.00186952 0.09612943 0.19547899 ... 0.26302816 0.26329225 0.26020781]\n",
      "[-0.16025721 -0.15886672 -0.15535686 ...  0.01837225  0.01947626\n",
      "  0.02036928]\n",
      "[-0.0265008  -0.02854599 -0.02994273 ...  0.00811196  0.01188012\n",
      "  0.01562032]\n",
      "[-0.02679936 -0.02717875 -0.02872323 ...  0.0264404   0.0285103\n",
      "  0.02994594]\n",
      "[-0.02472883 -0.02106778 -0.01735442 ... -0.04959545 -0.04855863\n",
      " -0.04723606]\n",
      "[-0.00710724 -0.00368823 -0.00277132 ... -0.00397416 -0.00714974\n",
      " -0.01051641]\n",
      "[ 0.00441877  0.001288   -0.00174369 ...  0.01037447  0.01279637\n",
      "  0.01517871]\n",
      "[-0.00101842 -0.0001378   0.00070577 ...  0.00126359 -0.00081185\n",
      "  0.00032235]\n",
      "[-0.00264289 -0.00999472 -0.01609594 ... -0.03413764 -0.03098283\n",
      " -0.02764719]\n",
      "[-0.01631319 -0.01381843 -0.01060324 ...  0.00159858  0.00248463\n",
      "  0.00391674]\n",
      "[-0.14079411 -0.14013446 -0.13389452 ... -0.01094301 -0.00932871\n",
      " -0.00722177]\n",
      "[ 0.03929227  0.04628412  0.04946213 ... -0.04401894 -0.05036279\n",
      " -0.05887253]\n",
      "[-0.00920615 -0.00738851 -0.00562292 ... -0.06342636 -0.06076207\n",
      " -0.05775878]\n",
      "[-0.01292322 -0.01639492 -0.01974854 ...  0.04363281  0.05196273\n",
      "  0.0586537 ]\n",
      "[-0.43967642 -0.24628333 -0.0198691  ... -0.00546278 -0.0042064\n",
      " -0.00132627]\n",
      "[ 0.02786524  0.02586405  0.02704084 ... -0.00366532 -0.00275035\n",
      " -0.00019527]\n",
      "[-0.36669407 -0.31024854 -0.2671541  ... -0.12575776 -0.13827693\n",
      " -0.14483772]\n",
      "[ 0.01687809  0.01437609  0.01570851 ... -0.00767933 -0.00691777\n",
      " -0.0056283 ]\n",
      "[ 0.00961844  0.00997927  0.01030513 ... -0.00105233 -0.00181778\n",
      " -0.0025799 ]\n",
      "[ 1.13294396e-02  1.10159839e-02  1.06840783e-02 ... -3.87975775e-03\n",
      " -1.91628693e-03  8.08515180e-05]\n",
      "[-0.05590487 -0.0546644  -0.05323021 ...  0.00974812  0.0132157\n",
      "  0.01708228]\n",
      "[-0.00309321 -0.0058655  -0.00936133 ...  0.00905524  0.00924934\n",
      "  0.00925839]\n",
      "[ 0.02238294  0.02302387  0.02385091 ... -0.00710816 -0.00541928\n",
      " -0.00344049]\n",
      "[0.01109717 0.01394709 0.01559503 ... 0.00986893 0.01042366 0.01116596]\n",
      "[0.03847398 0.03977163 0.0407278  ... 0.03285794 0.03518255 0.03754365]\n",
      "[ 0.01831274  0.02069258  0.02261499 ... -0.04208063 -0.04128543\n",
      " -0.04075015]\n",
      "[ 0.00607714  0.00597776  0.00612239 ... -0.04160583 -0.04611918\n",
      " -0.05027219]\n",
      "[-0.0675929  -0.07547814 -0.08248324 ... -0.00339255 -0.004228\n",
      " -0.00504042]\n",
      "[-0.02351882 -0.02192846 -0.02031163 ... -0.01125256 -0.01187263\n",
      " -0.0121349 ]\n",
      "[-0.9560172  -1.03326792 -1.08873308 ... -0.02215817 -0.02425883\n",
      " -0.02565738]\n",
      "[0.17014849 0.13823786 0.09974885 ... 0.0071834  0.00394057 0.00138336]\n",
      "[-0.04476192 -0.0437192  -0.04209344 ... -0.0009988   0.00512252\n",
      "  0.01194632]\n",
      "[-0.00582994 -0.00894741 -0.01154602 ... -0.01884398 -0.02105553\n",
      " -0.02315882]\n",
      "[-0.03616184 -0.01222961  0.02499575 ...  0.00558545 -0.00126208\n",
      " -0.00523795]\n",
      "[ 0.03029744  0.02821213  0.02499702 ... -0.00683203 -0.00977114\n",
      " -0.01199447]\n",
      "[-0.01255239 -0.00519978  0.00222429 ...  0.01077677  0.0096128\n",
      "  0.00846638]\n",
      "[0.02673908 0.0299199  0.0326209  ... 0.02245553 0.02258892 0.02266199]\n",
      "[ 0.00273518  0.0035054   0.00406102 ... -0.04910003 -0.05453775\n",
      " -0.06459909]\n",
      "[ 0.04476829  0.041302    0.03454341 ... -0.00943016 -0.00856674\n",
      " -0.00627907]\n",
      "[ 0.05388557  0.06044411  0.05712001 ... -0.0460477  -0.04845423\n",
      " -0.04640148]\n",
      "[ 0.07745587  0.06932544  0.06055921 ... -0.03762873 -0.03234262\n",
      " -0.02699288]\n",
      "[-0.03791535 -0.03690434 -0.03489034 ... -0.03535716 -0.03485124\n",
      " -0.03337629]\n",
      "[0.03721984 0.03717845 0.03681054 ... 0.03084029 0.0336913  0.03626598]\n",
      "[-0.02190203 -0.01829224 -0.01496723 ... -0.17443419 -0.15301302\n",
      " -0.11450091]\n",
      "[ 0.00226716  0.00082302 -0.00043501 ... -0.00208379 -0.00147738\n",
      " -0.00091896]\n",
      "[ 0.04863423  0.00998782 -0.02539728 ... -0.03227482 -0.04677322\n",
      " -0.06303786]\n",
      "[ 0.00639092  0.00809198  0.00943865 ... -0.00052847  0.00389969\n",
      "  0.00767628]\n",
      "[-0.02429198 -0.02215553 -0.02018142 ...  0.00675534  0.00698773\n",
      "  0.00663474]\n",
      "[-0.05707495 -0.05716186 -0.0587728  ... -0.03395258 -0.02962893\n",
      " -0.02502349]\n",
      "[-0.0125548  -0.01101125 -0.00895199 ... -0.00239273 -0.00410692\n",
      " -0.00582604]\n",
      "[ 0.01560581  0.01812364  0.01993746 ...  0.00169584 -0.00190657\n",
      " -0.00536553]\n",
      "[-0.01104662 -0.01764308 -0.02642331 ...  0.0750759   0.08202523\n",
      "  0.08897461]\n",
      "[ 0.03211351  0.03523909  0.03837709 ... -0.02610966 -0.02893948\n",
      " -0.03110022]\n",
      "[ 0.00187923  0.00528406  0.00866651 ...  0.00368612  0.0015257\n",
      " -0.00066933]\n",
      "[-0.00062296 -0.00027691  0.00045725 ... -0.01980624 -0.01990626\n",
      " -0.01994781]\n",
      "[-0.03059023 -0.02627101 -0.02374033 ... -0.02656152 -0.04571429\n",
      " -0.0627185 ]\n",
      "[0.01824785 0.01805766 0.02097269 ... 0.14614125 0.15421698 0.15558976]\n",
      "[ 0.03929655  0.01265927 -0.00714671 ...  0.02241839  0.03816335\n",
      "  0.05258733]\n",
      "[ 0.06365463  0.05990527  0.05606757 ... -0.00569016 -0.00813608\n",
      " -0.00953885]\n",
      "[-0.03688488 -0.04601324 -0.05051852 ... -0.02234903 -0.01355856\n",
      " -0.00983267]\n",
      "[ 0.02027097 -0.00251315 -0.02785973 ...  0.03834268  0.03585715\n",
      "  0.03186154]\n",
      "[-0.0110495  -0.01259637 -0.01387564 ... -0.02196979 -0.027349\n",
      " -0.0326901 ]\n",
      "[-0.04350175 -0.04522444 -0.047173   ...  0.01708124  0.01606661\n",
      "  0.01557305]\n",
      "[-0.00496485  0.06224776  0.13131648 ...  0.08466292  0.07260788\n",
      "  0.07368315]\n",
      "[-0.01984482 -0.02429596 -0.02703916 ... -0.12943551 -0.11132561\n",
      " -0.08058935]\n",
      "[0.09027036 0.0858436  0.08181205 ... 0.01291956 0.01236058 0.01192287]\n",
      "[0.00094953 0.00218161 0.0035412  ... 0.56709375 0.56309141 0.55919007]\n",
      "[-0.01560658 -0.01795659 -0.02174369 ... -0.02864431 -0.02099438\n",
      " -0.014304  ]\n",
      "[-0.03818363 -0.03730678 -0.03668194 ...  0.21060663  0.22521392\n",
      "  0.22347309]\n",
      "[-0.03252657 -0.03183509 -0.03240473 ...  0.02681495  0.02560418\n",
      "  0.02435587]\n",
      "[-0.00542324 -0.00570058 -0.00528983 ...  0.19616634  0.20795265\n",
      "  0.20487133]\n",
      "[-0.05400935 -0.05769158 -0.06078886 ... -0.01776133 -0.01735475\n",
      " -0.01672029]\n",
      "[-0.07474462 -0.08760293 -0.10225167 ... -0.01507659 -0.01552842\n",
      " -0.01596102]\n",
      "[-0.01854059 -0.01925811 -0.01819021 ...  0.06059832  0.09410051\n",
      "  0.12215884]\n",
      "[-0.04410332 -0.04182241 -0.03900151 ... -0.04670965 -0.04218823\n",
      " -0.03798104]\n",
      "[-0.00923596  0.00266173  0.01147752 ... -0.30168628 -0.19777106\n",
      " -0.06329752]\n",
      "[-0.01826444 -0.01772143 -0.01813446 ...  0.08196313  0.09062558\n",
      "  0.09690006]\n",
      "[-0.0047332  -0.00238338  0.00014995 ...  0.0193784   0.01438669\n",
      "  0.00887255]\n",
      "[-0.02158987 -0.01614271 -0.01065955 ...  0.01864886  0.02125282\n",
      "  0.02373589]\n",
      "[0.07434819 0.08400307 0.08049511 ... 0.45065934 0.47887772 0.50249856]\n",
      "[-0.06964797 -0.06567715 -0.0612669  ...  0.01826707  0.01908031\n",
      "  0.02155003]\n",
      "[-0.03903297 -0.0389653  -0.03881778 ...  0.01562931  0.01517024\n",
      "  0.01631667]\n",
      "[-0.0071256  -0.00430023 -0.00055408 ...  0.00314872  0.00721368\n",
      "  0.01102402]\n",
      "[0.00832152 0.00912212 0.0096408  ... 0.55717212 0.30143709 0.03430256]\n",
      "[0.00634585 0.00822839 0.00923088 ... 0.02679843 0.02893017 0.03031316]\n",
      "[-0.107987   -0.11929193 -0.1187657  ...  0.01100266  0.01263477\n",
      "  0.01429477]\n",
      "[-0.29007222 -0.30651948 -0.33254782 ... -0.02534408 -0.0035618\n",
      "  0.04810459]\n",
      "[-0.01256801 -0.00950466 -0.00523508 ... -0.03207851 -0.0405357\n",
      " -0.04896445]\n",
      "[0.02200342 0.02130576 0.01967115 ... 0.00462523 0.00500446 0.00551622]\n",
      "[ 0.03761734  0.03830294  0.03862301 ... -0.10782966 -0.11015722\n",
      " -0.11951006]\n",
      "[-0.03769573  0.03902817  0.11133932 ... -0.1729544  -0.1337403\n",
      " -0.08443933]\n",
      "[0.11217335 0.19816891 0.29221108 ... 0.07429348 0.0944873  0.11610553]\n",
      "[0.02710784 0.02568787 0.02358637 ... 0.01807238 0.01973636 0.0219494 ]\n",
      "[-0.04507033 -0.12581695 -0.18345735 ...  0.00389597  0.00333305\n",
      "  0.00276234]\n",
      "[-0.05059457 -0.0458145  -0.04114061 ... -0.0301654  -0.02834953\n",
      " -0.02633716]\n",
      "[ 0.00127395  0.00180197  0.00163101 ... -0.02199078 -0.02229544\n",
      " -0.02181038]\n",
      "[0.09048451 0.09340598 0.0952304  ... 0.01125583 0.01503079 0.01813038]\n",
      "[-0.01972519 -0.0227455  -0.02450886 ...  0.02350461  0.02301056\n",
      "  0.02268519]\n",
      "[-0.00499355 -0.00706149 -0.00979373 ... -0.02843377 -0.02617168\n",
      " -0.02394076]\n",
      "[-0.07189442 -0.06234452 -0.0549605  ...  0.01356012  0.01574812\n",
      "  0.01620776]\n",
      "[ 0.02881811  0.03186747  0.03501624 ... -0.01175439 -0.01572092\n",
      " -0.01976985]\n",
      "[-0.01767742 -0.0147495  -0.01256571 ...  0.00993474 -0.05901463\n",
      " -0.11988495]\n",
      "[ 0.32400522  0.24066061  0.14535417 ...  0.11734046  0.04576936\n",
      " -0.04093998]\n",
      "[-0.02737521 -0.01450938 -0.00688461 ... -0.36982849 -0.06424099\n",
      "  0.2175125 ]\n",
      "[-0.00750353 -0.00587382 -0.00275395 ... -0.00633192 -0.0069411\n",
      " -0.00703454]\n",
      "[0.36206212 0.37254194 0.3700817  ... 0.01620665 0.02170732 0.02692544]\n",
      "[-0.03298548 -0.03052533 -0.02664848 ... -0.02441114 -0.02384848\n",
      " -0.02235731]\n",
      "[ 0.03900981  0.0393409   0.03930793 ... -0.11846966 -0.11884977\n",
      " -0.1041997 ]\n",
      "[-0.02920099 -0.02502301 -0.01989464 ... -0.06878758 -0.03542488\n",
      "  0.01178791]\n",
      "[ 0.05177166  0.05511212  0.05834169 ... -0.04661412 -0.04649065\n",
      " -0.0471027 ]\n",
      "[ 0.00277928  0.0035559   0.0036873  ... -0.00141817 -0.00260637\n",
      " -0.00204002]\n",
      "[0.02609356 0.02832146 0.03041536 ... 0.09591671 0.09784745 0.09968138]\n",
      "[-0.11488888 -0.12236424 -0.12891141 ... -0.03361464 -0.03650065\n",
      " -0.03900078]\n",
      "[-0.12900452 -0.11343982 -0.08740592 ... -0.07645379 -0.07597949\n",
      " -0.081558  ]\n",
      "[ 0.01552483  0.01026739  0.01100178 ... -0.07129766 -0.06866678\n",
      " -0.0493341 ]\n",
      "[0.01998122 0.02224079 0.02428503 ... 0.01307042 0.01651933 0.0200786 ]\n",
      "[-0.0360464  -0.03682743 -0.03766063 ... -0.00115579 -0.00129195\n",
      " -0.00128543]\n",
      "[-0.01519797 -0.01447833 -0.01371359 ...  0.01250375  0.0147168\n",
      "  0.01726019]\n",
      "[-0.00061175  0.00537062  0.01345356 ...  0.01075552  0.01075617\n",
      "  0.01024054]\n",
      "[-0.04527795 -0.04910292 -0.05248072 ...  0.05912487  0.06096517\n",
      "  0.07201976]\n",
      "[-0.04915492 -0.05064481 -0.05157545 ... -0.00964271 -0.01166631\n",
      " -0.01322731]\n",
      "[0.04997403 0.02675664 0.00696047 ... 0.16829016 0.18486406 0.20410844]\n",
      "[-0.10031312 -0.09958021 -0.0984197  ... -0.02902259 -0.02493529\n",
      " -0.02207705]\n",
      "[ 0.06559174  0.05339811  0.05217311 ... -0.05430879 -0.05248601\n",
      " -0.04513174]\n",
      "[ 0.00265839  0.00325553  0.00336782 ... -0.0319068  -0.0434011\n",
      " -0.05188242]\n",
      "[-0.05966752 -0.06087655 -0.0618346  ...  0.0804149   0.08162313\n",
      "  0.08259032]\n",
      "[ 0.51995725  0.45642774  0.36683636 ... -0.03412898 -0.01998444\n",
      " -0.00686639]\n",
      "[-0.02510178 -0.02301707 -0.02250795 ...  0.01398298  0.01455609\n",
      "  0.01466427]\n",
      "[-0.07410981 -0.07577591 -0.07786838 ... -0.01508059 -0.01451606\n",
      " -0.01340335]\n",
      "[0.0076555  0.00955567 0.01098266 ... 0.11371581 0.06815211 0.02651901]\n",
      "[ 0.00747037 -0.00257356 -0.01378225 ...  0.03603538  0.03647565\n",
      "  0.03771563]\n",
      "[0.20644735 0.22025549 0.21648584 ... 0.10957327 0.05533467 0.00675514]\n",
      "[-0.00331981 -0.00608126 -0.00887975 ...  0.00448048  0.00758348\n",
      "  0.00911886]\n",
      "[0.04589195 0.04965595 0.05172767 ... 0.0413278  0.04248581 0.02379536]\n",
      "[0.01317887 0.01420436 0.01522239 ... 0.0208294  0.02055735 0.02020761]\n",
      "[-0.06299521 -0.06100741 -0.05882827 ... -0.0453065  -0.04015284\n",
      " -0.03574544]\n",
      "[-0.06742432 -0.06940658 -0.07442894 ... -0.00403261 -0.00238824\n",
      " -0.00232824]\n",
      "[0.03455565 0.02885856 0.02247764 ... 0.01189183 0.0129574  0.01311362]\n",
      "[ 0.0266797   0.02478652  0.01966747 ... -0.00488004 -0.00154462\n",
      " -0.00139431]\n",
      "[ 0.01894759  0.02204453  0.02514338 ... -0.02282436 -0.01952626\n",
      " -0.01610135]\n",
      "[-0.02635882 -0.02504809 -0.0242735  ... -0.02005965 -0.01941515\n",
      " -0.01857033]\n",
      "[-0.98495722 -1.06663569 -1.09247321 ...  0.0236206   0.03549762\n",
      "  0.04519536]\n",
      "[-0.09561425 -0.07140077 -0.03588299 ...  0.19466209  0.17512589\n",
      "  0.15685087]\n",
      "[ 0.02907881  0.02868475  0.02766875 ...  0.00349512 -0.00158037\n",
      " -0.00653686]\n",
      "[0.04217135 0.04084598 0.03900025 ... 0.02590889 0.02782732 0.02921562]\n",
      "[ 0.03713314  0.0548289   0.06891835 ... -0.10349423 -0.09769164\n",
      " -0.09218109]\n",
      "[-0.01861008 -0.02237029 -0.02553578 ... -0.02428018 -0.01911831\n",
      " -0.00935393]\n",
      "[ 3.36598550e-03 -2.42492908e-04 -4.17142051e-03 ...  1.85598036e-01\n",
      "  2.26757962e-01  2.51076204e-01]\n",
      "[-0.00580358 -0.00955112 -0.01367272 ... -0.08409945 -0.08701076\n",
      " -0.08930316]\n",
      "[0.49471693 0.47843266 0.45680194 ... 0.00719127 0.01905793 0.02312224]\n",
      "[-0.0199473  -0.02130436 -0.02529267 ... -0.02826033 -0.03198786\n",
      " -0.03614266]\n",
      "[-0.00696504 -0.00739711 -0.00710877 ... -0.01457567 -0.01673158\n",
      " -0.01811887]\n",
      "[-0.00276045 -0.00336337 -0.00400831 ... -0.02985157 -0.03361705\n",
      " -0.03666884]\n",
      "[ 0.00708937  0.00224158 -0.00277844 ...  0.02349951  0.03098048\n",
      "  0.03901196]\n",
      "[0.07755267 0.07861165 0.07940918 ... 0.13642402 0.14344835 0.15053441]\n",
      "[-0.00533268 -0.00675305 -0.00898006 ... -0.00916439 -0.00924444\n",
      " -0.00940561]\n",
      "[-0.00477758  0.00038553  0.00660595 ... -0.04262594 -0.04440751\n",
      " -0.04664916]\n",
      "[0.10142982 0.10310181 0.10470358 ... 0.00528212 0.01140767 0.01884233]\n",
      "[-0.00605009 -0.00332988 -0.00024071 ... -0.00746037 -0.00670138\n",
      " -0.00565254]\n",
      "[0.01029626 0.01062808 0.00956778 ... 0.00820977 0.00964876 0.01088155]\n",
      "[0.0198294  0.02770231 0.03184681 ... 0.07940307 0.08172272 0.0836699 ]\n",
      "[0.60360989 0.61925743 0.61850863 ... 0.06449512 0.06721171 0.07251835]\n",
      "[-0.07468891 -0.07559015 -0.07691292 ...  0.28429012  0.21153998\n",
      "  0.12887459]\n",
      "[-0.01437343 -0.01312219 -0.01232733 ... -0.00151089 -0.00084967\n",
      " -0.00020374]\n",
      "[-0.04643534 -0.04846747 -0.0498629  ... -0.03377839 -0.03353982\n",
      " -0.03344022]\n",
      "[ 0.00596394  0.00431336 -0.00054017 ... -0.00362356 -0.00192116\n",
      " -0.00020057]\n",
      "[ 0.03976683  0.04143216  0.042619   ... -0.0007184   0.00055084\n",
      "  0.00166239]\n",
      "[-0.01019961 -0.01112761 -0.01102947 ... -0.05751812 -0.0631593\n",
      " -0.05599603]\n",
      "[-0.00529304 -0.00454338 -0.00313398 ... -0.00642739 -0.00798242\n",
      " -0.00874492]\n",
      "[0.01549825 0.01686235 0.01802763 ... 0.00300849 0.00233033 0.00187302]\n",
      "[-0.09626759 -0.09107001 -0.08561121 ... -0.00457068  0.0019487\n",
      "  0.00662235]\n",
      "[ 0.03357278  0.03336733  0.03314081 ... -0.04909442 -0.0584311\n",
      " -0.06309747]\n",
      "[ 0.00072784 -0.00304494 -0.00591876 ... -0.06331852 -0.06225144\n",
      " -0.05968949]\n",
      "[-0.00048371  0.00264184  0.00609335 ... -0.01866032 -0.01739455\n",
      " -0.01448458]\n",
      "[-0.04375646 -0.03943459 -0.03633322 ... -0.06741822 -0.06456075\n",
      " -0.05102618]\n",
      "[0.03719522 0.03327951 0.02955552 ... 0.13921661 0.13387293 0.11713839]\n",
      "[ 0.06377531  0.03759722  0.01137981 ... -0.03896824  0.0257776\n",
      "  0.08360721]\n",
      "[0.03926134 0.0383075  0.03636252 ... 0.01326697 0.01006972 0.00697311]\n",
      "[-0.6448296  -0.63164019 -0.62245678 ...  0.00591679  0.00302741\n",
      "  0.00113707]\n",
      "[ 0.01005769  0.01292187  0.01510127 ... -0.03924989 -0.03107804\n",
      " -0.02421468]\n",
      "[-0.11820314 -0.08508423 -0.04391919 ...  0.00265341  0.0051834\n",
      "  0.00823361]\n",
      "[ 0.00990577  0.00756763  0.00508394 ... -0.00056001 -0.00233604\n",
      " -0.00389687]\n",
      "[-0.00252193 -0.00217976 -0.00243301 ...  0.05408701  0.0431092\n",
      "  0.03269753]\n",
      "[-0.04916509 -0.04602819 -0.0427119  ... -0.09994374 -0.10049498\n",
      " -0.10061808]\n",
      "[-0.01406276 -0.01775457 -0.0222832  ... -0.0437692  -0.04425159\n",
      " -0.04361262]\n",
      "[-0.03974874 -0.04011369 -0.04186336 ... -0.00850274 -0.00674939\n",
      " -0.00822292]\n",
      "[ 0.13070423  0.13013645  0.12985976 ...  0.0137424  -0.00784317\n",
      " -0.03054619]\n",
      "[-0.09423786 -0.08856945 -0.08052569 ... -0.01087528 -0.01260159\n",
      " -0.01221578]\n",
      "[ 0.00535201  0.00479859  0.00434001 ... -0.02307513 -0.02566171\n",
      " -0.02784168]\n",
      "[ 0.0116996   0.01155168  0.0116632  ...  0.00187719  0.00053677\n",
      " -0.00033008]\n",
      "[0.05674888 0.06966429 0.08958658 ... 0.01712842 0.01881661 0.02053566]\n",
      "[-0.01508523 -0.00793404 -0.00181735 ... -0.04150356 -0.03031306\n",
      " -0.02045295]\n",
      "[0.13729762 0.15889071 0.17374232 ... 0.0413418  0.03400987 0.02499487]\n",
      "[-0.01960769 -0.01949803 -0.0196005  ... -0.10561231 -0.0998342\n",
      " -0.0974528 ]\n",
      "[-0.45043528 -0.59242012 -0.74151226 ...  0.01987084  0.03052214\n",
      "  0.04460999]\n",
      "[ 4.06235618e-02  9.44307652e-02  1.49289739e-01 ...  1.20922836e-03\n",
      " -3.89355061e-05 -8.53752190e-04]\n",
      "[-0.04378204 -0.04803777 -0.04951531 ...  0.02887546  0.02676033\n",
      "  0.02526518]\n",
      "[-0.01959931 -0.01977463 -0.02032701 ... -0.00402296 -0.00365526\n",
      " -0.00361544]\n",
      "[-1.13624055e-02 -1.15945758e-02 -1.04907663e-02 ...  8.87212483e-05\n",
      "  1.94681648e-03  3.85607246e-03]\n",
      "[-0.0217659  -0.0302744  -0.03171345 ... -0.01371572 -0.01788991\n",
      " -0.03330116]\n",
      "[ 0.19209964  0.22330293  0.23773481 ... -0.01774343 -0.01844942\n",
      " -0.01728326]\n",
      "[-0.02179097 -0.01942052 -0.01659493 ...  0.02448808  0.02632005\n",
      "  0.02794556]\n",
      "[-0.00567277 -0.00656342 -0.00644954 ... -0.01828132 -0.01806214\n",
      " -0.01824763]\n",
      "[ 0.00427545 -0.00142545 -0.00775801 ... -0.03101976 -0.03341451\n",
      " -0.03520283]\n",
      "[ 0.1739087   0.14153109  0.0950142  ... -0.03415381 -0.03411351\n",
      " -0.02984283]\n",
      "[0.00807347 0.01235756 0.0155698  ... 0.01002146 0.01228884 0.01391355]\n",
      "[ 0.00893016  0.00651372  0.00294204 ... -0.08468976 -0.06867232\n",
      " -0.04809858]\n",
      "[-0.02712008 -0.01896631 -0.00916929 ... -0.00721186 -0.01033592\n",
      " -0.01504836]\n",
      "[-0.04824973 -0.03333771 -0.02739435 ...  0.02186836  0.02186864\n",
      "  0.02023575]\n",
      "[-0.1628824  -0.16885893 -0.15214619 ... -0.40246491 -0.36629905\n",
      " -0.32425198]\n",
      "[ 0.02847682  0.03486765  0.03617507 ... -0.17658701 -0.17103727\n",
      " -0.15563199]\n",
      "[-0.05036987 -0.05072352 -0.0508214  ... -0.00253961 -0.00714425\n",
      " -0.01174175]\n",
      "[-0.00066432 -0.00056966 -0.00020391 ... -0.00510418  0.00146747\n",
      "  0.00860725]\n",
      "[-0.02512699  0.01794015  0.06898202 ... -0.00882483 -0.01035317\n",
      " -0.01186822]\n",
      "[-0.0132411  -0.01487247 -0.01597919 ...  0.00636063  0.00524475\n",
      "  0.00436848]\n",
      "[-0.01556394 -0.01571549 -0.01623604 ... -0.14264461 -0.11488477\n",
      " -0.06782675]\n",
      "[0.34931858 0.28373144 0.21251063 ... 0.85297443 0.86646678 0.86018284]\n",
      "[ 0.03801758  0.04029979  0.04201513 ... -0.03708183 -0.03292153\n",
      " -0.02929081]\n",
      "[-0.02159541 -0.02299155 -0.02417857 ... -0.02055497 -0.02008501\n",
      " -0.01985772]\n",
      "[0.02654109 0.02605253 0.02710823 ... 0.00418148 0.00414497 0.00248302]\n",
      "[-0.06689962 -0.05681279 -0.04488615 ...  0.02606334  0.03436497\n",
      "  0.04108261]\n",
      "[-0.01555498 -0.01701567 -0.01720342 ... -0.01574719 -0.0235219\n",
      " -0.02743483]\n",
      "[-0.00183584  0.00362249  0.01132111 ... -0.0157363  -0.01595802\n",
      " -0.01630735]\n",
      "[ 3.00700358e-02  3.03895080e-02  3.01758945e-02 ...  7.07932426e-04\n",
      " -2.58753233e-05 -4.83607664e-04]\n",
      "[0.00389807 0.00240317 0.00103805 ... 0.00477478 0.00544769 0.00639571]\n",
      "[-0.00900836  0.0305827   0.07893257 ... -0.0250826  -0.02771922\n",
      " -0.02981162]\n",
      "[-0.08050946 -0.0333113   0.02610045 ... -0.01089828 -0.00891962\n",
      " -0.00796016]\n",
      "[ 0.00091102 -0.00634518 -0.01328285 ...  0.21194188  0.24906539\n",
      "  0.26240371]\n",
      "[ 0.04570149  0.03384536  0.02312188 ... -0.05007528 -0.03200164\n",
      " -0.01386891]\n",
      "[0.15243173 0.14001879 0.10666172 ... 0.03579602 0.03736229 0.03943877]\n",
      "[-0.01440567 -0.00834081 -0.00142094 ...  0.00817062  0.03064936\n",
      "  0.05822245]\n",
      "[ 0.01622838  0.01530885  0.01425205 ... -0.00121387 -0.00012404\n",
      "  0.00047091]\n",
      "[0.02258686 0.02884521 0.03617593 ... 0.54722752 0.40510817 0.23653342]\n",
      "[ 0.03977131  0.04265241  0.04636215 ... -0.05747787 -0.0548917\n",
      " -0.05212023]\n",
      "[-0.03039112 -0.03088138 -0.03062456 ... -0.00457831 -0.0086675\n",
      " -0.01207108]\n",
      "[-0.01048093 -0.01171431 -0.01197905 ... -0.00223551 -0.00513245\n",
      " -0.0070505 ]\n",
      "[0.01034901 0.0099539  0.00959215 ... 0.04296931 0.04323647 0.0429697 ]\n",
      "[-0.00617634 -0.00471145 -0.00371225 ... -0.12461612 -0.10593509\n",
      " -0.07517475]\n",
      "[-0.04538393 -0.06267726 -0.06661755 ...  0.05123288  0.04852728\n",
      "  0.05685485]\n",
      "[-0.02813115 -0.02848705 -0.03096757 ...  0.00470346  0.00907572\n",
      "  0.01142457]\n",
      "[-0.0123882  -0.01112204 -0.00843157 ... -0.11688805 -0.10446553\n",
      " -0.08761568]\n",
      "[-0.04292321 -0.04263587 -0.04211568 ...  0.00376491  0.00343087\n",
      "  0.00305867]\n",
      "[-0.04585932 -0.02003069 -0.01606979 ...  0.01291057  0.01130038\n",
      "  0.00529358]\n",
      "[ 0.01735915  0.01624229  0.01509878 ... -0.00690453 -0.0043822\n",
      " -0.00181032]\n",
      "[ 0.02225715  0.02503582  0.0278175  ... -0.01849265 -0.01847302\n",
      " -0.01808572]\n",
      "[-0.17953723 -0.0951138  -0.0305132  ... -0.58146509 -0.57675655\n",
      " -0.54892386]\n",
      "[-0.00521332 -0.00502931 -0.00412488 ... -0.02515098 -0.02669058\n",
      " -0.02856436]\n",
      "[-0.01631483 -0.02861262 -0.04038457 ...  0.01340581  0.01648488\n",
      "  0.01586441]\n",
      "[-0.00586606 -0.0066779  -0.00676514 ... -0.02160421 -0.01905206\n",
      " -0.01676503]\n",
      "[-0.01450817 -0.01498285 -0.0171587  ...  0.32292368  0.19423177\n",
      "  0.06841555]\n",
      "[-0.06483542 -0.06732246 -0.07031877 ...  0.04924178  0.05239489\n",
      "  0.05505043]\n",
      "[-0.02967281 -0.03182742 -0.0336415  ...  0.01408074  0.01887482\n",
      "  0.02319637]\n",
      "[-0.00258729 -0.01541114 -0.02858073 ... -0.06403076 -0.07030169\n",
      " -0.07567912]\n",
      "[-0.00117825 -0.00170989 -0.00203696 ...  0.00877077  0.01136206\n",
      "  0.01471681]\n",
      "[-0.01232116 -0.01675082 -0.0201785  ... -0.00897327 -0.01433642\n",
      " -0.02005706]\n",
      "[ 0.06053804  0.08253237  0.09172917 ... -0.0112907  -0.01497251\n",
      " -0.01701777]\n",
      "[-0.01157866 -0.00917221 -0.00585299 ...  0.00400054  0.00377875\n",
      "  0.00285853]\n",
      "[-0.03451605 -0.02498    -0.01422741 ...  0.2857961   0.25491428\n",
      "  0.20624296]\n",
      "[-0.06330911 -0.06702903 -0.07072315 ...  0.0994362   0.09254324\n",
      "  0.08893814]\n",
      "[ 0.00414173  0.00188492 -0.00069096 ... -0.04849376 -0.02953916\n",
      " -0.00957078]\n",
      "[-0.01138115 -0.01049863 -0.00901977 ...  0.01916306  0.02208\n",
      "  0.02377044]\n",
      "[ 0.01512073  0.01728121  0.01908107 ... -0.15279298 -0.13084273\n",
      " -0.09269502]\n",
      "[-0.02695412 -0.03148597 -0.0357143  ...  0.02902087  0.03995794\n",
      "  0.05104407]\n",
      "[-0.00454605 -0.00051602  0.00486762 ...  0.00082891  0.01736288\n",
      "  0.03076466]\n",
      "[-0.02262933 -0.02452592 -0.02551507 ...  0.02532788  0.02645222\n",
      "  0.02764245]\n",
      "[-0.0145618  -0.01664619 -0.01792493 ... -0.04334266 -0.04399573\n",
      " -0.04191351]\n",
      "[-0.03838145 -0.02760278 -0.01703513 ...  0.39977613  0.40468587\n",
      "  0.37859761]\n",
      "[ 0.01448692  0.02760954  0.03246251 ... -0.02210001 -0.0215426\n",
      " -0.01999872]\n",
      "[ 0.00792837  0.00694333  0.00585647 ... -0.01833213 -0.02175725\n",
      " -0.02445911]\n",
      "[-0.03084589 -0.02940703 -0.02686986 ... -0.00433163 -0.00617687\n",
      " -0.00808813]\n",
      "[-0.03010106 -0.03020289 -0.02927274 ... -0.01125412 -0.01540489\n",
      " -0.01874533]\n",
      "[-0.04031908 -0.03960584 -0.03811572 ... -0.03122448 -0.03181637\n",
      " -0.03175325]\n",
      "[-0.04256177 -0.04382288 -0.04560073 ...  0.00391401  0.00600053\n",
      "  0.00829194]\n",
      "[-0.00653876 -0.00264193  0.00053225 ...  0.00071795  0.00239153\n",
      "  0.00426825]\n",
      "[-0.05385654 -0.05059456 -0.04706073 ...  0.57965969  0.57676302\n",
      "  0.55680804]\n",
      "[-0.03634227 -0.03297968 -0.03064564 ... -0.01431649 -0.01411139\n",
      " -0.01368758]\n",
      "[ 0.01250928  0.01284408  0.01327684 ... -0.00129342  0.00082952\n",
      "  0.00281637]\n",
      "[-0.05277531 -0.05655467 -0.05408368 ... -0.02224033 -0.01940498\n",
      " -0.01671592]\n",
      "[ 0.01418575  0.02370161  0.02459483 ... -0.04401159 -0.04406229\n",
      " -0.02994605]\n",
      "[ 0.00141733  0.00030009 -0.00100111 ... -0.00492426 -0.00626061\n",
      " -0.00724827]\n",
      "[ 0.24148154  0.23104245  0.22400309 ... -0.03786772 -0.0385693\n",
      " -0.03916375]\n",
      "[-0.00900878 -0.01045456 -0.01210803 ...  0.03442778  0.03446799\n",
      "  0.03334661]\n",
      "[-0.03253184 -0.03324637 -0.03391912 ... -0.00054731 -0.00538216\n",
      " -0.00949349]\n",
      "[-0.01160748 -0.00910312 -0.00590265 ... -0.03313334 -0.0372741\n",
      " -0.04061917]\n",
      "[ 2.46008935e-02 -3.33250967e-04  5.01582093e-04 ...  5.54233443e-01\n",
      "  5.57550383e-01  6.02164615e-01]\n",
      "[-0.09253743 -0.12114413 -0.14278886 ...  0.19258724  0.24633902\n",
      "  0.28356927]\n",
      "[-0.02879857 -0.02880209 -0.02784783 ... -0.00815945 -0.00820954\n",
      " -0.00845816]\n",
      "[-0.03301748 -0.03062725 -0.02846038 ... -0.01037168 -0.01464464\n",
      " -0.01920145]\n",
      "[-0.13750966 -0.25233912 -0.35365095 ... -0.02623125 -0.0259542\n",
      " -0.02504617]\n",
      "[ 0.00997526  0.00886782  0.00825593 ... -0.06236831 -0.05904299\n",
      " -0.05426989]\n",
      "[ 0.09028275  0.05314125  0.01288648 ... -0.02855411 -0.03119451\n",
      " -0.02979051]\n",
      "[-0.07208791 -0.09880559 -0.12899981 ...  0.0015532  -0.00609968\n",
      " -0.01211558]\n",
      "[ 0.00084535  0.00179449  0.0036877  ... -0.02640762 -0.02482748\n",
      " -0.02406585]\n",
      "[-0.02706098 -0.03958241 -0.0474175  ... -0.22122676 -0.20763462\n",
      " -0.1901846 ]\n",
      "[0.01437163 0.00843543 0.00084833 ... 0.03688537 0.09078448 0.14485856]\n",
      "[-0.01565425 -0.01737355 -0.01892989 ...  0.19097996  0.19340912\n",
      "  0.200172  ]\n",
      "[-0.02955311 -0.0276455  -0.02561959 ... -0.04340395 -0.04646814\n",
      " -0.04608196]\n",
      "[-0.0002201  -0.00083236 -0.00169265 ... -0.04580209 -0.04866167\n",
      " -0.0513279 ]\n",
      "[-0.0271534  -0.04213373 -0.05545489 ...  0.03823845  0.03330219\n",
      "  0.02847582]\n",
      "[ 0.0604908   0.04213497  0.02641411 ... -0.00067835  0.00344766\n",
      "  0.00835023]\n",
      "[-0.04793415 -0.05350803 -0.05427509 ...  0.02738301  0.02626363\n",
      "  0.02426033]\n",
      "[-0.03785488 -0.03884021 -0.03864268 ...  0.08675715  0.10538204\n",
      "  0.11529171]\n",
      "[-0.01580341 -0.01579646 -0.01566105 ... -0.00059455  0.00039973\n",
      "  0.0023352 ]\n",
      "[ 0.21988987  0.21507541  0.20328607 ... -0.00465794 -0.00708787\n",
      " -0.00833899]\n",
      "[ 0.00886302  0.01849539  0.02678354 ... -0.03971686 -0.05342564\n",
      " -0.06246797]\n",
      "[ 0.01857527  0.02257271  0.02563729 ... -0.00936837 -0.01400063\n",
      " -0.01933684]\n",
      "[-0.02261278 -0.02359555 -0.02447128 ...  0.00973385  0.00958127\n",
      "  0.00920537]\n",
      "[-0.03046347 -0.03060618 -0.03036335 ... -0.00306728 -0.00171352\n",
      " -0.00024646]\n",
      "[ 0.01050343  0.00295573 -0.00519916 ...  0.25971481  0.24950258\n",
      "  0.22205697]\n",
      "[-0.03190271 -0.04672082 -0.06012132 ...  0.04610614  0.0511762\n",
      "  0.05662949]\n",
      "[ 0.00608323  0.00699618  0.00782198 ... -0.00864004 -0.01046411\n",
      " -0.012228  ]\n",
      "[ 0.04279126  0.03998974  0.03552291 ... -0.01861387 -0.01211907\n",
      " -0.00583287]\n",
      "[-0.02333774 -0.02184134 -0.01840857 ... -0.00878819 -0.01087999\n",
      " -0.01256902]\n",
      "[ 0.07129998  0.01914961 -0.03182739 ...  0.01022691  0.01443224\n",
      "  0.01616068]\n",
      "[-0.00231174  0.00069799  0.00391904 ... -0.00408747 -0.00542015\n",
      " -0.00704871]\n",
      "[ 0.0006319   0.00132653  0.0017205  ...  0.00456647  0.00081548\n",
      " -0.00171398]\n",
      "[-2.16672970e-02 -2.14708402e-02 -2.05219204e-02 ... -5.63674831e-04\n",
      " -3.30459225e-04  9.33926104e-05]\n",
      "[-0.00661011 -0.00502937 -0.00331635 ...  0.00315382 -0.00552024\n",
      " -0.01294875]\n",
      "[ 0.00198642  0.00284715  0.00208016 ...  0.00037629  0.00133775\n",
      " -0.00091659]\n",
      "[ 0.00051321  0.00222819  0.00386643 ... -0.03139235 -0.03482211\n",
      " -0.04012932]\n",
      "[ 0.07185921  0.06782969  0.06260447 ... -0.0698986  -0.06614983\n",
      " -0.06270967]\n",
      "[-0.02983637 -0.03281368 -0.03186756 ...  0.0054219   0.00029465\n",
      " -0.00306793]\n",
      "[0.0159069  0.03932211 0.05052376 ... 0.0721763  0.11304018 0.14458909]\n",
      "[-0.00961757 -0.00570604 -0.00067574 ... -0.00485586  0.00087164\n",
      "  0.00635515]\n",
      "[ 0.00396427  0.00044928 -0.00281533 ... -0.02386039  0.04074559\n",
      "  0.09580893]\n",
      "[0.02756229 0.03752916 0.04868867 ... 0.01612545 0.01482133 0.01345459]\n",
      "[-0.05020155 -0.04759685 -0.04511457 ...  0.0302625   0.02710815\n",
      "  0.02353666]\n",
      "[ 0.00249543 -0.00136221 -0.0079964  ...  0.00471622  0.00590432\n",
      "  0.00706016]\n",
      "[0.07434819 0.08400307 0.08049511 ... 0.4506597  0.4788781  0.50249896]\n",
      "[-0.01618236 -0.0405072  -0.05282185 ... -0.01130033  0.02838749\n",
      "  0.05647484]\n",
      "[ 0.05558091  0.02925976 -0.00321969 ...  0.01544607  0.01525143\n",
      "  0.0153325 ]\n",
      "[0.01457227 0.01314566 0.0108341  ... 0.05049189 0.04394827 0.03681001]\n",
      "[-0.00015327 -0.00029978 -0.00081265 ...  0.02824664  0.02788213\n",
      "  0.02713176]\n",
      "[-0.08697612 -0.08575846 -0.08110771 ... -0.02782509 -0.0281187\n",
      " -0.02462072]\n",
      "[-0.26184498 -0.28905058 -0.31661239 ... -0.11180045 -0.11069377\n",
      " -0.09963902]\n",
      "[-0.00848581 -0.00863555 -0.00916    ...  0.00439858  0.00306369\n",
      "  0.00221388]\n",
      "[ 0.02047571  0.01794238  0.01481637 ... -0.03250166 -0.03730686\n",
      " -0.04106345]\n",
      "[ 0.03023183  0.03163146  0.03159165 ... -0.00501921  0.01165049\n",
      "  0.02971514]\n",
      "[-0.12209681 -0.15122816 -0.14076049 ... -0.05654178 -0.04800206\n",
      " -0.03809474]\n",
      "[-0.06341497 -0.06216515 -0.0618674  ... -0.00098644 -0.0032187\n",
      " -0.00538812]\n",
      "[-0.0217909  -0.02117366 -0.02116854 ...  0.0208472   0.02149828\n",
      "  0.02265324]\n",
      "[-0.04609605 -0.03321084 -0.01958534 ... -0.01756399 -0.01391065\n",
      " -0.01017211]\n",
      "[ 0.12066351  0.11550419  0.11021524 ... -0.05195002 -0.00149983\n",
      "  0.03835417]\n",
      "[ 0.03885357  0.05783393  0.08293843 ... -0.01279166 -0.00379816\n",
      "  0.00477507]\n",
      "[-0.03417916 -0.03779102 -0.03768159 ...  0.03890014  0.0347023\n",
      "  0.03035089]\n",
      "[0.16681638 0.11445895 0.06753909 ... 0.01825107 0.01316055 0.01060495]\n",
      "[-0.01125105 -0.013368   -0.01810051 ... -0.00499697 -0.00486959\n",
      " -0.00450555]\n",
      "[ 0.18167213  0.17010208  0.16020645 ...  0.00604557  0.00021939\n",
      " -0.0061691 ]\n",
      "[ 0.00752306 -0.01323734 -0.03467608 ...  0.04036957  0.02844871\n",
      "  0.0159543 ]\n",
      "[ 0.51483466  0.27945737 -0.02875361 ... -0.03560082 -0.02166105\n",
      " -0.00654171]\n",
      "[-0.2143303  -0.26577786 -0.264147   ...  0.00327566  0.0057829\n",
      "  0.01026507]\n",
      "[-0.73308257 -0.73188737 -0.73510225 ...  0.30138222  0.32668095\n",
      "  0.31965441]\n",
      "[0.31257321 0.29600534 0.2787745  ... 0.50046556 0.33984638 0.1947687 ]\n",
      "[-0.00480985 -0.00617467 -0.0069078  ...  0.00402473  0.00537889\n",
      "  0.00610889]\n",
      "[0.09937833 0.20225583 0.20913452 ... 0.003527   0.0045317  0.01828213]\n",
      "[-3.78691276e-04  4.51047366e-04  9.25518488e-05 ... -5.37440005e-03\n",
      " -1.47140212e-03  2.36579466e-03]\n",
      "[ 0.01978194  0.01928195  0.01870914 ... -0.05177568 -0.05318256\n",
      " -0.05411166]\n",
      "[0.01892322 0.01596076 0.01059103 ... 0.00609027 0.00560826 0.00246199]\n",
      "[ 0.01380642  0.05800397  0.10767657 ... -0.00506859 -0.00258084\n",
      "  0.00091964]\n",
      "[-0.0210396  -0.02138758 -0.02139822 ...  0.02105116  0.02557419\n",
      "  0.03139082]\n",
      "[-0.00718278 -0.0008097   0.00590571 ... -0.00486311 -0.00332937\n",
      " -0.00164364]\n",
      "[-0.01308161 -0.01234685 -0.01200793 ...  0.060987    0.06219159\n",
      "  0.06341218]\n",
      "[-5.73076204e-02 -5.28458008e-02 -4.83657721e-02 ... -4.72518793e-05\n",
      " -5.66738930e-04 -1.51522836e-03]\n",
      "[ 0.25437915  0.22546614  0.1797235  ... -0.00848299 -0.00753085\n",
      " -0.00737818]\n",
      "[-0.01533748 -0.01717404 -0.01873217 ... -0.00882117 -0.00942447\n",
      " -0.00868441]\n",
      "[0.11502099 0.11396732 0.11311824 ... 0.02542482 0.02838153 0.02476978]\n",
      "[-0.00364704 -0.00112381  0.0022679  ...  0.15924976  0.17605301\n",
      "  0.21656242]\n",
      "[-0.01320045 -0.01537987 -0.01722834 ... -0.00018449 -0.00116276\n",
      " -0.00169934]\n",
      "[ 0.00394712  0.00446052  0.00527456 ... -0.53488272 -0.54322343\n",
      " -0.53685559]\n",
      "[-0.10681877 -0.1131893  -0.11841222 ... -0.01586799 -0.0170779\n",
      " -0.01728026]\n",
      "[ 0.23155129  0.37350846  0.51591545 ... -0.01640792 -0.01333222\n",
      " -0.00834913]\n",
      "[ 0.00919869  0.02551172  0.02804044 ... -0.04658778 -0.04426762\n",
      " -0.04583144]\n",
      "[ 0.06259459  0.05969064  0.05694729 ... -0.00208188 -0.00054669\n",
      "  0.0011194 ]\n",
      "[0.00144073 0.0061534  0.00695976 ... 0.00247897 0.00588803 0.0113055 ]\n",
      "[-0.0571315  -0.04142562 -0.03006649 ...  0.02175772  0.01752972\n",
      "  0.00881314]\n",
      "[0.0201779  0.02347038 0.02694419 ... 0.01113596 0.01150266 0.0119458 ]\n",
      "[0.0280688  0.02620498 0.02423391 ... 0.0359209  0.03536189 0.03090569]\n",
      "[-0.02928156 -0.01885737 -0.01830029 ...  0.00858009  0.01010659\n",
      "  0.01378317]\n",
      "[-0.02107606 -0.01559211 -0.01159546 ... -0.00409584 -0.0016246\n",
      "  0.00077231]\n",
      "[-0.00334366 -0.00469497 -0.00658092 ... -0.00709175  0.01646016\n",
      "  0.05530987]\n",
      "[ 0.01005458  0.01047728  0.01246588 ... -0.00154214 -0.00124227\n",
      "  0.00391636]\n",
      "[ 0.00602143 -0.00625658 -0.0167913  ... -0.00220549  0.00458554\n",
      "  0.01154018]\n",
      "[ 0.00550525  0.00611532  0.00736717 ... -0.03248249 -0.0317392\n",
      " -0.03043253]\n",
      "[ 0.02313662  0.02169522  0.02039169 ... -0.00113755 -0.00460898\n",
      " -0.00802699]\n",
      "[-0.01898682 -0.0205804  -0.02217356 ... -0.00671714 -0.00534354\n",
      " -0.00413461]\n",
      "[-0.01755408 -0.02204197 -0.02456693 ...  0.07292979  0.07272457\n",
      "  0.06639173]\n",
      "[0.3117849  0.29775496 0.28287988 ... 0.12072675 0.13461381 0.13592465]\n",
      "[0.04890832 0.04846106 0.04785376 ... 0.01554199 0.01241739 0.00905082]\n",
      "[ 0.01299001  0.00977091  0.00633801 ... -0.05492225 -0.05664709\n",
      " -0.058244  ]\n",
      "[0.06157334 0.06503135 0.06830766 ... 0.04085509 0.04747869 0.05364085]\n",
      "[ 0.02238368  0.02562967  0.02859173 ... -0.02491323 -0.02552653\n",
      " -0.02568721]\n",
      "[ 0.00727183  0.00957874  0.01156077 ... -0.01154162 -0.01132113\n",
      " -0.01095808]\n",
      "[-0.01026662 -0.01399543 -0.01810161 ... -0.02447544 -0.01888425\n",
      " -0.01393775]\n",
      "[ 0.00618118  0.00991997  0.01346996 ... -0.11559176 -0.10046053\n",
      " -0.06950205]\n",
      "[ 0.01539179  0.06580055  0.09712704 ... -0.00439338 -0.00380213\n",
      " -0.0024948 ]\n",
      "[0.04698915 0.04622356 0.04523073 ... 0.01121629 0.00993558 0.01023931]\n",
      "[-0.04190592 -0.03703494 -0.03350533 ... -0.04634549 -0.0452113\n",
      " -0.04425792]\n",
      "[-0.01285725 -0.01055014 -0.00777902 ... -0.0292946  -0.01617498\n",
      " -0.0023541 ]\n",
      "[-0.04272844 -0.04390527 -0.04500719 ... -0.01854278 -0.01916364\n",
      " -0.01975569]\n",
      "[0.00643986 0.00572292 0.00470538 ... 0.00329708 0.00186604 0.00094266]\n",
      "[-0.04010716 -0.03782594 -0.03905797 ... -0.14379864 -0.14660851\n",
      " -0.21361442]\n",
      "[-0.05750726 -0.06463659 -0.07057314 ... -0.00348392 -0.00779377\n",
      " -0.01045329]\n",
      "[-0.12131661 -0.12454146 -0.12580883 ... -0.00669812 -0.00642042\n",
      " -0.00884614]\n",
      "[-0.05485407 -0.04547807 -0.03241745 ...  0.02309757  0.01786979\n",
      "  0.01279907]\n",
      "[-0.02039494 -0.01779217 -0.01453524 ... -0.02301127  0.00742349\n",
      "  0.04652793]\n",
      "[-0.00417046 -0.00107948  0.00201229 ...  0.00421416  0.00260386\n",
      " -0.0032643 ]\n",
      "[ 0.00537187  0.00346652  0.00056545 ... -0.14683689 -0.13249465\n",
      " -0.11860686]\n",
      "[0.33015358 0.29721098 0.21147809 ... 0.01342915 0.01075135 0.00492362]\n",
      "[ 0.18469652  0.19121425  0.19749428 ... -0.0387567  -0.03574143\n",
      " -0.03348928]\n",
      "[ 0.02642947  0.02597354  0.02395759 ... -0.04253841 -0.04029399\n",
      " -0.03798364]\n",
      "[0.00862092 0.01133609 0.01211078 ... 0.03192042 0.03458072 0.03702369]\n",
      "[-0.09564098 -0.09356589 -0.08052876 ...  0.01019335  0.00956103\n",
      "  0.00878702]\n",
      "[ 0.0101779   0.0093285   0.00661686 ...  0.01104012  0.004989\n",
      " -0.00254752]\n",
      "[ 0.00287018 -0.00363729 -0.00843411 ...  0.01580257  0.03120597\n",
      "  0.05006155]\n",
      "[-0.03943434 -0.04058662 -0.04325081 ... -0.00288913 -0.00515469\n",
      " -0.00745169]\n",
      "[-0.01397743 -0.01296662 -0.01137504 ...  0.20789032  0.25829622\n",
      "  0.28324135]\n",
      "[ 0.0235435   0.02141115  0.0195675  ... -0.11051227 -0.08010207\n",
      " -0.04425111]\n",
      "[-0.01827375 -0.01600164 -0.01584357 ... -0.01952478 -0.02052567\n",
      " -0.02167949]\n",
      "[ 0.01778122  0.01582064  0.01374241 ... -0.00186186 -0.0003426\n",
      "  0.00109294]\n",
      "[ 0.20394139  0.1778599   0.13349013 ... -0.08189898 -0.08845601\n",
      " -0.09096764]\n",
      "[-0.0258487  -0.00998438 -0.00232503 ...  0.04692566  0.046567\n",
      "  0.04661406]\n",
      "[ 0.04954843  0.03128796  0.01353166 ... -0.01602705 -0.01338043\n",
      " -0.01042154]\n",
      "[ 0.00203139  0.00451504  0.00698234 ... -0.00682053  0.02378719\n",
      "  0.06019177]\n",
      "[ 0.00286359  0.00293689  0.00260006 ... -0.04147998 -0.04001238\n",
      " -0.03893289]\n",
      "[ 0.00917323  0.0072954   0.00475886 ... -0.02822485 -0.02316392\n",
      " -0.01907701]\n",
      "[ 0.04463619  0.04023694  0.0346178  ... -0.04124902 -0.03302599\n",
      " -0.02263557]\n",
      "[-0.07110956 -0.05171796 -0.04153758 ... -0.00625755 -0.00738664\n",
      " -0.00797697]\n",
      "[0.00776141 0.0053624  0.00336493 ... 0.01500688 0.01294159 0.01088838]\n",
      "[ 0.04040916  0.03779156  0.03439785 ... -0.03701587 -0.03449571\n",
      " -0.03000624]\n",
      "[0.0190562  0.01829199 0.01650866 ... 0.0174103  0.01501702 0.01244392]\n",
      "[-0.01569912 -0.01687592 -0.0188383  ... -0.01974093 -0.02062598\n",
      " -0.02134178]\n",
      "[ 0.07772836  0.09333861  0.08591479 ...  0.07210743  0.02164452\n",
      " -0.02639146]\n",
      "[-0.0016591  -0.00243983 -0.0033312  ... -0.0033564  -0.00539925\n",
      " -0.00703787]\n",
      "[ 0.02413884  0.02415608  0.02356441 ... -0.0508652  -0.05213145\n",
      " -0.04979141]\n",
      "[-0.0050365  -0.00590828 -0.00621894 ...  0.00091159 -0.00235793\n",
      " -0.00483943]\n",
      "[-1.07071679e-03 -5.01163866e-04  1.50855601e-05 ...  9.49945778e-03\n",
      "  7.53218900e-03  5.63091312e-03]\n",
      "[-0.03446791 -0.02906404 -0.02387247 ...  0.01219055  0.01679929\n",
      "  0.02053113]\n",
      "[ 0.01523405  0.01953161  0.02083372 ... -0.00418758  0.00063047\n",
      "  0.01089246]\n",
      "[-0.02953093 -0.02978886 -0.03056194 ...  0.00207636  0.00129387\n",
      "  0.0004313 ]\n",
      "[0.05056849 0.06618074 0.07728365 ... 0.11263496 0.10787621 0.10214792]\n",
      "[-0.01887387 -0.01762966 -0.01726374 ...  0.09194277  0.08326472\n",
      "  0.07391652]\n",
      "[-0.01409309 -0.01219765 -0.01068395 ... -0.03147259 -0.02949919\n",
      " -0.02782553]\n",
      "[-0.00365246 -0.00183538 -0.00027187 ... -0.00502366 -0.00264952\n",
      " -0.00044523]\n",
      "[-0.02606511 -0.0259487  -0.02560555 ... -0.00309016 -0.00350831\n",
      " -0.0035786 ]\n",
      "[-0.005608   -0.00496772 -0.00511013 ... -0.05212605 -0.04884465\n",
      " -0.04560756]\n",
      "[-0.02433133 -0.02239236 -0.02131831 ... -0.00558517 -0.0069128\n",
      " -0.00804307]\n",
      "[-0.00109369 -0.00027538  0.00053098 ...  0.00520594  0.0029083\n",
      "  0.00057417]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[ 0.00373675  0.00249106  0.00046786 ... -0.00447608 -0.00557586\n",
      " -0.00591911]\n",
      "[ 0.01148081  0.00535642 -0.00034999 ... -0.0180973  -0.01774372\n",
      " -0.01763595]\n",
      "[-0.01076206 -0.01333962 -0.0173037  ... -0.09611928 -0.09662858\n",
      " -0.09429948]\n",
      "[ 0.00701319  0.00605159  0.00493721 ... -0.57080919 -0.58317872\n",
      " -0.53669618]\n",
      "[ 0.00365773 -0.00325712 -0.0047318  ...  0.59342995  0.59796029\n",
      "  0.6367573 ]\n",
      "[ 0.00158903  0.00067921  0.00039325 ... -0.00056639 -0.00498691\n",
      " -0.00931218]\n",
      "[ 0.02212337  0.02403132  0.02597409 ... -0.00944832 -0.00751581\n",
      " -0.00521095]\n",
      "[ 0.01638761  0.0714865   0.13032284 ... -0.00076021 -0.00177956\n",
      " -0.00287932]\n",
      "[-3.54102531e-03 -9.92961340e-04 -4.11670322e-05 ... -3.76168555e-02\n",
      " -5.48192860e-03  2.88874232e-02]\n",
      "[-0.01882207 -0.017369   -0.01621306 ...  0.0127374   0.00965434\n",
      "  0.00544874]\n",
      "[0.05715367 0.04593509 0.02945412 ... 0.3641985  0.34862918 0.33093186]\n",
      "[-0.14652513 -0.1462232  -0.14316729 ...  0.0375588   0.02923757\n",
      "  0.01989672]\n",
      "[-0.02366803 -0.02446005 -0.02868669 ...  0.03471871  0.03769138\n",
      "  0.04335598]\n",
      "[-0.02831967 -0.0215482  -0.01715295 ...  0.04188991  0.04758674\n",
      "  0.05134258]\n",
      "[0.07539292 0.10736703 0.1387408  ... 0.0555117  0.04980302 0.03762347]\n",
      "[-1.28545821e-02 -1.06279063e-02 -9.97962608e-03 ... -5.01294082e-04\n",
      " -2.37234454e-04  1.59573664e-05]\n",
      "[ 0.00285152  0.00125876 -0.0061113  ... -0.01096482 -0.0125898\n",
      " -0.01311885]\n",
      "[-0.00820614 -0.00265182  0.00017314 ...  0.00766306  0.00518973\n",
      "  0.00453231]\n",
      "[-0.082128   -0.07159893 -0.06395732 ... -0.08847624 -0.07955709\n",
      " -0.06895887]\n",
      "[-0.01708729 -0.01533279 -0.01369019 ... -0.00084904  0.00146755\n",
      "  0.00395741]\n",
      "[-0.00045872  0.00492716  0.00722968 ... -0.00456895 -0.00379735\n",
      " -0.00270401]\n",
      "[-0.00178214 -0.00184173 -0.00144061 ...  0.01220544  0.00966935\n",
      "  0.00706405]\n",
      "[-0.36612914 -0.42533106 -0.47598636 ... -0.31009174 -0.28779125\n",
      " -0.26513981]\n",
      "[-0.06204441 -0.05374754 -0.04037623 ...  0.00916415  0.00654774\n",
      "  0.00300359]\n",
      "[-0.03039434 -0.03369379 -0.03520456 ... -0.00052988 -0.00461639\n",
      " -0.00913908]\n",
      "[-0.07554599 -0.0713986  -0.06742027 ... -0.01486907 -0.01576775\n",
      " -0.01647658]\n",
      "[ 0.05417588 -0.01275804 -0.06005967 ...  0.01349335 -0.00287245\n",
      " -0.01669621]\n",
      "[ 0.00204888  0.00378905  0.00629709 ... -0.02043777 -0.02163313\n",
      " -0.02162585]\n",
      "[-0.01395137 -0.0144572  -0.01522614 ...  0.00209554 -0.00032754\n",
      " -0.00303878]\n",
      "[0.10841425 0.09620364 0.0834281  ... 0.07305477 0.07474871 0.07625668]\n",
      "[ 0.03839699  0.03950016  0.03973001 ... -0.0658529  -0.05794727\n",
      " -0.05080131]\n",
      "[ 0.0326888   0.01711923 -0.00086637 ... -0.01356261 -0.02582144\n",
      " -0.0358374 ]\n",
      "[0.01400684 0.01408801 0.01334842 ... 0.00856201 0.00891871 0.00975899]\n",
      "[-0.00355822 -0.00819876 -0.01239    ... -0.03479721 -0.02820558\n",
      " -0.02161378]\n",
      "[ 0.03974726  0.0387083   0.03713129 ... -0.0077624  -0.00938716\n",
      " -0.011042  ]\n",
      "[ 0.19546427  0.19948165  0.19595431 ... -0.0330706  -0.03143388\n",
      " -0.02787068]\n",
      "[0.08849061 0.12569965 0.1649431  ... 0.77149061 0.78836294 0.73385222]\n",
      "[-0.00154418 -0.00088668 -0.00065314 ... -0.00654324 -0.00672447\n",
      " -0.00676631]\n",
      "[-0.00164782 -0.00047109  0.00096001 ... -0.14920929 -0.1263311\n",
      " -0.10348605]\n",
      "[0.00215853 0.00190628 0.00113244 ... 0.01053693 0.01143208 0.01253443]\n",
      "[ 0.00656879  0.0065506   0.00215884 ... -0.02925013 -0.01643872\n",
      " -0.00404164]\n",
      "[ 0.01348236  0.01468406  0.0152352  ... -0.01255691 -0.01387774\n",
      " -0.01435326]\n",
      "[-0.73217098 -0.76462962 -0.75359275 ... -0.30298269 -0.30587052\n",
      " -0.31477765]\n",
      "[0.01237306 0.0092281  0.00544002 ... 0.22823306 0.19548926 0.13457668]\n",
      "[-0.03308166 -0.03408957 -0.03500708 ... -0.01160879 -0.0161736\n",
      " -0.0198806 ]\n",
      "[-0.01919246 -0.02098183 -0.02312815 ... -0.2229353  -0.22701179\n",
      " -0.23024129]\n",
      "[ 0.15424276  0.14588995  0.13698023 ... -0.03049326  0.0004945\n",
      "  0.02032617]\n",
      "[-0.01981532 -0.02027308 -0.02066154 ... -0.04686953 -0.0361059\n",
      " -0.01384137]\n",
      "[ 0.03816546  0.04813061  0.05638079 ... -0.02586357 -0.02526627\n",
      " -0.02348318]\n",
      "[ 0.02219576 -0.00093139 -0.01100736 ... -0.00697457 -0.00691836\n",
      " -0.00635528]\n",
      "[ 0.08170619  0.04218063 -0.00510525 ... -0.06690338 -0.08674289\n",
      " -0.09457404]\n",
      "[-0.01779761 -0.01889559 -0.01992167 ... -0.02583305 -0.02145714\n",
      " -0.01494349]\n",
      "[-0.04982643 -0.05250796 -0.05169905 ... -0.031174   -0.02957867\n",
      " -0.02788474]\n",
      "[ 0.01902571  0.02123335  0.02282636 ... -0.10359601 -0.10454601\n",
      " -0.10585706]\n",
      "[0.00054563 0.00327115 0.00443793 ... 0.01273026 0.01196036 0.01075306]\n",
      "[-0.02654673 -0.0342524  -0.03852778 ... -0.05035864 -0.05691156\n",
      " -0.06244345]\n",
      "[ 0.00472386  0.01114814  0.01202078 ... -0.03719129 -0.03714329\n",
      " -0.02965089]\n",
      "[-0.01138538 -0.01424546 -0.01910752 ...  0.23429335  0.24269655\n",
      "  0.23721504]\n",
      "[ 0.01574004  0.01677579  0.01817442 ... -0.04422325 -0.04859731\n",
      " -0.05426266]\n",
      "[-0.02109396 -0.00885205  0.00409635 ... -0.0248584  -0.02471444\n",
      " -0.02700961]\n",
      "[-0.01064128 -0.00671981 -0.00046143 ... -0.00542232 -0.00764794\n",
      " -0.00951478]\n",
      "[-0.01572769 -0.01939667 -0.02411257 ...  0.04614404  0.04458892\n",
      "  0.04104669]\n",
      "[-1.42450950e-03 -7.78994014e-04  4.47155927e-05 ... -2.22795217e-01\n",
      " -1.73507782e-01 -1.10153819e-01]\n",
      "[-0.0955304  -0.09201491 -0.08835726 ...  0.17291433  0.19299611\n",
      "  0.20532825]\n",
      "[ 0.20820126  0.21587427  0.21551968 ... -0.02841468 -0.03255712\n",
      " -0.03682428]\n",
      "[-0.00983135 -0.01278335 -0.01718802 ... -0.00554449 -0.00065274\n",
      "  0.00249617]\n",
      "[-0.01209144 -0.01195338 -0.01109641 ...  0.11033696  0.01620429\n",
      " -0.07002171]\n",
      "[-0.00423803 -0.01123058 -0.01676169 ... -0.0613311  -0.054897\n",
      " -0.04609712]\n",
      "[ 0.03010174  0.02712949  0.02150618 ... -0.01647901 -0.00980776\n",
      " -0.00286393]\n",
      "[0.01741983 0.0119528  0.00209396 ... 0.02907857 0.02983827 0.03152837]\n",
      "[0.00571992 0.00322331 0.00063964 ... 0.03239693 0.02830601 0.02386584]\n",
      "[ 0.12032276  0.0986849   0.07001288 ... -0.06028926 -0.04648248\n",
      " -0.02832594]\n",
      "[-0.03986998 -0.03832779 -0.03869294 ... -0.00748108 -0.0063181\n",
      " -0.00398096]\n",
      "[-0.10202354 -0.10505088 -0.1074448  ... -0.0213773  -0.0161862\n",
      " -0.01068806]\n",
      "[ 0.00428333  0.00535709  0.00645839 ...  0.00144125 -0.01691207\n",
      " -0.03381683]\n",
      "[ 0.00929668  0.00770611  0.00602386 ... -0.20401002 -0.22621251\n",
      " -0.23620752]\n",
      "[-0.00610223 -0.02468596 -0.00121354 ... -0.02591551 -0.0192658\n",
      " -0.01408122]\n",
      "Before\n",
      "(1017, 1, 4000)\n",
      "x.shape\n",
      "torch.Size([1017, 1, 4000])\n",
      "40\n",
      "torch.Size([40, 1017, 108])\n",
      "torch.Size([1017, 108, 40])\n",
      "x.shape\n",
      "torch.Size([127, 1, 4000])\n",
      "40\n",
      "torch.Size([40, 127, 108])\n",
      "torch.Size([127, 108, 40])\n",
      "x.shape\n",
      "torch.Size([126, 1, 4000])\n",
      "40\n",
      "torch.Size([40, 126, 108])\n",
      "torch.Size([126, 108, 40])\n",
      "data.shape after\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "#print(y_train.shape)\n",
    "#y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "#y_val = y_val.reshape(-1, 1)\n",
    "#labels as digit representation instead of letters\n",
    "#encoder = preprocessing.LabelEncoder()\n",
    "#encoder.fit(y)\n",
    "#y = encoder.transform(y)\n",
    "#encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "def data2tensor(X, y, encoder):\n",
    "    \"\"\"convert rawdata and rawlabel with encoder to pytorch tensor\n",
    "\n",
    "    Keyword arguments:\n",
    "    rawdata -- np array of rawdata\n",
    "    rawlabels -- np array of labels corresponding to rawdata\n",
    "    encoder -- instance of LabelEncoder used for encoding\n",
    "\n",
    "    Returns:\n",
    "    tensor: torch.Tensor of type DoubleTensor with\n",
    "            dimension [batch size (i.e. number of X instances), NUM_FEATURES, SEQ_LENGTH]\n",
    "    \"\"\"\n",
    "    # labels as digit representation instead of letters\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    #print('ANOTHER TEST')\n",
    "    tensors = []\n",
    "    labels = []\n",
    "    for i in range(len(y)):\n",
    "        #if X[i].shape == (NUM_FEATURES, SEQ_LENGTH):  # skip data with incorrect dimensions TODO: avoid hardcoding\n",
    "            # r_tensor = torch.tensor(rawdata[i].real, device=device)\n",
    "            # i_tensor = torch.tensor(rawdata[i].imag, device=device)\n",
    "            # tensors.append(torch.cat((r_tensor, i_tensor), 0))\n",
    "\n",
    "            # append the absolute value (TODO should be configurable)\n",
    "\n",
    "            # ts_fft = sp.fftpack.fft(rawdata[i])\n",
    "            # ts_psd = np.abs(ts_fft) ** 2\n",
    "            # tensors.append(torch.tensor(ts_psd, device=device))\n",
    "        print((X[i]))\n",
    "        tensors.append(torch.tensor(np.absolute(X[i])))\n",
    "        labels.append(y[i])\n",
    "    #tensors=np.array(tensors)\n",
    "    #tensors=np.expand_dims(tensors,2)\n",
    "    return torch.stack(tensors), torch.as_tensor(labels, device=device)\n",
    "\n",
    "#rawdata, rawlabels = load_dataset(csi_data)\n",
    "print('ANOTHER TEST')\n",
    "print()\n",
    "#X_train=X_train.cpu().numpy()\n",
    "#X_test=X_test.cpu().numpy()\n",
    "#X_val=X_val.cpu().numpy()\n",
    "\n",
    "X_train, y_train = data2tensor(X_train, y_train, encoder)\n",
    "X_test, y_test = data2tensor(X_test, y_test, encoder)\n",
    "X_val, y_val = data2tensor(X_val, y_val, encoder)\n",
    "#print(data.type)\n",
    "#data= data.argmax\n",
    "#X_train=X_train.cpu().numpy()\n",
    "#X_test=X_test.cpu().numpy()\n",
    "#X_val=X_val.cpu().numpy()\n",
    "\n",
    "#data=np.array(data)\n",
    "#print(data.shape)\n",
    "#expanding dimensions to make it 3-D\n",
    "print('Before')\n",
    "#data=data.expand_dims(data,1)\n",
    "\n",
    "X_train=np.expand_dims(X_train.cpu(),1)\n",
    "X_test=np.expand_dims(X_test.cpu(),1)\n",
    "X_val=np.expand_dims(X_val.cpu(),1)\n",
    "print(X_train.shape)\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "X_val = torch.tensor(X_val)\n",
    "\n",
    "X_train = dim_embedding(X_train)\n",
    "X_test = dim_embedding(X_test)\n",
    "X_val = dim_embedding(X_val)\n",
    "print(\"data.shape after\")\n",
    "\n",
    "mean_train = torch.mean(X_train)\n",
    "std_train = torch.std(X_train)\n",
    "mean_test = torch.mean(X_test)\n",
    "std_test = torch.std(X_test)\n",
    "mean_val = torch.mean(X_val)\n",
    "std_val = torch.std(X_val)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c600c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##from torchvision import transforms\n",
    "normalize = transforms.Normalize(mean_train, std_train)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "nor_data_train = normalize(X_train).to(device)\n",
    "\n",
    "normalize_test = transforms.Normalize(mean_test, std_test)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "nor_data_test = normalize(X_test).to(device)\n",
    "\n",
    "normalize_val = transforms.Normalize(mean_val, std_val)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "nor_data_val = normalize(X_val).to(device)\n",
    "#print(nor_data_train.shape)\n",
    "train_dataset = TensorDataset(nor_data_train, y_train)\n",
    "test_dataset = TensorDataset(nor_data_test, y_test)\n",
    "val_dataset = TensorDataset(nor_data_val, y_val)\n",
    "dataloader_train = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator())\n",
    "dataloader_val = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator())\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=torch.Generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3ee41c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER dataloading\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa914028e90>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa8d4192190>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa90df08590>\n",
      "AFTER DIVISION\n",
      "7\n",
      "7\n",
      "DATA SHAPE 4000\n",
      "BEFO>rE\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "TransformerModel                                                  --\n",
      "PositionalEncoding: 1-1                                         --\n",
      "TransformerEncoder: 1-2                                         --\n",
      "    ModuleList: 2-1                                            --\n",
      "        TransformerEncoderLayer: 3-1                          80,178\n",
      "        TransformerEncoderLayer: 3-2                          80,178\n",
      "        TransformerEncoderLayer: 3-3                          80,178\n",
      "        TransformerEncoderLayer: 3-4                          80,178\n",
      "        TransformerEncoderLayer: 3-5                          80,178\n",
      "        TransformerEncoderLayer: 3-6                          80,178\n",
      "        TransformerEncoderLayer: 3-7                          80,178\n",
      "        TransformerEncoderLayer: 3-8                          80,178\n",
      "Dropout: 1-3                                                    --\n",
      "Linear: 1-4                                                     12,963\n",
      "==========================================================================================\n",
      "Total params: 371,859\n",
      "Trainable params: 371,859\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.111875  [    0/ 1017]\n",
      "loss: 1.214197  [  200/ 1017]\n",
      "loss: 0.791695  [  400/ 1017]\n",
      "loss: 0.812414  [  600/ 1017]\n",
      "loss: 0.937977  [  800/ 1017]\n",
      "loss: 0.868276  [  850/ 1017]\n",
      "Accuracy: 75.40%, Avg loss: 0.754483\n",
      "Model saved\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.046010  [    0/ 1017]\n",
      "loss: 0.630021  [  200/ 1017]\n",
      "loss: 0.418265  [  400/ 1017]\n",
      "loss: 0.391267  [  600/ 1017]\n",
      "loss: 0.392592  [  800/ 1017]\n",
      "loss: 0.484070  [  850/ 1017]\n",
      "Accuracy: 83.33%, Avg loss: 0.462784\n",
      "Model saved\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.265405  [    0/ 1017]\n",
      "loss: 0.334482  [  200/ 1017]\n",
      "loss: 0.376342  [  400/ 1017]\n",
      "loss: 0.265157  [  600/ 1017]\n",
      "loss: 0.249889  [  800/ 1017]\n",
      "loss: 0.239761  [  850/ 1017]\n",
      "Accuracy: 89.68%, Avg loss: 0.252410\n",
      "Model saved\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.169291  [    0/ 1017]\n",
      "loss: 0.301642  [  200/ 1017]\n",
      "loss: 0.571801  [  400/ 1017]\n",
      "loss: 0.401087  [  600/ 1017]\n",
      "loss: 0.091202  [  800/ 1017]\n",
      "loss: 0.111218  [  850/ 1017]\n",
      "Accuracy: 88.89%, Avg loss: 0.273112\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.062637  [    0/ 1017]\n",
      "loss: 0.200126  [  200/ 1017]\n",
      "loss: 0.146424  [  400/ 1017]\n",
      "loss: 0.014767  [  600/ 1017]\n",
      "loss: 0.183906  [  800/ 1017]\n",
      "loss: 0.233230  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.332305\n",
      "Model saved\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.054052  [    0/ 1017]\n",
      "loss: 0.133142  [  200/ 1017]\n",
      "loss: 0.162228  [  400/ 1017]\n",
      "loss: 0.052004  [  600/ 1017]\n",
      "loss: 0.208851  [  800/ 1017]\n",
      "loss: 0.063241  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.253574\n",
      "Model saved\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.012680  [    0/ 1017]\n",
      "loss: 0.031101  [  200/ 1017]\n",
      "loss: 0.017926  [  400/ 1017]\n",
      "loss: 0.019485  [  600/ 1017]\n",
      "loss: 0.005708  [  800/ 1017]\n",
      "loss: 0.263057  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.155335\n",
      "Model saved\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.194240  [    0/ 1017]\n",
      "loss: 0.037360  [  200/ 1017]\n",
      "loss: 0.415659  [  400/ 1017]\n",
      "loss: 0.368104  [  600/ 1017]\n",
      "loss: 0.107277  [  800/ 1017]\n",
      "loss: 0.095065  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.219412\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.014067  [    0/ 1017]\n",
      "loss: 0.074373  [  200/ 1017]\n",
      "loss: 0.025874  [  400/ 1017]\n",
      "loss: 0.044181  [  600/ 1017]\n",
      "loss: 0.003941  [  800/ 1017]\n",
      "loss: 0.013959  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.209683\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.027077  [    0/ 1017]\n",
      "loss: 0.002728  [  200/ 1017]\n",
      "loss: 0.024203  [  400/ 1017]\n",
      "loss: 0.002529  [  600/ 1017]\n",
      "loss: 0.000467  [  800/ 1017]\n",
      "loss: 0.001096  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.135571\n",
      "Model saved\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.000775  [    0/ 1017]\n",
      "loss: 0.001805  [  200/ 1017]\n",
      "loss: 0.008465  [  400/ 1017]\n",
      "loss: 0.001996  [  600/ 1017]\n",
      "loss: 0.001239  [  800/ 1017]\n",
      "loss: 0.002400  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.244552\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.024207  [    0/ 1017]\n",
      "loss: 0.001996  [  200/ 1017]\n",
      "loss: 0.003297  [  400/ 1017]\n",
      "loss: 0.016623  [  600/ 1017]\n",
      "loss: 0.000687  [  800/ 1017]\n",
      "loss: 0.001570  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.165940\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.005682  [    0/ 1017]\n",
      "loss: 0.001017  [  200/ 1017]\n",
      "loss: 0.033108  [  400/ 1017]\n",
      "loss: 0.004804  [  600/ 1017]\n",
      "loss: 0.000575  [  800/ 1017]\n",
      "loss: 0.000653  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.097193\n",
      "Model saved\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.000284  [    0/ 1017]\n",
      "loss: 0.000730  [  200/ 1017]\n",
      "loss: 0.001273  [  400/ 1017]\n",
      "loss: 0.000903  [  600/ 1017]\n",
      "loss: 0.001417  [  800/ 1017]\n",
      "loss: 0.001841  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.189698\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.000101  [    0/ 1017]\n",
      "loss: 0.000915  [  200/ 1017]\n",
      "loss: 0.000301  [  400/ 1017]\n",
      "loss: 0.001094  [  600/ 1017]\n",
      "loss: 0.001141  [  800/ 1017]\n",
      "loss: 0.000863  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.112063\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.001039  [    0/ 1017]\n",
      "loss: 0.000117  [  200/ 1017]\n",
      "loss: 0.000893  [  400/ 1017]\n",
      "loss: 0.000433  [  600/ 1017]\n",
      "loss: 0.000534  [  800/ 1017]\n",
      "loss: 0.002229  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.142647\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.000113  [    0/ 1017]\n",
      "loss: 0.000093  [  200/ 1017]\n",
      "loss: 0.000255  [  400/ 1017]\n",
      "loss: 0.000537  [  600/ 1017]\n",
      "loss: 0.000255  [  800/ 1017]\n",
      "loss: 0.000440  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.139234\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.000118  [    0/ 1017]\n",
      "loss: 0.000261  [  200/ 1017]\n",
      "loss: 0.000630  [  400/ 1017]\n",
      "loss: 0.000215  [  600/ 1017]\n",
      "loss: 0.000165  [  800/ 1017]\n",
      "loss: 0.001287  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.156488\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.000145  [    0/ 1017]\n",
      "loss: 0.000250  [  200/ 1017]\n",
      "loss: 0.000107  [  400/ 1017]\n",
      "loss: 0.000266  [  600/ 1017]\n",
      "loss: 0.000229  [  800/ 1017]\n",
      "loss: 0.000198  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.177710\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.000245  [    0/ 1017]\n",
      "loss: 0.000482  [  200/ 1017]\n",
      "loss: 0.000178  [  400/ 1017]\n",
      "loss: 0.000128  [  600/ 1017]\n",
      "loss: 0.000231  [  800/ 1017]\n",
      "loss: 0.000421  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.143800\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/ 1017]\n",
      "loss: 0.000065  [  200/ 1017]\n",
      "loss: 0.000112  [  400/ 1017]\n",
      "loss: 0.000081  [  600/ 1017]\n",
      "loss: 0.000193  [  800/ 1017]\n",
      "loss: 0.000127  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.138314\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.000029  [    0/ 1017]\n",
      "loss: 0.000118  [  200/ 1017]\n",
      "loss: 0.000080  [  400/ 1017]\n",
      "loss: 0.000099  [  600/ 1017]\n",
      "loss: 0.000106  [  800/ 1017]\n",
      "loss: 0.003827  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.163860\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.000172  [    0/ 1017]\n",
      "loss: 0.000035  [  200/ 1017]\n",
      "loss: 0.000279  [  400/ 1017]\n",
      "loss: 0.000460  [  600/ 1017]\n",
      "loss: 0.000305  [  800/ 1017]\n",
      "loss: 0.000090  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.196441\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/ 1017]\n",
      "loss: 0.000609  [  200/ 1017]\n",
      "loss: 0.000243  [  400/ 1017]\n",
      "loss: 0.000250  [  600/ 1017]\n",
      "loss: 0.000103  [  800/ 1017]\n",
      "loss: 0.000089  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.233982\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/ 1017]\n",
      "loss: 0.000068  [  200/ 1017]\n",
      "loss: 0.000138  [  400/ 1017]\n",
      "loss: 0.000327  [  600/ 1017]\n",
      "loss: 0.000091  [  800/ 1017]\n",
      "loss: 0.000200  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.186134\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000086  [    0/ 1017]\n",
      "loss: 0.000252  [  200/ 1017]\n",
      "loss: 0.000084  [  400/ 1017]\n",
      "loss: 0.000026  [  600/ 1017]\n",
      "loss: 0.000062  [  800/ 1017]\n",
      "loss: 0.000057  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.159467\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.000163  [    0/ 1017]\n",
      "loss: 0.000098  [  200/ 1017]\n",
      "loss: 0.000174  [  400/ 1017]\n",
      "loss: 0.000130  [  600/ 1017]\n",
      "loss: 0.000093  [  800/ 1017]\n",
      "loss: 0.000059  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.240926\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.000035  [    0/ 1017]\n",
      "loss: 0.000019  [  200/ 1017]\n",
      "loss: 0.000136  [  400/ 1017]\n",
      "loss: 0.000054  [  600/ 1017]\n",
      "loss: 0.000028  [  800/ 1017]\n",
      "loss: 0.000016  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.187984\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000036  [  200/ 1017]\n",
      "loss: 0.000072  [  400/ 1017]\n",
      "loss: 0.000051  [  600/ 1017]\n",
      "loss: 0.000031  [  800/ 1017]\n",
      "loss: 0.000178  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.138631\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000267  [    0/ 1017]\n",
      "loss: 0.000113  [  200/ 1017]\n",
      "loss: 0.000034  [  400/ 1017]\n",
      "loss: 0.000026  [  600/ 1017]\n",
      "loss: 0.000144  [  800/ 1017]\n",
      "loss: 0.000048  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.183769\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.000031  [    0/ 1017]\n",
      "loss: 0.000059  [  200/ 1017]\n",
      "loss: 0.000044  [  400/ 1017]\n",
      "loss: 0.000025  [  600/ 1017]\n",
      "loss: 0.000423  [  800/ 1017]\n",
      "loss: 0.000040  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.167550\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.000138  [    0/ 1017]\n",
      "loss: 0.000077  [  200/ 1017]\n",
      "loss: 0.000287  [  400/ 1017]\n",
      "loss: 0.000026  [  600/ 1017]\n",
      "loss: 0.000058  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 97.62%, Avg loss: 0.156170\n",
      "Model saved\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.000137  [    0/ 1017]\n",
      "loss: 0.000017  [  200/ 1017]\n",
      "loss: 0.000027  [  400/ 1017]\n",
      "loss: 0.000021  [  600/ 1017]\n",
      "loss: 0.000014  [  800/ 1017]\n",
      "loss: 0.000068  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.209564\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.000087  [    0/ 1017]\n",
      "loss: 0.000088  [  200/ 1017]\n",
      "loss: 0.000221  [  400/ 1017]\n",
      "loss: 0.000050  [  600/ 1017]\n",
      "loss: 0.000020  [  800/ 1017]\n",
      "loss: 0.000129  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.178720\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.000021  [    0/ 1017]\n",
      "loss: 0.000109  [  200/ 1017]\n",
      "loss: 0.000030  [  400/ 1017]\n",
      "loss: 0.000040  [  600/ 1017]\n",
      "loss: 0.000029  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.179998\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000020  [  400/ 1017]\n",
      "loss: 0.000042  [  600/ 1017]\n",
      "loss: 0.000312  [  800/ 1017]\n",
      "loss: 0.000048  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.199881\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.000062  [    0/ 1017]\n",
      "loss: 0.000064  [  200/ 1017]\n",
      "loss: 0.000094  [  400/ 1017]\n",
      "loss: 0.000047  [  600/ 1017]\n",
      "loss: 0.000035  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.160273\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000016  [  200/ 1017]\n",
      "loss: 0.000040  [  400/ 1017]\n",
      "loss: 0.000018  [  600/ 1017]\n",
      "loss: 0.000022  [  800/ 1017]\n",
      "loss: 0.000011  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.168159\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000059  [  200/ 1017]\n",
      "loss: 0.000023  [  400/ 1017]\n",
      "loss: 0.000012  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.193389\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.000053  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000043  [  600/ 1017]\n",
      "loss: 0.000011  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.210600\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000021  [  200/ 1017]\n",
      "loss: 0.000016  [  400/ 1017]\n",
      "loss: 0.000039  [  600/ 1017]\n",
      "loss: 0.000064  [  800/ 1017]\n",
      "loss: 0.000069  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.180209\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.000033  [    0/ 1017]\n",
      "loss: 0.000044  [  200/ 1017]\n",
      "loss: 0.000013  [  400/ 1017]\n",
      "loss: 0.000019  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000116  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.178161\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.000044  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000025  [  400/ 1017]\n",
      "loss: 0.000043  [  600/ 1017]\n",
      "loss: 0.000044  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.176927\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000026  [  200/ 1017]\n",
      "loss: 0.000042  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000044  [  800/ 1017]\n",
      "loss: 0.000017  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.150607\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000040  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000056  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000028  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.160911\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.000032  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000013  [  600/ 1017]\n",
      "loss: 0.000024  [  800/ 1017]\n",
      "loss: 0.000021  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.200606\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000021  [  400/ 1017]\n",
      "loss: 0.000138  [  600/ 1017]\n",
      "loss: 0.000011  [  800/ 1017]\n",
      "loss: 0.000044  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.191224\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1017]\n",
      "loss: 0.000042  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000024  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000054  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.203094\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000017  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000011  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.180676\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000142  [  200/ 1017]\n",
      "loss: 0.000043  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000035  [  800/ 1017]\n",
      "loss: 0.000018  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.202351\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000033  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.178571\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000023  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000033  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.200800\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000014  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.267138\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000047  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000017  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.173656\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000012  [  200/ 1017]\n",
      "loss: 0.000151  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000016  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.184532\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000089  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000022  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.208880\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000047  [    0/ 1017]\n",
      "loss: 0.000056  [  200/ 1017]\n",
      "loss: 0.000013  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.215426\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000059  [  400/ 1017]\n",
      "loss: 0.000027  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.196929\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000020  [  400/ 1017]\n",
      "loss: 0.000026  [  600/ 1017]\n",
      "loss: 0.000163  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.194608\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.190637\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000042  [  600/ 1017]\n",
      "loss: 0.000037  [  800/ 1017]\n",
      "loss: 0.000126  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.203111\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000053  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.170072\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000020  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000018  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.200721\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000015  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.166528\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.000041  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000027  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.242971\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.000027  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000039  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.274883\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.000014  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.207451\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000013  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.222309\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.000200  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000022  [  600/ 1017]\n",
      "loss: 0.000017  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.224990\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000048  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.218978\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000015  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.275303\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.325561\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000008  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.226392\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000016  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.187476\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000029  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.201012\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.208769\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000011  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000028  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.242480\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000022  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.277894\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/ 1017]\n",
      "loss: 0.000016  [  200/ 1017]\n",
      "loss: 0.000005  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000008  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.198025\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000016  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.210337\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.223421\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.229322\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.166656\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000011  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.221096\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000014  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.245091\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000044  [  800/ 1017]\n",
      "loss: 0.000016  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.245918\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000019  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000823  [  800/ 1017]\n",
      "loss: 0.000057  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.436527\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.455108  [  200/ 1017]\n",
      "loss: 0.991997  [  400/ 1017]\n",
      "loss: 0.987286  [  600/ 1017]\n",
      "loss: 1.219303  [  800/ 1017]\n",
      "loss: 0.292821  [  850/ 1017]\n",
      "Accuracy: 73.81%, Avg loss: 0.699413\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.582661  [    0/ 1017]\n",
      "loss: 0.430173  [  200/ 1017]\n",
      "loss: 0.196332  [  400/ 1017]\n",
      "loss: 0.243810  [  600/ 1017]\n",
      "loss: 0.356920  [  800/ 1017]\n",
      "loss: 0.119593  [  850/ 1017]\n",
      "Accuracy: 88.89%, Avg loss: 0.336780\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.167015  [    0/ 1017]\n",
      "loss: 0.126843  [  200/ 1017]\n",
      "loss: 0.126830  [  400/ 1017]\n",
      "loss: 0.397165  [  600/ 1017]\n",
      "loss: 0.065235  [  800/ 1017]\n",
      "loss: 0.116861  [  850/ 1017]\n",
      "Accuracy: 88.89%, Avg loss: 0.362104\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.159569  [    0/ 1017]\n",
      "loss: 0.038333  [  200/ 1017]\n",
      "loss: 0.029085  [  400/ 1017]\n",
      "loss: 0.097912  [  600/ 1017]\n",
      "loss: 0.169575  [  800/ 1017]\n",
      "loss: 0.039454  [  850/ 1017]\n",
      "Accuracy: 89.68%, Avg loss: 0.320730\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.020656  [    0/ 1017]\n",
      "loss: 0.007484  [  200/ 1017]\n",
      "loss: 0.084316  [  400/ 1017]\n",
      "loss: 0.019124  [  600/ 1017]\n",
      "loss: 0.006150  [  800/ 1017]\n",
      "loss: 0.013543  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.450494\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.011142  [    0/ 1017]\n",
      "loss: 0.020362  [  200/ 1017]\n",
      "loss: 0.057864  [  400/ 1017]\n",
      "loss: 0.040335  [  600/ 1017]\n",
      "loss: 0.009189  [  800/ 1017]\n",
      "loss: 0.001890  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.290126\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.108114  [    0/ 1017]\n",
      "loss: 0.012782  [  200/ 1017]\n",
      "loss: 0.010050  [  400/ 1017]\n",
      "loss: 0.003840  [  600/ 1017]\n",
      "loss: 0.010266  [  800/ 1017]\n",
      "loss: 0.000945  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.318388\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.002835  [    0/ 1017]\n",
      "loss: 0.001362  [  200/ 1017]\n",
      "loss: 0.005272  [  400/ 1017]\n",
      "loss: 0.021154  [  600/ 1017]\n",
      "loss: 0.001998  [  800/ 1017]\n",
      "loss: 0.004181  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.227609\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.003122  [    0/ 1017]\n",
      "loss: 0.010486  [  200/ 1017]\n",
      "loss: 0.003071  [  400/ 1017]\n",
      "loss: 0.002483  [  600/ 1017]\n",
      "loss: 0.005120  [  800/ 1017]\n",
      "loss: 0.000491  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.268022\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.004445  [    0/ 1017]\n",
      "loss: 0.000812  [  200/ 1017]\n",
      "loss: 0.002843  [  400/ 1017]\n",
      "loss: 0.004030  [  600/ 1017]\n",
      "loss: 0.002578  [  800/ 1017]\n",
      "loss: 0.085863  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.533986\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.003612  [    0/ 1017]\n",
      "loss: 0.002466  [  200/ 1017]\n",
      "loss: 0.003986  [  400/ 1017]\n",
      "loss: 0.003348  [  600/ 1017]\n",
      "loss: 0.001954  [  800/ 1017]\n",
      "loss: 0.000413  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.222296\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.003581  [    0/ 1017]\n",
      "loss: 0.002541  [  200/ 1017]\n",
      "loss: 0.004786  [  400/ 1017]\n",
      "loss: 0.010627  [  600/ 1017]\n",
      "loss: 0.000840  [  800/ 1017]\n",
      "loss: 0.007857  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.212452\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.000657  [    0/ 1017]\n",
      "loss: 0.001546  [  200/ 1017]\n",
      "loss: 0.000362  [  400/ 1017]\n",
      "loss: 0.000096  [  600/ 1017]\n",
      "loss: 0.001817  [  800/ 1017]\n",
      "loss: 0.001486  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.283169\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.000288  [    0/ 1017]\n",
      "loss: 0.000290  [  200/ 1017]\n",
      "loss: 0.000314  [  400/ 1017]\n",
      "loss: 0.000269  [  600/ 1017]\n",
      "loss: 0.000152  [  800/ 1017]\n",
      "loss: 0.000554  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.239835\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.000908  [    0/ 1017]\n",
      "loss: 0.000406  [  200/ 1017]\n",
      "loss: 0.000249  [  400/ 1017]\n",
      "loss: 0.004870  [  600/ 1017]\n",
      "loss: 0.000347  [  800/ 1017]\n",
      "loss: 0.000181  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.164942\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.000900  [    0/ 1017]\n",
      "loss: 0.001356  [  200/ 1017]\n",
      "loss: 0.000067  [  400/ 1017]\n",
      "loss: 0.000174  [  600/ 1017]\n",
      "loss: 0.000351  [  800/ 1017]\n",
      "loss: 0.000134  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.187523\n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.000116  [    0/ 1017]\n",
      "loss: 0.000148  [  200/ 1017]\n",
      "loss: 0.000116  [  400/ 1017]\n",
      "loss: 0.000100  [  600/ 1017]\n",
      "loss: 0.000104  [  800/ 1017]\n",
      "loss: 0.000547  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.459319\n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.000453  [    0/ 1017]\n",
      "loss: 0.000210  [  200/ 1017]\n",
      "loss: 0.000185  [  400/ 1017]\n",
      "loss: 0.000344  [  600/ 1017]\n",
      "loss: 0.000568  [  800/ 1017]\n",
      "loss: 0.000994  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.309645\n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.000091  [    0/ 1017]\n",
      "loss: 0.000751  [  200/ 1017]\n",
      "loss: 0.000844  [  400/ 1017]\n",
      "loss: 0.000090  [  600/ 1017]\n",
      "loss: 0.000481  [  800/ 1017]\n",
      "loss: 0.000086  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.230529\n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/ 1017]\n",
      "loss: 0.000105  [  200/ 1017]\n",
      "loss: 0.000150  [  400/ 1017]\n",
      "loss: 0.000336  [  600/ 1017]\n",
      "loss: 0.000114  [  800/ 1017]\n",
      "loss: 0.000240  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.190981\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.000196  [    0/ 1017]\n",
      "loss: 0.000092  [  200/ 1017]\n",
      "loss: 0.000281  [  400/ 1017]\n",
      "loss: 0.000078  [  600/ 1017]\n",
      "loss: 0.001367  [  800/ 1017]\n",
      "loss: 0.000044  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.244252\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/ 1017]\n",
      "loss: 0.000089  [  200/ 1017]\n",
      "loss: 0.000242  [  400/ 1017]\n",
      "loss: 0.000177  [  600/ 1017]\n",
      "loss: 0.000300  [  800/ 1017]\n",
      "loss: 0.000035  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.232410\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.000412  [    0/ 1017]\n",
      "loss: 0.000035  [  200/ 1017]\n",
      "loss: 0.000152  [  400/ 1017]\n",
      "loss: 0.000045  [  600/ 1017]\n",
      "loss: 0.000124  [  800/ 1017]\n",
      "loss: 0.002560  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.199058\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.000148  [    0/ 1017]\n",
      "loss: 0.000032  [  200/ 1017]\n",
      "loss: 0.001378  [  400/ 1017]\n",
      "loss: 0.000517  [  600/ 1017]\n",
      "loss: 0.000128  [  800/ 1017]\n",
      "loss: 0.000137  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.232527\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/ 1017]\n",
      "loss: 0.000076  [  200/ 1017]\n",
      "loss: 0.000025  [  400/ 1017]\n",
      "loss: 0.000026  [  600/ 1017]\n",
      "loss: 0.000033  [  800/ 1017]\n",
      "loss: 0.000134  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.214358\n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.000484  [    0/ 1017]\n",
      "loss: 0.000182  [  200/ 1017]\n",
      "loss: 0.000339  [  400/ 1017]\n",
      "loss: 0.000077  [  600/ 1017]\n",
      "loss: 0.001693  [  800/ 1017]\n",
      "loss: 0.000100  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.425320\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.000026  [    0/ 1017]\n",
      "loss: 0.000044  [  200/ 1017]\n",
      "loss: 0.000068  [  400/ 1017]\n",
      "loss: 0.000067  [  600/ 1017]\n",
      "loss: 0.000094  [  800/ 1017]\n",
      "loss: 0.000075  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.244873\n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.000275  [    0/ 1017]\n",
      "loss: 0.000051  [  200/ 1017]\n",
      "loss: 0.000097  [  400/ 1017]\n",
      "loss: 0.000050  [  600/ 1017]\n",
      "loss: 0.000194  [  800/ 1017]\n",
      "loss: 0.000142  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.184632\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.000463  [    0/ 1017]\n",
      "loss: 0.000033  [  200/ 1017]\n",
      "loss: 0.000765  [  400/ 1017]\n",
      "loss: 0.000038  [  600/ 1017]\n",
      "loss: 0.000115  [  800/ 1017]\n",
      "loss: 0.000025  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.261050\n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.000026  [    0/ 1017]\n",
      "loss: 0.000033  [  200/ 1017]\n",
      "loss: 0.000026  [  400/ 1017]\n",
      "loss: 0.000206  [  600/ 1017]\n",
      "loss: 0.000028  [  800/ 1017]\n",
      "loss: 0.000046  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.245555\n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.000222  [    0/ 1017]\n",
      "loss: 0.000029  [  200/ 1017]\n",
      "loss: 0.000020  [  400/ 1017]\n",
      "loss: 0.000200  [  600/ 1017]\n",
      "loss: 0.000042  [  800/ 1017]\n",
      "loss: 0.000025  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.250908\n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000336  [  400/ 1017]\n",
      "loss: 0.000067  [  600/ 1017]\n",
      "loss: 0.000089  [  800/ 1017]\n",
      "loss: 0.000028  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.190985\n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.000660  [    0/ 1017]\n",
      "loss: 0.000016  [  200/ 1017]\n",
      "loss: 0.000028  [  400/ 1017]\n",
      "loss: 0.000014  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000051  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.291555\n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/ 1017]\n",
      "loss: 0.000021  [  200/ 1017]\n",
      "loss: 0.000091  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000019  [  800/ 1017]\n",
      "loss: 0.000060  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.241408\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.000027  [    0/ 1017]\n",
      "loss: 0.000031  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000018  [  600/ 1017]\n",
      "loss: 0.000088  [  800/ 1017]\n",
      "loss: 0.000030  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.329363\n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/ 1017]\n",
      "loss: 0.000024  [  200/ 1017]\n",
      "loss: 0.000078  [  400/ 1017]\n",
      "loss: 0.000030  [  600/ 1017]\n",
      "loss: 0.000059  [  800/ 1017]\n",
      "loss: 0.000055  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.208671\n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.000014  [    0/ 1017]\n",
      "loss: 0.000043  [  200/ 1017]\n",
      "loss: 0.000028  [  400/ 1017]\n",
      "loss: 0.000024  [  600/ 1017]\n",
      "loss: 0.000047  [  800/ 1017]\n",
      "loss: 0.000019  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.268025\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.000087  [    0/ 1017]\n",
      "loss: 0.000107  [  200/ 1017]\n",
      "loss: 0.000089  [  400/ 1017]\n",
      "loss: 0.000027  [  600/ 1017]\n",
      "loss: 0.000017  [  800/ 1017]\n",
      "loss: 0.000080  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.258254\n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000531  [  400/ 1017]\n",
      "loss: 0.000181  [  600/ 1017]\n",
      "loss: 0.000051  [  800/ 1017]\n",
      "loss: 0.000152  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.268702\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000012  [  200/ 1017]\n",
      "loss: 0.000022  [  400/ 1017]\n",
      "loss: 0.000022  [  600/ 1017]\n",
      "loss: 0.000026  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.212827\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.000186  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000260  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000030  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.236757\n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.000054  [    0/ 1017]\n",
      "loss: 0.000137  [  200/ 1017]\n",
      "loss: 0.000018  [  400/ 1017]\n",
      "loss: 0.000016  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000020  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.185522\n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/ 1017]\n",
      "loss: 0.000023  [  200/ 1017]\n",
      "loss: 0.000018  [  400/ 1017]\n",
      "loss: 0.000093  [  600/ 1017]\n",
      "loss: 0.000032  [  800/ 1017]\n",
      "loss: 0.000180  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.246182\n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.000026  [    0/ 1017]\n",
      "loss: 0.000029  [  200/ 1017]\n",
      "loss: 0.000119  [  400/ 1017]\n",
      "loss: 0.000110  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.223069\n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000024  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000027  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000213  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.364223\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/ 1017]\n",
      "loss: 0.000024  [  200/ 1017]\n",
      "loss: 0.000104  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000021  [  800/ 1017]\n",
      "loss: 0.000122  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.247799\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.000044  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000029  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.209805\n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000020  [  200/ 1017]\n",
      "loss: 0.000042  [  400/ 1017]\n",
      "loss: 0.000015  [  600/ 1017]\n",
      "loss: 0.000041  [  800/ 1017]\n",
      "loss: 0.000023  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.211525\n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.000058  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000015  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000043  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.324371\n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000022  [  400/ 1017]\n",
      "loss: 0.000015  [  600/ 1017]\n",
      "loss: 0.000222  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.487757\n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000031  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000024  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.227440\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.000037  [    0/ 1017]\n",
      "loss: 0.000021  [  200/ 1017]\n",
      "loss: 0.000014  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000175  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.248945\n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.000046  [    0/ 1017]\n",
      "loss: 0.000022  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000032  [  600/ 1017]\n",
      "loss: 0.000032  [  800/ 1017]\n",
      "loss: 0.000044  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.294676\n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000109  [  800/ 1017]\n",
      "loss: 0.000045  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.277186\n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.000037  [    0/ 1017]\n",
      "loss: 0.000014  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000028  [  800/ 1017]\n",
      "loss: 0.000025  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.223738\n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000021  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000017  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.186494\n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000031  [  600/ 1017]\n",
      "loss: 0.000036  [  800/ 1017]\n",
      "loss: 0.000057  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.295409\n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000243  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000046  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.273303\n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000060  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.204151\n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.000071  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000005  [  400/ 1017]\n",
      "loss: 0.000054  [  600/ 1017]\n",
      "loss: 0.000039  [  800/ 1017]\n",
      "loss: 0.000028  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.217145\n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.267536\n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000040  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.253145\n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000024  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000018  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.556437\n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000033  [  600/ 1017]\n",
      "loss: 0.000097  [  800/ 1017]\n",
      "loss: 0.000025  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.276294\n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000018  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.241706\n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.000256  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000005  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.240100\n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000021  [  600/ 1017]\n",
      "loss: 0.000011  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.266724\n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000015  [  600/ 1017]\n",
      "loss: 0.000023  [  800/ 1017]\n",
      "loss: 0.000013  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.315208\n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.305068\n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000025  [  600/ 1017]\n",
      "loss: 0.000019  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.255976\n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000013  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.238169\n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000024  [  600/ 1017]\n",
      "loss: 0.000008  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.207274\n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000020  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.224306\n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000013  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000028  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.198088\n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000011  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.325600\n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000020  [  800/ 1017]\n",
      "loss: 0.000035  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.279772\n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000012  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.259532\n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000015  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000011  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.252023\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.313426\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.200580\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.295804\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.254276\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000029  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.310195\n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.253122\n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000013  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.246383\n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000008  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.242240\n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000014  [  800/ 1017]\n",
      "loss: 0.000021  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.254783\n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000029  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.266495\n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.242707\n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000015  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.344668\n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.000133  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000019  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.355340\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.214532\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.282025\n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.287326\n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.245861\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000021  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.538317\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.300505\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000012  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.261170\n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.246111\n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000008  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.310043\n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000074  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.202440\n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.237538\n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000014  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.196641\n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.232033\n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.255452\n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000005  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.242321\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.237344\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.244503\n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.198166\n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.229989\n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.205625\n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000008  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.276707\n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.251807\n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.285485\n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.409760\n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.529079\n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.276528\n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.309595\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.249201\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.298241\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000005  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.302072\n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.288094\n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.242759\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.258325\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.293105\n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.267708\n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.419296\n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.253374\n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.259961\n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.392110\n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.292661\n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.274044\n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.271503\n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.248437\n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.329270\n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.251492\n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.334545\n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.233393\n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.286011\n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.314852\n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.352444\n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.296641\n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.226341\n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.271903\n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.250859\n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.517992\n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.272273\n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.297780\n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.286864\n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.256771\n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.251551\n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.249937\n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.223579\n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.254219\n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.340610\n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.239274\n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.310859\n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.231518\n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.310982\n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.239338\n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 98.41%, Avg loss: 0.168126\n",
      "Model saved\n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.289924\n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.243434\n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.226650\n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.366446\n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.253054\n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.281994\n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.472219\n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.357713\n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000000  [  400/ 1017]\n",
      "loss: 0.000000  [  600/ 1017]\n",
      "loss: 0.000000  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.314886\n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000000  [    0/ 1017]\n",
      "loss: 0.000000  [  200/ 1017]\n",
      "loss: 0.247661  [  400/ 1017]\n",
      "loss: 1.124159  [  600/ 1017]\n",
      "loss: 0.302192  [  800/ 1017]\n",
      "loss: 1.227460  [  850/ 1017]\n",
      "Accuracy: 53.97%, Avg loss: 0.974102\n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.550562  [    0/ 1017]\n",
      "loss: 0.509920  [  200/ 1017]\n",
      "loss: 1.068969  [  400/ 1017]\n",
      "loss: 0.068365  [  600/ 1017]\n",
      "loss: 0.315448  [  800/ 1017]\n",
      "loss: 1.109376  [  850/ 1017]\n",
      "Accuracy: 78.57%, Avg loss: 1.192074\n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.695305  [    0/ 1017]\n",
      "loss: 0.269476  [  200/ 1017]\n",
      "loss: 0.133959  [  400/ 1017]\n",
      "loss: 0.097296  [  600/ 1017]\n",
      "loss: 0.041851  [  800/ 1017]\n",
      "loss: 0.010767  [  850/ 1017]\n",
      "Accuracy: 88.10%, Avg loss: 0.371948\n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.021723  [    0/ 1017]\n",
      "loss: 0.004802  [  200/ 1017]\n",
      "loss: 0.149477  [  400/ 1017]\n",
      "loss: 0.085876  [  600/ 1017]\n",
      "loss: 0.018910  [  800/ 1017]\n",
      "loss: 0.003495  [  850/ 1017]\n",
      "Accuracy: 88.10%, Avg loss: 0.410613\n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.276611  [    0/ 1017]\n",
      "loss: 0.253007  [  200/ 1017]\n",
      "loss: 0.015292  [  400/ 1017]\n",
      "loss: 0.052315  [  600/ 1017]\n",
      "loss: 0.132922  [  800/ 1017]\n",
      "loss: 0.012725  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.373156\n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.004040  [    0/ 1017]\n",
      "loss: 0.006581  [  200/ 1017]\n",
      "loss: 0.001970  [  400/ 1017]\n",
      "loss: 0.078528  [  600/ 1017]\n",
      "loss: 0.009958  [  800/ 1017]\n",
      "loss: 0.026616  [  850/ 1017]\n",
      "Accuracy: 88.89%, Avg loss: 0.322942\n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.007076  [    0/ 1017]\n",
      "loss: 0.003646  [  200/ 1017]\n",
      "loss: 0.005336  [  400/ 1017]\n",
      "loss: 0.002689  [  600/ 1017]\n",
      "loss: 0.000617  [  800/ 1017]\n",
      "loss: 0.002662  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.269167\n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.001896  [    0/ 1017]\n",
      "loss: 0.006976  [  200/ 1017]\n",
      "loss: 0.012021  [  400/ 1017]\n",
      "loss: 0.001589  [  600/ 1017]\n",
      "loss: 0.000968  [  800/ 1017]\n",
      "loss: 0.001729  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.241700\n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000550  [    0/ 1017]\n",
      "loss: 0.002260  [  200/ 1017]\n",
      "loss: 0.001145  [  400/ 1017]\n",
      "loss: 0.000842  [  600/ 1017]\n",
      "loss: 0.003710  [  800/ 1017]\n",
      "loss: 0.001592  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.550186\n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000853  [    0/ 1017]\n",
      "loss: 0.000450  [  200/ 1017]\n",
      "loss: 0.000418  [  400/ 1017]\n",
      "loss: 0.000173  [  600/ 1017]\n",
      "loss: 0.000665  [  800/ 1017]\n",
      "loss: 0.000108  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.241130\n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000814  [    0/ 1017]\n",
      "loss: 0.000842  [  200/ 1017]\n",
      "loss: 0.001612  [  400/ 1017]\n",
      "loss: 0.001041  [  600/ 1017]\n",
      "loss: 0.000559  [  800/ 1017]\n",
      "loss: 0.000133  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.349965\n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.000279  [    0/ 1017]\n",
      "loss: 0.000859  [  200/ 1017]\n",
      "loss: 0.002279  [  400/ 1017]\n",
      "loss: 0.000325  [  600/ 1017]\n",
      "loss: 0.000560  [  800/ 1017]\n",
      "loss: 0.000118  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.290281\n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.000412  [    0/ 1017]\n",
      "loss: 0.001506  [  200/ 1017]\n",
      "loss: 0.000236  [  400/ 1017]\n",
      "loss: 0.000186  [  600/ 1017]\n",
      "loss: 0.000205  [  800/ 1017]\n",
      "loss: 0.000694  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.236751\n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/ 1017]\n",
      "loss: 0.001451  [  200/ 1017]\n",
      "loss: 0.000068  [  400/ 1017]\n",
      "loss: 0.000639  [  600/ 1017]\n",
      "loss: 0.000733  [  800/ 1017]\n",
      "loss: 0.000120  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.263012\n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.000115  [    0/ 1017]\n",
      "loss: 0.000043  [  200/ 1017]\n",
      "loss: 0.000160  [  400/ 1017]\n",
      "loss: 0.001871  [  600/ 1017]\n",
      "loss: 0.002097  [  800/ 1017]\n",
      "loss: 0.000050  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.272597\n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.001010  [    0/ 1017]\n",
      "loss: 0.000083  [  200/ 1017]\n",
      "loss: 0.000614  [  400/ 1017]\n",
      "loss: 0.000138  [  600/ 1017]\n",
      "loss: 0.000701  [  800/ 1017]\n",
      "loss: 0.000135  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.264746\n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.000133  [    0/ 1017]\n",
      "loss: 0.000162  [  200/ 1017]\n",
      "loss: 0.000094  [  400/ 1017]\n",
      "loss: 0.000048  [  600/ 1017]\n",
      "loss: 0.000267  [  800/ 1017]\n",
      "loss: 0.000209  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.244523\n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/ 1017]\n",
      "loss: 0.000211  [  200/ 1017]\n",
      "loss: 0.000097  [  400/ 1017]\n",
      "loss: 0.000598  [  600/ 1017]\n",
      "loss: 0.000289  [  800/ 1017]\n",
      "loss: 0.000157  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.376468\n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000361  [    0/ 1017]\n",
      "loss: 0.000016  [  200/ 1017]\n",
      "loss: 0.000070  [  400/ 1017]\n",
      "loss: 0.000083  [  600/ 1017]\n",
      "loss: 0.000516  [  800/ 1017]\n",
      "loss: 0.000090  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.423694\n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.000647  [    0/ 1017]\n",
      "loss: 0.000096  [  200/ 1017]\n",
      "loss: 0.000030  [  400/ 1017]\n",
      "loss: 0.000044  [  600/ 1017]\n",
      "loss: 0.000019  [  800/ 1017]\n",
      "loss: 0.000017  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.237962\n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000254  [  200/ 1017]\n",
      "loss: 0.000089  [  400/ 1017]\n",
      "loss: 0.000040  [  600/ 1017]\n",
      "loss: 0.000315  [  800/ 1017]\n",
      "loss: 0.000097  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.317325\n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/ 1017]\n",
      "loss: 0.000200  [  200/ 1017]\n",
      "loss: 0.000173  [  400/ 1017]\n",
      "loss: 0.000781  [  600/ 1017]\n",
      "loss: 0.000227  [  800/ 1017]\n",
      "loss: 0.000019  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.306275\n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.000384  [    0/ 1017]\n",
      "loss: 0.000038  [  200/ 1017]\n",
      "loss: 0.000068  [  400/ 1017]\n",
      "loss: 0.000045  [  600/ 1017]\n",
      "loss: 0.000101  [  800/ 1017]\n",
      "loss: 0.003702  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.285567\n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000034  [    0/ 1017]\n",
      "loss: 0.000841  [  200/ 1017]\n",
      "loss: 0.000172  [  400/ 1017]\n",
      "loss: 0.000163  [  600/ 1017]\n",
      "loss: 0.000069  [  800/ 1017]\n",
      "loss: 0.000411  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.225875\n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.000025  [    0/ 1017]\n",
      "loss: 0.000043  [  200/ 1017]\n",
      "loss: 0.000011  [  400/ 1017]\n",
      "loss: 0.000059  [  600/ 1017]\n",
      "loss: 0.000077  [  800/ 1017]\n",
      "loss: 0.000029  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.261466\n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000161  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000065  [  400/ 1017]\n",
      "loss: 0.000046  [  600/ 1017]\n",
      "loss: 0.000053  [  800/ 1017]\n",
      "loss: 0.000072  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.270492\n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000203  [    0/ 1017]\n",
      "loss: 0.000026  [  200/ 1017]\n",
      "loss: 0.000079  [  400/ 1017]\n",
      "loss: 0.000148  [  600/ 1017]\n",
      "loss: 0.125168  [  800/ 1017]\n",
      "loss: 0.000195  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.602781\n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.136355  [    0/ 1017]\n",
      "loss: 0.111234  [  200/ 1017]\n",
      "loss: 0.006710  [  400/ 1017]\n",
      "loss: 0.035375  [  600/ 1017]\n",
      "loss: 0.017166  [  800/ 1017]\n",
      "loss: 0.004060  [  850/ 1017]\n",
      "Accuracy: 85.71%, Avg loss: 0.547114\n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.041138  [    0/ 1017]\n",
      "loss: 0.087491  [  200/ 1017]\n",
      "loss: 0.127285  [  400/ 1017]\n",
      "loss: 0.022273  [  600/ 1017]\n",
      "loss: 0.094758  [  800/ 1017]\n",
      "loss: 0.018981  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.358537\n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.046530  [    0/ 1017]\n",
      "loss: 0.016284  [  200/ 1017]\n",
      "loss: 0.011367  [  400/ 1017]\n",
      "loss: 0.003873  [  600/ 1017]\n",
      "loss: 0.000738  [  800/ 1017]\n",
      "loss: 0.009501  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.292842\n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.001989  [    0/ 1017]\n",
      "loss: 0.000365  [  200/ 1017]\n",
      "loss: 0.000590  [  400/ 1017]\n",
      "loss: 0.000210  [  600/ 1017]\n",
      "loss: 0.003119  [  800/ 1017]\n",
      "loss: 0.000360  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.253328\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.002207  [    0/ 1017]\n",
      "loss: 0.003977  [  200/ 1017]\n",
      "loss: 0.018654  [  400/ 1017]\n",
      "loss: 0.002920  [  600/ 1017]\n",
      "loss: 0.004836  [  800/ 1017]\n",
      "loss: 0.000283  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.268061\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000636  [    0/ 1017]\n",
      "loss: 0.000547  [  200/ 1017]\n",
      "loss: 0.000083  [  400/ 1017]\n",
      "loss: 0.000116  [  600/ 1017]\n",
      "loss: 0.001240  [  800/ 1017]\n",
      "loss: 0.000304  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.238242\n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.000738  [    0/ 1017]\n",
      "loss: 0.000497  [  200/ 1017]\n",
      "loss: 0.000057  [  400/ 1017]\n",
      "loss: 0.000487  [  600/ 1017]\n",
      "loss: 0.000224  [  800/ 1017]\n",
      "loss: 0.000296  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.221679\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.002310  [    0/ 1017]\n",
      "loss: 0.000764  [  200/ 1017]\n",
      "loss: 0.000108  [  400/ 1017]\n",
      "loss: 0.000842  [  600/ 1017]\n",
      "loss: 0.001858  [  800/ 1017]\n",
      "loss: 0.000151  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.252566\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.000095  [    0/ 1017]\n",
      "loss: 0.000216  [  200/ 1017]\n",
      "loss: 0.000552  [  400/ 1017]\n",
      "loss: 0.000485  [  600/ 1017]\n",
      "loss: 0.000570  [  800/ 1017]\n",
      "loss: 0.000083  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.248046\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/ 1017]\n",
      "loss: 0.000293  [  200/ 1017]\n",
      "loss: 0.000169  [  400/ 1017]\n",
      "loss: 0.001510  [  600/ 1017]\n",
      "loss: 0.000852  [  800/ 1017]\n",
      "loss: 0.000221  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.263206\n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000104  [    0/ 1017]\n",
      "loss: 0.000136  [  200/ 1017]\n",
      "loss: 0.000367  [  400/ 1017]\n",
      "loss: 0.000175  [  600/ 1017]\n",
      "loss: 0.000174  [  800/ 1017]\n",
      "loss: 0.000190  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.213432\n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.000152  [    0/ 1017]\n",
      "loss: 0.000135  [  200/ 1017]\n",
      "loss: 0.000016  [  400/ 1017]\n",
      "loss: 0.000278  [  600/ 1017]\n",
      "loss: 0.000121  [  800/ 1017]\n",
      "loss: 0.000041  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.233388\n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000115  [    0/ 1017]\n",
      "loss: 0.000078  [  200/ 1017]\n",
      "loss: 0.000132  [  400/ 1017]\n",
      "loss: 0.000029  [  600/ 1017]\n",
      "loss: 0.000062  [  800/ 1017]\n",
      "loss: 0.000021  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.279647\n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.000148  [    0/ 1017]\n",
      "loss: 0.000184  [  200/ 1017]\n",
      "loss: 0.000073  [  400/ 1017]\n",
      "loss: 0.000190  [  600/ 1017]\n",
      "loss: 0.000033  [  800/ 1017]\n",
      "loss: 0.000129  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.348200\n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.000201  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000052  [  400/ 1017]\n",
      "loss: 0.000065  [  600/ 1017]\n",
      "loss: 0.000644  [  800/ 1017]\n",
      "loss: 0.000022  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.225869\n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000011  [  200/ 1017]\n",
      "loss: 0.000178  [  400/ 1017]\n",
      "loss: 0.000204  [  600/ 1017]\n",
      "loss: 0.000043  [  800/ 1017]\n",
      "loss: 0.000041  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.240633\n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/ 1017]\n",
      "loss: 0.000183  [  200/ 1017]\n",
      "loss: 0.000050  [  400/ 1017]\n",
      "loss: 0.000130  [  600/ 1017]\n",
      "loss: 0.000123  [  800/ 1017]\n",
      "loss: 0.002075  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.455519\n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.000025  [    0/ 1017]\n",
      "loss: 0.000115  [  200/ 1017]\n",
      "loss: 0.000174  [  400/ 1017]\n",
      "loss: 0.000020  [  600/ 1017]\n",
      "loss: 0.000121  [  800/ 1017]\n",
      "loss: 0.000043  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.260765\n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/ 1017]\n",
      "loss: 0.000053  [  200/ 1017]\n",
      "loss: 0.000020  [  400/ 1017]\n",
      "loss: 0.000082  [  600/ 1017]\n",
      "loss: 0.000032  [  800/ 1017]\n",
      "loss: 0.000022  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.313150\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/ 1017]\n",
      "loss: 0.000177  [  200/ 1017]\n",
      "loss: 0.000192  [  400/ 1017]\n",
      "loss: 0.055461  [  600/ 1017]\n",
      "loss: 0.000070  [  800/ 1017]\n",
      "loss: 0.094910  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.505188\n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.011996  [    0/ 1017]\n",
      "loss: 0.191454  [  200/ 1017]\n",
      "loss: 0.200371  [  400/ 1017]\n",
      "loss: 0.003773  [  600/ 1017]\n",
      "loss: 0.004376  [  800/ 1017]\n",
      "loss: 0.000623  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.332313\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.000780  [    0/ 1017]\n",
      "loss: 0.000730  [  200/ 1017]\n",
      "loss: 0.605310  [  400/ 1017]\n",
      "loss: 0.046707  [  600/ 1017]\n",
      "loss: 0.009104  [  800/ 1017]\n",
      "loss: 0.128545  [  850/ 1017]\n",
      "Accuracy: 88.10%, Avg loss: 0.453505\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.000736  [    0/ 1017]\n",
      "loss: 0.004027  [  200/ 1017]\n",
      "loss: 0.002956  [  400/ 1017]\n",
      "loss: 0.026321  [  600/ 1017]\n",
      "loss: 0.000775  [  800/ 1017]\n",
      "loss: 0.001109  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.505079\n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.004442  [    0/ 1017]\n",
      "loss: 0.002996  [  200/ 1017]\n",
      "loss: 0.004442  [  400/ 1017]\n",
      "loss: 0.002471  [  600/ 1017]\n",
      "loss: 0.000965  [  800/ 1017]\n",
      "loss: 0.002412  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.528503\n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.002414  [    0/ 1017]\n",
      "loss: 0.004645  [  200/ 1017]\n",
      "loss: 0.001039  [  400/ 1017]\n",
      "loss: 0.000470  [  600/ 1017]\n",
      "loss: 0.001775  [  800/ 1017]\n",
      "loss: 0.000522  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.489369\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.000240  [    0/ 1017]\n",
      "loss: 0.000699  [  200/ 1017]\n",
      "loss: 0.034918  [  400/ 1017]\n",
      "loss: 0.001085  [  600/ 1017]\n",
      "loss: 0.001316  [  800/ 1017]\n",
      "loss: 0.036677  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.347629\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.000806  [    0/ 1017]\n",
      "loss: 0.000341  [  200/ 1017]\n",
      "loss: 0.000887  [  400/ 1017]\n",
      "loss: 0.000617  [  600/ 1017]\n",
      "loss: 0.004088  [  800/ 1017]\n",
      "loss: 0.000023  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.303959\n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.000186  [    0/ 1017]\n",
      "loss: 0.000177  [  200/ 1017]\n",
      "loss: 0.000194  [  400/ 1017]\n",
      "loss: 0.002353  [  600/ 1017]\n",
      "loss: 0.000272  [  800/ 1017]\n",
      "loss: 0.000261  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.331971\n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.000146  [    0/ 1017]\n",
      "loss: 0.000245  [  200/ 1017]\n",
      "loss: 0.000977  [  400/ 1017]\n",
      "loss: 0.000289  [  600/ 1017]\n",
      "loss: 0.000146  [  800/ 1017]\n",
      "loss: 0.000253  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.306910\n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.000144  [    0/ 1017]\n",
      "loss: 0.000314  [  200/ 1017]\n",
      "loss: 0.000037  [  400/ 1017]\n",
      "loss: 0.001036  [  600/ 1017]\n",
      "loss: 0.000254  [  800/ 1017]\n",
      "loss: 0.000163  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.300454\n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.000191  [    0/ 1017]\n",
      "loss: 0.000115  [  200/ 1017]\n",
      "loss: 0.000074  [  400/ 1017]\n",
      "loss: 0.000277  [  600/ 1017]\n",
      "loss: 0.000037  [  800/ 1017]\n",
      "loss: 0.000233  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.297418\n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.000175  [    0/ 1017]\n",
      "loss: 0.000093  [  200/ 1017]\n",
      "loss: 0.000086  [  400/ 1017]\n",
      "loss: 0.000136  [  600/ 1017]\n",
      "loss: 0.000319  [  800/ 1017]\n",
      "loss: 0.000174  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.426201\n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.000075  [    0/ 1017]\n",
      "loss: 0.000014  [  200/ 1017]\n",
      "loss: 0.000093  [  400/ 1017]\n",
      "loss: 0.000174  [  600/ 1017]\n",
      "loss: 0.000116  [  800/ 1017]\n",
      "loss: 0.000141  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.288974\n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.000093  [    0/ 1017]\n",
      "loss: 0.000027  [  200/ 1017]\n",
      "loss: 0.001466  [  400/ 1017]\n",
      "loss: 0.000582  [  600/ 1017]\n",
      "loss: 0.000122  [  800/ 1017]\n",
      "loss: 0.000054  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.281757\n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.000092  [    0/ 1017]\n",
      "loss: 0.000043  [  200/ 1017]\n",
      "loss: 0.000049  [  400/ 1017]\n",
      "loss: 0.000020  [  600/ 1017]\n",
      "loss: 0.000059  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.329510\n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.000124  [    0/ 1017]\n",
      "loss: 0.000028  [  200/ 1017]\n",
      "loss: 0.000070  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000073  [  800/ 1017]\n",
      "loss: 0.000081  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.286188\n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.000033  [    0/ 1017]\n",
      "loss: 0.000090  [  200/ 1017]\n",
      "loss: 0.000364  [  400/ 1017]\n",
      "loss: 0.000051  [  600/ 1017]\n",
      "loss: 0.000367  [  800/ 1017]\n",
      "loss: 0.000034  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.274082\n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.000039  [    0/ 1017]\n",
      "loss: 0.000023  [  200/ 1017]\n",
      "loss: 0.000057  [  400/ 1017]\n",
      "loss: 0.000225  [  600/ 1017]\n",
      "loss: 0.000110  [  800/ 1017]\n",
      "loss: 0.000105  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.258387\n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.000049  [    0/ 1017]\n",
      "loss: 0.000055  [  200/ 1017]\n",
      "loss: 0.000042  [  400/ 1017]\n",
      "loss: 0.000033  [  600/ 1017]\n",
      "loss: 0.000036  [  800/ 1017]\n",
      "loss: 0.000044  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.278492\n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/ 1017]\n",
      "loss: 0.000148  [  200/ 1017]\n",
      "loss: 0.000034  [  400/ 1017]\n",
      "loss: 0.000015  [  600/ 1017]\n",
      "loss: 0.000028  [  800/ 1017]\n",
      "loss: 0.000532  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.296014\n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.000027  [    0/ 1017]\n",
      "loss: 0.000084  [  200/ 1017]\n",
      "loss: 0.000064  [  400/ 1017]\n",
      "loss: 0.000030  [  600/ 1017]\n",
      "loss: 0.000181  [  800/ 1017]\n",
      "loss: 0.000032  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.286013\n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.000097  [    0/ 1017]\n",
      "loss: 0.000074  [  200/ 1017]\n",
      "loss: 0.000323  [  400/ 1017]\n",
      "loss: 0.000087  [  600/ 1017]\n",
      "loss: 0.000066  [  800/ 1017]\n",
      "loss: 0.000095  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.332729\n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.000016  [    0/ 1017]\n",
      "loss: 0.000630  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000048  [  600/ 1017]\n",
      "loss: 0.000205  [  800/ 1017]\n",
      "loss: 0.000088  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.337999\n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.000037  [    0/ 1017]\n",
      "loss: 0.000023  [  200/ 1017]\n",
      "loss: 0.000092  [  400/ 1017]\n",
      "loss: 0.000017  [  600/ 1017]\n",
      "loss: 0.000273  [  800/ 1017]\n",
      "loss: 0.000171  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.287954\n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.000098  [    0/ 1017]\n",
      "loss: 0.000011  [  200/ 1017]\n",
      "loss: 0.000075  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000158  [  800/ 1017]\n",
      "loss: 0.000025  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.326519\n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.000031  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000209  [  400/ 1017]\n",
      "loss: 0.000021  [  600/ 1017]\n",
      "loss: 0.000123  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.288415\n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.000148  [    0/ 1017]\n",
      "loss: 0.000033  [  200/ 1017]\n",
      "loss: 0.000018  [  400/ 1017]\n",
      "loss: 0.000032  [  600/ 1017]\n",
      "loss: 0.000023  [  800/ 1017]\n",
      "loss: 0.000019  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.278326\n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.000098  [    0/ 1017]\n",
      "loss: 0.000023  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000051  [  600/ 1017]\n",
      "loss: 0.000019  [  800/ 1017]\n",
      "loss: 0.000020  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.442678\n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.000023  [    0/ 1017]\n",
      "loss: 0.000044  [  200/ 1017]\n",
      "loss: 0.000035  [  400/ 1017]\n",
      "loss: 0.000039  [  600/ 1017]\n",
      "loss: 0.000016  [  800/ 1017]\n",
      "loss: 0.000090  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.570702\n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.000135  [    0/ 1017]\n",
      "loss: 0.000026  [  200/ 1017]\n",
      "loss: 0.000043  [  400/ 1017]\n",
      "loss: 0.000044  [  600/ 1017]\n",
      "loss: 0.000087  [  800/ 1017]\n",
      "loss: 0.000040  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.292251\n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.000019  [    0/ 1017]\n",
      "loss: 0.000055  [  200/ 1017]\n",
      "loss: 0.000027  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000063  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.334715\n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000042  [  400/ 1017]\n",
      "loss: 0.000180  [  600/ 1017]\n",
      "loss: 0.000012  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.273068\n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000027  [  200/ 1017]\n",
      "loss: 0.000032  [  400/ 1017]\n",
      "loss: 0.000478  [  600/ 1017]\n",
      "loss: 0.000128  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.293244\n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.000016  [    0/ 1017]\n",
      "loss: 0.000033  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000054  [  600/ 1017]\n",
      "loss: 0.000008  [  800/ 1017]\n",
      "loss: 0.000095  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.568627\n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.000034  [    0/ 1017]\n",
      "loss: 0.000076  [  200/ 1017]\n",
      "loss: 0.000025  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000045  [  800/ 1017]\n",
      "loss: 0.000101  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.266107\n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000036  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000017  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000309  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.340832\n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000061  [  200/ 1017]\n",
      "loss: 0.000051  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.488663\n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.000035  [    0/ 1017]\n",
      "loss: 0.000019  [  200/ 1017]\n",
      "loss: 0.000012  [  400/ 1017]\n",
      "loss: 0.000013  [  600/ 1017]\n",
      "loss: 0.000027  [  800/ 1017]\n",
      "loss: 0.001389  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.253362\n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000023  [  400/ 1017]\n",
      "loss: 0.000111  [  600/ 1017]\n",
      "loss: 0.000038  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.467202\n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000022  [  200/ 1017]\n",
      "loss: 0.000022  [  400/ 1017]\n",
      "loss: 0.000040  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.283456\n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.000064  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000288  [  400/ 1017]\n",
      "loss: 0.000140  [  600/ 1017]\n",
      "loss: 0.000092  [  800/ 1017]\n",
      "loss: 0.000086  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.281744\n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.000090  [    0/ 1017]\n",
      "loss: 0.000052  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000101  [  600/ 1017]\n",
      "loss: 0.000052  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.270922\n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.000053  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000012  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.286301\n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.000035  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000018  [  600/ 1017]\n",
      "loss: 0.000099  [  800/ 1017]\n",
      "loss: 0.000016  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.322158\n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.000093  [    0/ 1017]\n",
      "loss: 0.000021  [  200/ 1017]\n",
      "loss: 0.000012  [  400/ 1017]\n",
      "loss: 0.000014  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000020  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.647688\n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000027  [  200/ 1017]\n",
      "loss: 0.000076  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000038  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.365076\n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.434759\n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.000032  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000111  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.629379\n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000007  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000093  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.292651\n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.000029  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000035  [  400/ 1017]\n",
      "loss: 0.000064  [  600/ 1017]\n",
      "loss: 0.000008  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.324258\n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000018  [  600/ 1017]\n",
      "loss: 0.000026  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.295496\n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000005  [  400/ 1017]\n",
      "loss: 0.000012  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.289057\n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000017  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.314290\n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000042  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.296091\n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000014  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000047  [  600/ 1017]\n",
      "loss: 0.000012  [  800/ 1017]\n",
      "loss: 0.000060  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.288241\n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.300156\n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/ 1017]\n",
      "loss: 0.000025  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.603150\n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000057  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.351790\n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000022  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.305316\n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000031  [  600/ 1017]\n",
      "loss: 0.000363  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.324454\n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000008  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000043  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.421592\n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000017  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.001179  [  600/ 1017]\n",
      "loss: 0.004042  [  800/ 1017]\n",
      "loss: 0.057714  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.613710\n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.004186  [    0/ 1017]\n",
      "loss: 0.343708  [  200/ 1017]\n",
      "loss: 0.097876  [  400/ 1017]\n",
      "loss: 0.023300  [  600/ 1017]\n",
      "loss: 0.088077  [  800/ 1017]\n",
      "loss: 0.118903  [  850/ 1017]\n",
      "Accuracy: 88.89%, Avg loss: 0.666130\n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.028258  [    0/ 1017]\n",
      "loss: 0.201708  [  200/ 1017]\n",
      "loss: 0.012106  [  400/ 1017]\n",
      "loss: 0.006807  [  600/ 1017]\n",
      "loss: 0.007752  [  800/ 1017]\n",
      "loss: 0.167819  [  850/ 1017]\n",
      "Accuracy: 87.30%, Avg loss: 0.776787\n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.160641  [    0/ 1017]\n",
      "loss: 0.008586  [  200/ 1017]\n",
      "loss: 0.000319  [  400/ 1017]\n",
      "loss: 0.000373  [  600/ 1017]\n",
      "loss: 0.005292  [  800/ 1017]\n",
      "loss: 0.001776  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.324208\n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.004949  [    0/ 1017]\n",
      "loss: 0.002921  [  200/ 1017]\n",
      "loss: 0.003030  [  400/ 1017]\n",
      "loss: 0.002685  [  600/ 1017]\n",
      "loss: 0.001368  [  800/ 1017]\n",
      "loss: 0.000461  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.296972\n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.021288  [    0/ 1017]\n",
      "loss: 0.002210  [  200/ 1017]\n",
      "loss: 0.000610  [  400/ 1017]\n",
      "loss: 0.001224  [  600/ 1017]\n",
      "loss: 0.000474  [  800/ 1017]\n",
      "loss: 0.000336  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.369862\n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.000538  [    0/ 1017]\n",
      "loss: 0.001930  [  200/ 1017]\n",
      "loss: 0.000793  [  400/ 1017]\n",
      "loss: 0.001433  [  600/ 1017]\n",
      "loss: 0.000409  [  800/ 1017]\n",
      "loss: 0.002268  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.460417\n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.000130  [    0/ 1017]\n",
      "loss: 0.000093  [  200/ 1017]\n",
      "loss: 0.000087  [  400/ 1017]\n",
      "loss: 0.000123  [  600/ 1017]\n",
      "loss: 0.000386  [  800/ 1017]\n",
      "loss: 0.001190  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.415568\n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.000325  [    0/ 1017]\n",
      "loss: 0.000672  [  200/ 1017]\n",
      "loss: 0.000839  [  400/ 1017]\n",
      "loss: 0.000532  [  600/ 1017]\n",
      "loss: 0.000070  [  800/ 1017]\n",
      "loss: 0.000166  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.454911\n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.000137  [    0/ 1017]\n",
      "loss: 0.000264  [  200/ 1017]\n",
      "loss: 0.000047  [  400/ 1017]\n",
      "loss: 0.000107  [  600/ 1017]\n",
      "loss: 0.000426  [  800/ 1017]\n",
      "loss: 0.000689  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.327299\n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.000088  [    0/ 1017]\n",
      "loss: 0.000124  [  200/ 1017]\n",
      "loss: 0.000058  [  400/ 1017]\n",
      "loss: 0.000113  [  600/ 1017]\n",
      "loss: 0.001629  [  800/ 1017]\n",
      "loss: 0.000219  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.368643\n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.000079  [    0/ 1017]\n",
      "loss: 0.000491  [  200/ 1017]\n",
      "loss: 0.000415  [  400/ 1017]\n",
      "loss: 0.000534  [  600/ 1017]\n",
      "loss: 0.000230  [  800/ 1017]\n",
      "loss: 0.000441  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.372278\n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.000544  [    0/ 1017]\n",
      "loss: 0.000855  [  200/ 1017]\n",
      "loss: 0.000329  [  400/ 1017]\n",
      "loss: 0.000397  [  600/ 1017]\n",
      "loss: 0.000075  [  800/ 1017]\n",
      "loss: 0.000059  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.302994\n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.000069  [    0/ 1017]\n",
      "loss: 0.000238  [  200/ 1017]\n",
      "loss: 0.000759  [  400/ 1017]\n",
      "loss: 0.000171  [  600/ 1017]\n",
      "loss: 0.000282  [  800/ 1017]\n",
      "loss: 0.000138  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.349679\n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.000237  [    0/ 1017]\n",
      "loss: 0.000040  [  200/ 1017]\n",
      "loss: 0.000041  [  400/ 1017]\n",
      "loss: 0.000357  [  600/ 1017]\n",
      "loss: 0.000230  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.363892\n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/ 1017]\n",
      "loss: 0.000063  [  200/ 1017]\n",
      "loss: 0.000161  [  400/ 1017]\n",
      "loss: 0.000052  [  600/ 1017]\n",
      "loss: 0.000017  [  800/ 1017]\n",
      "loss: 0.000015  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.380178\n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.000048  [    0/ 1017]\n",
      "loss: 0.000097  [  200/ 1017]\n",
      "loss: 0.000119  [  400/ 1017]\n",
      "loss: 0.000415  [  600/ 1017]\n",
      "loss: 0.000125  [  800/ 1017]\n",
      "loss: 0.000475  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.372078\n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000430  [  200/ 1017]\n",
      "loss: 0.000066  [  400/ 1017]\n",
      "loss: 0.000044  [  600/ 1017]\n",
      "loss: 0.000078  [  800/ 1017]\n",
      "loss: 0.000018  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.645596\n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/ 1017]\n",
      "loss: 0.000035  [  200/ 1017]\n",
      "loss: 0.000101  [  400/ 1017]\n",
      "loss: 0.000146  [  600/ 1017]\n",
      "loss: 0.000047  [  800/ 1017]\n",
      "loss: 0.000123  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.335309\n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.000300  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000077  [  400/ 1017]\n",
      "loss: 0.000090  [  600/ 1017]\n",
      "loss: 0.000076  [  800/ 1017]\n",
      "loss: 0.000120  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.464280\n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.000226  [    0/ 1017]\n",
      "loss: 0.000278  [  200/ 1017]\n",
      "loss: 0.000068  [  400/ 1017]\n",
      "loss: 0.000035  [  600/ 1017]\n",
      "loss: 0.000069  [  800/ 1017]\n",
      "loss: 0.000025  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.421980\n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.000067  [    0/ 1017]\n",
      "loss: 0.000753  [  200/ 1017]\n",
      "loss: 0.000060  [  400/ 1017]\n",
      "loss: 0.000164  [  600/ 1017]\n",
      "loss: 0.000041  [  800/ 1017]\n",
      "loss: 0.000068  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.328872\n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.000622  [    0/ 1017]\n",
      "loss: 0.000107  [  200/ 1017]\n",
      "loss: 0.000142  [  400/ 1017]\n",
      "loss: 0.000066  [  600/ 1017]\n",
      "loss: 0.000329  [  800/ 1017]\n",
      "loss: 0.000018  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.332306\n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.000046  [    0/ 1017]\n",
      "loss: 0.000029  [  200/ 1017]\n",
      "loss: 0.000150  [  400/ 1017]\n",
      "loss: 0.000110  [  600/ 1017]\n",
      "loss: 0.000029  [  800/ 1017]\n",
      "loss: 0.000106  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.360332\n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.000029  [    0/ 1017]\n",
      "loss: 0.000024  [  200/ 1017]\n",
      "loss: 0.000025  [  400/ 1017]\n",
      "loss: 0.000033  [  600/ 1017]\n",
      "loss: 0.000017  [  800/ 1017]\n",
      "loss: 0.000024  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.474955\n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.000046  [    0/ 1017]\n",
      "loss: 0.000041  [  200/ 1017]\n",
      "loss: 0.000263  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000172  [  800/ 1017]\n",
      "loss: 0.000483  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.447104\n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.000059  [  200/ 1017]\n",
      "loss: 0.000049  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000036  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.461366\n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.000147  [    0/ 1017]\n",
      "loss: 0.000060  [  200/ 1017]\n",
      "loss: 0.000045  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000191  [  800/ 1017]\n",
      "loss: 0.000243  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.446371\n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.000029  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000028  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000331  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.386992\n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000024  [  400/ 1017]\n",
      "loss: 0.000025  [  600/ 1017]\n",
      "loss: 0.000011  [  800/ 1017]\n",
      "loss: 0.000077  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.458770\n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000117  [  200/ 1017]\n",
      "loss: 0.000029  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000029  [  800/ 1017]\n",
      "loss: 0.000012  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.394349\n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.000041  [    0/ 1017]\n",
      "loss: 0.000042  [  200/ 1017]\n",
      "loss: 0.000070  [  400/ 1017]\n",
      "loss: 0.000116  [  600/ 1017]\n",
      "loss: 0.000005  [  800/ 1017]\n",
      "loss: 0.000061  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.368595\n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.000016  [    0/ 1017]\n",
      "loss: 0.000028  [  200/ 1017]\n",
      "loss: 0.000056  [  400/ 1017]\n",
      "loss: 0.000020  [  600/ 1017]\n",
      "loss: 0.000022  [  800/ 1017]\n",
      "loss: 0.000020  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.461154\n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.000028  [    0/ 1017]\n",
      "loss: 0.000013  [  200/ 1017]\n",
      "loss: 0.000033  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000012  [  800/ 1017]\n",
      "loss: 0.000040  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.367146\n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1017]\n",
      "loss: 0.000021  [  200/ 1017]\n",
      "loss: 0.000042  [  400/ 1017]\n",
      "loss: 0.000062  [  600/ 1017]\n",
      "loss: 0.000037  [  800/ 1017]\n",
      "loss: 0.000028  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.543354\n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.000116  [    0/ 1017]\n",
      "loss: 0.000170  [  200/ 1017]\n",
      "loss: 0.000057  [  400/ 1017]\n",
      "loss: 0.000067  [  600/ 1017]\n",
      "loss: 0.000112  [  800/ 1017]\n",
      "loss: 0.000102  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.327402\n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.000030  [    0/ 1017]\n",
      "loss: 0.000675  [  200/ 1017]\n",
      "loss: 0.000037  [  400/ 1017]\n",
      "loss: 0.065178  [  600/ 1017]\n",
      "loss: 0.004489  [  800/ 1017]\n",
      "loss: 0.006070  [  850/ 1017]\n",
      "Accuracy: 89.68%, Avg loss: 0.632075\n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.027612  [    0/ 1017]\n",
      "loss: 0.000836  [  200/ 1017]\n",
      "loss: 0.000349  [  400/ 1017]\n",
      "loss: 0.000519  [  600/ 1017]\n",
      "loss: 0.538341  [  800/ 1017]\n",
      "loss: 0.086489  [  850/ 1017]\n",
      "Accuracy: 84.13%, Avg loss: 0.454791\n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.020419  [    0/ 1017]\n",
      "loss: 0.005555  [  200/ 1017]\n",
      "loss: 0.032891  [  400/ 1017]\n",
      "loss: 0.123550  [  600/ 1017]\n",
      "loss: 0.144014  [  800/ 1017]\n",
      "loss: 0.134299  [  850/ 1017]\n",
      "Accuracy: 88.10%, Avg loss: 0.402494\n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.127960  [    0/ 1017]\n",
      "loss: 0.000557  [  200/ 1017]\n",
      "loss: 0.004989  [  400/ 1017]\n",
      "loss: 0.000349  [  600/ 1017]\n",
      "loss: 0.021454  [  800/ 1017]\n",
      "loss: 0.002585  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.318119\n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 1017]\n",
      "loss: 0.000887  [  200/ 1017]\n",
      "loss: 0.000269  [  400/ 1017]\n",
      "loss: 0.001951  [  600/ 1017]\n",
      "loss: 0.000622  [  800/ 1017]\n",
      "loss: 0.001252  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.282661\n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.000394  [    0/ 1017]\n",
      "loss: 0.007365  [  200/ 1017]\n",
      "loss: 0.001193  [  400/ 1017]\n",
      "loss: 0.000419  [  600/ 1017]\n",
      "loss: 0.000312  [  800/ 1017]\n",
      "loss: 0.000064  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.337150\n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.000897  [    0/ 1017]\n",
      "loss: 0.000163  [  200/ 1017]\n",
      "loss: 0.001344  [  400/ 1017]\n",
      "loss: 0.000336  [  600/ 1017]\n",
      "loss: 0.000537  [  800/ 1017]\n",
      "loss: 0.000370  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.296339\n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.006754  [    0/ 1017]\n",
      "loss: 0.011668  [  200/ 1017]\n",
      "loss: 0.000301  [  400/ 1017]\n",
      "loss: 0.000563  [  600/ 1017]\n",
      "loss: 0.000189  [  800/ 1017]\n",
      "loss: 0.000530  [  850/ 1017]\n",
      "Accuracy: 87.30%, Avg loss: 0.703872\n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.009739  [    0/ 1017]\n",
      "loss: 0.001383  [  200/ 1017]\n",
      "loss: 0.001149  [  400/ 1017]\n",
      "loss: 0.000168  [  600/ 1017]\n",
      "loss: 0.003052  [  800/ 1017]\n",
      "loss: 0.015932  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.261227\n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.000738  [    0/ 1017]\n",
      "loss: 0.000261  [  200/ 1017]\n",
      "loss: 0.000910  [  400/ 1017]\n",
      "loss: 0.000117  [  600/ 1017]\n",
      "loss: 0.000919  [  800/ 1017]\n",
      "loss: 0.000327  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.277958\n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.000417  [    0/ 1017]\n",
      "loss: 0.000804  [  200/ 1017]\n",
      "loss: 0.000100  [  400/ 1017]\n",
      "loss: 0.000498  [  600/ 1017]\n",
      "loss: 0.002053  [  800/ 1017]\n",
      "loss: 0.000582  [  850/ 1017]\n",
      "Accuracy: 90.48%, Avg loss: 0.441060\n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.000166  [    0/ 1017]\n",
      "loss: 0.000716  [  200/ 1017]\n",
      "loss: 0.000108  [  400/ 1017]\n",
      "loss: 0.000092  [  600/ 1017]\n",
      "loss: 0.000135  [  800/ 1017]\n",
      "loss: 0.000231  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.288620\n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.001586  [    0/ 1017]\n",
      "loss: 0.000251  [  200/ 1017]\n",
      "loss: 0.000025  [  400/ 1017]\n",
      "loss: 0.000098  [  600/ 1017]\n",
      "loss: 0.000032  [  800/ 1017]\n",
      "loss: 0.000062  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.476879\n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.000494  [    0/ 1017]\n",
      "loss: 0.000074  [  200/ 1017]\n",
      "loss: 0.000046  [  400/ 1017]\n",
      "loss: 0.000285  [  600/ 1017]\n",
      "loss: 0.000076  [  800/ 1017]\n",
      "loss: 0.000121  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.317836\n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000055  [  200/ 1017]\n",
      "loss: 0.000056  [  400/ 1017]\n",
      "loss: 0.000187  [  600/ 1017]\n",
      "loss: 0.000320  [  800/ 1017]\n",
      "loss: 0.000011  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.328111\n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.000095  [    0/ 1017]\n",
      "loss: 0.000054  [  200/ 1017]\n",
      "loss: 0.000020  [  400/ 1017]\n",
      "loss: 0.000065  [  600/ 1017]\n",
      "loss: 0.000076  [  800/ 1017]\n",
      "loss: 0.000126  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.267523\n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000020  [  200/ 1017]\n",
      "loss: 0.000082  [  400/ 1017]\n",
      "loss: 0.000056  [  600/ 1017]\n",
      "loss: 0.000063  [  800/ 1017]\n",
      "loss: 0.000037  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.291913\n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1017]\n",
      "loss: 0.000140  [  200/ 1017]\n",
      "loss: 0.000182  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000028  [  800/ 1017]\n",
      "loss: 0.000585  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.355938\n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.000702  [    0/ 1017]\n",
      "loss: 0.000100  [  200/ 1017]\n",
      "loss: 0.000118  [  400/ 1017]\n",
      "loss: 0.000129  [  600/ 1017]\n",
      "loss: 0.000051  [  800/ 1017]\n",
      "loss: 0.000022  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.268223\n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.000037  [    0/ 1017]\n",
      "loss: 0.000029  [  200/ 1017]\n",
      "loss: 0.000040  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000017  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.366744\n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.000065  [    0/ 1017]\n",
      "loss: 0.000023  [  200/ 1017]\n",
      "loss: 0.000052  [  400/ 1017]\n",
      "loss: 0.000040  [  600/ 1017]\n",
      "loss: 0.000364  [  800/ 1017]\n",
      "loss: 0.000051  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.286526\n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.000042  [    0/ 1017]\n",
      "loss: 0.000026  [  200/ 1017]\n",
      "loss: 0.000036  [  400/ 1017]\n",
      "loss: 0.000029  [  600/ 1017]\n",
      "loss: 0.000035  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.346317\n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.000731  [    0/ 1017]\n",
      "loss: 0.000280  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000069  [  600/ 1017]\n",
      "loss: 0.000023  [  800/ 1017]\n",
      "loss: 0.000011  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.338994\n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.000055  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000027  [  400/ 1017]\n",
      "loss: 0.000019  [  600/ 1017]\n",
      "loss: 0.000065  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.332185\n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.000030  [    0/ 1017]\n",
      "loss: 0.000039  [  200/ 1017]\n",
      "loss: 0.000011  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000117  [  800/ 1017]\n",
      "loss: 0.000054  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.335128\n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000052  [  400/ 1017]\n",
      "loss: 0.000020  [  600/ 1017]\n",
      "loss: 0.000082  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.302624\n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.000033  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000066  [  600/ 1017]\n",
      "loss: 0.000011  [  800/ 1017]\n",
      "loss: 0.000028  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.309687\n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000050  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000021  [  800/ 1017]\n",
      "loss: 0.000024  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.332573\n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000086  [  400/ 1017]\n",
      "loss: 0.000034  [  600/ 1017]\n",
      "loss: 0.000035  [  800/ 1017]\n",
      "loss: 0.000036  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.424602\n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.000137  [    0/ 1017]\n",
      "loss: 0.108462  [  200/ 1017]\n",
      "loss: 0.001493  [  400/ 1017]\n",
      "loss: 0.001682  [  600/ 1017]\n",
      "loss: 0.100976  [  800/ 1017]\n",
      "loss: 0.009964  [  850/ 1017]\n",
      "Accuracy: 88.89%, Avg loss: 0.594162\n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.003391  [    0/ 1017]\n",
      "loss: 0.007621  [  200/ 1017]\n",
      "loss: 0.077765  [  400/ 1017]\n",
      "loss: 0.003769  [  600/ 1017]\n",
      "loss: 0.051387  [  800/ 1017]\n",
      "loss: 0.000207  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.478129\n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.000400  [    0/ 1017]\n",
      "loss: 0.022989  [  200/ 1017]\n",
      "loss: 0.000237  [  400/ 1017]\n",
      "loss: 0.000329  [  600/ 1017]\n",
      "loss: 0.001222  [  800/ 1017]\n",
      "loss: 0.006009  [  850/ 1017]\n",
      "Accuracy: 89.68%, Avg loss: 0.492514\n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.000868  [    0/ 1017]\n",
      "loss: 0.001282  [  200/ 1017]\n",
      "loss: 0.000090  [  400/ 1017]\n",
      "loss: 0.000423  [  600/ 1017]\n",
      "loss: 0.000189  [  800/ 1017]\n",
      "loss: 0.000325  [  850/ 1017]\n",
      "Accuracy: 88.10%, Avg loss: 0.585877\n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.042372  [    0/ 1017]\n",
      "loss: 0.005527  [  200/ 1017]\n",
      "loss: 0.000313  [  400/ 1017]\n",
      "loss: 0.003379  [  600/ 1017]\n",
      "loss: 0.000271  [  800/ 1017]\n",
      "loss: 0.001175  [  850/ 1017]\n",
      "Accuracy: 89.68%, Avg loss: 0.468537\n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.001585  [    0/ 1017]\n",
      "loss: 0.000105  [  200/ 1017]\n",
      "loss: 0.000301  [  400/ 1017]\n",
      "loss: 0.000131  [  600/ 1017]\n",
      "loss: 0.001024  [  800/ 1017]\n",
      "loss: 0.002981  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.427058\n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.000206  [    0/ 1017]\n",
      "loss: 0.000570  [  200/ 1017]\n",
      "loss: 0.000292  [  400/ 1017]\n",
      "loss: 0.000163  [  600/ 1017]\n",
      "loss: 0.000141  [  800/ 1017]\n",
      "loss: 0.000037  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.576127\n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.000091  [    0/ 1017]\n",
      "loss: 0.000195  [  200/ 1017]\n",
      "loss: 0.000998  [  400/ 1017]\n",
      "loss: 0.000258  [  600/ 1017]\n",
      "loss: 0.000067  [  800/ 1017]\n",
      "loss: 0.000096  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.506040\n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000071  [  200/ 1017]\n",
      "loss: 0.000288  [  400/ 1017]\n",
      "loss: 0.000105  [  600/ 1017]\n",
      "loss: 0.000130  [  800/ 1017]\n",
      "loss: 0.000112  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.405568\n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.000150  [    0/ 1017]\n",
      "loss: 0.000294  [  200/ 1017]\n",
      "loss: 0.000066  [  400/ 1017]\n",
      "loss: 0.000095  [  600/ 1017]\n",
      "loss: 0.000280  [  800/ 1017]\n",
      "loss: 0.000177  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.476215\n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.000155  [    0/ 1017]\n",
      "loss: 0.000163  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000045  [  600/ 1017]\n",
      "loss: 0.000016  [  800/ 1017]\n",
      "loss: 0.000017  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.387113\n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/ 1017]\n",
      "loss: 0.000464  [  200/ 1017]\n",
      "loss: 0.000060  [  400/ 1017]\n",
      "loss: 0.000158  [  600/ 1017]\n",
      "loss: 0.000126  [  800/ 1017]\n",
      "loss: 0.000218  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.373208\n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.000060  [    0/ 1017]\n",
      "loss: 0.000169  [  200/ 1017]\n",
      "loss: 0.000226  [  400/ 1017]\n",
      "loss: 0.000063  [  600/ 1017]\n",
      "loss: 0.000406  [  800/ 1017]\n",
      "loss: 0.000115  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.406386\n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.000170  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000187  [  400/ 1017]\n",
      "loss: 0.000112  [  600/ 1017]\n",
      "loss: 0.000302  [  800/ 1017]\n",
      "loss: 0.000031  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.439830\n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/ 1017]\n",
      "loss: 0.000044  [  200/ 1017]\n",
      "loss: 0.000175  [  400/ 1017]\n",
      "loss: 0.000112  [  600/ 1017]\n",
      "loss: 0.000614  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.393210\n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.000061  [    0/ 1017]\n",
      "loss: 0.000132  [  200/ 1017]\n",
      "loss: 0.000317  [  400/ 1017]\n",
      "loss: 0.000027  [  600/ 1017]\n",
      "loss: 0.000033  [  800/ 1017]\n",
      "loss: 0.000039  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.416410\n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000058  [  200/ 1017]\n",
      "loss: 0.000023  [  400/ 1017]\n",
      "loss: 0.000038  [  600/ 1017]\n",
      "loss: 0.000055  [  800/ 1017]\n",
      "loss: 0.000072  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.369287\n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.000063  [    0/ 1017]\n",
      "loss: 0.000034  [  200/ 1017]\n",
      "loss: 0.000081  [  400/ 1017]\n",
      "loss: 0.000069  [  600/ 1017]\n",
      "loss: 0.000054  [  800/ 1017]\n",
      "loss: 0.000038  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.396424\n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.000096  [    0/ 1017]\n",
      "loss: 0.000154  [  200/ 1017]\n",
      "loss: 0.000197  [  400/ 1017]\n",
      "loss: 0.000011  [  600/ 1017]\n",
      "loss: 0.000290  [  800/ 1017]\n",
      "loss: 0.000605  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.416542\n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.000043  [    0/ 1017]\n",
      "loss: 0.000253  [  200/ 1017]\n",
      "loss: 0.000030  [  400/ 1017]\n",
      "loss: 0.000031  [  600/ 1017]\n",
      "loss: 0.000164  [  800/ 1017]\n",
      "loss: 0.000048  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.418424\n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.000077  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000058  [  400/ 1017]\n",
      "loss: 0.000019  [  600/ 1017]\n",
      "loss: 0.000396  [  800/ 1017]\n",
      "loss: 0.000442  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.431194\n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.000047  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000011  [  400/ 1017]\n",
      "loss: 0.000190  [  600/ 1017]\n",
      "loss: 0.000038  [  800/ 1017]\n",
      "loss: 0.000024  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.411073\n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.000023  [    0/ 1017]\n",
      "loss: 0.000079  [  200/ 1017]\n",
      "loss: 0.000052  [  400/ 1017]\n",
      "loss: 0.000055  [  600/ 1017]\n",
      "loss: 0.000042  [  800/ 1017]\n",
      "loss: 0.004459  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.599205\n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000021  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000019  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.474959\n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/ 1017]\n",
      "loss: 0.000038  [  200/ 1017]\n",
      "loss: 0.000032  [  400/ 1017]\n",
      "loss: 0.000127  [  600/ 1017]\n",
      "loss: 0.000075  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.422477\n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.000091  [    0/ 1017]\n",
      "loss: 0.000030  [  200/ 1017]\n",
      "loss: 0.000060  [  400/ 1017]\n",
      "loss: 0.000048  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000033  [  850/ 1017]\n",
      "Accuracy: 91.27%, Avg loss: 0.484344\n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/ 1017]\n",
      "loss: 0.000015  [  200/ 1017]\n",
      "loss: 0.000031  [  400/ 1017]\n",
      "loss: 0.000012  [  600/ 1017]\n",
      "loss: 0.000105  [  800/ 1017]\n",
      "loss: 0.000372  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.414837\n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.000045  [    0/ 1017]\n",
      "loss: 0.000060  [  200/ 1017]\n",
      "loss: 0.000051  [  400/ 1017]\n",
      "loss: 0.000019  [  600/ 1017]\n",
      "loss: 0.000022  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.366874\n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.000608  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000063  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000052  [  800/ 1017]\n",
      "loss: 0.000022  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.391605\n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000061  [  200/ 1017]\n",
      "loss: 0.000020  [  400/ 1017]\n",
      "loss: 0.000068  [  600/ 1017]\n",
      "loss: 0.000018  [  800/ 1017]\n",
      "loss: 0.000023  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.398460\n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.000143  [    0/ 1017]\n",
      "loss: 0.000025  [  200/ 1017]\n",
      "loss: 0.000038  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000056  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.371033\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/ 1017]\n",
      "loss: 0.000036  [  200/ 1017]\n",
      "loss: 0.000014  [  400/ 1017]\n",
      "loss: 0.000079  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 92.06%, Avg loss: 0.476434\n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000087  [  200/ 1017]\n",
      "loss: 0.000039  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000016  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.444292\n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000007  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000013  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.403879\n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.000039  [    0/ 1017]\n",
      "loss: 0.000050  [  200/ 1017]\n",
      "loss: 0.000029  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000014  [  800/ 1017]\n",
      "loss: 0.000023  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.416626\n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.000023  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000041  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000019  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.675313\n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.003543  [  200/ 1017]\n",
      "loss: 0.000034  [  400/ 1017]\n",
      "loss: 0.000024  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000033  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.372835\n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.000307  [    0/ 1017]\n",
      "loss: 0.000017  [  200/ 1017]\n",
      "loss: 0.000023  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000072  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.362975\n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.000238  [    0/ 1017]\n",
      "loss: 0.000050  [  200/ 1017]\n",
      "loss: 0.000022  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000014  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.389356\n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.000026  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000030  [  400/ 1017]\n",
      "loss: 0.000113  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000005  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.389803\n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000015  [  400/ 1017]\n",
      "loss: 0.000023  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000032  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.331777\n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/ 1017]\n",
      "loss: 0.000012  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.391285\n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.000051  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000008  [  600/ 1017]\n",
      "loss: 0.000048  [  800/ 1017]\n",
      "loss: 0.000030  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.383559\n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000029  [  400/ 1017]\n",
      "loss: 0.000025  [  600/ 1017]\n",
      "loss: 0.000010  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.427665\n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000012  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000202  [  800/ 1017]\n",
      "loss: 0.000013  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.600501\n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000009  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000040  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.378549\n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000005  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.535287\n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/ 1017]\n",
      "loss: 0.000048  [  200/ 1017]\n",
      "loss: 0.000015  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000015  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.494466\n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000010  [  200/ 1017]\n",
      "loss: 0.000008  [  400/ 1017]\n",
      "loss: 0.000036  [  600/ 1017]\n",
      "loss: 0.000043  [  800/ 1017]\n",
      "loss: 0.000027  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.404448\n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/ 1017]\n",
      "loss: 0.000192  [  200/ 1017]\n",
      "loss: 0.000018  [  400/ 1017]\n",
      "loss: 0.000010  [  600/ 1017]\n",
      "loss: 0.000063  [  800/ 1017]\n",
      "loss: 0.000001  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.356331\n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/ 1017]\n",
      "loss: 0.000018  [  200/ 1017]\n",
      "loss: 0.000019  [  400/ 1017]\n",
      "loss: 0.000022  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000000  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 1.055495\n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.000050  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000059  [  400/ 1017]\n",
      "loss: 0.000032  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.392786\n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000118  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000006  [  850/ 1017]\n",
      "Accuracy: 92.86%, Avg loss: 0.418997\n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000009  [  600/ 1017]\n",
      "loss: 0.000036  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.419658\n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.000182  [    0/ 1017]\n",
      "loss: 0.000053  [  200/ 1017]\n",
      "loss: 0.000004  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000009  [  800/ 1017]\n",
      "loss: 0.000010  [  850/ 1017]\n",
      "Accuracy: 97.62%, Avg loss: 0.338577\n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/ 1017]\n",
      "loss: 0.000082  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000020  [  800/ 1017]\n",
      "loss: 0.000083  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.384939\n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000002  [  200/ 1017]\n",
      "loss: 0.000011  [  400/ 1017]\n",
      "loss: 0.000001  [  600/ 1017]\n",
      "loss: 0.000049  [  800/ 1017]\n",
      "loss: 0.000021  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.403207\n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.000132  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000032  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.787219\n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000001  [  200/ 1017]\n",
      "loss: 0.000081  [  400/ 1017]\n",
      "loss: 0.000006  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000007  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.368288\n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000259  [  200/ 1017]\n",
      "loss: 0.000006  [  400/ 1017]\n",
      "loss: 0.000002  [  600/ 1017]\n",
      "loss: 0.000002  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 94.44%, Avg loss: 0.388464\n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000106  [  400/ 1017]\n",
      "loss: 0.000017  [  600/ 1017]\n",
      "loss: 0.000023  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.429048\n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/ 1017]\n",
      "loss: 0.000006  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000006  [  800/ 1017]\n",
      "loss: 0.000008  [  850/ 1017]\n",
      "Accuracy: 96.03%, Avg loss: 0.427370\n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000069  [  400/ 1017]\n",
      "loss: 0.000004  [  600/ 1017]\n",
      "loss: 0.000013  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.373338\n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000010  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000007  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.423142\n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000005  [  200/ 1017]\n",
      "loss: 0.000039  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000023  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.441564\n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/ 1017]\n",
      "loss: 0.000009  [  200/ 1017]\n",
      "loss: 0.000002  [  400/ 1017]\n",
      "loss: 0.000015  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000003  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.445304\n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000004  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000004  [  850/ 1017]\n",
      "Accuracy: 93.65%, Avg loss: 0.618254\n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000024  [  200/ 1017]\n",
      "loss: 0.000001  [  400/ 1017]\n",
      "loss: 0.000007  [  600/ 1017]\n",
      "loss: 0.000001  [  800/ 1017]\n",
      "loss: 0.000026  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.416418\n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000003  [  400/ 1017]\n",
      "loss: 0.000030  [  600/ 1017]\n",
      "loss: 0.000004  [  800/ 1017]\n",
      "loss: 0.000009  [  850/ 1017]\n",
      "Accuracy: 95.24%, Avg loss: 0.409149\n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/ 1017]\n",
      "loss: 0.000003  [  200/ 1017]\n",
      "loss: 0.000047  [  400/ 1017]\n",
      "loss: 0.000003  [  600/ 1017]\n",
      "loss: 0.000003  [  800/ 1017]\n",
      "loss: 0.000002  [  850/ 1017]\n",
      "Accuracy: 96.83%, Avg loss: 0.926184\n",
      "\n",
      "Done! Validation accuracy: 98.41%\n",
      "Training took 659.34 seconds\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "from torchinfo import summary\n",
    "EPOCHS = 500 #initially 500\n",
    "SEQ_LENGTH = 40\n",
    "#LEARNING_RATE = 0.00001##also good with 100 epochs .0002#initially 0.00002\n",
    "LEARNING_RATE = 0.0003#0.00003\n",
    "print('AFTER dataloading')\n",
    "print(dataloader_train)\n",
    "print(dataloader_val)\n",
    "print(dataloader_test)\n",
    "#X_ptbdb_train, X_ptbdb_val, y_ptbdb_train, y_ptbdb_val = train_test_split(ptbdb.iloc[:,:-1].values, ptbdb.iloc[:,-1].values, test_size=0.2, random_state=42)\n",
    "#X_ptbdb_val, X_ptbdb_test, y_ptbdb_val, y_ptbdb_test  = train_test_split(X_ptbdb_val, y_ptbdb_val, test_size=0.5, random_state=42)\n",
    "print('AFTER DIVISION')\n",
    "#print(X_ptbdb_train.shape)\n",
    "\n",
    "#print(X_ptbdb_val.shape)\n",
    "print(len(dataloader_val))\n",
    "print(len(dataloader_test))\n",
    "\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Main TransformerModel used\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dmodel : itensor\n",
    "        input tensor\n",
    "    seq_len : int\n",
    "        length of sequence (time dim)\n",
    "    nhead : int\n",
    "        number of heads in nn.MultiheadAttention\n",
    "    d_hid : int\n",
    "        dimension of the feedforward network model in nn.TransformerEncoder\n",
    "    nlayers : int\n",
    "        number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dmodel, seq_len, nhead, d_hid, nlayers):\n",
    "        super().__init__()\n",
    "        self.dmodel = dmodel\n",
    "        self.seq_len = seq_len\n",
    "        #self.cnn = CNN(seq_length = seq_len, feature_length = NUM_CLASSES)\n",
    "        self.pos_encoder = PositionalEncoding(dmodel, seq_len)\n",
    "        encoder_layers = TransformerEncoderLayer(dmodel, nhead, d_hid)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        # TODO: Must not hardcode dropout\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(in_features=seq_len * dmodel, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.cnn(x)\n",
    "        # 3d: batch, embedding_dim, seq_len\n",
    "        #print('SHAPE OF X')\n",
    "        x = x.permute(2, 0, 1)\n",
    "        #x=x.permute()        \n",
    "        # 3d: seq_len, batch_size, embedding_dim\n",
    "        #x = self.pos_encoder(x)\n",
    "        x = x + self.transformer_encoder(x)\n",
    "        #x = self.dropout(x)\n",
    "        # 3d: seq_len, batch_size, features\n",
    "        #x = x.permute(1, 0, 2)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        # print(x.shape)\n",
    "        # 3d: batch_size, seq_len,features\n",
    "        x = x.reshape(-1, self.seq_len * self.dmodel)\n",
    "        #x = x.reshape(self.seq_len * self.dmodel)\n",
    "        # 2d: batch_size, seq_len*features\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# from pytorch website https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        # pos = torch.arange(seq_len).unsqueeze(1)\n",
    "        # every_second_dim = torch.arange(start=0, end=d_model, step=2)\n",
    "        # TODO must not hardcode\n",
    "        # frequency =10000.0\n",
    "        frequency = 100.0\n",
    "        # div_term = frequency ** (every_second_dim / d_model)\n",
    "        # pe = torch.zeros(seq_len, 1, d_model)\n",
    "\n",
    "        # pe[:, 0, 0::2] = torch.sin(pos / div_term)\n",
    "        # pe[:, 0, 1::2] = torch.cos(pos / div_term)\n",
    "        # self.register_buffer('pe', pe)\n",
    "\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(frequency) / d_model))\n",
    "        pe = torch.zeros(seq_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        # print(self.d_model)\n",
    "        # x = x * np.sqrt(self.d_model)\n",
    "        # x = x * self.d_model\n",
    "\n",
    "        # print(x.shape)\n",
    "        # print(torch.mean(x))\n",
    "        # x = x + torch.mean(x)*self.pe[:x.size(0)]\n",
    "        x = x.to(device=torch.device(\"cuda:0\"))\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        # x = x + 5*self.pe[:x.size(0)]\n",
    "        # return self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    log_step = 10\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % log_step == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= num_batches\n",
    "    train_losses.append(train_loss.item())\n",
    "    # For loss graph on tensorboard\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.float())\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    validation_loss /= num_batches\n",
    "    val_losses.append(validation_loss)\n",
    "    correct /= size\n",
    "    # For loss graph on tensorboard\n",
    "    writer.add_scalar('Loss/Validation', validation_loss, epoch)\n",
    "    print(f\"Accuracy: {(100*correct):>0.2f}%, Avg loss: {validation_loss:>8f}\")\n",
    "    return (correct, validation_loss)\n",
    "\n",
    "#dmodel = 408#36#13\n",
    "#dmodel = 208#36#13\n",
    "dmodel = 108#40#13\n",
    "    #data.shape[1] # NUM_FEATURES\n",
    "print('DATA SHAPE',data.shape[1])\n",
    "d_hid = 150  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "#nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nlayers = 8#10  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "#nhead = 3  # number of heads in nn.MultiheadAttention\n",
    "nhead = 4  # number of heads in nn.MultiheadAttention\n",
    "model = TransformerModel(dmodel, SEQ_LENGTH, nhead, d_hid, nlayers).to(device)\n",
    "#model = CNN(seq_length = SEQ_LENGTH, feature_length = NUM_CLASSES).to(device)\n",
    "# Add some tensorflow information\n",
    "print('BEFO>rE')\n",
    "#writer.add_graph(model, data.float()[0:1,])\n",
    "\n",
    "# save graph to tensorflow\n",
    "#writer.add_graph(model, data.float()[0:1,])\n",
    "\n",
    "#print model summary for debugging\n",
    "print(summary(model))\n",
    "# empty loss arrays for clean performance figures\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "#model = LSTM(data.shape[2], data.shape[1]).to(device)\n",
    "#model = CNN(data.shape[2], data.shape[1]).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_of_best_accuracy = float('inf')\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "\n",
    "start_time = datetime.now()\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(dataloader_train, model, loss_fn, optimizer, t+1)\n",
    "\n",
    "    accuracy, loss = validation_loop(dataloader_val, model, loss_fn, t+1)\n",
    "    # TODO: make \"best model\" strategy configurable\n",
    "    #if loss < loss_of_best_accuracy:\n",
    "    if accuracy > best_accuracy or (accuracy == best_accuracy and loss < loss_of_best_accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        loss_of_best_accuracy = loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_epoch = t+1\n",
    "        print('Model saved')\n",
    "end_time = datetime.now()\n",
    "print(f\"\\nDone! Validation accuracy: {(100*best_accuracy):>0.2f}%\")\n",
    "print(f\"Training took {(end_time-start_time).total_seconds():>0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "254cbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    # initialise empty tensors for predictions and targets\n",
    "    all_preds = torch.tensor([], device=device, dtype=int)\n",
    "    all_targets = torch.tensor([], device=device, dtype=int)\n",
    "    model.eval()\n",
    "    for batch in loader:\n",
    "        data, labels = batch\n",
    "        preds = model(data.float()).argmax(1)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "        all_targets = torch.cat((all_targets, labels.int()), dim=0)\n",
    "    model.train()    \n",
    "    return all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f8e5c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  predictions, targets = predict(best_model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1713aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9448818897637795"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions.cpu(), targets.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b4522882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.49%\n",
      "\n",
      "Done! Validation accuracy: 99.21%\n",
      "Training took 757.83 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa8405d6a10>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(targets.cpu(), predictions.cpu())\n",
    "test_correct = 0\n",
    "for i in range(3):\n",
    "  test_correct += cm[i][i]\n",
    "test_accuracy = test_correct/len(predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:>0.2f}%\")\n",
    "print(f\"\\nDone! Validation accuracy: {(100*best_accuracy):>0.2f}%\")\n",
    "print(f\"Training took {(end_time-start_time).total_seconds():>0.2f} seconds\")\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=encoder.classes_)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9d3d8eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot simple loss graph, see also tensorboard\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(val_losses,label=\"val\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c548cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
